{"meta":{"title":"SylensHub","subtitle":"","description":"Sylens Wong 的小博客","author":"Sylens Wong","url":"https://silenwang.github.io","root":"/"},"pages":[{"title":"","date":"2026-02-10T14:03:13.682Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"about/index.html","permalink":"https://silenwang.github.io/about/index.html","excerpt":"","text":"关于我关于我页面重整啦! 现在用了Tab将内容折叠起来… 免得太常浪费版面~ 个人简介 自称: Silen Wang &#x2F; Sylens Wong &#x2F; 汪兴伦, 是一颗逐渐开心起来的卤蛋 (guāng tóu) ! 兴趣: 打游戏, 打游戏, 还是TMD 打! 游! 戏! 动漫也看, 但是最近感兴趣番的越来越少了…, 2024年重新开始追番！迷宫饭真是太好看了！都给我去看！ 学习&#x2F;工作路线: 公卫 -&gt; 分子流病 -&gt; 生信 -&gt; 新生抗原 -&gt; 类器官 -&gt; 各种各样 emmmm… 越来越博学 (zá luàn) 了 词云更新啦！但是并没有我想象的变化那么大… GitHub: 教育经历 2009.09-2014.06 学校: 广东药学院(现广东药科大学)学院: 公共卫生学院专业: 预防医学(本科)学位: 学士 2014.09-2017.06 学校: 南方医科大学学院: 公共卫生学院专业: 流行病与卫生统计学学位: 硕士 工作履历2017.07-2018.082018.08-2019.072019.07-2024.042024.05-至今 就职情况: 天津某生信服务公司 生物信息分析工程师 工作内容: 人基因组二代测序数据（WES &#x2F; WGS）质控及分析 基于频率、基因区域、有害性软件预测、家系遗传模式进行变异结果筛选 依据全基因组关联分析（GWAS）结果定位可能有害的变异 根据客户要求进行筛选方案定制并展示结果 特定疾病研究现状调研 对特定疾病的基本知识及研究现状进行调研学习，为开发相关分析模块作前置准备 数据交付流程维护与升级 就职情况: 杭州某基因科技公司 生信技术部 生物信息工程师 工作内容: 数据处理 cfDNA&#x2F;FFPE&#x2F;白细胞样品测序数据处理 二代测序分析流程构建 &#x2F; 测试 二代测序分析用工具开发(Python &#x2F; R &#x2F; Julia &#x2F; Shell)细胞样品测序数据拆分及质量控制 原始测序数据(fastq)比对, 及质量控制 UMI数据 &#x2F; Molecular Barcode数据处理 分析流程相关 对现有生物信息分析流程Debug 编写新的分析模块并整合进流程框架 分析模块的测试及Debug 分析用软件部署及依赖处理 分析用软件性能测试及分析结果比较 流程文档的编写与维护 单细胞测序分析流程的搭建及测试 算法及工具开发: UMI去重算法比较及复现 质控图形绘制工具开发 基于机器学习的变异结果筛选工具的开发 已有分析工具的效能优化(并行化) 2019.07-2020.03 杭州某生物科技公司 生物信息工程师 基于NGS的cfDNA分析方案调研, 分析流程搭建 新生抗原相关数据统计分析 生物信息分析程序维护 用药指导报告数据库维护 2020.03-2024.04 杭州某生物科技公司 生信主管 基于NGS的HLA分型&#x2F;定量模块开发 基于flask的生信分析工具后端开发 新生抗原筛选模块开发 生信分析主流程维护与升级 按要求进行材料撰写与修订 2024.05-至今 杭州某医学科技公司 高级生物信息分析工程师 开发WES&#x2F;RNA-Seq&#x2F;单细胞分析流程 根据客户要求解读、制订并执行生物信息分析方案 生物信息数据库构建、运维 生物信息服务器运维 网站、系统云服务器运维 网站、内部实验管理系统开发、运维、迁移、自动化测试 微信小程序运维 工作相关技能常用语言与工具编程语言 数据科学&#x2F;数据库 Web IDE &#x2F; Dev DevOps"},{"title":"所有分类","date":"2026-02-10T14:03:13.682Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"categories/index.html","permalink":"https://silenwang.github.io/categories/index.html","excerpt":"","text":""},{"title":"我的基友们","date":"2026-02-10T14:03:13.682Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"friends/index.html","permalink":"https://silenwang.github.io/friends/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2026-02-10T14:03:13.682Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"tags/index.html","permalink":"https://silenwang.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"终于用 pixi 搞定了用于自动构建的 recipe 和 action：踩坑与解决方案","slug":"终于用pixi搞定了用于自动构建的recipe和action","date":"2026-02-02T20:51:28.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2026/02/02/终于用pixi搞定了用于自动构建的recipe和action/","permalink":"https://silenwang.github.io/2026/02/02/%E7%BB%88%E4%BA%8E%E7%94%A8pixi%E6%90%9E%E5%AE%9A%E4%BA%86%E7%94%A8%E4%BA%8E%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E7%9A%84recipe%E5%92%8Caction/","excerpt":"新工具总是这样：好用的地方让人惊艳，但尚未完善的部分却让人头疼。最近我尝试使用 pixi 和 rattler‑build 搭建一个自动化构建系统，用于定期打包并上传 opencode 到 prefix.dev。整个过程耗时约 6 小时，期间遇到了不少预料之外的问题。","text":"新工具总是这样：好用的地方让人惊艳，但尚未完善的部分却让人头疼。最近我尝试使用 pixi 和 rattler‑build 搭建一个自动化构建系统，用于定期打包并上传 opencode 到 prefix.dev。整个过程耗时约 6 小时，期间遇到了不少预料之外的问题。 背景之前我已经成功为 opencode 创建了 recipe 并手动上传到了 prefix.dev。但 opencode 的更新频率相当高，我不可能每次都手动跟进。于是我想构建一个类似 bioconda 的自动化系统：存放 recipe，并通过 GitHub Action 自动检测新版本、构建并上传 conda 包。 感觉这工作应该不难？毕竟 recipe 已经有了，写个 Action 应该易如反掌，更何况还有 AI 辅助。然而这其中碰到的坑比我想的多的多的多… 主要挑战与解决方案1. recipe 的 context 中不能使用 if‑then 判断在 rattler‑build 的 recipe 中，context 部分用于定义变量，但这里不能像build里那样使用条件判断。AI 也是说 context 的部分只能静态的定义变量。然而这个说法… 对也不对。对的是，在 yaml 的语法内，确实是只能定义变量的，但是… rattler-build 其实是会先用 jinjia（是的又是jijia）来渲染出一个配置文件的，因此支持的 minijinjia 函数是可以实现判断的： 12context: architect: $&#123;&#123; &quot;linux‑x64&quot; if platform == &quot;linux‑64&quot; else &quot;linux‑arm64&quot; &#125;&#125; 2. bump‑recipe 与 build 部分的兼容性问题rattler‑build 的 bump‑recipe 功能可以自动更新 recipe 中的版本和 sha256，这非常方便，我可以不用在后续的 workflow 中用额外的 step 去进行一些操作了。但是，这个功能要求 recipe 的 build 部分不能包含条件判断。我之前的手动 recipe 在 build 部分使用了 if‑then，导致无法使用 bump‑recipe 功能。 于是我在更新后的 recipe 中全部使用 minijinjia 的函数， 不再使用 yaml 支持的特殊语法了。 3. AI 关于环境变量引用的错误描述当我询问 AI 如何在 recipe 中引用环境变量时，得到的回答是使用 $&#123;&#123; VAR_NAME &#125;&#125;。这也是不正确的， 同样得通过 minijinja 模板引擎实现，语法如下： 12context: platform: &#123;&#123; env.get(&quot;TARGET_PLATFORM&quot;, default=&quot;linux‑64&quot;) &#125;&#125; 4. pixi build 只能指定 platform，版本控制需另寻他法我需要在一台机器上交叉处理其他平台的可执行文件，同时也需要指定处理的软件版本，再同时，我还希望使用 pixi build 来构建， 而不是 rattler-build build，这又踩了个坑， pixi build 目前是实验性质功能，因此它尚不能对 rattler-build 传递太多参数，目前只能通过环境变量来让 pixi 和 rattler-build build 获得一致的参数： 1TARGET_PLATFORM=linux‑64 VERSION=1.1.35 pixi build 然后在 recipe 中通过 &#123;&#123; env.get(\"VERSION\") &#125;&#125; 来获取。 5. pixi 内置脚本的变量传递限制由于要使用 rattler-build bump-recipe，为了让 action 和手动构建时输入的内容一致，也为了简单，我设置了 tasks，于是又是一坑，pixi 可以给 task 依赖传参数，但是不能指定环境变量（我前面要用环境变量来设置构建参数），当然这个问题还好，都是 shell，传不了我当参数传过去， 然后手动设置环境变量就是： 12345678910[tasks.bump]cmd = &quot;TARGET_PLATFORM=&#123;&#123; platform &#125;&#125; rattler-build bump-recipe&quot;args = [ &#123; arg = &quot;platform&quot;, default = &quot;linux-64&quot; &#125;,][tasks.build]cmd = &quot;TARGET_PLATFORM=&#123;&#123; platform &#125;&#125; pixi build -t &#123;&#123; platform &#125;&#125;&quot;args = [&quot;platform&quot;]depends-on = [&#123; task = &quot;bump&quot;, args = [&quot;&#123;&#123; platform &#125;&#125;&quot;] &#125;] 这里有要注意的一点是，build任务中必须环境变量和参数都指定平台信息，pixi build 似乎并不读TARGET_PLATFORM这个环境变量，因此要-t来指定平台，如果不指定，实际上会使用当前平台作为默认值，导致跨平台构建失败。 6. prefix.dev 缺少查询 API，需用 pixi search 解析目前 prefix.dev 似乎没有提供专门的 API 来指定 conda 包查询对应版本信息。这个好解决，解析 pixi search 命令的输出就成，shell 作为万能胶水还是必不可少啊… 1version=$(pixi search -q --no‑progress -p linux‑64 -c https://prefix.dev/sylens opencode | grep -oP &#x27;\\K[0‑9]+\\.[0‑9]+\\.[0‑9]+&#x27; | head -1) 7. bump‑recipe 的重复下载问题rattler‑build bump‑recipe 在更新 sha256 时会下载一次源码包，而随后的 pixi build 又会再次下载相同的包。这种重复下载在网速较慢或包较大时会显著增加构建时间。不过，这个目前确实无解，还好不影响功能实现。 完整实现经过多次调整，最终的 pixi 项目配置如下： 12345678910111213141516171819202122232425[workspace]authors = [&quot;Sylens Wong &lt;qiumin14@163.com&gt;&quot;]channels = [&quot;conda‑forge&quot;]name = &quot;opencode‑recipe&quot;platforms = [&quot;linux‑aarch64&quot;, &quot;linux‑64&quot;]version = &quot;0.1.0&quot;preview = [&quot;pixi‑build&quot;][dependencies]rattler‑build = &quot;*&quot;[tasks.bump]cmd = &quot;TARGET_PLATFORM=&#123;&#123; platform &#125;&#125; &amp;&amp; rattler‑build bump‑recipe&quot;args = [ &#123; arg = &quot;platform&quot;, default = &quot;linux‑64&quot; &#125;,][tasks.build]cmd = &quot;TARGET_PLATFORM=&#123;&#123; platform &#125;&#125; &amp;&amp; pixi build -t &#123;&#123; platform &#125;&#125;&quot;args = [&quot;platform&quot;]depends‑on = [&#123; task = &quot;bump&quot;, args = [&quot;&#123;&#123; platform &#125;&#125;&quot;] &#125;][package.build.backend]name = &quot;pixi‑build‑rattler‑build&quot;version = &quot;0.3.*&quot; recipe 文件的关键部分： 12345678910111213141516171819202122context: name: opencode version: &#123;&#123; env.get(&quot;VERSION&quot;, default=&quot;1.1.35&quot;) &#125;&#125; platform: &#123;&#123; env.get(&quot;TARGET_PLATFORM&quot;, default=&quot;linux‑64&quot;) &#125;&#125;package: name: &#123;&#123; name &#125;&#125; version: &#123;&#123; version &#125;&#125;source: url: https://github.com/anomalyco/opencode/releases/download/v&#123;&#123; version &#125;&#125;/opencode‑&#123;&#123; &quot;linux‑x64&quot; if platform == &quot;linux‑64&quot; else &quot;linux‑arm64&quot; &#125;&#125;.tar.gz sha256: &#123;&#123; sha256 &#125;&#125; file_name: opencode.tar.gzbuild: number: 0 string: h&#123;&#123; hash &#125;&#125;_&#123;&#123; platform &#125;&#125; script: | tar xvf opencode.tar.gz mkdir -p $PREFIX/bin mv opencode $PREFIX/bin/opencode chmod 755 $PREFIX/bin/opencode GitHub Action 的核心步骤： 123456789101112131415161718- name: Run Pixi Task run: | cd opencode # 获取当前已上传版本 current_version=$(pixi search -q --no‑progress -p $&#123;&#123; matrix.platform &#125;&#125; -c https://prefix.dev/sylens opencode | grep -oP &#x27;\\K[0‑9]+\\.[0‑9]+\\.[0‑9]+&#x27; | head -1) # 获取上游最新版本 upstream_version=&quot;$&#123;&#123; steps.origin_release.outputs.release &#125;&#125;&quot; if [ &quot;$upstream_version&quot; != &quot;v$current_version&quot; ]; then echo &quot;检测到新版本: $upstream_version (当前: $current_version)&quot; export VERSION=$&#123;upstream_version#v&#125; pixi run build $&#123;&#123; matrix.platform &#125;&#125; pixi upload prefix opencode*.conda -c sylens else echo &quot;已是最新版本&quot; fi","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"},{"name":"github action","slug":"github-action","permalink":"https://silenwang.github.io/tags/github-action/"},{"name":"recipe","slug":"recipe","permalink":"https://silenwang.github.io/tags/recipe/"},{"name":"rattler","slug":"rattler","permalink":"https://silenwang.github.io/tags/rattler/"}]},{"title":"想打包个opencode结果又遇坑了","slug":"想打包个opencode结果又遇坑了","date":"2026-01-31T15:54:18.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2026/01/31/想打包个opencode结果又遇坑了/","permalink":"https://silenwang.github.io/2026/01/31/%E6%83%B3%E6%89%93%E5%8C%85%E4%B8%AAopencode%E7%BB%93%E6%9E%9C%E5%8F%88%E9%81%87%E5%9D%91%E4%BA%86/","excerpt":"上次成功打包了我自己的程序，这想来试个别的，最近 opencode 贼火，我也有在用，刚好 conda 上到目前位置也没有，因此想打包一个。","text":"上次成功打包了我自己的程序，这想来试个别的，最近 opencode 贼火，我也有在用，刚好 conda 上到目前位置也没有，因此想打包一个。 打包顺利，但是…opencode 使用 typescript 编写，同时使用比较新的 bun.js 来进行管理，bun.js 目前在 conda 还没有。另外opencode本身已经为了能在各种环境运行，准备了各种安装包，因此本次编译准备根据 rattler-build 的文档，采用 repackaging 的策略来进行，即不进行编译，而是对编译好的包进行解包然后二次打包，类似之前 AUR 中的各种 deb 转 arch 包的情况。 由于 typescipt 是单文件的程序， 其打包也尤其简单，解压缩出可执行文件放到特定目录就行了。 123456789101112131415161718192021222324252627282930313233343536373839package: name: opencode version: 1.1.35source: - if: target_platform == &quot;linux-64&quot; then: url: https://github.com/anomalyco/opencode/releases/download/v1.1.35/opencode-linux-x64.tar.gz sha256: 451f5a36e2875b5540adf55e8cc9e144902b44959a6f31899fc21876b38b31ae file_name: opencode.tar.gz - if: target_platform == &quot;linux-aarch64&quot; then: url: https://github.com/anomalyco/opencode/releases/download/v1.1.35/opencode-linux-arm64.tar.gz sha256: e7544ae14afb10e75d28a3623b1fd33d60e17f372106665566ca4e085c2b157b file_name: opencode.tar.gzbuild: number: 0 script: | tar xvf opencode.tar.gz mkdir -p $PREFIX/bin mv opencode $PREFIX/bin/opencode chmod 755 $PREFIX/bin/opencode requirements: build: - tartests: - script: - opencode -habout: homepage: https://opencode.ai/ license: MIT summary: &#x27;The open source coding agent.&#x27; description: | The open source coding agent. repository: https://github.com/anomalyco/opencode 但是问题来了，虽然打包非常顺利，但是与之前无依赖的 Go 程序不同，这次的 conda 包生成后，安装到环境内是不能用的，提示段错误。 找问题于是开始了与 AI 的漫长讨论，最终在 AI 的指导下， 使用 rattler-build，解 conda 包，发现二进制被修改过（md5sum不一致）。进而了解到，不论是 rattller-build 还是 conda-build，都有特别的机制，即对二进制文件进行额外的库路径设置。 使用 readelf -d opencode 可以看到，相比获得的二进制文件，conda 包里的 opencode 多了一行 Library rpath 内容，就是这个改变导致了程序不能用。 12345678Dynamic section at offset 0xd588 contains 32 entries: 标记 类型 名称/值 0x000000000000000f (RPATH) Library rpath: [$ORIGIN/../lib] 0x0000000000000001 (NEEDED) 共享库：[libc.so.6] 0x0000000000000001 (NEEDED) 共享库：[ld-linux-aarch64.so.1] 0x0000000000000001 (NEEDED) 共享库：[libpthread.so.0] 0x0000000000000001 (NEEDED) 共享库：[libdl.so.2] 0x0000000000000001 (NEEDED) 共享库：[libm.so.6] 根据文档，这个修改 rpath 的行为是可以关掉的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package: name: opencode version: 1.1.35source: - if: target_platform == &quot;linux-64&quot; then: url: https://github.com/anomalyco/opencode/releases/download/v1.1.35/opencode-linux-x64.tar.gz sha256: 451f5a36e2875b5540adf55e8cc9e144902b44959a6f31899fc21876b38b31ae file_name: opencode.tar.gz - if: target_platform == &quot;linux-aarch64&quot; then: url: https://github.com/anomalyco/opencode/releases/download/v1.1.35/opencode-linux-arm64.tar.gz sha256: e7544ae14afb10e75d28a3623b1fd33d60e17f372106665566ca4e085c2b157b file_name: opencode.tar.gzbuild: number: 0 script: | tar xvf opencode.tar.gz mkdir -p $PREFIX/bin mv opencode $PREFIX/bin/opencode chmod 755 $PREFIX/bin/opencode prefix_detection: ignore_binary_files: true dynamic_linking: binary_relocation: falserequirements: build: - tartests: - script: - opencode -habout: homepage: https://opencode.ai/ license: MIT summary: &#x27;The open source coding agent.&#x27; description: | The open source coding agent. repository: https://github.com/anomalyco/opencode 但是诡异的事情来了，在修改设置后，包内的二进制程序和打包前的 md5 一致后，安装 conda 包依然有段错误，检测安装到环境的包，发现这个 rpath 的改动依然存在。 由于 pixi 本身比较新，我自己完全检索不到这个问题的相关讨论，于是我开始了为期一周的，与 AI 的 Battle … 最后的结果是，pixi global install 的机制如此，没有办法解决。 然而，事实并不如此… 我猛然发现，不论我怎么改 Recipe 文件，似乎打出来的包的名称是固定不变的… conda 和 pixi 都有缓存机制，于是我试着把缓存清除掉… 然后，发现能运行了… 虽然浪费了比较多的时间，好在结果是好的… 目前来说，只依赖 AI，果然还是不完全现实的…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[]},{"title":"使用 pixi 和 rattler_build 打包AI帮我写的程序","slug":"使用-pixi-和-rattler-build-打包AI帮我写的程序","date":"2026-01-25T20:50:24.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2026/01/25/使用-pixi-和-rattler-build-打包AI帮我写的程序/","permalink":"https://silenwang.github.io/2026/01/25/%E4%BD%BF%E7%94%A8-pixi-%E5%92%8C-rattler-build-%E6%89%93%E5%8C%85AI%E5%B8%AE%E6%88%91%E5%86%99%E7%9A%84%E7%A8%8B%E5%BA%8F/","excerpt":"之前我已经尝试了修改和添加recipe到conda的频道，这次试试把我的DevSSH打包上传到我自己的频道内。这次我想试试自己打conda包。","text":"之前我已经尝试了修改和添加recipe到conda的频道，这次试试把我的DevSSH打包上传到我自己的频道内。这次我想试试自己打conda包。 为什么选择pixi和rattler-build？这次其实是个巧合… 本来想注册anaconda帐号用conda-build，结果他们官网不知道抽什么风，就是注册不成功，于是直接转prefix.dev了，正好学习一下更新的共苦 rattler-build简介rattler-build是开发pixi团队开发的新一代conda包构建工具，它用Rust编写，自然就拥有更快的构建速度，它一定程度上与conda-forge的构建系统兼容，并且与pixi互相进行了一定程度的集成。 配置pixi.tomlpixi的基本功能是配置开发环境，但是其实它也可以用来配置软件包的构建环境。进行相关的配置需要用到package关键字，同时需要在[workspace]内开启实验性质的pixi-build特性。 12345678910111213141516171819202122232425[workspace]authors = [&quot;Sylens Wong &lt;qiumin14@163.com&gt;&quot;]channels = [&quot;conda-forge&quot;]name = &quot;DevSSH&quot;platforms = [&quot;linux-aarch64&quot;, &quot;linux-64&quot;]version = &quot;0.1.1&quot;preview = [&quot;pixi-build&quot;] # 需要开启pixi-build[tasks]build = &#123;cmd = &quot;go build -o bin/devssh cmd/devssh/main.go&quot;, cwd = &quot;./&quot;&#125;[activation.env]CGO_ENABLED = &quot;0&quot;[dependencies]go = &quot;&gt;=1.25.4,&lt;2&quot;# 下面是构建包的配置部分[package]name = &quot;DevSSH&quot;version = &quot;0.1.1&quot;[package.build.backend]name = &quot;pixi-build-rattler-build&quot; # 构建的是go程序，没有专门构建器，所以使用rattler-buildversion = &quot;0.3.*&quot; 编写rattler-build的reciperattler-build使用YAML格式的recipe文件来定义如何构建包，它与conda-build下的recipe是兼容的，不过并不支持所有的conda-build recipe语法。 以下是为DevSSH编写的recipe： 123456789101112131415161718192021222324252627package: name: devssh version: 0.1.1source: path: . use_gitignore: true build: number: 0 script: | # 构建二进制文件 go build -o &quot;$PREFIX/bin/devssh&quot; cmd/devssh/main.gorequirements: build: - $&#123;&#123; compiler(&#x27;go-nocgo&#x27;) &#125;&#125; # 我的程序纯go没有c依赖，因此选择nocgo编译器 - patchelf # 执行post-process必须about: homepage: https://github.com/SilenWang/DevSSH license: MPL-2.0 license_file: LICENSE summary: &#x27;A CLI tool to quickly set up remote development tools over SSH&#x27; description: | A CLI tool to quickly set up remote development tools over SSH repository: https://github.com/SilenWang/DevSSH 构建和上传包1. 本地构建如果配置文件设置无问题，执行构建命令应该就能得到conda格式的包了。 12345# 使用pixi构建pixi build# 指定目标平台构建pixi build -t linux-64 如果有问题，就一点点问AI，不过值得注意的是，现在rattler-build可能不是太主流，得到的答案经常会是按照conda-build来答的，还是需要自己对着文档去鉴别尝试。 2. 配置prefix.dev账户并上传上传前还是需要登录了，需要在账户下创建频道和设置API_TOKEN。 12# 设置API令牌pixi auth login --token YOUR_API_TOKEN prefix.dev 设置好了，直接把编译好的内容上传就是，网速好的话很快就完成了。 1pixi upload prefix devssh-0.1.1-hb0f4dca_0.conda -c sylens 3. 通过频道安装包用 pixi 或者 conda 都可以安装。 123pixi global install -c https://prefix.dev/sylens devsshconda install -c https://prefix.dev/sylens devssh","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"},{"name":"rattler-build","slug":"rattler-build","permalink":"https://silenwang.github.io/tags/rattler-build/"},{"name":"conda-build","slug":"conda-build","permalink":"https://silenwang.github.io/tags/conda-build/"},{"name":"Go","slug":"Go","permalink":"https://silenwang.github.io/tags/Go/"},{"name":"devssh","slug":"devssh","permalink":"https://silenwang.github.io/tags/devssh/"}]},{"title":"到处都有 cherry-pick","slug":"到处都有cherry-pick","date":"2026-01-20T00:05:43.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2026/01/20/到处都有cherry-pick/","permalink":"https://silenwang.github.io/2026/01/20/%E5%88%B0%E5%A4%84%E9%83%BD%E6%9C%89cherry-pick/","excerpt":"之前想给 Fydetab Duo Wiki 做点贡献，但是为了本地编译博客预览，我需要向项目中加入 pixi 或者其他配置，这些内容是不适合提交到原项目的。所以学习了一下如何选择性提交，也就是 git cherry-pick。","text":"之前想给 Fydetab Duo Wiki 做点贡献，但是为了本地编译博客预览，我需要向项目中加入 pixi 或者其他配置，这些内容是不适合提交到原项目的。所以学习了一下如何选择性提交，也就是 git cherry-pick。 Git 的 cherry-pick在 Git 版本控制系统中，cherry-pick 命令用于将某个特定的提交（commit）应用到当前分支，而不需要合并整个分支。这很适合我现在的需求：我 Fork 了源代码，创建了一个用于修改的分支（dev），分支的前两个 commit 是我进行本地配置用的文件，后面的才是对文档内容修改的部分。当我完成修改准备提交时，我可以基于未修改的原分支，再创建一个提交专用分支，然后利用 cherry-pick 来选择要纳入的后三个提交： 12345678# 将指定提交应用到当前分支git cherry-pick COMMIT3 COMMIT4 COMMIT5# 如果遇到冲突，解决后继续git cherry-pick --continue# 或者放弃 cherry-pickgit cherry-pick --abort 然后再使用这个分支提交 PR，就不会把不必要的内容提交到原项目了。 同时，上游合并了我的 PR 后，我也可以再从上游拉取更改到 dev 分支，这样就能继续更新，然后再修改和使用合并专用分支。 在数据分析中的 cherry-picking当时看到 cherry-pick 的时候觉得还挺有趣的，因为这个词之前在数据分析相关的讨论中也见过，其意思比较负面，即”选择性展示”。说实在的，这种事情工作后干的还真不少… 也是一种统计学的”魅力”时刻了… 另外，问了一下 AI，cherry pick 的说法似乎由来已久… Emmmmmm… 果然是太阳底下无新鲜事…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://silenwang.github.io/tags/Git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://silenwang.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"cherry-pick","slug":"cherry-pick","permalink":"https://silenwang.github.io/tags/cherry-pick/"}]},{"title":"啊这...原来 devpod 已经被官方搁置了吗","slug":"啊这-原来devpod已经被官方放弃了么","date":"2026-01-17T02:54:00.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2026/01/17/啊这-原来devpod已经被官方放弃了么/","permalink":"https://silenwang.github.io/2026/01/17/%E5%95%8A%E8%BF%99-%E5%8E%9F%E6%9D%A5devpod%E5%B7%B2%E7%BB%8F%E8%A2%AB%E5%AE%98%E6%96%B9%E6%94%BE%E5%BC%83%E4%BA%86%E4%B9%88/","excerpt":"事情的起因是，使用 devpod 配置基于 docker-compose 的容器时，发现 devpod 似乎不能正确地调用 docker-compose 完成容器创建。结果不搜不知道，一搜… 啊？这项目居然被 loft-sh 放弃了吗？","text":"事情的起因是，使用 devpod 配置基于 docker-compose 的容器时，发现 devpod 似乎不能正确地调用 docker-compose 完成容器创建。结果不搜不知道，一搜… 啊？这项目居然被 loft-sh 放弃了吗？ 根据 issue 1946 和 issue 1915 的描述，vCluster 是 loft-sh 商业化最成功、最有前景的项目，因此他们的所有精力都暂时放在上面，抽不出时间来维护社区项目了。 这个情况感觉跟 Fyde 团队类似，之前 Discord 上他们也说过，会优先倾向于能让公司继续运营的工作… 不过好在，一位社区大神创建了 Devpod 的社区分支，并且以惊人的速度持续更新（目前已经 0.9.* 了）！ 使用 skevetter 的 Fork，可以正常地使用 docker-compose，算是不幸中的万幸吧。 不过到目前为止，绝大部分的代码都是 skevetter 一人贡献的，这其实不是太健康。就如之前 onelist 那样，项目非常有名，但是几乎所有开发工作都集中在原作者一人身上，这样用爱发电的状态终究是无法持续的，一定程度上导致了最后卖项目跑路的问题。 希望 devpod 能像 gitea 那样，衍生自 gogs，但是最后发展出了完备的社区，让好项目能一直延续下去。","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"开源软件","slug":"开源软件","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6/"},{"name":"Devpod","slug":"Devpod","permalink":"https://silenwang.github.io/tags/Devpod/"},{"name":"开源项目维护","slug":"开源项目维护","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E7%BB%B4%E6%8A%A4/"},{"name":"社区分支","slug":"社区分支","permalink":"https://silenwang.github.io/tags/%E7%A4%BE%E5%8C%BA%E5%88%86%E6%94%AF/"},{"name":"项目可持续性","slug":"项目可持续性","permalink":"https://silenwang.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%8F%AF%E6%8C%81%E7%BB%AD%E6%80%A7/"},{"name":"Docker Compose","slug":"Docker-Compose","permalink":"https://silenwang.github.io/tags/Docker-Compose/"}]},{"title":"不是，哥们你真写出来了？","slug":"不是哥们-你真写出来了","date":"2026-01-14T22:12:22.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2026/01/14/不是哥们-你真写出来了/","permalink":"https://silenwang.github.io/2026/01/14/%E4%B8%8D%E6%98%AF%E5%93%A5%E4%BB%AC-%E4%BD%A0%E7%9C%9F%E5%86%99%E5%87%BA%E6%9D%A5%E4%BA%86/","excerpt":"新年又被AI惊艳到…","text":"新年又被AI惊艳到… 上周经常看到opencode的推荐文，说这是目前最好的开源GitHub Copilot替代，写代码的执行率相当不错。 起初我当然是持怀疑态度的，毕竟我用过aider和openhands，它们当然都是很好的工具，但是配合DeepSeek使用的时候，效果半数时候都是比较一言难尽的… 很多时候都不能正确理解我的意思。即使用其他AI优化prompt后，依然不能很好地完成稍微复杂一丢丢的任务。 但是既然推荐的这么多，也不妨一试。不试不知道，效果还真是超出我的预期。 我去年就提到过，我其实想要一个能快速在远程机器上开启VS Code的工具，但是奈何个人时间和能力有限，还没实施，就找到了devpod，解决了70%的需求… 于是暂时没有动力写了… 当时我就分别用了aider和openhands来尝试给我一个框架，我的要求也比较简单，能够在远程机器自动安装VS Code，然后自动将目标端口发到本地，实现过程尽量参考devpod的源码或直接用它的接口。 结果两者效果都不好，只能我自己在Copilot的指导下看代码，然而理解的相当慢，我自己调devpod接口也调不明白… 但是opencode，一次就成功搓了个能实际运行的demo出来，用的也不是更好的模型，同样是DeepSeek。虽然说尽量参考devpod的这个要求没有太做到，但是一次性能完成可运行，符合我功能描述的程序，在我看来已经是非常厉害了… 在第一版完成后，我也让opencode继续做了3次修改，除了有1次没改完直接停止外，都顺利完成了，真的出乎我意料。 虽然它的token消耗也非常的狠，但我用的毕竟是DeepSeek-Chat，过去一年只用了25块… 这次测试也就花了两三块，这个钱我还是付得起的。 另外，再试用之后，我也对Manus有所改观，没准人家是真有东西呢！原来prompt和工程上的优化，是可以带来显著的效果改善的… 果然还是要实践出真知… 试一试才是最真实的，就是… 希望试的成本能低点…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"aider","slug":"aider","permalink":"https://silenwang.github.io/tags/aider/"},{"name":"远程开发","slug":"远程开发","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/"},{"name":"opencode","slug":"opencode","permalink":"https://silenwang.github.io/tags/opencode/"},{"name":"AI编程","slug":"AI编程","permalink":"https://silenwang.github.io/tags/AI%E7%BC%96%E7%A8%8B/"},{"name":"代码生成","slug":"代码生成","permalink":"https://silenwang.github.io/tags/%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/"},{"name":"devpod","slug":"devpod","permalink":"https://silenwang.github.io/tags/devpod/"},{"name":"openhands","slug":"openhands","permalink":"https://silenwang.github.io/tags/openhands/"},{"name":"DeepSeek","slug":"DeepSeek","permalink":"https://silenwang.github.io/tags/DeepSeek/"},{"name":"自动化工具","slug":"自动化工具","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7/"}]},{"title":"尝试向Bioconda/Conda‑Forge提交新的包","slug":"尝试向bioconda-conda-forge提交新的包","date":"2026-01-11T17:15:43.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2026/01/11/尝试向bioconda-conda-forge提交新的包/","permalink":"https://silenwang.github.io/2026/01/11/%E5%B0%9D%E8%AF%95%E5%90%91bioconda-conda-forge%E6%8F%90%E4%BA%A4%E6%96%B0%E7%9A%84%E5%8C%85/","excerpt":"在上次尝试了对conda‑forge的包做小贡献之后，我想继续来点更进阶的：尝试将 singler‑py 这个 Python 包发布到 conda 生态中。结果不做不知道，一做…还有点麻烦…","text":"在上次尝试了对conda‑forge的包做小贡献之后，我想继续来点更进阶的：尝试将 singler‑py 这个 Python 包发布到 conda 生态中。结果不做不知道，一做…还有点麻烦… 罗马并不能一天建成我原本以为，设置好recipe，一次提交，通过审核就行了，但是发现了如下问题： 原本打算直接提交到 conda‑forge，却在阅读贡献指南时发现：专门面向生物信息学的软件应当优先提交到 Bioconda 频道。 之后阅读Bioconda的文档并尝试逐步尝试，发现 singler‑py 依赖的不少包都未进入任何 conda 频道，AI告诉我官方并不建议在同一个 PR 中提交多个新包，因此我只能从依赖树的最底层开始一个个来。 逐级往下解析，发现BiocPy下的一系列包都是没有进入Conda生态的… 梳理依赖后，singler‑py 所需的构建工作实际上是一个层层递进的依赖树。从最底层的 biocutils 开始，向上构建 biocframe、summarizedexperiment 和 singlecellexperiment，最后才是 singler‑py 本身。就目前来说，已知的依赖树就有： 12345flowchart TD A[biocutils] --&gt; B[biocframe] B --&gt; E[summarizedexperiment] E --&gt; F[singlecellexperiment] F --&gt; G[singler‑py] 可以看出，完成 singler‑py 的 conda 发布需要至少 4 个层级的构建工作，假设审核周期为 2‑3 个工作日，整个链条将耗时约 3‑4 周。实际上应该会在过程中发现更多的依赖包…估计只长不短… conda-forge和Bioconda不同的recipe工作流由于这个中实际上了解了两边的工作流，所以记录一下。 conda‑forge 与 Bioconda 简介conda‑forge 是一个由社区主导的 conda 软件包仓库，它覆盖了大量通用领域的开源软件。任何人都可以通过 GitHub 向它的 staged‑recipes 仓库提交新的配方（recipe），经过自动化检查和维护者审核后，新包就会出现在 conda‑forge 频道中，供全球用户通过 conda install -c conda-forge &lt;package&gt; 安装。性质上应该跟AUR是类似的。 Bioconda 则是一个专注于生物信息学软件的 conda 频道，是一个专门收录生物相关包的仓库，文档里也特别强调，如果一个包并不专门服务于生物相关的目的，那么它应该被提交到conda‑forge 频道。 两者管理和生成 Recipe 的工具有重合，但是实际上两者的 Recipe 整理方式不太一样。conda‑forge准备了一个 Recipe 模板，提交 Recipe 后，CI工作流会生成 feedstock 仓库，后续的维护工作在 feedstock 仓库上进行，所以是一包一库的形式。 Bioconda 则是所有 Recipe 集中在一个仓库，直接向这个集中仓库提交 PR 就好。差异应该来自于包的数目吧，毕竟生物信息应该是数据科学的分支，所以工具的数量应该远小于前者，愿意维护和贡献的人的数量… 估计更是远小于前者了…（有代码用就不错了…标准化和打包别想太多） 工具准备本次我暂时是使用 conda 工具集，毕竟初上手，跟着官方文档走… 所有的工具pixi都可以获取，运行： 1pixi global install --environment conda -c conda-forge -c bioconda conda conda-build bioconda-utils greyskull grayskull 这里有个小彩蛋，greyskull和grayskull同时存在，其实都指向的是grayskull，bioconda的文档有一页提到的是greyskull，不知道是不是项目开始的时候出现了什么小错误… 向 conda‑forge 提交新包的简要步骤conda‑forge 的方式是先提交 recipe，生成 feedstock 再维护feedstock Fork 仓库访问 conda‑forge&#x2F;staged‑recipes 并点击 “Fork” 按钮，将仓库复制到自己的 GitHub 账号下。 准备本地环境克隆你 fork 后的仓库，并创建一个新分支： 123git clone https://github.com/&lt;你的用户名&gt;/staged-recipes.gitcd staged-recipesgit checkout -b add-&lt;包名&gt; 生成配方文件像我提交的是pypi本来就有的包，所以直接grayskull pypi --strict-conda-forge &lt;包名&gt;就可以了 本地验证使用 conda smithy 工具在本地运行 lint 和构建测试（需先安装 conda‑smithy）： 12conda smithy recipe-lint recipes/&lt;包名&gt;/conda build recipes/&lt;包名&gt;/ 提交 PR将修改推送到你的 fork，然后在 GitHub 界面向 conda‑forge/staged‑recipes 发起 Pull Request。CI 会自动运行多平台构建测试，维护者会在评论中提出修改意见，直至所有检查通过后合并。 3. 向 Bioconda 提交新包的简要步骤 Fork 仓库访问 bioconda&#x2F;bioconda‑recipes 并 Fork 到自己的账号。 准备本地环境克隆仓库并创建分支（同样建议分支名称包含包名）： 123git clone https://github.com/&lt;你的用户名&gt;/bioconda-recipes.gitcd bioconda-recipesgit checkout -b add-&lt;包名&gt; 生成配方文件直接grayskull pypi &lt;包名&gt;就行 使用 bioconda‑utils 验证Bioconda 提供了专门的工具链来测试配方： 12345# 运行 lint 检查bioconda-utils lint recipes/&lt;包名&gt;/# 构建测试conda build recipes/&lt;包名&gt;/ 提交 PR推送到你的 fork 并向 bioconda/bioconda‑recipes 发起 PR。Bioconda 的 CI 会执行更严格的生物信息学软件兼容性测试，同样需要等待维护者审核并批准。 小发现检查包构建文件的语法时，发现 conda 现在也引入并行了。原来下载各个平台的包配置文件是串行的，大陆这里即使用了加速也得等个好几分钟，更不用说后面的依赖计算了。现在引入了并行机制，还是比原来强了点（虽然我还是会继续用 Pixi） 另外，印象中Pixi使用了更新的包构建工具，也许速度会比现在的conda生态更快，之后如果再提交别的，我一定试试。 后记还在天津工作的时候（7年前了都…），就想过自己编译 conda 包，这样就能解决没有 root 权限安装生信软件的问题了。只不过当时的文档是一个字也看不懂… 更别提写了。现在有了高度自动化的工具，也有了 AI 答疑… 确实可以来做点贡献了。 BiocUtils 0.3.3 的实际提交尝试应用前面所说的内容，我尝试向 Bioconda 提交了 BiocUtils 过程中得到几个略囧的经验： 文档中说的需要指定软件证书，并不是要把软件证书附加到 recipe 中，而是指定在原项目中的位置 bioconda 并不为老版本 python 提供包，所以不用针对 3.9 以下版本去做兼容 conda-build 自动解析出来的内容不一定准确，比如 BiocUtils 原 pypi 依赖指定了 python &gt;&#x3D; 3.9，但是解析出的 recipe 并没有解析到 另外，bioconda 的包提交后，后续的新版本是可以根据源代码的更新自动解析的， 所以如果没有特别问题，不需要每次更新 recipe","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"conda-forge","slug":"conda-forge","permalink":"https://silenwang.github.io/tags/conda-forge/"},{"name":"conda-build","slug":"conda-build","permalink":"https://silenwang.github.io/tags/conda-build/"},{"name":"包管理","slug":"包管理","permalink":"https://silenwang.github.io/tags/%E5%8C%85%E7%AE%A1%E7%90%86/"},{"name":"Bioconda","slug":"Bioconda","permalink":"https://silenwang.github.io/tags/Bioconda/"},{"name":"singler-py","slug":"singler-py","permalink":"https://silenwang.github.io/tags/singler-py/"},{"name":"biocutils","slug":"biocutils","permalink":"https://silenwang.github.io/tags/biocutils/"},{"name":"biocframe","slug":"biocframe","permalink":"https://silenwang.github.io/tags/biocframe/"},{"name":"summarizedexperiment","slug":"summarizedexperiment","permalink":"https://silenwang.github.io/tags/summarizedexperiment/"},{"name":"singlecellexperiment","slug":"singlecellexperiment","permalink":"https://silenwang.github.io/tags/singlecellexperiment/"},{"name":"依赖解析","slug":"依赖解析","permalink":"https://silenwang.github.io/tags/%E4%BE%9D%E8%B5%96%E8%A7%A3%E6%9E%90/"},{"name":"grayskull","slug":"grayskull","permalink":"https://silenwang.github.io/tags/grayskull/"}]},{"title":"为conda_forge做一点小贡献","slug":"为conda-forge做一点小贡献","date":"2026-01-09T10:03:56.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2026/01/09/为conda-forge做一点小贡献/","permalink":"https://silenwang.github.io/2026/01/09/%E4%B8%BAconda-forge%E5%81%9A%E4%B8%80%E7%82%B9%E5%B0%8F%E8%B4%A1%E7%8C%AE/","excerpt":"Conda 上的终于有 aider-chat 的 conda包了，这样理论上可以通过 pixi global 来全局安装它了。但是实际安装会发现，其依赖项之一 tree_sitter_languages 却没有对应的 aarch64 版本，安装过程会因此失败。于是我就想到，我能不能靠AI来解决这个。","text":"Conda 上的终于有 aider-chat 的 conda包了，这样理论上可以通过 pixi global 来全局安装它了。但是实际安装会发现，其依赖项之一 tree_sitter_languages 却没有对应的 aarch64 版本，安装过程会因此失败。于是我就想到，我能不能靠AI来解决这个。 什么是 conda‑forge？说来惭愧，在这之前，我一致不明白 conda 的 anaconda 和 conda‑forge 频道有什么区别… 这次翻文档才知道Conda‑forge 是一个社区驱动的 Conda 软件包分发频道，而 Anaconda 是 conda 的官方资源（以及如果在商业公司随便使用Anaconda，可能会被警告和要求付费…）。而 Conda‑forge 上的每一个软件包都对应一个 feedstock 仓库，其中包含了构建该包所需的全部文件，其中最关键的就是 recipe。 什么是 recipe？Recipe 是指导 Conda 如何构建一个软件包的配置文件，很形象的被叫成了“菜谱”，具体可以见官方文档。 由于我本次并不是从头构建一个conda包，所以实际上这次并没有涉及修改 Recipe。 准备 feedstock 仓库如前所述，每一个软件包都对应一个 feedstock 仓库，tree_sitter_languages‑feedstock的仓库 就在conda-forge组织下。根据官方文档的建议，对仓库做贡献建议先Fork仓库到自己的账户，然后开分支修改，推送到原仓库。 修改文件根据 Aider 对这个 feedstock 的解析，这个库并没有什么特别不支持的 aarch64 的地方，可能只是单纯建立的时候就没有想支持 aarch64，并且默认状况下，feedstock 也不会自动支持 aarch64 （大概是，用户太少没人权吧…）。因此，修改很简单，只需要改 conda-forge.yml，加上： 12provider: linux_aarch64: azure 之后，根据文档，我需要手动运行conda-smithy render -c auto，conda 会自动对构建脚本进行更新（真自动化，这就是专业的CI和CD么…） 向原项目提交 PR 以进行更新最后就是将代码提交到自己仓库的fork，然后从github向原项目提交PR，PR会触发原项目库的CI，这个流程会自动完成构建和测试，测试通过，包的Maintainer接受PR后，包就能在conda上搜到了。 有了这个包，在Fydetab Duo上就能直接pixi global install aider-chat了，目前使用没有出现啥问题~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"conda-forge","slug":"conda-forge","permalink":"https://silenwang.github.io/tags/conda-forge/"},{"name":"tree_sitter_languages","slug":"tree-sitter-languages","permalink":"https://silenwang.github.io/tags/tree-sitter-languages/"},{"name":"PR","slug":"PR","permalink":"https://silenwang.github.io/tags/PR/"},{"name":"feedstock","slug":"feedstock","permalink":"https://silenwang.github.io/tags/feedstock/"}]},{"title":"词云更新","slug":"词云更新","date":"2026-01-08T01:22:04.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2026/01/08/词云更新/","permalink":"https://silenwang.github.io/2026/01/08/%E8%AF%8D%E4%BA%91%E6%9B%B4%E6%96%B0/","excerpt":"新单位的分析基本上全是个性化，所以每个项目都少不了要插论文，又有一阵看论文看到头疼的感觉。想起上次画词云已经是22年的事了，3年之期已过，恭迎… 好吧就是更新一下…","text":"新单位的分析基本上全是个性化，所以每个项目都少不了要插论文，又有一阵看论文看到头疼的感觉。想起上次画词云已经是22年的事了，3年之期已过，恭迎… 好吧就是更新一下… 本次的更新比较简单，导出文献库后，再次绘制，不过使用的文本做了一些小改动，原来是只获取摘要的部分，这次我翻了以下文献库的情况，发现还是挺多文献只有标题并没有摘要的，并且论文的摘要多少有点八股文，因此这次使用的对象为关键词，和标题，有关键词用关键词，没有则用标题： 1234567with open(filepath, &#x27;r&#x27;) as bibliography_file: entries = rispy.load(bibliography_file) for entry in entries: if &#x27;keywords&#x27; in entry: text += &#x27; &#x27;.join(entry[&#x27;keywords&#x27;]) + &#x27; &#x27; else: text += entry[&#x27;title&#x27;] + &#x27; &#x27; 另外，感谢AI的建议，发现了之前轮廓绘制失败的原因，加上Image.open(&quot;Sylens_Happy_Background.png&quot;).convert(&quot;L&quot;)后，能正常的按轮廓绘制了。 新版图如下： 附原版的图： 出人意料的是… Emmm，变化并没有想象中的大，看来这一年半来，我确实是IT方面的工作多了… 觉得论文看到吐，也许是项目经常是扎堆过来？","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"数据可视化","slug":"数据可视化","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"文献管理","slug":"文献管理","permalink":"https://silenwang.github.io/tags/%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/"},{"name":"词云","slug":"词云","permalink":"https://silenwang.github.io/tags/%E8%AF%8D%E4%BA%91/"}]},{"title":"这一年来AI给我带来的改变","slug":"这一年来AI给我带来的改变","date":"2026-01-06T22:30:10.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2026/01/06/这一年来AI给我带来的改变/","permalink":"https://silenwang.github.io/2026/01/06/%E8%BF%99%E4%B8%80%E5%B9%B4%E6%9D%A5AI%E7%BB%99%E6%88%91%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%94%B9%E5%8F%98/","excerpt":"2022年末到2023年初，ChatGPT爆火，我开始用LLM来辅助写脚本。虽然相当好用，但是价格较贵，且个人付款始终是问题，应用也就仅限于简单的代码问题了。2024年末到2025年初，DeepSeek爆火。虽然它的回答很多时候不那么令人满意，且增加了思考模式后，得到结果的时间总是会慢一拍，但是，它便宜呀！在一年之后，DeepSeek依然是输出结果还不错的前提下，Token最便宜的模型之一。年初充了50块，到现在刚好差不多一年，还剩27… 因此，我就更大胆地将LLM用在了各种其他方面。","text":"2022年末到2023年初，ChatGPT爆火，我开始用LLM来辅助写脚本。虽然相当好用，但是价格较贵，且个人付款始终是问题，应用也就仅限于简单的代码问题了。2024年末到2025年初，DeepSeek爆火。虽然它的回答很多时候不那么令人满意，且增加了思考模式后，得到结果的时间总是会慢一拍，但是，它便宜呀！在一年之后，DeepSeek依然是输出结果还不错的前提下，Token最便宜的模型之一。年初充了50块，到现在刚好差不多一年，还剩27… 因此，我就更大胆地将LLM用在了各种其他方面。 从“奢侈品”到“日用品”如果前两年使用 AI 还像是偶尔尝鲜的奢侈品，那么今年它已经彻底变成了我工作流中的日用品。DeepSeek 低廉的价格让我可以毫无心理负担地用它处理各种任务：从简单命令的查询，到整个脚本的重构，再到完全陌生领域的探索。虽然不一定达到了效率的飞跃，但是它确实扩展了我的能力边界，让我能做之前只有概念但从未实践的工作（然后成为了更牛马的牛马）。 本年的成功应用案例批量翻译博客利用命令行 AI 工具 Aider，我编写了一个简单的 Shell 脚本，让它自动读取中文博客目录下的每一篇文章，将其翻译成英文，并保存到对应的英文目录中。 脚本完成翻译只花了一个半小时的时间，但是我人工校对足足花了一个星期的夜晚时间… 这也是我过去虽有将博客英文化的想法，但是最终做不下去的原因——没有脚本化的工具，一篇篇复制粘贴也能弄到吐血。另外，校对英文翻译的那一周，也让我回想起了当时准备英文临床试验材料的那段时间… 即使现在看过的英文专业论文及材料已经数以千计了… 还是会觉得这个过程相当折磨… 这大概就是没有语言天赋吧… 给 FydeTab Duo Wiki 贡献中文翻译除了我的博客，我还向 FydeTab Duo Wiki 贡献了好几次中文翻译。也是借由 Aider 初翻，然后我再进行一遍校对，同时我也借它了解了一下 FydeTab Duo Wiki，毕竟它采用的 Wiki 框架我之前并没有用过。 撰写博客初稿今年下半年开始，我上传的博客数目开始指数增加，这也是拜 Aider + DeepSeek 的组合所赐。因为我写博客主要是记录给自己看，没有什么风格化的要求，记录目的远大于展示目的。所以列个提纲出来，把相关代码或者 Notebook 甩给它们，生成草稿我再改就可以了。这真的很省时间。原来我一个博文就能写一整个晚上… 现在只要有题材，一晚上写5篇都不是问题… 配合之前的翻译，中英文同步发布也不是问题。 批量生成 API 测试面对多个服务组的 Swagger 描述文件，手动编写 pytest 测试用例过去是一件不难但相当耗时的事情。同样借助 Aider，我只需提供 Swagger 描述文件，它就能在几分钟内生成一套可运行的基础测试代码框架。我只需要在此基础上微调，就能快速提高测试覆盖率。 今年上半年在给接手的系统构建 CI 体系时，Aider + DeepSeek 的组合让我比预期早很多完成了工作。 修复 Hexo 主题的国际化问题在为博客搭建英文站时，我发现主题 Volantis 的小部分文字实际上是硬编码在配置文件或者项目代码中的，且部分交互功能在子目录路由下失效。通过 DeepSeek 分析浏览器控制台报错和主题源码，我快速定位到问题根源： CDN 路径配置错误导致 app.js 加载失败，修复后交互功能恢复正常。 将主题配置文件中固定的中文标题、描述等字段逐一替换为英文。 最终，我通过生成并应用补丁的方式，在不直接修改主题源码仓库的前提下，解决了双语支持问题。这在过去是非常难想象的，毕竟我并没有真的做过完整的 JS 项目开发，看代码找问题本身会很费劲，但是 AI 帮我缩小了检查范围，让短时间内解决问题成为了可能。 配置 GitHub Actions 进行 CI 和 CD这也是一个比较好的例子。我今年有两个平台的自动化流程使用经验，一个是 Azure Pipeline，另外则是 GitHub Actions。前者我是对着说明文档手动写的，花了大概一整天，因为是全英文的文档，翻译又比较一言难尽（微软很多文档的中文感觉就像是根本没有中文用户，所以全是机翻也不优化）。 GitHub Actions 则很大程度上是在 AI 指导下完成的，生成大致样例后我再改，基本上 1~2 小时就能搞定。 为 conda‑forge 贡献 ARM64 包当发现 tree_sitter_languages 缺少 ARM64 架构的 conda 包，导致 aider‑chat 无法在 Fydetab Duo（ARM 设备）上安装时，我决定自己动手补充。在 AI 的指引下，我： 了解了 conda‑forge 的 feedstock 工作机制。 在对应的 conda‑forge.yml 中添加了 linux_aarch64 构建支持。 按照社区流程提交 PR，并成功通过 CI 测试。 本年的失败或部分失败案例AI 显然也不是万能的，其给出的方案往往需要专业判断，否则就会原地打转，甚至很多时候我也不知道我是在打转还是还没摸到尽头。 尝试修改 Theia 的远程模块我希望在浏览器版的 Theia IDE 中增加远程开发支持，因为我在 FydeTab Duo 上用 Linux 子系统的 VSCode 实在太卡了… Aider 和 OpenHands 都能给出代码修改建议，但由于我对 Electron&#x2F;Node.js 的大型项目一无所知，无法判断这些修改是否正确，也不知如何调试。最终，这个尝试无果而终。 尝试更新 FydeOS 内核以支持 Vulkan为了提升图形性能，我考虑将 FydeTab Duo 的内核升级到新版，以期支持 Vulkan 驱动。AI 帮我找到了适用于 RK3588 的新内核源码，但我无法理解编译时的 overlay 替换机制。最终我采取了简单粗暴的替换方式，结果导致设备变砖。 尝试基于 DevPod 的源码直接写一个符合我要求的应用DevPod 的功能非常符合我脱离 FydeOS 的 Linux 子系统创建开发环境的要求，只是它必须基于 Docker 或者 Podman，但是我目前无法在子系统外运行 Docker&#x2F;Podman。所以我曾经尝试让 AI 直接参照以及复用 DevPod 的源代码，写一个通过 SSH 连接，在远程机器上安装 VSCode 并进行端口转发的应用。然而 AI 并没有参考或复用 DevPod 已有的内容，而是根据我的描述一顿重写，然后代码却无法运行。 尝试在 FydeOS 上编译运行 Podman我成功使用 Pixi 管理依赖，编译出了 ARM64 版本的 Podman 及其依赖库。然而在运行时，却因 FydeOS&#x2F;ChromeOS 内核的 SafeSetID 安全限制，无法完成用户命名空间映射，导致 rootless Podman 最终无法运行。AI 给我解释了这一问题的来源，但是我至今也不确定它说的对或不对，以及我该怎么解决问题。 小结回顾这一年，AI 已经彻底融入我的工作学习日常。它帮我完成了大量重复劳动，解决了无数具体问题，甚至让我敢于涉足以前不敢随便涉及的领域。但与此同时，我也更加清醒地认识到，AI 的能力发挥极大程度依赖于使用者的知识储备和判断力。 在已有知识框架内，AI 能带来一定的效率提升，虽然绝对到不了各家宣传的可以当甩手掌柜的程度，但一定是有真实的效率提升的。 在一知半解的方面，AI 能大大缩短从0到1突破的时间，这在过去是很难想象的，但是今年很多新内容的上手，实际上就只花了半天时间。 在完全陌生的领域，没有足够的背景知识去验证和筛选 AI 的输出，只能被动地按照 AI 给出的建议一条条尝试，非常容易花大量时间在无用功上。 简单来说，就是我的上限决定 AI 的上限，最终，还是使用的人需要好好学习，提升自己。","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"自动化","slug":"自动化","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"DeepSeek","slug":"DeepSeek","permalink":"https://silenwang.github.io/tags/DeepSeek/"},{"name":"AI","slug":"AI","permalink":"https://silenwang.github.io/tags/AI/"}]},{"title":"搭一个用rendercv生成简历的容器","slug":"搭一个用rendercv生成简历的容器","date":"2026-01-06T21:17:55.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2026/01/06/搭一个用rendercv生成简历的容器/","permalink":"https://silenwang.github.io/2026/01/06/%E6%90%AD%E4%B8%80%E4%B8%AA%E7%94%A8rendercv%E7%94%9F%E6%88%90%E7%AE%80%E5%8E%86%E7%9A%84%E5%AE%B9%E5%99%A8/","excerpt":"准备简历说起来是不是什么难事，但实际做起来，还是会比较耗时的。现在不少岗位会对细分领域有一些只是或者项目的要求，求职者这么多，一份没有针对岗位要求突出重点的简历，也许就被用人单位忽略掉了。所以想要达到更好的效果，最好能对每个岗位针对性的优化… 这一点AI应该是擅长的，但是至少我现在没找到比较好的免费工具。 刚好最近看到了RenderCV，这是一个通过YAML配置文件生成简历的工具，它可以实现配置文件即简历，将它与Aider这种编程助手结合，基本就能构成一个快速准备简历的工作环境了。","text":"准备简历说起来是不是什么难事，但实际做起来，还是会比较耗时的。现在不少岗位会对细分领域有一些只是或者项目的要求，求职者这么多，一份没有针对岗位要求突出重点的简历，也许就被用人单位忽略掉了。所以想要达到更好的效果，最好能对每个岗位针对性的优化… 这一点AI应该是擅长的，但是至少我现在没找到比较好的免费工具。 刚好最近看到了RenderCV，这是一个通过YAML配置文件生成简历的工具，它可以实现配置文件即简历，将它与Aider这种编程助手结合，基本就能构成一个快速准备简历的工作环境了。 容器的构成组件容器的组件很简单： Pixi：用于安装依赖，即RenderCV和Aider Aider：用于生成大致的简历配置文件，同时也可以直接用来翻译 RenderCV：从配置文件生成简历 PDF预览插件：直接在VSCode中就能查看生成的PDF简历，配合RenderCV的--watch参数，也可以实现修改的实时预览 启动容器 使用Github Codespace：最方便的方式当然是直接白嫖Gihub的Codespace，fork 我的容器项目后，就可以在Web版的VSCode里准备简历了。简历生成后也可以直接从容器里下载到本地。 使用Devpod：使用Devpod也简单，有任意Provider后，运行 devpod up https://github.com/SilenWang/RenderCV_Pod就能开始写了 Aider生成简历配置的注意事项目前我配合DeepSeek的API进行简历生成，可能由于RenderCV项目本身比较新，DeepSeek显然是不知道RenderCV的配置文件应该是什么样的，它能给出看上去可以的文件，但是其中Section部分该怎么写完全是错误的，还是需要自行看RenderCV的文档来修正，当然RenderCV的设计就是为了简单快速，所以这些调整10分钟左右就能学会，到不是太大问题。 另外，准备一个示例完整的例子给AI以后，基本就能避免前述问题，之后有空我再在项目中补充。","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Pixi","slug":"Pixi","permalink":"https://silenwang.github.io/tags/Pixi/"},{"name":"容器","slug":"容器","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"开发环境","slug":"开发环境","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"name":"RenderCV","slug":"RenderCV","permalink":"https://silenwang.github.io/tags/RenderCV/"},{"name":"Aider","slug":"Aider","permalink":"https://silenwang.github.io/tags/Aider/"}]},{"title":"更新我的头像","slug":"更新我的头像","date":"2025-12-28T17:34:00.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2025/12/28/更新我的头像/","permalink":"https://silenwang.github.io/2025/12/28/%E6%9B%B4%E6%96%B0%E6%88%91%E7%9A%84%E5%A4%B4%E5%83%8F/","excerpt":"我的头像，印象中用了有10好几年了，自从我开始做生物信息工作之后，我就想过给它加一些复杂度，半边加上电路板的纹路，另外半边使用DNA的纹路，中间用一种过度效果连接起来，象征生物到信息的转化，这样贴合我的工作领域。但是奈何我并不怎么会P图，实现不了想要的效果。不过今年新出的图像编辑模型，让实现我的想法有了希望。","text":"我的头像，印象中用了有10好几年了，自从我开始做生物信息工作之后，我就想过给它加一些复杂度，半边加上电路板的纹路，另外半边使用DNA的纹路，中间用一种过度效果连接起来，象征生物到信息的转化，这样贴合我的工作领域。但是奈何我并不怎么会P图，实现不了想要的效果。不过今年新出的图像编辑模型，让实现我的想法有了希望。 其实在最早图像生成模型开始火，网上开始出现各种AI美女图的时候，我就把我能用得上的开源和商业模型都试了个遍，试图画出一个至少实现DNA到电路板纹路过度的图，最后只有Gemini给的图形比较能看，现在成为了博客的Banner。 今年，我无意中在微信里看到了阿里qwen-image-edit的介绍，才知道原来还有专门用来进行图像编辑的模型，可以把不同的元素拼在一起生成新图。这正适合实现我更新图形的想法。于是从Github找到了一个简单的前端（我感觉我这个需求，犯不着上comfyui那么复杂），然后自己Fork了一份，加上了模型选择和多图输入。然后就开始修改我的头像了。 正式开始修改图像前，我先用我修改的小工具测试了下qwen-image-edit和wan2.5-i2i-preview的效果，实测还是万象效果更好，因此后面的工作都是用万象完成的。 一步到位的尝试qwen-image-edit项目 的例子中，编辑的功能还是相当强大的，从替换衣服、修改文字、图形融合都可以。因此我期待的是，只要我给出描述，就能一次性的完成修改。但果然，宣传是宣传，使用是使用，卖家秀和买家秀始终是不一样的。 下面是我的一步到位尝试的效果图合集，第一排最左侧是我的头像原图，其余的是我自己写简单的Prompt得到的三个效果图。我的Prompt大致是下面这样的简单描述。 图1是一个标，我现在想将这个图标的形状，变成由特定的纹路组成的形状，图形左半边是电路板上的图样纹路，右侧则是DNA双螺旋的纹路 尝试了几次后，发现出来的结果与预期差太远，于是我借助ChatGPT来优化Prompt，得到的Prompt大致是下面这样的 在严格保持原始图标整体轮廓、比例、结构完全不变的前提下，对图标进行纹理重构。该图标由异形字母 S 与 W 组成，其中 S 由上下羽毛状弧形构成，W 位于中央，整体呈环形动态结构。修改要求：图标左半部分（包括对应的 S 与 W 区域轮廓）填充为精细的电路板纹路：包含 PCB 走线、芯片焊盘、微型电子线路线条清晰、科技感强、具有工程精度图标右半部分（包括对应的 S 与 W 区域轮廓）填充为DNA 双螺旋结构纹路：可见规则的双螺旋扭转包含碱基阶梯结构，具有生物科技与生命科学质感整体风格要求：所有纹理仅作为填充纹路，不得改变原有外轮廓左右两种纹理在中轴处自然过渡，但不混杂保持图标的简洁性与可识别性，适合作为科技 &#x2F; 生物信息 &#x2F; AI 相关品牌 Logo背景保持纯色或透明高对比度、矢量感、干净、专业输出为清晰、现代、可用于品牌视觉系统的图标效果。 有了这个更专业的Prompt后，就能得到第二排那样，极大程度接近我想要效果的图了，但是过程中发生两个问题： 原图形有2个弧形颜色较浅，模型似乎大部分时候不会去修改这部分 模型没法很好区分我描述的上半部分和下半部分，毕竟这俩部分不是严格的上下，也不是严格的左右… 分步走在一次性无法完成任务后，我最终选择了分布完成（得，难怪专业工作流要comfyui）。首先我自行改变原图的颜色，避免模型修改遗漏，之后我自行把要分别着色的两部分拆分开，避免模型识别不了我说的两部分，导致纹路修改不准确。 最后我自己拿到两部分结果后，再拼起来。这个过程中，还出现了下半部分绘制DNA纹路时，模型没法正确着色的问题，因此还又加了最后一步的着色。 小结虽然过程不是很顺利，最终的效果不说100%达到我的预期，也完成了85%吧。而且这个过程比我想的快得多，不算改工具的时间的话，图形部分实际上只试了2小时左右。我之前看过给Vup做图的Naing老师的工作直播，做一个小图样并没有那么简单… 尤其我要的这种电路板和DNA纹路本身有点复杂的情况。用模型能有现在的效果，我已经挺知足了…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"qwen-image-edit","slug":"qwen-image-edit","permalink":"https://silenwang.github.io/tags/qwen-image-edit/"},{"name":"wan2.5-i2i-preview","slug":"wan2-5-i2i-preview","permalink":"https://silenwang.github.io/tags/wan2-5-i2i-preview/"},{"name":"AI","slug":"AI","permalink":"https://silenwang.github.io/tags/AI/"},{"name":"图像编辑","slug":"图像编辑","permalink":"https://silenwang.github.io/tags/%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91/"}]},{"title":"我真是用什么都会踩坑--Devcontiner使用的若干问题","slug":"我真是用什么都会踩坑-Devcontainer使用的若干问题","date":"2025-12-19T22:27:38.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2025/12/19/我真是用什么都会踩坑-Devcontainer使用的若干问题/","permalink":"https://silenwang.github.io/2025/12/19/%E6%88%91%E7%9C%9F%E6%98%AF%E7%94%A8%E4%BB%80%E4%B9%88%E9%83%BD%E4%BC%9A%E8%B8%A9%E5%9D%91-Devcontainer%E4%BD%BF%E7%94%A8%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98/","excerpt":"我只是想设置一个devcontainer环境，更高效的完成维护公司官网的工作，没想到一件事上能踩三个坑…","text":"我只是想设置一个devcontainer环境，更高效的完成维护公司官网的工作，没想到一件事上能踩三个坑… 背景Devcontainer 是 Visual Studio Code 推出的一项功能，它允许我们利用 Docker 容器快速搭建与项目匹配的开发环境。这种“代码即环境”的方式可以极大地统一团队协作体验，减少“在我机器上能跑”的尴尬。我之前写的devpod就是基于这种格式的开源解决方案。 然而，理想很丰满，现实却总会在细节上给你使绊子。在最近一次为公司官网项目配置 Devcontainer 时，我接连遇到了三个意想不到的问题，每个都耗费了不少时间才找到解决方案。下面就把这些问题和解决方案记录下来，供大家参考。 坑一：Git 子模块（subtree）的缺失问题描述微软官方提供的Devcontainer基础镜像有 Debian 和 Ubuntu，两者都自带的 Git，但是，版本都比较基础。不含 subtree 子命令… 嗯，我也是第一次知道，git 的功能太多，以至于一些比较新的命令，做成了可选项… 但这都不是问题，Ubuntu 和 Debian 源中的 Git 应该都是功能完整的，因为我在 Devcontainer 之外从来没有收到过 subtree 命令不存在的提示。然后问题就出现了，即使通过 apt-get install git-man 或者 git-all，也无法直接获得 subtree 功能。为什么呢？其实很简单，Devcontainer 内自带的git，并不来自软件源，它位于 /usr/local/bin，而系统安装的 git 会在 /usr/bin。而环境变量 Path 中，/usr/local/bin 优先级更高， 所以自行安装的git，实际上不会被使用到，于是会一致找不到 subtree … 解决方案根据前面的问题，其实通过 apt 安装系统带的 git，然后把镜像里的干掉就是： 12345678910FROM mcr.microsoft.com/devcontainers/base:ubuntuRUN apt-get update &amp;&amp; \\ add-apt-repository -y ppa:git-core/ppa &amp;&amp; \\ apt-get update &amp;&amp; \\ apt-get install -y git vim &amp;&amp; \\ # 记得干掉容器里原来的git rm -r /usr/local/bin/git* &amp;&amp; \\ apt-get autoremove -y &amp;&amp; \\ apt-get clean -y 坑二：Windows 平台下的换行符自动转换问题描述当你在 Windows 主机上使用 Docker Desktop 运行 Devcontainer 时，Git 会根据 core.autocrlf 的默认设置（通常为 true）自动将行结束符 LF 转换为 CRLF。这本身是 Windows 开发环境中的常见行为，但在容器内部，文件系统是 Linux 风格的，因此 Git 会在检出文件时执行转换，导致几乎所有文件都被标记为“已修改”。 具体现象是：在容器内执行 git status，会发现大量文件显示为修改（即使你什么都没做）。这种干扰不仅让人困惑，还可能影响后续的提交操作。 解决方案Emmmm，我其实并没有解决这个问题，因为进行 git 的配置并不能阻止 vscode 执行这个转换… 这个问题只发生在 Windows 平台下使用 Docker Desktop 的情况，反正用 Docker Desktop 编译个网站都能导致桌面卡死，直接不用就是了… 老老实实用服务器作为 SSH Provider… 坑三：Devcontainer Desktop 与远程 SSH Provider 的掉线问题问题描述在尝试通过 Devpod Desktop 连接到远程 SSH Provider时，会发现连接极其不稳定，经常在几分钟内就会自动断开，且重连过程十分缓慢，连上不一会又掉。不足。由于 Devpod Desktop 也不给什么运行日志，我也不知道是啥毛病… 解决方案简单粗暴，Devpod Desktop 只用来进行 Provider 和工作区的配置，发起连接由 DevPod CLI 完成就好… 小结好消息，问题最终都解决了；坏消息，本周又少睡了七八个钟，愿我不要暴毙在2025…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"git","slug":"git","permalink":"https://silenwang.github.io/tags/git/"},{"name":"docker","slug":"docker","permalink":"https://silenwang.github.io/tags/docker/"},{"name":"devpod","slug":"devpod","permalink":"https://silenwang.github.io/tags/devpod/"},{"name":"devcontainer","slug":"devcontainer","permalink":"https://silenwang.github.io/tags/devcontainer/"}]},{"title":"Pixi进阶：使用Pixi作为数据科学/生物信息学/web开发的万能管理工具","slug":"Pixi进阶-使用Pixi作为项目的万能管理工具","date":"2025-12-17T21:56:40.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2025/12/17/Pixi进阶-使用Pixi作为项目的万能管理工具/","permalink":"https://silenwang.github.io/2025/12/17/Pixi%E8%BF%9B%E9%98%B6-%E4%BD%BF%E7%94%A8Pixi%E4%BD%9C%E4%B8%BA%E9%A1%B9%E7%9B%AE%E7%9A%84%E4%B8%87%E8%83%BD%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","excerpt":"去年我入职新公司的时候，接到了一项为生物信息培训准备教学用分析环境的任务，以此为契机，我接触到了Pixi。后来由于工作内容变动，我不仅要进行生物信息分析，还要兼任全栈维护的工作，接手的项目横跨前段后端，涉及的语言和框架不再限于数据科学常用的R、Python，Pixi也依然能充当一个跨语言&#x2F;技术栈的开发环境管理工具（Conda资源极丰富，主流的编程语言和常用框架都有资源），因此现在再次来小结下，在我的工作中用得上的Pixi实用功能。","text":"去年我入职新公司的时候，接到了一项为生物信息培训准备教学用分析环境的任务，以此为契机，我接触到了Pixi。后来由于工作内容变动，我不仅要进行生物信息分析，还要兼任全栈维护的工作，接手的项目横跨前段后端，涉及的语言和框架不再限于数据科学常用的R、Python，Pixi也依然能充当一个跨语言&#x2F;技术栈的开发环境管理工具（Conda资源极丰富，主流的编程语言和常用框架都有资源），因此现在再次来小结下，在我的工作中用得上的Pixi实用功能。 1. 处理多环境的公用依赖现在经手的项目七八成都是单细胞，这个领域到目前为止，都还是有两个主流的分析生态，即Python下的Scanpy，以及R下的Seurat，并且两种生态下都在持续产出前沿的新分析技术，因此不可避免的两个生态都要用，分析环境也就必然是多个。而我做的项目全部都是个性化的，因此安装和测试两套生态下的工具不可避免，单细胞数据又大，使用 Jupyter Notebook 这种工具进行交互性测试是必然的，为了避免每次创建新环境都反复配置共用软件包，将 Jupyter 以及必要的内核设为通用依赖是很必要的。 设置defualt环境在设置环境的关键字[dependencies]下配置的所有软件包都在defualt环境中，这个环境中记录的所有包都会在任一环境中被纳入依赖计算。 1234567891011121314151617181920212223[workspace]authors = [&quot;Sylens Wong &lt;qium@aimingmed.com&gt;&quot;]channels = [&quot;conda-forge&quot;, &quot;bioconda&quot;]name = &quot;DEMO1&quot;platforms = [&quot;linux-64&quot;]version = &quot;0.1.0&quot;[environments]scanpy = [&#x27;scanpy&#x27;]seurat = [&#x27;seurat&#x27;][dependencies]ipykernel = &#x27;*&#x27;r-irkernel = &#x27;*&#x27;jupyterlab = &#x27;*&#x27;[feature.scanpy.dependencies]python = &#x27;3.*&#x27;scanpy = &#x27;*&#x27;[feature.seurat.dependencies]r-base = &#x27;4.*&#x27;r-seurat = &#x27;*&#x27; 设置通用feature另一种方式，则是设置通用feature。在pixi.toml中，我们可以定义多个环境（[environments]），每个环境由一组feature组成。如果不同的环境有公共依赖（如ipykernel、r-irkernel、jupyterlab）放入一个名为kernel的feature中，然后在各个分析环境中引用该feature。 1234567891011121314151617181920212223[workspace]authors = [&quot;Sylens Wong &lt;qium@aimingmed.com&gt;&quot;]channels = [&quot;conda-forge&quot;, &quot;bioconda&quot;]name = &quot;DEMO1&quot;platforms = [&quot;linux-64&quot;]version = &quot;0.1.0&quot;[environments]scanpy = [&#x27;kernel&#x27;, &#x27;scanpy&#x27;]seurat = [&#x27;kernel&#x27;, &#x27;seurat&#x27;][feature.kernel.dependencies]ipykernel = &#x27;*&#x27;r-irkernel = &#x27;*&#x27;jupyterlab = &#x27;*&#x27;[feature.scanpy.dependencies]python = &#x27;3.*&#x27;scanpy = &#x27;*&#x27;[feature.seurat.dependencies]r-base = &#x27;4.*&#x27;r-seurat = &#x27;*&#x27; 这样，无论是scanpy环境还是seurat环境，都会自动包含kernel提供的Jupyter内核支持，避免了重复定义。另外，这种配置方式更模块化，可以配置多个包组件，然后自由组合成需要的环境。 2. 管理简单的部署任务以及任务之间的依赖除了依赖管理，Pixi还可以定义任务（tasks），并指定任务之间的依赖关系。等于是纳入了一个非常简单的Make工作流体系。这在需要顺序执行编译、打包、部署等步骤的项目中尤其有用。 在pixi.toml的[tasks]或[feature.xxx.tasks]节中，我们可以设置一系列的任务，每一个任务可以利用depends-on声明任务依赖。Pixi会确保所有依赖任务按顺序执行。 下面是一个生物信息分析项目中，需要依次安装几个Bioconductor数据包的任务定义： 12345[feature.rplot.tasks]GenomeInfoDbData = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;GenomeInfoDbData\\&quot;)&quot;&#x27;&#125;BSgenome = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;BSgenome.Hsapiens.UCSC.hg38\\&quot;)&quot;&#x27;&#125;EnsDb = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;EnsDb.Hsapiens.v86\\&quot;)&quot;&#x27;&#125;r_dep = &#123;cmd = &#x27;echo &quot;bio dep for R done&quot;&#x27;, depends-on=[&#x27;GenomeInfoDbData&#x27;, &#x27;BSgenome&#x27;, &#x27;EnsDb&#x27;]&#125; 执行pixi run r_dep时，Pixi会自动先执行三个安装任务，最后输出完成信息。除了这种指定任务名为依赖的组织方式，Pixi也支持以文件作为标志，从而跳过已完成步骤的组织方式，不过… 功能过于简单，我自己没有太多使用。 3. 为特定软件包指定来源有时我们需要从特定的channel安装某个软件包（例如某个内部channel），而其他包仍从默认channel获取。Pixi允许在依赖声明中单独指定channel属性。在依赖项后面添加&#123;version = &quot;*&quot;, channel = &quot;channel-name&quot;&#125;即可。唯一要注意的是，channel-name必须在前面的channel中被定义过。 123456789[workspace]name = &quot;DEMO1&quot;version = &quot;1.1&quot;channels = [&quot;conda-forge&quot;, &quot;bioconda&quot;, &quot;dnachun&quot;]platforms = [&quot;linux-64&quot;][feature.label.dependencies]r-seurat = &#x27;5.2.*&#x27;r-SeuratDisk = &#123;version = &quot;*&quot;, channel = &quot;dnachun&quot;&#125; 这里r-SeuratDisk将从dnachun这个channel安装，而其他包仍使用channels列表中定义的默认顺序。 4. 混合使用PyPI依赖Conda生态提供了非常丰富的Python资源，但是一些冷门或特别前沿的包还是会找不到的，这时候可以额外指定Pypi来源的依赖。 在[pypi-options]中设置PyPI镜像，然后在[dependencies]中列出conda包，在[pypi-dependencies]中列出PyPI包。如果使用workspace模式，也可以在feature中使用[feature.xxx.pypi-dependencies]。 12345678910111213141516[project]name = &quot;DEMO1&quot;version = &quot;1.0&quot;channels = [&quot;conda-forge&quot;, &quot;bioconda&quot;]platforms = [&quot;linux-64&quot;][pypi-options]index-url = &quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;[dependencies]snakemake = &#x27;*&#x27;scanpy = &#x27;*&#x27;[pypi-dependencies]singler = &#x27;*&#x27;celldex = &#x27;*&#x27; 上述配置中，singler和celldex将通过PyPI安装，其余包通过conda安装。 5. 跨平台依赖管理在团队协作或CI&#x2F;CD中，我们可能需要在Linux‑64、Linux‑aarch64（我的Fydetab Duo是Arm架构的RK3588）运行同一套环境。Pixi可以针对不同平台指定不同的依赖版本，甚至在不同的平台使用不同的包来源，以满足特定的依赖（有些包Conda上只有Linux64）。 使用[target.&lt;platform&gt;.dependencies]节可以为特定平台定义依赖。同时，可以在[environments]中利用platforms字段限制环境支持的平台。 123456789101112131415[workspace]channels = [&quot;conda-forge&quot;]platforms = [&quot;linux-64&quot;, &quot;linux-aarch64&quot;][target.linux-64.dependencies]git = &#x27;*&#x27;git-subtree = &#x27;*&#x27;[feature.frontend.dependencies]nodejs = &#x27;18.*&#x27;pnpm = &#x27;*&#x27;[feature.frontend.tasks]front_init = &#123; cmd = &quot;pnpm install&quot;, cwd = &quot;app/Frontend_Admin&quot; &#125;front_build = &#123; cmd = &quot;pnpm run build:prod&quot;, depends-on=[&#x27;front_init&#x27;]&#125; 这里，git和git-subtree只在linux-64上安装；而frontend环境仅支持linux-64平台（例如某些前端工具链在ARM上可能不兼容）。 6. 子环境的环境变量设定某些工具需要在特定环境下设置环境变量（例如Node.js的NODE_OPTIONS、代理设置等）。Pixi允许在feature中通过[feature.xxx.activation.env]定义环境变量，这些变量会在进入该环境时自动设置。 1234567891011121314[workspace]channels = [&quot;conda-forge&quot;]platforms = [&quot;linux-64&quot;, &quot;linux-aarch64&quot;][environments]frontend = [&quot;frontend&quot;]test = [&quot;test&quot;][feature.frontend.activation.env]NODE_OPTIONS = &quot;--openssl-legacy-provider&quot;[feature.frontend.dependencies]nodejs = &#x27;18.*&#x27;pnpm = &#x27;*&#x27; 这样，当运行frontend环境中的任务时，NODE_OPTIONS环境变量会自动生效，避免一些Node.js版本兼容性问题。 总结通过以上六个典型案例，我们可以看到Pixi不仅仅是一个包管理器，更是一个统一的项目环境与任务协调中心。它用一份简洁的pixi.toml文件，解决了多语言、多平台、多阶段任务的依赖管理与自动化问题，大大降低了项目配置的复杂度和维护成本。目前我所有自己编写和接收维护的项目都用它来统一进行依赖管理和任务设置。唯一的限制是MySQL这种一定要系统级服务的工具不可能通过它来管理（不过用SQLite就是了，项目其实都不大…）","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"跨平台","slug":"跨平台","permalink":"https://silenwang.github.io/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/"},{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"Pixi","slug":"Pixi","permalink":"https://silenwang.github.io/tags/Pixi/"},{"name":"依赖管理","slug":"依赖管理","permalink":"https://silenwang.github.io/tags/%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"},{"name":"数据科学","slug":"数据科学","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"}]},{"title":"还是搞不懂_为什么taipy的on_action不嵌套一下就报错","slug":"还是搞不懂-为什么taipy的on-action不嵌套一下就报错","date":"2025-12-17T21:45:09.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2025/12/17/还是搞不懂-为什么taipy的on-action不嵌套一下就报错/","permalink":"https://silenwang.github.io/2025/12/17/%E8%BF%98%E6%98%AF%E6%90%9E%E4%B8%8D%E6%87%82-%E4%B8%BA%E4%BB%80%E4%B9%88taipy%E7%9A%84on-action%E4%B8%8D%E5%B5%8C%E5%A5%97%E4%B8%80%E4%B8%8B%E5%B0%B1%E6%8A%A5%E9%94%99/","excerpt":"我使用过的所有应用快速开发框架，清一色的都是将元素动作绑定到某个Python函数，从而触发信息的更新或者改变，所以应该还算比较有经验。但是Taipy这个的属实让我有点摸不着头脑，时不时的就会报错…","text":"我使用过的所有应用快速开发框架，清一色的都是将元素动作绑定到某个Python函数，从而触发信息的更新或者改变，所以应该还算比较有经验。但是Taipy这个的属实让我有点摸不着头脑，时不时的就会报错… 在 Taipy 中，当我们为 on_action（或 on_change）属性直接传递一个函数对象时，会很随机的遇到类似“函数不合法（function not valid）”的错误。例如，以下写法可能会报错： 12345tgb.table( ... on_action=update_prod_link, # 直接传递函数名 ...) 但是如果用匿名函数，就不会出现前述的问题，一切正常： 12345tgb.table( ... on_action=lambda s, v, p: update_prod_link(s, v, p), ...) 由于官方的例子都比较简单，都是写的匿名函数，Issue区也没有看到类似的问题反馈，目前阶段我也就只能这么脱裤子放屁了…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"taipy","slug":"taipy","permalink":"https://silenwang.github.io/tags/taipy/"},{"name":"callback","slug":"callback","permalink":"https://silenwang.github.io/tags/callback/"}]},{"title":"taipy中利用独立的html扩展出新的组件","slug":"taipy中利用独立的html扩展出新的组件","date":"2025-12-17T21:42:31.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2025/12/17/taipy中利用独立的html扩展出新的组件/","permalink":"https://silenwang.github.io/2025/12/17/taipy%E4%B8%AD%E5%88%A9%E7%94%A8%E7%8B%AC%E7%AB%8B%E7%9A%84html%E6%89%A9%E5%B1%95%E5%87%BA%E6%96%B0%E7%9A%84%E7%BB%84%E4%BB%B6/","excerpt":"我之前就在疑惑，Taipy看上去是在活跃维护的，用户看上去应该也不少（一堆用户提的Issue），但是它的组件库并不能算多么丰富，甚至有些基本的功能都小bug一堆（比如我之前发现的明暗切换按钮bug）。然后我无意间看到了官网上嵌入第三方内容的教程，我突然理解了，虽然它组组件少，但是他可以缝啊！","text":"我之前就在疑惑，Taipy看上去是在活跃维护的，用户看上去应该也不少（一堆用户提的Issue），但是它的组件库并不能算多么丰富，甚至有些基本的功能都小bug一堆（比如我之前发现的明暗切换按钮bug）。然后我无意间看到了官网上嵌入第三方内容的教程，我突然理解了，虽然它组组件少，但是他可以缝啊！ 为什么需要嵌入第三方组件Taipy 作为一个以 Python 为中心的 Web 应用框架，其内置的视觉元素（Visual Elements）已经能够覆盖很多常见的交互场景。但在实际项目中，总能轻松的从甲方那收到刚好在现有组件外的要求，这时候，我们只能自己想办法将这些内容“缝”进 Taipy 的页面里。 Taipy固然提供扩展当前Python组件的说明，但是为了一个用过即丢的小项目，实在没必要先写html&#x2F;js，然后准备好接口绑定到Taipy，然后再做测试、编译、重新安装… 如果真这么干，感觉完成组件前我就被老板开了… 幸运的是，Taipy 还提供了另外一种“缝”的机制，允许我们将任意 HTML + css + js 编写的页面直接在页面中渲染（其实就是弄了个iframe 套进去）。这个机制的核心就是 Gui.register_content_provider() 函数。 核心机制：register_content_providerGui.register_content_provider(type, provider_func) 接受两个参数： type：需要是一个Python类型（例如 folium.folium.Map） provider_func：一个回调函数，它接收一个该类型的对象，并返回一个 bytes 对象，这个 bytes 对象应当是该对象对应的 HTML 内容。 当 Taipy 在页面中遇到一个属于该类型的变量，并且这个变量被放在 part 组件的 content 属性中时，Taipy 就会自动调用你注册的 provider_func，将返回的 HTML 以 iframe 的方式嵌入页面中。 这样一来，只要能最终得到 HTML 文件 的内容 Taipy 就能进行渲染，显示在页面上。 官方给的例子是Folium地图对象，这个库与plotly类似，也是将多种地图的js库进行封装后，提供python api，完成绘制后，可以直接输出html页面，因此可以将生成的html内容直接嵌入到taipy中。 AI 带来了更强的扩展性如果是在两年前，Taipy的方案其实多少有些鸡肋，因为扩展功能最终还是要老老实实的编写Web那一套，违背通过Python快速开发的初衷。但是 LLM 当道，情况发生了极大的改变，现在各种 LLM 可以在极短的时间内生成一个可用的 Web 小组件，然后只需要稍微学习 Jinja2模板 ,就能快速的将数据和Web小组件连接起来，扩展Taipy的功能。虽然这不适用于要求功能特别复杂的情况，但是开发个原型程序绝对够用了。","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"taipy","slug":"taipy","permalink":"https://silenwang.github.io/tags/taipy/"},{"name":"html","slug":"html","permalink":"https://silenwang.github.io/tags/html/"}]},{"title":"实操写一个自动部署的github_action","slug":"实操写一个自动部署的github-action","date":"2025-12-17T01:44:13.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2025/12/17/实操写一个自动部署的github-action/","permalink":"https://silenwang.github.io/2025/12/17/%E5%AE%9E%E6%93%8D%E5%86%99%E4%B8%80%E4%B8%AA%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2%E7%9A%84github-action/","excerpt":"随着手上要维护的内容越来越多（3个官网，2个系统，1个小程序，全部是前后端分离且数据库独立的项目），出现了很多做1次不费事，但是穿插着做很多次非常乱的工作。我之前已经尝试过用Github进行 CI，这次学习和实践了一下 CD。","text":"随着手上要维护的内容越来越多（3个官网，2个系统，1个小程序，全部是前后端分离且数据库独立的项目），出现了很多做1次不费事，但是穿插着做很多次非常乱的工作。我之前已经尝试过用Github进行 CI，这次学习和实践了一下 CD。 个人维护多项目的痛点作为被迫单打独斗的打工人，我需要同时维护多个技术栈各异的项目。每个项目都有独立的代码库、构建流程和部署环境。以往的做法是：本地修改代码 → 手动运行构建脚本 → 通过 SCP 将产物上传到服务器 → 登录服务器执行替换和重启操作。这种流程重复性极高，且容易因操作遗漏或手误导致线上问题。 尤其是当修复一个紧急 bug 后，需要在多个项目间来回切换时，手动部署的耗时和心智负担会显著增加。因此，我希望将这套重复性的操作交给机器自动完成，从而让自己更聚焦于代码逻辑本身。 为什么需要 CD（持续部署）CI（持续集成）负责代码的自动化构建与测试，确保每次提交都是可运行的；而 CD（持续部署）则在此基础上，将通过测试的代码自动部署到生产或预览环境。对于需要频繁更新、多项目并行的团队，CD 能极大减少重复的手动操作，降低人为错误，让开发者更专注于功能开发。 当然，我不是这样的团队，我只有一个人，但如前所述，一个可用的 CD 工作流依然能让我免于进行机械的重复工作，将精力放到代码问题本身的修复上。 编写一个 GitHub Actions CD 工作流下面是我为维护的官网项目设计的部署工作流。它会在代码推送到 main 分支、且变更发生在 app/Official_Site/** 或 app/Official_Site_EN/** 目录时自动触发，同时也支持手动在 GitHub 界面点击运行（workflow_dispatch）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273name: DEPLOYon: push: branches: - main paths: # 只有此目录发生变化才触发 - &#x27;app/Official_Site/**&#x27; - &#x27;app/Official_Site_EN/**&#x27; workflow_dispatch:jobs: build: runs-on: ubuntu-latest strategy: matrix: environment: [website] steps: - name: Checkout repository uses: actions/checkout@v3 with: ref: main - name: Setup Pixi uses: prefix-dev/setup-pixi@v0.9.3 with: pixi-version: v0.59.0 environments: $&#123;&#123; matrix.environment &#125;&#125; - name: Build Website for ZH/EN run: | pixi run web_build mv app/Official_Site/dist front mv app/Official_Site_EN/dist front-en - name: Copy files ZH uses: appleboy/scp-action@v1 with: host: $&#123;&#123; vars.PROD_IP &#125;&#125; username: root password: $&#123;&#123; secrets.PROD_PASSWD &#125;&#125; port: 22 source: &quot;front&quot; target: /opt/project/uploadPath - name: Copy files EN uses: appleboy/scp-action@v1 with: host: $&#123;&#123; vars.PROD_IP &#125;&#125; username: root password: $&#123;&#123; secrets.PROD_PASSWD &#125;&#125; port: 22 source: &quot;front-en&quot; target: /opt/project/uploadPath - name: Deploy uses: appleboy/ssh-action@v1 with: host: $&#123;&#123; vars.PROD_IP &#125;&#125; username: root password: $&#123;&#123; secrets.PROD_PASSWD &#125;&#125; port: 22 script: | cd /opt/project rm -rf front.bak front-en.bak mv front front.bak mv front-en front-en.bak mv uploadPath/front front mv uploadPath/front-en front-en systemctl restart nginx 关键步骤说明 触发条件（on） push 到 main 分支且仅当指定目录有变动，避免无关提交触发构建。 workflow_dispatch 提供手动触发入口，方便在需要时立即部署。 代码检出（Checkout） 使用官方 actions/checkout 动作拉取代码，并指定 ref: main 确保构建基于最新提交。 依赖安装（构建产物（Build Website）） 采用 Pixi 作为跨语言包管理工具，这里用它内置的命令同时完成环境设置和静态网站构建 文件传输（SCP） 使用 appleboy/scp-action 将构建产物分别上传到服务器的临时目录 /opt/project/uploadPath。 服务器 IP 通过 vars.PROD_IP（项目变量）传递，密码则存放在 secrets.PROD_PASSWD（仓库机密）中，避免敏感信息暴露在代码里。 部署与回滚（SSH） 通过 appleboy/ssh-action 登录服务器执行替换操作。 关键逻辑：先将当前运行的 front 和 front-en 目录备份为 .bak 后缀，再从上传目录移入新版本，最后重启 Nginx。 备份操作提供了快速回滚的能力——只需将备份目录移回即可恢复上一版本。 总结通过这个简单的 GitHub Actions 工作流，我成功将静态官网的部署时间从每次约 10+ 分钟的手动操作压缩到 2‑3 分钟的自动执行，并且完全杜绝了因操作遗漏导致的问题。 CD 并不是大团队的专利，个人项目同样可以通过自动化获得显著的效率提升。如果你也在维护多个需要频繁更新的项目，不妨花一小时配置一套属于自己的持续部署流水线，相信它会给你的开发体验带来质的飞跃。","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"github action","slug":"github-action","permalink":"https://silenwang.github.io/tags/github-action/"},{"name":"CD","slug":"CD","permalink":"https://silenwang.github.io/tags/CD/"},{"name":"自动部署","slug":"自动部署","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/"}]},{"title":"对R中绘制的单细胞点图进行格栅化","slug":"对R中绘制的单细胞点图进行格栅化","date":"2025-12-17T01:08:35.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2025/12/17/对R中绘制的单细胞点图进行格栅化/","permalink":"https://silenwang.github.io/2025/12/17/%E5%AF%B9R%E4%B8%AD%E7%BB%98%E5%88%B6%E7%9A%84%E5%8D%95%E7%BB%86%E8%83%9E%E7%82%B9%E5%9B%BE%E8%BF%9B%E8%A1%8C%E6%A0%BC%E6%A0%85%E5%8C%96/","excerpt":"在生物信息学绘图中，我们经常需要处理包含成千上万个数据点的图形，例如单细胞RNA测序的散点图。这类图形在保存为PDF等矢量格式时会面临文件过大、渲染缓慢的问题（除了AI其他软件基本都会直接死机），因为矢量图会记录每个数据点的坐标、颜色、大小等属性，导致PDF文件包含大量对象，进而影响查看和编辑的效率。","text":"在生物信息学绘图中，我们经常需要处理包含成千上万个数据点的图形，例如单细胞RNA测序的散点图。这类图形在保存为PDF等矢量格式时会面临文件过大、渲染缓慢的问题（除了AI其他软件基本都会直接死机），因为矢量图会记录每个数据点的坐标、颜色、大小等属性，导致PDF文件包含大量对象，进而影响查看和编辑的效率。 相比之下，位图（如PNG、JPEG）将图像存储为像素矩阵，文件大小相对固定且渲染快速，但放大时会失真。结合两种格式的优点，我们可以对图形中数据密集的图层进行格栅化（rasterization），即只将特定图层转换为位图，同时保持其他图层（如坐标轴、文字标签）为矢量，从而在保证清晰度的前提下显著降低文件大小。 下面这段R代码展示了如何使用ggrastr包的rasterise函数对ggplot2体系的图形对象进行格栅化： 1234567891011121314151617library(ggrastr)library(scRNAtoolVis)# 绘制图形，任何会返回ggplot2对象的绘图函数原理一样 plot &lt;- jjVolcano( diffData = markerspbmc.markers, log2FC.cutoff = 0.5, col.type = &quot;adjustP&quot;, size = 3.5, fontface = &#x27;italic&#x27;)layers &lt;- plot$layers# 查看layers内容后，第三个图层是我想格栅化的点图layers[[3]] &lt;- rasterise(layers[[3]], dpi = 300)# 替换回 plotplot$layers &lt;- layers 这种方法特别适合用于单细胞点图、基因组浏览器图等大数据量的可视化场景，既能保留重要标注的矢量清晰度，又能让存下来的图形可被一般电脑编辑（当然如果你要编辑点本身、当我没说…","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"ggplot2","slug":"ggplot2","permalink":"https://silenwang.github.io/tags/ggplot2/"},{"name":"格栅化","slug":"格栅化","permalink":"https://silenwang.github.io/tags/%E6%A0%BC%E6%A0%85%E5%8C%96/"},{"name":"rasterization","slug":"rasterization","permalink":"https://silenwang.github.io/tags/rasterization/"}]},{"title":"git中的subtree与submodule","slug":"git中的subtree和submodule","date":"2025-12-06T01:49:33.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2025/12/06/git中的subtree和submodule/","permalink":"https://silenwang.github.io/2025/12/06/git%E4%B8%AD%E7%9A%84subtree%E5%92%8Csubmodule/","excerpt":"Emmmmm，今年官网供应商的合同到期了，于是… 多了一个项目要管… 这个项目依旧是前后端分离的，不同的是，官网有英文版本，且英文版本是前端项目的一个分支。我以前用过Submodule，以将同事写的独立模块整合到主项目中，但是这次我在跟AI请教后，选择了另外一种方式，Subtree","text":"Emmmmm，今年官网供应商的合同到期了，于是… 多了一个项目要管… 这个项目依旧是前后端分离的，不同的是，官网有英文版本，且英文版本是前端项目的一个分支。我以前用过Submodule，以将同事写的独立模块整合到主项目中，但是这次我在跟AI请教后，选择了另外一种方式，Subtree 快速比较：Submodule vs Subtree简单来说，Submodule 是在主仓库中创建一个指向子仓库特定提交的“链接”，而 Subtree 则是将子仓库的代码完全复制到主仓库的一个子目录中。两者各有优劣，下表可以帮助你快速了解它们的核心区别： 特性 Submodule Subtree 代码存放方式 主仓库仅保存子仓库的引用（commit hash） 子仓库的代码完全复制到主仓库中 克隆后是否需要额外初始化 需要 git submodule init &amp;&amp; git submodule update 无需额外操作，所有文件已就绪 在主项目中直接修改子项目代码 必须进入子模块目录单独提交，步骤繁琐 可直接在主仓库目录中修改并提交 历史记录 子仓库历史与主仓库完全分离 子仓库的历史可选择性地合并（--squash）或完整保留 适合场景 子项目相对稳定，更新频率低；多个主项目共享同一个子项目 需要频繁在主项目中修改子项目；需引入同一仓库的多个不同分支 简而言之，Subtree实际上是把子项目代码完整克隆了一份，修改后提交的时候是将主项目里产生的修改记录同步一份到子项目，而子项目被修改时，也可以将这些修改同步回主项目，而submodule实际上是软链接，主项目中只是指定用哪个版本的子项目代码，提交代码回子项目会相对麻烦一些。 对我而言，一方面，我想要将同一个仓库的两个不同分支（master 与 en）分别作为独立的子目录引入；另一方面，我实际需要频繁修改子项目的代码，主项目实际是对这前端后端的整合，根据AI的建议，Subtree是操作更简单的组合。 Subtree 的实际使用方式下面是我在主项目中添加各个子项目的具体命令。注意，我使用了 --squash 参数，它可以将子项目的历史提交合并为一个，避免主项目历史被过多的子项目提交淹没。 1. 添加远程仓库12git remote add Backend https://github.com/user/Backendgit remote add Frontend https://github.com/user/Frontend 2. 将子项目以 subtree 形式引入1234567# 中文网站（master 分支）git subtree add --prefix=app/Backend Backend master --squash# 英文站独立分支（en 分支）git subtree add --prefix=app/Backend_EN Backend en --squash# 后端管理项目git subtree add --prefix=app/Backend Backend_Admin aiming_med --squash 3. 日常同步操作 拉取子项目更新：git subtree pull --prefix=&lt;目录&gt; &lt;远程名&gt; &lt;分支&gt; --squash 推送主项目内对子项目的修改：git subtree push --prefix=&lt;目录&gt; &lt;远程名&gt; &lt;分支&gt; 当然为了简化操作，可以在Pixi中配置响应的命令 4. 注意事项 使用上述方式设置 subtree 后，子项目代码在本项目已有一份完整拷贝，因此，再次部署时，克隆主项目后无需再次运行 subtree add。 如果是为了开发而克隆，仍需添加远程仓库（如上第一步），以便后续推送更新信息到子项目。 后记实际使用了Subtree两周，除了踩到个Devcontainer的git没有subtree模块的坑，其他方面倒是运行良好… 希望不要有什么新问题吧…","categories":[{"name":"Other","slug":"Other","permalink":"https://silenwang.github.io/categories/Other/"}],"tags":[{"name":"版本控制","slug":"版本控制","permalink":"https://silenwang.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"git","slug":"git","permalink":"https://silenwang.github.io/tags/git/"},{"name":"subtree","slug":"subtree","permalink":"https://silenwang.github.io/tags/subtree/"},{"name":"submodule","slug":"submodule","permalink":"https://silenwang.github.io/tags/submodule/"}]},{"title":"pixi也可以在github_action中使用了","slug":"pixi也可以在github-action中使用了","date":"2025-12-06T01:43:09.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2025/12/06/pixi也可以在github-action中使用了/","permalink":"https://silenwang.github.io/2025/12/06/pixi%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%9C%A8github-action%E4%B8%AD%E4%BD%BF%E7%94%A8%E4%BA%86/","excerpt":"在 CI&#x2F;CD 流程中，依赖管理往往是决定构建效率与可靠性的关键因素。最近，我在一个静态网站部署流水线中尝试了 setup-pixi 这个 GitHub Action，","text":"在 CI&#x2F;CD 流程中，依赖管理往往是决定构建效率与可靠性的关键因素。最近，我在一个静态网站部署流水线中尝试了 setup-pixi 这个 GitHub Action， 为什么选择 Pixi？我最开始选择Pixi的时候，主要是出于因为它在使用 conda 的预编译资源基础上，具有比mamba更快的依赖计算速度，且能跟 nodejs 一样有依赖锁机制，适合进行快速的环境迁移部署，这些在软件经常变动的生物信息分析中都是非常需要的特性。 而在使用了一年多后，我不仅使用它管理生物信息分析的环境，也进一步用他来建立和管理开发环境，目前除了MySQL这种必须要系统常驻服务的没有办法处理外，Pixi完全可以安装所有我工作中需要用到的工具链。 使用单一的工具就可以进行各种工具链的管理，并且也内置简单的工作流设置，使用体验相当之好。 唯一的美中不足，就是之前根据领导要求使用Github Action做自动化的时候有那么一点点不便，因为 pixi 毕竟还是涉及虚拟环境，安装和运行的时候都需要进行一些额外的环境变量操作才能使用。 但是其实官方早就开发了setup-pixi action，只是我一致不知道而已… 在 GitHub Actions 中使用 setup-pixisetup-pixi 使用起来很简单，下面是一个例子： 123456789101112131415161718192021222324252627282930name: DEPLOYon: push: branches: - main workflow_dispatch:jobs: build: runs-on: ubuntu-latest strategy: matrix: environment: [website] steps: - name: Checkout repository uses: actions/checkout@v3 with: ref: main - name: Setup Pixi uses: prefix-dev/setup-pixi@v0.9.3 with: pixi-version: v0.59.0 environments: $&#123;&#123; matrix.environment &#125;&#125; - name: Run Pixi Task run: | pixi run build 步骤解析 Checkout repository：使用 actions/checkout 获取最新代码，需要在 Setup Pixi 之前，毕竟 pixi.toml 和 pixi.lock 在项目里； Setup Pixi：prefix-dev/setup-pixi Action 会下载并安装指定版本的 Pixi，并自动激活我们在matrix 中指定，并在 pixi.toml 中定义过的环境（本例中的 website 环境）； Run Pixi Task：有了环境，就可以任意调用项目中已经定义过的task了。 整个过程简洁清晰，Pixi 环境保证了构建阶段依赖的一致性，一切交给它，定义一次，就不需要再做其他的设置了。 小结通过在 GitHub Actions 中利用 setup-pixi，我们可以轻松地使用 pixi 的强大依赖管理能力，简化配置过程，减少人工设置的时间，并保证了从开发到生产环境的高度一致。","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"},{"name":"github action","slug":"github-action","permalink":"https://silenwang.github.io/tags/github-action/"}]},{"title":"又踩坑了--plotly的scattermap不能对大部分marker图标设置颜色","slug":"又踩坑了-plotly的scattermap不能对大部分marker图标设置颜色","date":"2025-12-02T15:20:39.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2025/12/02/又踩坑了-plotly的scattermap不能对大部分marker图标设置颜色/","permalink":"https://silenwang.github.io/2025/12/02/%E5%8F%88%E8%B8%A9%E5%9D%91%E4%BA%86-plotly%E7%9A%84scattermap%E4%B8%8D%E8%83%BD%E5%AF%B9%E5%A4%A7%E9%83%A8%E5%88%86marker%E5%9B%BE%E6%A0%87%E8%AE%BE%E7%BD%AE%E9%A2%9C%E8%89%B2/","excerpt":"啊, 没想到plotly这么多年了, 还是稍微一用就能触到它的能力边界, 之前是画不了时间轴图, 这次又发现地图的Marker自定义程度不够…","text":"啊, 没想到plotly这么多年了, 还是稍微一用就能触到它的能力边界, 之前是画不了时间轴图, 这次又发现地图的Marker自定义程度不够… 我需要用plotly带的Scattermap对象绘制一个地图, 地图上需要设置一些标点. 然后需求方看了第一版, 觉得想用地图上常见的反水滴形图标来代替默认的圆形. 正好Scattermap支持, 于是我这么写: 123456789101112131415161718map_fig = ( go.Figure() .add_trace( go.Scattermap( lat = Lat, lon = Lon, mode = &#x27;markers&#x27;, marker = dict( size = 12, color = AIMINGMED_COLOR[&#x27;AIMING_RED&#x27;], opacity = 0.5, symbol = &#x27;marker&#x27;, allowoverlap = True ), hoverinfo = &#x27;none&#x27; ) )) 结果发现, 图标虽然能自定义, 但是并不能变色… 于是又是一番查找, 最后又发现了一个去年的Issue, 这里面给了很绝望的答案, plotly到目前为止就是不支持这个改变, 因为它调用的是maki-icons, 这里面的图标是固定黑色的, 也没有提供通过请求改颜色的接口. 这个问题的等级是P3, 也就是… 排上日程, 但是最不重要的那一级别… 又是个猴年马月的东西了… 但是我可不能等, 我又折磨了Copilot一上午, 最后得到的了一个更绝望的答案, plotly.py只是plotly.js的一个包装, 只负责将数据和参数按照要求整理好, 实际的绘制完全由plotly.js实现, 也就是说, 如果我要修复这个问题, 我又要看JS代码, 并且不是修改了就好, 我还要把JS部分的接口写出来, 然后再跟Python的部分对接上… 这… 不是不行, 但是我时间不够… 于是我又一排脑门想邪门办法了, 根据观察, plotly.js实际上会通过https请求图标的svg文件, 然后用这个文件进行绘图, 那… 有没有可能, 我靠油猴脚本, 拦截这个请求, 塞我准备好的svg文件给他呢? 这次是chatGPT救我狗命了, deepseek完败… chatGPT确实给我了我一个能够拦截并替换svg文件的脚本: 1234567891011121314151617181920212223242526272829303132333435363738394041// ==UserScript==// @name Intercept Mapbox Maki Icon via Image.src// @namespace http://tampermonkey.net/// @version 1.0// @description 拦截 Mapbox 图标请求并替换成自定义 SVG// @match *://*/*// @run-at document-start// @grant none// ==/UserScript==(function() &#123; &#x27;use strict&#x27;; const TARGET_PREFIX = &quot;https://unpkg.com/maki@2.1.0/icons/&quot;; const CUSTOM_SVG_CONTENT = `&lt;svg version=&quot;1.1&quot; id=&quot;svg4619&quot; inkscape:version=&quot;0.91 r13725&quot; sodipodi:docname=&quot;marker-15.svg&quot; xmlns:cc=&quot;http://creativecommons.org/ns#&quot; xmlns:dc=&quot;http://purl.org/dc/elements/1.1/&quot; xmlns:inkscape=&quot;http://www.inkscape.org/namespaces/inkscape&quot; xmlns:rdf=&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot; xmlns:sodipodi=&quot;http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd&quot; xmlns:svg=&quot;http://www.w3.org/2000/svg&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; x=&quot;0px&quot; y=&quot;0px&quot; width=&quot;15px&quot; height=&quot;15px&quot; viewBox=&quot;0 0 15 15&quot; style=&quot;enable-background:new 0 0 15 15;&quot; xml:space=&quot;preserve&quot;&gt;&lt;path id=&quot;path4133&quot; inkscape:connector-curvature=&quot;0&quot; d=&quot;M7.5,0C5.0676,0,2.2297,1.4865,2.2297,5.2703 C2.2297,7.8378,6.2838,13.5135,7.5,15c1.0811-1.4865,5.2703-7.027,5.2703-9.7297C12.7703,1.4865,9.9324,0,7.5,0z&quot; fill=&quot;#E72410&quot;/&gt;&lt;/svg&gt;`; const CUSTOM_SVG_URL = &quot;data:image/svg+xml;base64,&quot; + btoa(CUSTOM_SVG_CONTENT); // 劫持 Image.src Object.defineProperty(Image.prototype, &quot;src&quot;, &#123; set(url) &#123; if (typeof url === &quot;string&quot; &amp;&amp; url.startsWith(TARGET_PREFIX)) &#123; console.log(&quot;[Tampermonkey] 拦截 Mapbox 图标: &quot;, url); url = CUSTOM_SVG_URL; &#125; this.setAttribute(&quot;src&quot;, url); &#125;, get() &#123; return this.getAttribute(&quot;src&quot;); &#125; &#125;);&#125;)(); 总算是… 先实现了, 之后的问题, 之后再说吧哎, 继续加班了…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"taipy","slug":"taipy","permalink":"https://silenwang.github.io/tags/taipy/"},{"name":"scattermap","slug":"scattermap","permalink":"https://silenwang.github.io/tags/scattermap/"}]},{"title":"大家的想法还真是一样的--读devpod代码有感","slug":"大家的想法还真是一样的","date":"2025-12-01T22:27:29.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2025/12/01/大家的想法还真是一样的/","permalink":"https://silenwang.github.io/2025/12/01/%E5%A4%A7%E5%AE%B6%E7%9A%84%E6%83%B3%E6%B3%95%E8%BF%98%E7%9C%9F%E6%98%AF%E4%B8%80%E6%A0%B7%E7%9A%84/","excerpt":"在使用devpod一小段时间后, 我确定, 我还是需要一个能不依赖容器, 直接通过ssh在宿主机上自动安装vscode, 然后把端口转发回来的工具. 于是我开始白嫖Copilot来给我解释devpod的代码…","text":"在使用devpod一小段时间后, 我确定, 我还是需要一个能不依赖容器, 直接通过ssh在宿主机上自动安装vscode, 然后把端口转发回来的工具. 于是我开始白嫖Copilot来给我解释devpod的代码… 然后, 在拷问Copilot一段时间后, 我开始和我的前室友一样, 被AI气的不轻, 给的解释很少有对的, 然后给的运行示例更是一个也运行不了… 最后回到了最基础的, 给一个文件, 一点点给我解释里头有哪些对象, 有什么方法, 我能怎么用(只是少了我自己复制代码到对话框这一步)… 在一点点的看了几个周末后, 再次发现, 果然是想法人人有, 就看谁有能力执行… 之前没有找到devpod, 我想自己从头写一个程序来快速安装vscode的时候, 我编写边总结出来需要实现的内容有: 程序通过ssh登录远程机器, 检测远程机器是否安装过vscode, 没有则机器上下载vscode 由于通过ssh执行命令完成前1点很麻烦, 所以将上述功能写到主程序里, 然后给主程序设置一个上传自己的功能, 将程序本身复制到远程机器, 然后校验md5 由于远程机器的架构可能是x86可能是arm, 项目编译的时候需要一次性编译出所有架构的可执行文件, 方便直接从本地传到远程去 程序需要能转发远程机器端口到本地, 使用宿主机的ssh程序可能存在不兼容, 需要用golang下的ssh实现来完成 然后我发现, 我想到的这些, devpod都干了… vscode安装支持: devpod不只支持openvscode, 还支持安装所有常用的web ide, 其中甚至有rstudio 上传自己到远程: devpod在远程宿主机和容器workspace中都会放一份自己的可执行文件, 接收客户端发送的子命令, 并通过 agent 子命令来完成要执行的各种子命令 远程机器的多种架构支持: 这个倒是没有在本地放不同架构的可执行文件, 但是会检测远程主机的架构, 下载对应架构的 devpod 使用golang的ssh实现: 端口转发部分使用了golang.org/x/crypto/ssh 当然, 即使devpod已经有这么多现成的接口和示例了, 我要基于它做二次开发也不是一件简单的事情… 首要的障碍就是, golang作为静态语言, 对我来说还是有很多习惯上的不适应的, 毕竟我常用的无一例外都是弱类型的偏脚本语言, 很多golang的东西, 真是不太能理解… 另外就是, 它的语法, 跟我熟悉的语言还是很不一样的… 甚至我觉得比C#与python的差异都更大, 许多内容不能靠猜, 在AI也经常不给力的情况下, 理解内容还是相当慢的…(甚至应该伴随着挺多理解错误的) 希望我能坚持到, 弄出一个基本的demo, 祝我好运…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"devpod","slug":"devpod","permalink":"https://silenwang.github.io/tags/devpod/"},{"name":"golang","slug":"golang","permalink":"https://silenwang.github.io/tags/golang/"}]},{"title":"对发现bug的R函数进行热修复","slug":"对发现bug的R函数进行热修复","date":"2025-11-26T21:54:29.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2025/11/26/对发现bug的R函数进行热修复/","permalink":"https://silenwang.github.io/2025/11/26/%E5%AF%B9%E5%8F%91%E7%8E%B0bug%E7%9A%84R%E5%87%BD%E6%95%B0%E8%BF%9B%E8%A1%8C%E7%83%AD%E4%BF%AE%E5%A4%8D/","excerpt":"短时间内，我碰到两次需要修复R函数Bug的情况了，也顺便学习了一下如何进行热替换…","text":"短时间内，我碰到两次需要修复R函数Bug的情况了，也顺便学习了一下如何进行热替换… 为什么需要热修复？在数据分析项目中，时间往往是关键因素。如果依赖的R包函数存在bug，可能会阻塞整个分析流程。虽然说向包维护者报告bug并帮助修复是最能回馈开源社区的方式，但是… 其实你总不可能跟老板说，我已经跟作者反馈Bug了，猴年马月之后，我们就能等到正确结果啦！ 所以自己找到问题，并进行热修复更实际一些。 最基本的修复–替换据我这些年的使用经验，R虽然支持对象，但是真这么用的并不多，至少大多数生物信息的包还是函数式的，因此，最简单的思路，哪个函数出问题，用修改后的函数替换就是。 首先，我们可以定位到要修复的函数，然后print(YOUR_FUNCTION)，这样就能得到你目前工作环境中，对应函数的代码了。 当然，有些时候我们要修复的函数并不是包内导出的给用户使用的函数，可能是包的内部函数，这时需要用包名+:::+函数名来获得代码。 在对函数做了修改之后，直接&lt;-盖掉原来的函数，就能完成修改了。比如我给Azimuth那个问题的方案，就是直接改函数这么替换。 修改函数后，进行命名空间设置当然大部分函数并不能真像上面那样那么简单就完成修复，因为大多数函数不是孤立的，它可能要在原包内调用其他函数，也可能它是一个不导出的内置函数，这样子在当前命名空间下完成替换，并不能起效，还要替换对应包命名空间下的原函数，步骤如下： R提供了assignInNamespace函数，允许我们替换包命名空间中的对象。 用assignInNamespace设置函数的环境为包的命名空间 将修改后的函数赋值回包的命名空间 实际操作起来很简单： 12345678910# 写好修改的函数createOncoMatrix &lt;- function( print(&#x27;Mod！&#x27;))# 设置函数环境为包的命名空间environment(createOncoMatrix) &lt;- asNamespace(&quot;maftools&quot;)# 将修改后的函数替换回包的命名空间assignInNamespace(&quot;createOncoMatrix&quot;, createOncoMatrix, ns = &quot;maftools&quot;) 后记虽然记录了热修复方案，单我还是更希望，不要再让我遇上这种问题了… 30分钟的分析变成一下午的Debug…","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"Debug","slug":"Debug","permalink":"https://silenwang.github.io/tags/Debug/"}]},{"title":"为了复现结果，需要一并复现bug","slug":"为了复现结果一并复现bug","date":"2025-11-26T21:11:53.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/11/26/为了复现结果一并复现bug/","permalink":"https://silenwang.github.io/2025/11/26/%E4%B8%BA%E4%BA%86%E5%A4%8D%E7%8E%B0%E7%BB%93%E6%9E%9C%E4%B8%80%E5%B9%B6%E5%A4%8D%E7%8E%B0bug/","excerpt":"只要活的够久，就会见到足够多的囧事情。","text":"只要活的够久，就会见到足够多的囧事情。 跟客户合作的一篇文章需要小修，我们需要根据审稿人的意见补充一些展示WES状况的图，由于之前负责的同事已经离职了，这项工作自然交给我了… 但是就像大部分半路接收的工作一样，拿到数据，一跑，结果不出所料的，跟文章里的图不一样。 需要绘制的是maftools产生的oncoplot，大概选择了20+个基因来展示配对样本的突变一致性，然而同样的文件，我画出来的突变类型跟前同事提供的基本都对不上。相比前同事的版本，我的图里Splice_Site消失了，同时虽然都检出突变，但是我的版本显示出大量的MultiHit，但是前同事的版本却基本都是每个基因单突变类型。 遂查看了原始文件，发现原始文件中确实有Splice_Site，所以判断是我的版本有问题，再次开始翻Github的Issue，经过一段折腾，没想到，涉及了2个bug，一个是我版本里的，另一个，是前同事的… 背景补充首先补充一下，软件版本的差异。 前同事是使用个人电脑分析的，自行装的R和Rstudio，版本反正不可考了。我这边入职的是有已经购置了服务器，所以一直是使用服务器分析。然后因为我按照Pixi的原设计逻辑，一项目一配置，且我跨项目不保留pixi.lock，pixi.toml中除非有兼容性问题，并不限定版本，所以我用的包都会是依赖满足范围内，bioconda上有的最新版本。目前maftools在上面更新到2.22。 再然后是输入文件的情况，现在的单位使用的是ANNOVAR（跳槽了一圈又回到ANNOVAR了） Splice_Site解析问题追溯我的版本中，Splice_Site的丢失情况，可以发现，是将ANNOVAR结果中的突变类型，映射成MAF对应的类型时出的问题，具体见下： 12345678910111213141516171819202122232425262728ann[, `:=`(Hugo_Symbol, unlist(data.table::tstrsplit(Gene.refGene, split = &quot;;&quot;, keep = 1)))]annovar_values = c(exonic = &quot;RNA&quot;, splicing = &quot;Splice_Site&quot;, UTR5 = &quot;5&#x27;UTR&quot;, UTR3 = &quot;3&#x27;UTR&quot;, intronic = &quot;Intron&quot;, upstream = &quot;5&#x27;Flank&quot;, downstream = &quot;3&#x27;Flank&quot;, intergenic = &quot;IGR&quot;, `frameshift insertion` = &quot;Frame_Shift_Ins&quot;, `frameshift deletion` = &quot;Frame_Shift_Del&quot;, `frameshift block substitution` = &quot;Frameshift_INDEL&quot;, `frameshift substitution` = &quot;Frameshift_INDEL&quot;, stopgain = &quot;Nonsense_Mutation&quot;, stoploss = &quot;Nonstop_Mutation&quot;, startloss = &quot;Translation_Start_Site&quot;, startgain = &quot;Unknown&quot;, `nonframeshift insertion` = &quot;In_Frame_Ins&quot;, `nonframeshift deletion` = &quot;In_Frame_Del&quot;, `nonframeshift block substitution` = &quot;Inframe_INDEL&quot;, `nonframeshift substitution` = &quot;Inframe_INDEL&quot;, `nonsynonymous SNV` = &quot;`Missense`_Mutation&quot;, `synonymous SNV` = &quot;Silent&quot;, unknown = &quot;Unknown&quot;, ncRNA_exonic = &quot;RNA&quot;, ncRNA_intronic = &quot;RNA&quot;, ncRNA_UTR3 = &quot;RNA&quot;, ncRNA_UTR5 = &quot;RNA&quot;, ncRNA = &quot;RNA&quot;, ncRNA_splicing = &quot;RNA&quot;)ann[, `:=`(Func.refGene, unlist(data.table::tstrsplit(x = as.character(Func.refGene), split = &quot;;&quot;, keep = 1)))]ann[, `:=`(ExonicFunc.refGene, unlist(data.table::tstrsplit(x = as.character(ExonicFunc.refGene), split = &quot;;&quot;, keep = 1)))]ann$Variant_Classification = ifelse( # 出问题的地方在这里，这里的逻辑是： # 当ExonicFunc.refGene不存在数值时，使用Func.refGene数值带入命名向量以进行映射， # 否则使用ExonicFunc.refGene带入映射。但是，根据ANNOVAR的文档，进行注释时一般都会 # 加上 `-nasting .`，即用点号表示缺失，因此ExonicFunc.refGene根本不会缺失 is.na(ann$ExonicFunc.refGene), annovar_values[ann$Func.refGene], annovar_values[ann$ExonicFunc.refGene] ) 经过上面描述的问题，由于ExonicFunc.refGene根本不会缺失，所有ExonicFunc.refGene为缺失的变异，其实也就是外显子区域以外的变异，都会因为Variant_Classification映射出缺失值被过滤掉，体现出来的效果就是，这些突变解析后全部不见了。 所以修复也很简单，额外判断一下.，或者前面fread读取的时候指定.是缺失就行了。 123456ann$Variant_Classification = ifelse( # 我选择直接改判断 is.na(ann$ExonicFunc.refGene) | ann$ExonicFunc.refGene == &quot;.&quot;, annovar_values[ann$Func.refGene], annovar_values[ann$ExonicFunc.refGene] ) 这个问题追溯起来，其实不一定是maftools的原因，我往前倒了好多个版本，没见这个地方有修改，说不定是fread改了默认的nastring参数…反正我的问题解决了，我也不继续追了… MultiHit解析问题这个问题是源自一个有Issue的问题了。简单来说就是，maftools的老版本中，MultiHit的逻辑有问题。MultiHit想展示的，是一个基因发生两个不同的改变氨基酸的突变（Missense + Missense &#x3D; MultiHit）。但是老版本中，实际上同一个基因发生不同类型的突变才会是MultiHit，如果都是Missense突变，则会直接显示Missense。 在我使用的最新版本中，这个问题已经被修复，因此我的结果中出现了大量的MultiHit… 那…能怎么办呢，对着Issue的修改，把Bug复现出来呗… 后记前两天才吐槽过，Azimuth的Bug，我真没想到这么快，用过好多次的maftools也会有问题。 只能说敝人不只是天煞孤星，还是特么是扫把星…","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"maftools","slug":"maftools","permalink":"https://silenwang.github.io/tags/maftools/"}]},{"title":"出身豪门也还是会坑--Azimuth也是Bug成堆","slug":"出身豪门也还是会坑","date":"2025-11-22T23:00:37.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2025/11/22/出身豪门也还是会坑/","permalink":"https://silenwang.github.io/2025/11/22/%E5%87%BA%E8%BA%AB%E8%B1%AA%E9%97%A8%E4%B9%9F%E8%BF%98%E6%98%AF%E4%BC%9A%E5%9D%91/","excerpt":"从事生物信息分析，研究方向越前沿，就要面临越多来自信息侧的问题。即使是文章发的非常好，原作者共享了代码，甚至写了现成软件工具，也不代表我们能轻松顺利的用这些现成的东西来复现或进行研究，混乱的环境设置只是一方面，更多时候，由于软件作者并不是专业的软件工程师，工具功能大致能用已经谢天谢地了，不能奢望这些软件没有一点毛病，更不能奢望有性能可言（除非开发时性能被来就是开发点）。即使这工具来自于有实力的大实验室，很多时候也不能幸免，比如… Azimuth。","text":"从事生物信息分析，研究方向越前沿，就要面临越多来自信息侧的问题。即使是文章发的非常好，原作者共享了代码，甚至写了现成软件工具，也不代表我们能轻松顺利的用这些现成的东西来复现或进行研究，混乱的环境设置只是一方面，更多时候，由于软件作者并不是专业的软件工程师，工具功能大致能用已经谢天谢地了，不能奢望这些软件没有一点毛病，更不能奢望有性能可言（除非开发时性能被来就是开发点）。即使这工具来自于有实力的大实验室，很多时候也不能幸免，比如… Azimuth。 Azimuth 介绍Azimuth是由Satija实验室开发的单细胞数据注释工具，旨在简化 Seurat 中的 Label Transfer 流程，快速的对待分型细胞进行 Label Transfer。 问题描述在当前最新的 0.5.0 版本中， 在Jupyter Notebook 中运行 AzimuthReference 会提示 Error in ValidateAzimuthReference(object = object): Reference must contain an AzimuthData object in the tools slot. 谷歌一搜，发现该问题在2024年4月就已经被提出（issue #219）了，提出问题的用户已经给了解决方案，但这个Issue至今开放，且问题仍未被解决（上周又有用户反馈遇到同样的问题）。 解决思路如前所述，Issue发起人zacharyrs已经提到了问题所在，在b1b6895这个提交中，代码作者使用sys.calls()来判断当前调用的函数名称，并根据这个名称来判断后续处理。 1234567891011121314tool.name &lt;- as.character(x = sys.calls()) # &lt;-- 这里的sys.calls()会返回一个list，如果不是直接调用AzimuthReference，就会删除对象中的一些信息tool.name &lt;- lapply( X = strsplit(x = tool.name, split = &quot;(&quot;, fixed = TRUE), FUN = &quot;[&quot;, 1)[[1]]if (tool.name != &quot;AzimuthReference&quot;) &#123; slot(object, name = &quot;tools&quot;)[&quot;AzimuthReference&quot;] &lt;- slot(object, name = &quot;tools&quot;)[tool.name] slot(object, name = &quot;tools&quot;)[tool.name] &lt;- NULL&#125;object &lt;- DietSeurat(object = object, counts = FALSE, assays = c(&quot;refAssay&quot;, assays), dimreducs = c(&quot;refDR&quot;, &quot;refUMAP&quot;)) 然而实际上我们很多时候需要将AzimuthReference包到函数里使用，这时候，sys.calls() 返回的list中，第一项内容是最外侧的函数名称，这样就会导致Azimuth运行需要的数据被删除，下面的检查就会报错了。 对于我的情况来说，我也是第一次知道，notebook中所有的代码都是包在IRKernel的函数下的（感谢AI给了我排查方法），所以即使我笔记中直接运行AzimuthReference，也会发生将AzimuthReference放在函数中运行时才触发的错误。 处理也很简单，修改这里的判断，sys.calls()返回list后，去最后一项，再做正则取函数名就行： 12call_list &lt;- sys.calls()tool.name &lt;- as.character(x = call_list[[length(call_list)]]) 在我们的实际代码中，则可以加载Azimuth后，自行用修改后的函数去覆盖原来的AzimuthReference，这样后续代码就能运行了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091library(Azimuth)AzimuthReference &lt;- function (object, refUMAP = &quot;umap&quot;, refDR = &quot;spca&quot;, refAssay = &quot;SCT&quot;, dims = 1:50, k.param = 31, plotref = &quot;umap&quot;, plot.metadata = NULL, ori.index = NULL, colormap = NULL, assays = NULL, metadata = NULL, reference.version = &quot;0.0.0&quot;, verbose = FALSE) &#123; if (!refUMAP %in% Reductions(object = object)) &#123; stop(&quot;refUMAP (&quot;, refUMAP, &quot;) not found in Seurat object provided&quot;) &#125; if (is.null(x = Misc(object = object[[refUMAP]], slot = &quot;model&quot;))) &#123; stop(&quot;refUMAP (&quot;, refUMAP, &quot;) does not have the umap model info stored. &quot;, &quot;Please rerun RunUMAP with return.model = TRUE.&quot;) &#125; if (!refDR %in% Reductions(object = object)) &#123; stop(&quot;refDR (&quot;, refDR, &quot;) not found in Seurat object provided&quot;) &#125; if (is.null(x = metadata)) &#123; stop(&quot;Please specify at least one metadata field (for transfer and plotting).&quot;) &#125; for (i in metadata) &#123; if (!i %in% colnames(x = object[[]])) &#123; warning(i, &quot; not found in Seurat object metadata&quot;) next &#125; if (!is.factor(x = object[[i, drop = TRUE]])) &#123; warning(i, &quot; is not a factor. Converting to factor with alphabetical &quot;, &quot;levels.&quot;, call. = FALSE) object[[i, drop = TRUE]] &lt;- factor(x = object[[i, drop = TRUE]], levels = sort(x = unique(object[[i, drop = TRUE]]))) &#125; &#125; if (!refAssay %in% Assays(object = object)) &#123; stop(&quot;Seurat object provided must have the SCT Assay stored.&quot;) &#125; if (!inherits(x = object[[refAssay]], what = &quot;SCTAssay&quot;)) &#123; stop(&quot;refAssay (&quot;, refAssay, &quot;) is not an SCTAssay.&quot;) &#125; if (length(x = levels(x = object[[refAssay]])) != 1) &#123; stop(&quot;refAssay (&quot;, refAssay, &quot;) should contain a single SCT model.&quot;) &#125; suppressWarnings(expr = object[[&quot;refUMAP&quot;]] &lt;- object[[refUMAP]]) suppressWarnings(expr = object[[&quot;refDR&quot;]] &lt;- object[[refDR]]) object &lt;- FindNeighbors(object = object, reduction = &quot;refDR&quot;, dims = dims, graph.name = &quot;refdr.annoy.neighbors&quot;, k.param = k.param, nn.method = &quot;annoy&quot;, annoy.metric = &quot;cosine&quot;, cache.index = TRUE, return.neighbor = TRUE, l2.norm = FALSE, verbose = verbose) if (verbose) &#123; message(&quot;Computing pseudobulk averages&quot;) &#125; features &lt;- rownames(x = Loadings(object = object[[&quot;refDR&quot;]])) plot.metadata &lt;- plot.metadata %||% object[[metadata]] if (inherits(x = plotref, what = &quot;DimReduc&quot;)) &#123; plot.metadata &lt;- plot.metadata[Cells(x = plotref), ] &#125; ad &lt;- CreateAzimuthData(object = object, plotref = plotref, plot.metadata = plot.metadata, colormap = colormap, reference.version = reference.version) ori.index &lt;- ori.index %||% match(Cells(x = object), Cells(x = object[[&quot;refUMAP&quot;]])) object$ori.index &lt;- ori.index DefaultAssay(object = object) &lt;- refAssay object[[refAssay]] &lt;- subset(x = object[[refAssay]], features = features) DefaultAssay(object = object[[&quot;refDR&quot;]]) &lt;- refAssay object &lt;- DietSeurat(object = object, counts = FALSE, assays = c(refAssay, assays), dimreducs = c(&quot;refDR&quot;, &quot;refUMAP&quot;)) metadata &lt;- c(metadata, &quot;ori.index&quot;) for (i in colnames(x = object[[]])) &#123; if (!i %in% metadata) &#123; object[[i]] &lt;- NULL &#125; &#125; sct.model &lt;- slot(object = object[[refAssay]], name = &quot;SCTModel.list&quot;)[[1]] object[[&quot;refAssay&quot;]] &lt;- as(object = suppressWarnings(Seurat:::CreateDummyAssay(assay = object[[refAssay]])), Class = &quot;SCTAssay&quot;) slot(object = object[[&quot;refAssay&quot;]], name = &quot;SCTModel.list&quot;) &lt;- list(refmodel = sct.model) DefaultAssay(object = object) &lt;- &quot;refAssay&quot; DefaultAssay(object = object[[&quot;refDR&quot;]]) &lt;- &quot;refAssay&quot; Tool(object = object) &lt;- ad call_list &lt;- sys.calls() # use the last element of sys.call() to get the right function name tool.name &lt;- as.character(x = call_list[[length(call_list)]]) # use the last element of sys.call() to get the right function name tool.name &lt;- lapply(X = strsplit(x = tool.name, split = &quot;(&quot;, fixed = TRUE), FUN = &quot;[&quot;, 1)[[1]] if (tool.name != &quot;AzimuthReference&quot;) &#123; slot(object, name = &quot;tools&quot;)[&quot;AzimuthReference&quot;] &lt;- slot(object, name = &quot;tools&quot;)[tool.name] slot(object, name = &quot;tools&quot;)[tool.name] &lt;- NULL &#125; object &lt;- DietSeurat(object = object, counts = FALSE, assays = c(&quot;refAssay&quot;, assays), dimreducs = c(&quot;refDR&quot;, &quot;refUMAP&quot;)) ValidateAzimuthReference(object = object) return(object)&#125; Azimuth感觉被放弃了虽然出自Satija实验室，但总感觉这个项目基本已经被放弃了，github上有近百个开放Issue，去年开始提的PR到现在还有5个未合并也未拒绝。最近他们又弄了个基于Python和深度学习的通用细胞类型Label Transfer项目，感觉是研究进入下一步，老的项目就不准备维护了。 况且要进行Label Transfer，也可以自己跟着教程一步步做，不是非要用Azimuth，也许再过段时间，这个项目就会被Archieve了吧…","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"生物信息","slug":"生物信息","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF/"},{"name":"单细胞","slug":"单细胞","permalink":"https://silenwang.github.io/tags/%E5%8D%95%E7%BB%86%E8%83%9E/"},{"name":"开源软件","slug":"开源软件","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6/"},{"name":"软件维护","slug":"软件维护","permalink":"https://silenwang.github.io/tags/%E8%BD%AF%E4%BB%B6%E7%BB%B4%E6%8A%A4/"}]},{"title":"从一个讲RISC-V的视频想到的","slug":"从一个讲riscv的视频想到","date":"2025-11-22T22:22:47.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/11/22/从一个讲riscv的视频想到/","permalink":"https://silenwang.github.io/2025/11/22/%E4%BB%8E%E4%B8%80%E4%B8%AA%E8%AE%B2riscv%E7%9A%84%E8%A7%86%E9%A2%91%E6%83%B3%E5%88%B0/","excerpt":"我一直有下班骑车路上听视频的习惯，这周听到了差评讲 RISC-V 的视频。视频中提到一个观点：RISC-V 作为一种指令集架构，基于它的芯片产品存在严重的碎片化问题，导致应用生态发展面临很大困难，因此必须解决碎片化问题，通过统一标准才能实现快速发展。这个观点让我联想到多年来使用 Linux、安卓以及 R 语言的经历，我觉得视频中的说法可能并不完全准确。","text":"我一直有下班骑车路上听视频的习惯，这周听到了差评讲 RISC-V 的视频。视频中提到一个观点：RISC-V 作为一种指令集架构，基于它的芯片产品存在严重的碎片化问题，导致应用生态发展面临很大困难，因此必须解决碎片化问题，通过统一标准才能实现快速发展。这个观点让我联想到多年来使用 Linux、安卓以及 R 语言的经历，我觉得视频中的说法可能并不完全准确。 如果真如视频中所说，碎片化问题会对技术推广产生严重阻碍，那么很难解释为何 Linux 在服务器领域的市场份额能够远超 Windows，安卓系统能够在全球移动设备市场占据自己的地位，以及 R 语言在统计计算领域的发展甚至对 SAS 等商业软件构成了强有力的竞争。 个人认为，”碎片化”这个词往往被用来强调开源技术的负面特性。很多讨论在关注这个问题时，过于放大”碎片化”的负面影响，而选择性忽视了开源技术核心的”自由”价值——即便是 GPL 协议所定义的”有限自由”。 正是这种自由度，使得有兴趣但缺乏资金和资源的人才能够参与进来，最大限度地汇集众人智慧，推动技术进步。 我详细RISC-V之后会像其他开源技术一样以超出预期的速度发展，尤其在这个保不齐哪天商业技术说不能用就不能用了的时代…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"RISC-V","slug":"RISC-V","permalink":"https://silenwang.github.io/tags/RISC-V/"},{"name":"SAS","slug":"SAS","permalink":"https://silenwang.github.io/tags/SAS/"}]},{"title":"AI还是改变生活--让我能做以前很难起步的事情","slug":"AI还是改变生活-让我能做以前很难起步的事情","date":"2025-11-22T20:25:43.000Z","updated":"2026-02-10T14:03:13.673Z","comments":true,"path":"2025/11/22/AI还是改变生活-让我能做以前很难起步的事情/","permalink":"https://silenwang.github.io/2025/11/22/AI%E8%BF%98%E6%98%AF%E6%94%B9%E5%8F%98%E7%94%9F%E6%B4%BB-%E8%AE%A9%E6%88%91%E8%83%BD%E5%81%9A%E4%BB%A5%E5%89%8D%E5%BE%88%E9%9A%BE%E8%B5%B7%E6%AD%A5%E7%9A%84%E4%BA%8B%E6%83%85/","excerpt":"我还是挺喜欢现在的 hexo 主题的，从 2021 年使用它的前身material-x，到2023年升级到 Volantis 5.x，主题的功能已经完全满足我个人的需求了，以至于没有继续升级作者后续的6和7了。不过上半年利用 AI 对博客进行批量英文翻译后，一直有一些界面元素还是中文的问题。今年就不大动工，直接在 AI 指导下自己动手修一修。","text":"我还是挺喜欢现在的 hexo 主题的，从 2021 年使用它的前身material-x，到2023年升级到 Volantis 5.x，主题的功能已经完全满足我个人的需求了，以至于没有继续升级作者后续的6和7了。不过上半年利用 AI 对博客进行批量英文翻译后，一直有一些界面元素还是中文的问题。今年就不大动工，直接在 AI 指导下自己动手修一修。 问题背景自从使用 AI 工具将博客内容批量翻译成英文后，我的博客就具备了中英双语版本。但是修改的时候出现俩问题： 英文站中部分组件的切换效果无效，如关于我页面的选项卡，点击后无法切换 主题界面上的许多元素仍然是中文的，页面最下侧的访问统计也总是会出现一段明显是加入多语言支持时忘记处理的固定中文内容。 在查看了主题的代码后，感觉前者是个配置问题， 后者则更多是 hexo 这个框架本身的问题导致。比如页面中很多标题和分类的标题， 都是直接编码在配置文件中的，Deepseek 说，hexo 下更简单的方式是直接准备两个配置文件。我现在的方案本来就是中文站一个文件夹，英文站另一个，上述问题在实际尝试后发现，都是修改Volantis代码中的配置文件就能解决的，所以我最后选择直接写俩补丁文件，放在我的博客项目下。 解决方案1. 不能切换的问题从浏览器的报错看，当我把英文站的root设置为/en/后，页面上的app.js这个文件的路径，被错误设置成了/en/en/js/app.js，这个文件应该是负责实现切换效果的，文件找不到，切换效果也就无了。 根据 Deepseek 的解释，发现修改 _config.yml 下的cdn设置就能解决问题，具体的diff情况如下 123456789101112--- a/_config.yml+++ b/_config.yml@@ -50,7 +50,7 @@ cdn: # 以下配置可以覆盖 cdn.prefix,配置项的值可以为空，但是要使用CDN必须依据路径填写配置项的键 set: js:- #app: /js/app.js+ app: /js/app.js css: #style: /css/style.css # (异步加载样式) # 静态资源版本控制 2. 英文化不全的问题这些问题更简单，把需要显示板块的title替换成英文，然后找到页面底部不用的部分，去掉就行了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990--- a/_config.yml+++ b/_config.yml@@ -266,12 +266,12 @@ article: # 文章创建日期 date: icon: fa-solid fa-calendar-alt- title: &#x27;发布于：&#x27;+ title: &#x27;Published on: &#x27; format: &#x27;ll&#x27; # 日期格式 http://momentjs.com/docs/ # 文章更新日期 updated: icon: fa-solid fa-edit- title: &#x27;更新于：&#x27;+ title: &#x27;Updated on: &#x27; format: &#x27;ll&#x27; # 日期格式 http://momentjs.com/docs/ # 文章分类 category:@@ -279,15 +279,15 @@ article: # 文章浏览计数 counter: icon: fa-solid fa-eye- unit: &#x27;次浏览&#x27;+ unit: &#x27;views&#x27; # waline 文章评论数量 walinecount: icon: fa-solid fa-comment-dots- desc: &#x27;条评论&#x27; # 条评论+ desc: &#x27;comments&#x27; # 条评论 # artalk 文章评论数量 artalkcount: icon: fa-solid fa-comment-dots- desc: &#x27;条评论&#x27; # 条评论+ desc: &#x27;comments&#x27; # 条评论 # 文章字数和阅读时长 wordcount: icon_wordcount: fa-solid fa-keyboard@@ -523,7 +523,7 @@ sidebar: sticky: true header: icon: fa-solid fa-list- title: 本文目录+ title: TOC list_number: false min_depth: 2 max_depth: 5@@ -540,7 +540,7 @@ sidebar: display: [desktop] # [desktop, mobile] header: icon: fa-solid fa-folder-open- title: 文章分类+ title: Categories url: /blog/categories/ # --------------------------------------- # tagcloud widget@@ -549,7 +549,7 @@ sidebar: display: [desktop, mobile] # [desktop, mobile] header: icon: fa-solid fa-tags- title: 热门标签+ title: Tags url: /blog/tags/ min_font: 14 max_font: 24@@ -572,7 +572,7 @@ sidebar: display: [desktop] header: icon: fa-solid fa-award- title: 站点信息+ title: Website ino type: article: enable: true@@ -608,7 +608,7 @@ sidebar: display: [desktop, mobile] header: icon: fa-solid fa-clock WISTERIA- title: 最近更新+ title: Laste Update ############################### Sidebar ############################### &gt; end @@ -647,8 +647,6 @@ site_footer: source: https://github.com/volantis-x/volantis-docs/ # analytics using leancloud analytics: &gt;- &lt;span id=&quot;lc-sv&quot;&gt;本站总访问量为 &lt;span id=&#x27;number&#x27;&gt;&lt;i class=&quot;fa-solid fa-loader fa-spin fa-fw&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt; 次&lt;/span&gt;- &lt;span id=&quot;lc-uv&quot;&gt;访客数为 &lt;span id=&#x27;number&#x27;&gt;&lt;i class=&quot;fa-solid fa-loader fa-spin fa-fw&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&lt;/span&gt; 人&lt;/span&gt; # site copyright copyright: &#x27;[Copyright © since 2017 XXX](/)&#x27; # You can add your own property here. (Support markdown, for example: br: &#x27;&lt;br&gt;&#x27;) 3. 补丁生成将上面修改保存后，git commit，然后就可以使用git diff COMMIT1 COMMIT2 &gt; PATCH_FILE生成补丁。 由于我是克隆volantis原项目代码然后修改生成补丁，补丁文件中文件的路径是不对的，需要修改补丁文件中下面的路径为实际的文件路径。 12--- a/_config.yml+++ b/_config.yml 另外上方的index 91bd9709..9304175e 100644需要去掉，否则会因为commit核验补上而失败。 总结今年二季度以来，因为部门逐渐只剩我一个人，公司所有需要自己维护的网站和系统都跑我手上了… 如果没有AI救我狗命，我断然是无法一边做着分析，一边还要维护这么些的前后端的，现在也不可能有那么点常识后，自己修博客的小Bug… 但就跟去年用AI的感受一样，我的上限决定AI的上限，我们有办法判断拿到方案对错的时候，就只能像追自己尾巴的小狗狗一样，原地转圈圈了…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://silenwang.github.io/tags/hexo/"},{"name":"Volantis","slug":"Volantis","permalink":"https://silenwang.github.io/tags/Volantis/"},{"name":"博客","slug":"博客","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"国际化","slug":"国际化","permalink":"https://silenwang.github.io/tags/%E5%9B%BD%E9%99%85%E5%8C%96/"}]},{"title":"只成功了一半----利用pixi在FydeOS编译运行podman","slug":"只成功了一半-利用pixi在FydeOS编译运行podman","date":"2025-11-11T01:30:59.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2025/11/11/只成功了一半-利用pixi在FydeOS编译运行podman/","permalink":"https://silenwang.github.io/2025/11/11/%E5%8F%AA%E6%88%90%E5%8A%9F%E4%BA%86%E4%B8%80%E5%8D%8A-%E5%88%A9%E7%94%A8pixi%E5%9C%A8FydeOS%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8Cpodman/","excerpt":"最近在FydeOS上尝试使用pixi来编译和运行podman，虽然取得了一些进展，但最终只成功了一半。在这篇博客中，我将分享整个过程以及遇到的问题。","text":"最近在FydeOS上尝试使用pixi来编译和运行podman，虽然取得了一些进展，但最终只成功了一半。在这篇博客中，我将分享整个过程以及遇到的问题。 背景与动机我使用Fydetab Duo进行本地开发，希望通过devpod来提高开发效率。然而，FydeOS自带的Linux环境存在稳定性问题：设备从休眠状态唤醒后，经常无法通过网络访问Linux环境，这严重影响了开发工作流程。 作为替代方案，我考虑在虚拟机外运行podman来管理开发环境。这样即使Linux环境不可用，也能通过podman维持开发环境的运行。但是，conda-forge提供的podman包没有ARM64架构版本，无法直接在Fydetab Duo（基于ARM架构）上使用。 因此，我决定克隆conda-forge的podman包构建代码，使用pixi环境管理工具自行编译ARM64版本的podman。Pixi是一个跨平台的包管理器和环境管理器，能够帮助管理复杂的编译依赖关系。 环境配置与编译过程首先，我克隆了conda-forge的podman包构建代码，并创建了一个pixi项目来管理编译环境。配置pixi.toml文件如下： 12345678910111213141516171819[workspace]authors = [&quot;Sylens &lt;qiumin14@163.com&gt;&quot;]channels = [&quot;conda-forge&quot;, &quot;file:///usr/local/share/project/podman/.pixi/envs/default/conda-bld&quot;]name = &quot;podman&quot;platforms = [&quot;linux-aarch64&quot;]version = &quot;0.1.0&quot;[tasks][system-requirements]libc = &#123; family = &quot;glibc&quot;, version = &quot;2.39&quot; &#125;[dependencies]boa = &quot;&gt;=0.17.0,&lt;0.18&quot;mamba = &quot;&gt;=1.5.12,&lt;2&quot;conda-build = &quot;&gt;=24.5.1,&lt;25&quot;diffutils = &quot;&gt;=3.12,&lt;4&quot;podman = &quot;&gt;=5.6.2,&lt;6&quot;libcap = &quot;&gt;=2.76,&lt;3&quot; 这个配置指定了项目依赖和系统要求，特别是针对ARM64架构（linux-aarch64）和glibc 2.39版本。[system-requirements]部分的版本指定，其实是Pixi的一种虚拟包指定机制，用于在计算依赖时，告诉依赖计算器当前系统的系统库版本（万物依赖libc）。而channels中指定了一个本地的路径，因为podman还有一个必要依赖netavark也没有Arm64版本，需要先行编译形成本地Conda包后，才能开始编译podman。 编译解决方案两个软件的conda包构建代码分别在https://github.com/conda-forge/netavark-feedstock和https://github.com/conda-forge/podman-feedstock，克隆下来后依次编译。在编译netavark和podman时，都会有依赖问题，我们需要修改他们的recipe/conda_build_config.yaml文件，具体差异别见下，其实就是指定使用sysroot作为C标准库。 123456789index d402d1d..7dbfd74 100644--- a/recipe/conda_build_config.yaml+++ b/recipe/conda_build_config.yaml@@ -1,2 +1,5 @@+c_stdlib:+ - sysroot+ c_stdlib_version: # [linux64] - 2.17 # [linux64] 编译成功后，就可以使用pixi add添加podman到环境，就有podman命令行了 运行失败的核心问题事情到这都还挺顺利的，然而如果运行podman pull alpine，会提示没有newgidmap程序和newuidmap。他们是用来做用户和组编号映射的。这难不倒常年借东墙补西墙的我，Linux虚拟机内复制一个出来就行。然而，在有这两个程序后，依然会看到下面的错误： 12newuidmap: Could not set capscannot set up namespace using &quot;/usr/bin/newuidmap&quot;: should have setuid or have filecaps setuid 到此位置，遇到了本次无法克服的障碍，FydeOS&#x2F;Chromeos的从设计上，就不允许用户命名空间中的UID&#x2F;GID映射。 我尝试根据AI提示，通过sudo chmod u+s为newuidmap和newgidmap设置了setuid位，系统仍然拒绝执行。内核日志显示： 1SafeSetID: Operation requires CAP_SETUID, which is not available to UID 1000 for operations besides approved set*uid transitions 以下是AI给我的回答： 1.SafeSetID 是 ChromeOS 特有的安全机制（LSM&#x2F;内核补丁），用于 限制 setuid &#x2F; UID 映射2.CAP_SETUID 不可用 → 即使 newuidmap 有 setuid 或 setcap，普通用户（UID 1000）也无法在 rootless Podman 中修改 UID 映射3.其他日志都是正常 remount 或 USB 设备信息，与 rootless Podman 无关 由于我没有足够的知识来判断它说的真假，所以我只能进Linux虚拟机以一样的方式编译Podman试了试，实测，虚拟机内的Podman是能正常运行的，这至少说明，宿主机部分确实有特别的限制。 总结这次尝试证明使用pixi在FydeOS上管理podman依赖是可行的，编译过程也能成功完成。但由于FydeOS深层的内核安全限制（特别是SafeSetID模块），运行时环境无法满足podman对用户命名空间的要求，因此只能算”成功了一半”。 所以，如果要实现我的目标，我只能自行去编译Openfyde镜像，直接在编译的时候修改内核的部分，并且直接加入podman了。","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"FydeOS","slug":"FydeOS","permalink":"https://silenwang.github.io/tags/FydeOS/"},{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"},{"name":"podman","slug":"podman","permalink":"https://silenwang.github.io/tags/podman/"}]},{"title":"修复pixi部署部分bioconda_r包后出现的缺依赖问题","slug":"修复pixi部署部分bioconda-r包后出现的缺依赖问题","date":"2025-10-29T03:37:56.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2025/10/29/修复pixi部署部分bioconda-r包后出现的缺依赖问题/","permalink":"https://silenwang.github.io/2025/10/29/%E4%BF%AE%E5%A4%8Dpixi%E9%83%A8%E7%BD%B2%E9%83%A8%E5%88%86bioconda-r%E5%8C%85%E5%90%8E%E5%87%BA%E7%8E%B0%E7%9A%84%E7%BC%BA%E4%BE%9D%E8%B5%96%E9%97%AE%E9%A2%98/","excerpt":"在使用pixi管理生物信息学分析环境时，经常会遇到一些Bioconductor的R包安装后出现依赖缺失的问题。目前暂不清楚这个问题的原因，用了pixi一年了，这个问题到目前为止（2025.10）也木有修复，因此本文介绍如何通过pixi tasks功能来解决这类问题。","text":"在使用pixi管理生物信息学分析环境时，经常会遇到一些Bioconductor的R包安装后出现依赖缺失的问题。目前暂不清楚这个问题的原因，用了pixi一年了，这个问题到目前为止（2025.10）也木有修复，因此本文介绍如何通过pixi tasks功能来解决这类问题。 问题描述在最近一年的pixi使用中，发现部署生物信息学分析环境时，Seurat和maftools这样的依赖GenomeInfoDbData、BSgenome.Hsapiens.UCSC.hg38获取基因组数据R包的依赖总是有问题，即使在依赖处显式的指定并安装这些包到pixi环境中，实际载入的时候还是会显示这些包并不存在，因此还需要配置额外的内容来补充这些依赖。 解决方案我目前是通过pixi的tasks功能，将安装依赖的命令变成一个任务，以在部署环境后快速修复依赖问题，实际的配置文件示例如下： 1234567891011121314151617181920212223242526[workspace]name = &quot;azimuth_demo&quot;version = &quot;1.1&quot;description = &quot;workspace with azimuth and jupyter&quot;authors = [&quot;Sylens Wong &lt;qiumin14@163.com&gt;&quot;]channels = [&quot;conda-forge&quot;, &quot;bioconda&quot;]platforms = [&quot;linux-64&quot;][environments]label = [&#x27;kernel&#x27;, &#x27;label&#x27;][feature.kernel.dependencies]r-irkernel = &#x27;*&#x27;jupyterlab = &#x27;*&#x27;[feature.label.dependencies]r-base = &#x27;*&#x27;r-azimuth = &#x27;*&#x27;r-BiocManager = &#x27;*&#x27;[feature.label.tasks]GenomeInfoDbData = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;GenomeInfoDbData\\&quot;)&quot;&#x27;&#125;BSgenome = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;BSgenome.Hsapiens.UCSC.hg38\\&quot;)&quot;&#x27;&#125;EnsDb = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;EnsDb.Hsapiens.v86\\&quot;)&quot;&#x27;&#125;JASPAR2020 = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;JASPAR2020\\&quot;)&quot;&#x27;&#125;r_dep = &#123;cmd = &#x27;echo &quot;bio dep for R done&quot;&#x27;, depends-on=[&#x27;GenomeInfoDbData&#x27;, &#x27;BSgenome&#x27;, &#x27;EnsDb&#x27;, &#x27;JASPAR2020&#x27;]&#125; 激活pixi环境后，执行pixi run r_dep就可以完成依赖修复，然后开始工作了。","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"依赖管理","slug":"依赖管理","permalink":"https://silenwang.github.io/tags/%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"},{"name":"Bioconductor","slug":"Bioconductor","permalink":"https://silenwang.github.io/tags/Bioconductor/"},{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"}]},{"title":"解决scanpy读写loom文件格式丢失obs和var的index的问题","slug":"解决scanpy读写loom文件格式丢失obs和var的index的问题","date":"2025-10-28T17:22:12.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2025/10/28/解决scanpy读写loom文件格式丢失obs和var的index的问题/","permalink":"https://silenwang.github.io/2025/10/28/%E8%A7%A3%E5%86%B3scanpy%E8%AF%BB%E5%86%99loom%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E4%B8%A2%E5%A4%B1obs%E5%92%8Cvar%E7%9A%84index%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"在我们现在基于scanp的单细胞流程中，有一步需要将AnnData对象保存为loom格式。但是与保存为h5ad不同，当我们不做任何处理，将AnnData对象写入loom文件后再次读取时，会发现obs和var的索引（index）信息丢失了，这些索引（通常是细胞条形码和基因名）变成了普通的数字编号。","text":"在我们现在基于scanp的单细胞流程中，有一步需要将AnnData对象保存为loom格式。但是与保存为h5ad不同，当我们不做任何处理，将AnnData对象写入loom文件后再次读取时，会发现obs和var的索引（index）信息丢失了，这些索引（通常是细胞条形码和基因名）变成了普通的数字编号。 问题描述根据实际的测试和write_loom方法的文档，中的描述，可以推测实际的读写，write_loom 写入时，实际上的不会写入obs和var两个表中的index部分，即使通过参数指定write_obsm_varm=True，写入时也只会按照固定的名称分别产生两个新列（obs_names和var_names）。 而根据read_loom方法的文档，read_loom在读取的时候，实际上要在obs中找名为CellID的列，在var中找名为Gene的列来分别作为两张表的编号。 这样一来一去，默认不存index，即使存了index，write_loom存的和read_loom读的也并不一致，就像两个部门对接没有做好，关键信息就这么没了… 解决方案我的目的是尽可能不对原流程代码进行变更，因此直接产生原流程可读的loom文件是最好的方式： 12345678910# 保存索引信息到obs和var的列中adata.obs[&#x27;CellID&#x27;] = adata.obs.index.tolist()adata.var[&#x27;Gene&#x27;] = adata.var.index.tolist()# 写入loom文件（包含obsm和varm信息）merge_adata.write_loom(&#x27;/path/to/raw.loom&#x27;)# 读取loom文件，由于CellID和Gene存在，# 读取的adata能成功保留两个表的index信息adata = sc.read_loom(&#x27;/path/to/raw.loom&#x27;)","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"scanpy","slug":"scanpy","permalink":"https://silenwang.github.io/tags/scanpy/"},{"name":"loom","slug":"loom","permalink":"https://silenwang.github.io/tags/loom/"},{"name":"adata","slug":"adata","permalink":"https://silenwang.github.io/tags/adata/"}]},{"title":"在R和Python下运行milo的对比","slug":"在R和Python下运行milo的对比","date":"2025-10-28T15:57:51.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2025/10/28/在R和Python下运行milo的对比/","permalink":"https://silenwang.github.io/2025/10/28/%E5%9C%A8R%E5%92%8CPython%E4%B8%8B%E8%BF%90%E8%A1%8Cmilo%E7%9A%84%E5%AF%B9%E6%AF%94/","excerpt":"Milo是一种用于单细胞RNA测序数据的差异丰度分析方法，能够检测不同条件下细胞邻域的组成变化。","text":"Milo是一种用于单细胞RNA测序数据的差异丰度分析方法，能够检测不同条件下细胞邻域的组成变化。 milo算法简介milo是一种专门为单细胞RNA测序数据设计的差异丰度分析方法。其核心思想是通过构建细胞邻域（neighborhoods）来检测不同实验条件下细胞群体组成的变化。 个人理解这个算法的设计目的是在不预先定义的情况下，找出两种情况下有群体比例差异的细胞，有了检测结果后，可以将这些有差异的细胞单独提出来进行进一步的分析。 R环境下的miloR实现R语言中使用miloR包进行分析，以下是相应的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# 加载所需库library(Seurat)library(miloR)library(SingleCellExperiment)library(scater)library(dplyr)library(tidyr)# 读取Seurat对象并转换为SingleCellExperimentseurat_obj &lt;- readRDS(&quot;seurat.rds&quot;)sce &lt;- as.SingleCellExperiment(seurat_obj)# 设置随机种子保证结果可重复，本方法中主要是kNN部分有随机成分set.seed(4466)# 创建Milo对象milo_obj &lt;- Milo(sce)# 构建领接结构，注意合理的k是kNN中的k# 而d是dimension，即需要使用多少个降维维度/成分milo_obj &lt;- buildGraph( milo_obj, k = 30, d = 20, transposed = TRUE, reduced.dim = &quot;UMAP&quot;)# 定义邻域，注意这里的k和d以及reduced_dims都要跟前一步一致# 这里的refinement_scheme是为了配合后续使用一种快速算法# 在数据集中细胞非常多时，有明显的计算加速作用milo_obj &lt;- makeNhoods( x = milo_obj, prop = 0.1, k = 30, d = 20, refined = TRUE, reduced_dims = &quot;UMAP&quot;, refinement_scheme = &quot;graph&quot;)# 计数邻域中的细胞milo_obj &lt;- countCells( milo_obj, meta.data = data.frame(colData(milo_obj)), sample = &quot;sample_id&quot;)# 准备实验设计，其实就是构建一个有样品编号和分组tag的数据框traj_design &lt;- data.frame(colData(milo_obj))[,c(&quot;sample_id&quot;, &quot;group&quot;)] %&gt;% distinct() %&gt;% mutate( sample_id = as.character(sample_id), group = as.character(group) )rownames(traj_design) &lt;- traj_design$sample_idtraj_design &lt;- traj_design[colnames(nhoodCounts(milo_obj)), , drop=FALSE]# 差异丰度检验，这里的fdr.weighting = &quot;graph-overlap&quot;# 配合前面makeNhoods中的参数，提高计算速度# 注意这里可以进行比较组的指定，指定的方式比较特殊，是用类公式的语法进行指定# design = ~ 0 + group 代表使用group变量进行分组，前面的 0 + 是固定写法# model.contrasts = c(&#x27;groupCase - groupControl&#x27;) 的意义是# 使用 group 列等于 Case 的行作为目标，等于 Control的行作为对照da_results &lt;- testNhoods( milo_obj, design = ~ 0 + group, model.contrasts = c(&#x27;groupCase - groupControl&#x27;), design.df = traj_design, fdr.weighting = &quot;graph-overlap&quot;)# 查看显著结果da_results %&gt;% arrange(SpatialFDR) %&gt;% filter(SpatialFDR &lt; 0.1) %&gt;% tail(3)# 构建邻域图milo_obj &lt;- buildNhoodGraph(milo_obj)# 所有计算步骤完成# 后续可使用plotUMAP或其他函数进行可视化展示 Python环境下的Milo实现Python中有多个milo实现，除了官方miloR项目中提到的Mipopy，pertpy库也实现Milo的算法，以下是用pertpy完成计算的例子 12345678910111213141516171819202122232425262728293031323334353637import numpy as npimport pertpy as ptimport scanpy as scimport pandas as pd# 读取数据adata = sc.read_h5ad(&#x27;adata.h5ad&#x27;)# 初始化Milo分析对象milo = pt.tl.Milo()mdata = milo.load(adata)# 构建邻居图sc.pp.neighbors( mdata[&quot;rna&quot;], use_rep=&quot;X_umap&quot;, # 利用已有umap降维信息 n_pcs=20, # 主成分数，对应miloR的d参数 n_neighbors=30, # 邻居数，对应miloR的k参数)# 创建邻域milo.make_nhoods(mdata[&quot;rna&quot;], prop=0.1)mdata = milo.count_nhoods(mdata, sample_col=&quot;sample_id&quot;)# 这里指定Case Control的方式比miloR更容易懂一些，不过顺序有些差异，这里Control在前mdata[&quot;rna&quot;].obs[&quot;group&quot;] = mdata[&quot;rna&quot;].obs[&quot;group&quot;].cat.reorder_categories([&quot;Control&quot;, &quot;Case&quot;])# 差异丰度分析（使用pydeseq2求解器）milo.da_nhoods(mdata, design=&quot;~group&quot;, solver=&quot;pydeseq2&quot;)# 构建邻域图，用于可视化milo.build_nhood_graph(mdata)# 筛选显著结果significant_results = mdata[&#x27;milo&#x27;].var.query(&#x27;SpatialFDR &lt; 0.1&#x27;)# 完成所有计算 后记实际运行的性能上，两者差距木有太大，但是计算结果上还是又差的，毕竟py版本是算法实现，而不是一点点复现。具体的计算一致性几何，后续我从cellxgene上找个数据集再来实际算算好了。","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"单细胞分析","slug":"单细胞分析","permalink":"https://silenwang.github.io/tags/%E5%8D%95%E7%BB%86%E8%83%9E%E5%88%86%E6%9E%90/"},{"name":"差异丰度分析","slug":"差异丰度分析","permalink":"https://silenwang.github.io/tags/%E5%B7%AE%E5%BC%82%E4%B8%B0%E5%BA%A6%E5%88%86%E6%9E%90/"},{"name":"Milo","slug":"Milo","permalink":"https://silenwang.github.io/tags/Milo/"}]},{"title":"使用 DevPod 设置自部署的 Codespace","slug":"使用devpod设置自部署的codespace","date":"2025-10-28T05:49:54.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/10/28/使用devpod设置自部署的codespace/","permalink":"https://silenwang.github.io/2025/10/28/%E4%BD%BF%E7%94%A8devpod%E8%AE%BE%E7%BD%AE%E8%87%AA%E9%83%A8%E7%BD%B2%E7%9A%84codespace/","excerpt":"DevPod 是一个开源的开发环境管理工具，可以让你在任何 Kubernetes 集群或 Docker 主机上创建类似 GitHub Codespaces 的开发环境。本文将介绍如何使用 DevPod CLI 创建工作区，并详细解析 DevContainer 配置文件的编写。","text":"DevPod 是一个开源的开发环境管理工具，可以让你在任何 Kubernetes 集群或 Docker 主机上创建类似 GitHub Codespaces 的开发环境。本文将介绍如何使用 DevPod CLI 创建工作区，并详细解析 DevContainer 配置文件的编写。 DevPod 介绍DevPod 是由 Loft Labs 开发的开源工具，它允许开发者在任何基础设施上创建可重复、一次性的开发环境。与 GitHub Codespaces 类似，但 DevPod 是可以自托管的，可以在任何在本地机器、支持的云服务器商或 Kubernetes 集群上运行。 主要特性包括： 支持多种后端（Docker、Kubernetes、AWS EC2 等） 基于 DevContainer 标准 开发环境即代码 快速启动和销毁环境 DevPod Provider 和工作区创建安装 DevPodDevpod 提供桌面版本，但是我现在是要在 FydeOS 上运行，所以安装 DevPod CLI。比较友好的是 Devpod CLI 几乎没有外部依赖，甚至SSH都有内建的，因此使用官方的命令就能安装到 FydeOS 的原生命令行。 1curl -fsSL https://raw.githubusercontent.com/loft-sh/devpod/master/scripts/install.sh | sh 配置 ProviderProvider 是 DevPod 的后端驱动，定义了开发环境的运行位置。以 SSH 为例： 1devpod provider add ssh --name amd -o HOST=AMD 上面的添加方式基于已有的 ssh 配置，对应 ~/.ssh/config 中的内容是： 12345Host AMD HostName 192.168.0.2 Port 22 User user IdentityFile /home/user/.ssh/AMD_Key 另须注意，DevPod 是基于容器技术的工具，因此 SSH 的目标机器需要已经安装好 docker 或者 podman。 另外，使用 Ubuntu 的话，还要额外注意 docker 软件的来源，因为 Ubuntu 下可以通过 Snap 安装 docker，这个版本的 docker 因为 Snap 的限制，是不能访问用户 Home 目录下的隐藏文件夹的（.开头的那些），导致 Devpod 调用 docker 执行任何构建命令都会失败。 创建工作区指定 provider 和项目路径即可启动工作区，Devpod会根据配置文件创建必要的工作环境，更重要的是，Devpod 会自动在工作区安装 web 版的 openvscode，启动该服务后，将服务的端口自动转发到本地，然后就可以快乐的写代码了，真正实现了项目介绍中说的，开发环境即配置的目标。同时，这些配置只需要服务器开 SSH 端口即可使用，可以说，真的相当方便。 1devpod up --provider amd --source git https://github.com/your-username/your-repo 这将基于仓库中的 .devcontainer 文件夹下的配置文件创建开发环境。 DevContainer 格式介绍DevContainer 是开发环境配置的标准格式，本次示例中包含两个主要文件：devcontainer.json 和 Dockerfile。 Dockerfile 配置Dockerfile 其实就是 docker build 时使用的配置文件，DevPod会利用这个文件来创建工作区的容器。 需要注意的是，配置构建容器最好基于 mcr.microsoft.com&#x2F;devcontainers 下的容器来构建，因为这些容器是根据一定的要求构建而成的，DevPod 的一些功能依赖容器内的文件和配置，如果使用其他容器，启动工作区会需要自行处理一些兼容性问题。 123456789101112131415# 使用 ms 官方基础镜像，含有vscode用户，避免devpod启动时有问题FROM mcr.microsoft.com/devcontainers/base:bookworm# 为vscode安装pixiUSER vscode# 安装pixi，因为我的项目都用它管理依赖RUN curl -fsSL https://pixi.sh/install.sh | sh# 配置 git 用户信息，同时向环境注入我需要的alias内容RUN git config --global user.name &quot;Sylens&quot; &amp;&amp; \\ git config --global user.email &quot;qiumin14@163.com&quot; &amp;&amp; \\ echo &#x27;alias aider=&quot;aider --no-check-update --no-show-model-warnings --yes --no-auto-commits --model deepseek/deepseek-reasoner&quot;&#x27; &gt;&gt; ~/.bashrcENV PATH=&quot;/home/vscode/.pixi/bin:$&#123;PATH&#125;&quot; 另外还需要注意的一点是，DevPod的运行逻辑是先构建容器，然后再根据 devcontainer.json 进行项目代码挂载和进一步配置，所以一切依赖项目代码的设置都是无法在容器构建阶段进行的。 devcontainer.json 配置devcontainer.json 定义了开发容器的元数据和 IDE 配置，我这里是个最基本的配置，只设置了一些环境变量以及最低限度的插件情况。 12345678910111213141516171819202122&#123; &quot;name&quot;: &quot;silen_blog&quot;, &quot;build&quot;: &#123; &quot;dockerfile&quot;: &quot;Dockerfile&quot; &#125;, &quot;postCreateCommand&quot;: &quot;pixi run deploy&quot;, &quot;containerEnv&quot;: &#123; &quot;AIDER_DARK_MODE&quot;: &quot;$&#123;localEnv:AIDER_DARK_MODE&#125;&quot;, &quot;AIDER_CODE_THEME&quot;: &quot;$&#123;localEnv:AIDER_CODE_THEME&#125;&quot;, &quot;DEEPSEEK_API_KEY&quot;: &quot;$&#123;localEnv:DEEPSEEK_API_KEY&#125;&quot; &#125;, &quot;customizations&quot;: &#123; &quot;vscode&quot;: &#123; &quot;settings&quot;: &#123; &quot;workbench.colorTheme&quot;: &quot;Solarized Dark&quot; &#125;, &quot;extensions&quot;: [ &quot;naumovs.color-highlight&quot;, &quot;ms-ceintl.vscode-language-pack-zh-hans&quot;, &quot;tamasfe.even-better-toml&quot; ] &#125; &#125;&#125; 须注意，postCreateCommand 只能写一项，如果需要执行的内容过多，建议写成shell脚本，放在 .devcontainer 目录然后用 postCreateCommand 调用。 后记早在去年写 ReviewGPT 的时候，我就体会到，想法人人有，做出来最重要。 我本来是在改写ChromeOS下的终端App，希望为它加入端口转发，和在目标机器上自动安装 vscode web 并自动转发端口到本地的功能。然后做着做着，发现google 早就废弃 pNaCl 了（如此一来原生的 App 并不能访问本地端口了），于是想用 Golang 开发一个满足我要求的引用，继续做着做着，发现了 DevPod，除了它是基于容器的… 已经非常接近我的需求了… 害，那我还写啥呢… 先学 Devpod 怎么用吧…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://silenwang.github.io/tags/Docker/"},{"name":"DevPod","slug":"DevPod","permalink":"https://silenwang.github.io/tags/DevPod/"},{"name":"DevOps","slug":"DevOps","permalink":"https://silenwang.github.io/tags/DevOps/"},{"name":"开发环境","slug":"开发环境","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"name":"Podman","slug":"Podman","permalink":"https://silenwang.github.io/tags/Podman/"}]},{"title":"TypeScript和JavaScript中的调试技巧","slug":"TS-JS中进行调试","date":"2025-10-13T23:08:14.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2025/10/13/TS-JS中进行调试/","permalink":"https://silenwang.github.io/2025/10/13/TS-JS%E4%B8%AD%E8%BF%9B%E8%A1%8C%E8%B0%83%E8%AF%95/","excerpt":"正如我同学所说，我现在有一点”被迫转码”的趋势… 目前维护的几个网站都有各自的前端、后端数据库，部分还有测试代码和迁移代码，涉及语言从生物信息学常用的Python到之前几乎不用的JS、TS、HTML、C#等。实际工作中，不可能有太多时间从头系统学习每门语言，因此掌握最基本的调试方法至关重要。其中JavaScript和TypeScript的调试方式，我觉得特别值得记录，因为它们与其他语言相比确实有些独特之处。","text":"正如我同学所说，我现在有一点”被迫转码”的趋势… 目前维护的几个网站都有各自的前端、后端数据库，部分还有测试代码和迁移代码，涉及语言从生物信息学常用的Python到之前几乎不用的JS、TS、HTML、C#等。实际工作中，不可能有太多时间从头系统学习每门语言，因此掌握最基本的调试方法至关重要。其中JavaScript和TypeScript的调试方式，我觉得特别值得记录，因为它们与其他语言相比确实有些独特之处。 Web前端框架中的调试环境与其说是纯JS&#x2F;TS调试，不如说是Web前端框架环境下的调试更为准确。现代前端框架（如Vue、React、Angular）与传统的HTML文件结构既有相似之处，也有明显差异。这些框架本质上是通过各种编译和构建工具，将模板、脚本和样式代码转换为最终的网页代码，再由浏览器渲染显示。 这种混合编程的模式类似于Snakemake的工作流文件，单个文件中可能包含多种语言元素。在实际开发中，我们主要需要调试的是模板部分（HTML-like）和脚本部分（JavaScript&#x2F;TypeScript）。 模板部分的调试技巧1. 直接显示变量值在Vue模板中，可以使用双花括号语法直接显示变量： 1&lt;p&gt;&#123;&#123; value &#125;&#125;&lt;/p&gt; 在React中，则使用单花括号： 1&lt;p&gt;&#123;value&#125;&lt;/p&gt; 2. 条件性调试显示有时我们只想在开发阶段显示调试信息： 123456&lt;template&gt; &lt;div&gt; &lt;p v-if=&quot;isDevelopment&quot;&gt;调试信息: &#123;&#123; debugValue &#125;&#125;&lt;/p&gt; &lt;!-- 正常内容 --&gt; &lt;/div&gt;&lt;/template&gt; 脚本部分的调试方法1. 基础console调试123console.log(&#x27;变量值:&#x27;, variable);console.table(arrayData); // 以表格形式显示数组或对象console.dir(object); // 显示对象的属性 2. 分组日志1234console.group(&#x27;用户信息&#x27;);console.log(&#x27;姓名:&#x27;, user.name);console.log(&#x27;邮箱:&#x27;, user.email);console.groupEnd(); 3. 条件断点和debugger123if (someCondition) &#123; debugger; // 浏览器会在该行自动暂停&#125;","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"调试","slug":"调试","permalink":"https://silenwang.github.io/tags/%E8%B0%83%E8%AF%95/"},{"name":"Typescript","slug":"Typescript","permalink":"https://silenwang.github.io/tags/Typescript/"},{"name":"Javascript","slug":"Javascript","permalink":"https://silenwang.github.io/tags/Javascript/"},{"name":"前端开发","slug":"前端开发","permalink":"https://silenwang.github.io/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"}]},{"title":"使用uptime_kuma监控我维护的网站","slug":"使用uptime-kuma监控我维护的网站","date":"2025-10-09T15:30:29.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2025/10/09/使用uptime-kuma监控我维护的网站/","permalink":"https://silenwang.github.io/2025/10/09/%E4%BD%BF%E7%94%A8uptime-kuma%E7%9B%91%E6%8E%A7%E6%88%91%E7%BB%B4%E6%8A%A4%E7%9A%84%E7%BD%91%E7%AB%99/","excerpt":"Uptime Kuma 是一个极其易用的开源监控工具，它让监控各种网络服务变得简单而高效。它支持多种协议监控，包括 HTTP(s)、TCP、Ping、DNS 查询等，甚至还能通过 Chrome 内核模式模拟真实用户访问，以更真实的监控服务是否稳定运行。此外，它还支持数十种异常通知方式，可以直接接入我们日常使用的各种应用。同时还提供了独特的 Push 监控方式，让用户能够通过自定义代码扩展监控功能（比如监控 SSH 服务是否可用）。","text":"Uptime Kuma 是一个极其易用的开源监控工具，它让监控各种网络服务变得简单而高效。它支持多种协议监控，包括 HTTP(s)、TCP、Ping、DNS 查询等，甚至还能通过 Chrome 内核模式模拟真实用户访问，以更真实的监控服务是否稳定运行。此外，它还支持数十种异常通知方式，可以直接接入我们日常使用的各种应用。同时还提供了独特的 Push 监控方式，让用户能够通过自定义代码扩展监控功能（比如监控 SSH 服务是否可用）。 Uptime Kuma 简介Uptime Kuma 由 Louis Lam 开发的一个服务监控应用。这个项目的设计哲学就是简单易用，即使是没有技术背景的用户也能快速上手。 安装 Uptime Kuma最简单的方式是使用 Docker 安装，在iStoreOS的商店中有现成配置好的方案，直接安装后启动即可，项目默认跑在3001端口，如果同时使用了Gogs，会冲突，需要改下端口。 基本使用1. 初始设置首次访问时需要设置管理员账号和密码，整个过程只需几分钟就能完成。 2. 添加监控项点击 “添加监控项” 按钮，填写以下信息： 监控类型: 选择监控类型（如 HTTP、TCP、Ping 等） 显示名称: 为监控项起一个易记的名称 URL&#x2F;主机名: 要监控的网站地址或主机 心跳间隔: 检查间隔（默认 60 秒） 特别值得一提的是Chrome 内核监控模式：在 HTTP 监控的高级设置中，可以选择浏览器内核选项。这种模式会使用真实的 Chrome 浏览器内核来访问网站，能够执行 JavaScript 并检测页面加载是否真正完成，对于单页应用（SPA）和需要用户交互的网站特别有用。 3. 设置通知在 “设置通知” 按钮中可以添加各种通知方式。Uptime Kuma 支持数十种通知渠道，包括： 即时通讯：Telegram、Discord、Slack、Line、Mattermost 等 邮件：SMTP 邮件通知 移动推送：Pushover、Gotify、NTFY 等 Webhook：可通过一定方式直接接入企业微信、钉钉、飞书等国内办公软件 以企业微信为例： 在群里创建一个通知机器人 记下机器人的key 在 Uptime Kuma 中选择企业威信通知方式 填写 key 这样在服务无法访问和恢复访问时，就能在企业微信收到通知了 4. 使用 Push 监控模式Push 监控是 Uptime Kuma 的一个独特功能，它允许服务主动向 Uptime Kuma 报告自己的状态。这样即使是不支持的服务（如SSH），我们也可以自己编写简单的脚本，将监控结果推送到Uptime Kuma以实现监测，准备后续有空用Go写一个监控ssh是否能正常联通的服务。 总结Uptime Kuma 是一个功能极其丰富且非常易用的监控工具，特别适合个人开发者和小团队使用。 如果你也在寻找一个既强大又易用的监控解决方案，我强烈推荐试试 Uptime Kuma，一起化身赛博监控室大爷！","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"监控","slug":"监控","permalink":"https://silenwang.github.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"Uptime-Kuma","slug":"Uptime-Kuma","permalink":"https://silenwang.github.io/tags/Uptime-Kuma/"},{"name":"网站维护","slug":"网站维护","permalink":"https://silenwang.github.io/tags/%E7%BD%91%E7%AB%99%E7%BB%B4%E6%8A%A4/"},{"name":"服务监控","slug":"服务监控","permalink":"https://silenwang.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7/"}]},{"title":"绘制一个配对样本的Circos图","slug":"绘制一个配对样本的Circos图","date":"2025-10-06T22:09:54.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2025/10/06/绘制一个配对样本的Circos图/","permalink":"https://silenwang.github.io/2025/10/06/%E7%BB%98%E5%88%B6%E4%B8%80%E4%B8%AA%E9%85%8D%E5%AF%B9%E6%A0%B7%E6%9C%AC%E7%9A%84Circos%E5%9B%BE/","excerpt":"在癌症研究中，比较肿瘤样本和类器官模型的基因组特征对于验证模型的可靠性至关重要。Circos图能比较直观地展示基因组中检测到突变的情况，所以在描述代表样本的总体检测结果时非常常用。在阅读circlize的文档的时候，看到作者给了一个配对样品的展示例子，我觉得用来展示配对的原代样本和类器官挺合适的，就搓了一个用来展示配对样本的图。代码主要参考自官方文档的9.5 Concatenating two genomes","text":"在癌症研究中，比较肿瘤样本和类器官模型的基因组特征对于验证模型的可靠性至关重要。Circos图能比较直观地展示基因组中检测到突变的情况，所以在描述代表样本的总体检测结果时非常常用。在阅读circlize的文档的时候，看到作者给了一个配对样品的展示例子，我觉得用来展示配对的原代样本和类器官挺合适的，就搓了一个用来展示配对样本的图。代码主要参考自官方文档的9.5 Concatenating two genomes 准备工作加载必要的R包首先，我们需要加载一些必要的R包： 12345library(circlize)library(dplyr)library(stringr)library(MutationalPatterns)library(BSgenome.Hsapiens.UCSC.hg38) 其中，MutationalPatterns主要是用来加载vcf文件，这样不用手动处理，BSgenome.Hsapiens.UCSC.hg38是绘制基本的染色体区间时需要包提供的信息 数据准备我这次展示了三方面的信息，分别是： 体细胞突变检测结果（VCF文件） CNV检测结果（来自CNVKit） 测序覆盖度数据（直接利用CNV软件给的结果，这样不用重复） 构建基因组框架数据我们首先构建一个包含肿瘤和类器官基因组的合并框架： 1234567# 去除XY，构建合并的基因组数据tumor_cytoband &lt;- read.cytoband(species = &quot;hg38&quot;)$df %&gt;% filter(!(V1 %in% c(&#x27;chrX&#x27;, &#x27;chrY&#x27;)))organoid_cytoband &lt;- read.cytoband(species = &quot;hg38&quot;)$df %&gt;% filter(!(V1 %in% c(&#x27;chrX&#x27;, &#x27;chrY&#x27;)))tumor_cytoband[ ,1] &lt;- paste0(&quot;tumor_&quot;, tumor_cytoband[, 1])organoid_cytoband[ ,1] &lt;- paste0(&quot;organoid_&quot;, organoid_cytoband[, 1])cytoband &lt;- rbind(tumor_cytoband, organoid_cytoband) 这里实际上是产生了名为cytoband的数据框，这个数据框丽包含要绘制的两个基因组的基本信息。 处理突变数据使用MutationalPatterns包读取VCF文件，并转换为适合绘制的格式： 12345678910111213141516171819vcfs &lt;- read_vcfs_as_granges( c( &#x27;tumor.vcf&#x27;, &#x27;pdo.vcf&#x27; ), c(&quot;tumor&quot;, &quot;pdo&quot;), &quot;BSgenome.Hsapiens.UCSC.hg38&quot;)mut_data &lt;- rbind( data.frame(vcfs[[t_sample]]) %&gt;% mutate(value = 1) %&gt;% mutate(seqnames = str_c(&quot;tumor_&quot;, seqnames)) %&gt;% select(seqnames, start, end, value), data.frame(vcfs[[o_sample]]) %&gt;% mutate(value = 1) %&gt;% mutate(seqnames = str_c(&quot;organoid_&quot;, seqnames)) %&gt;% select(seqnames, start, end, value)) 处理CNV和覆盖度数据CNV和覆盖度的数据都取自CNVkit： 12345678910111213141516171819202122232425262728293031# CNV数据cnv_data &lt;- rbind( read.table( &quot;tumor.cnvkit.call.cns&quot;, sep=&quot;\\t&quot;, header = F, col.names = c(&quot;chromosome&quot;, &quot;start&quot;, &quot;end&quot;, &quot;cn&quot;) ) %&gt;% mutate(value = cn) %&gt;% mutate(chromosome = str_c(&quot;tumor_&quot;, chromosome)) %&gt;% select(chromosome, start, end, value), read.table( &quot;pdo.cnvkit.call.cns&quot;, sep=&quot;\\t&quot;, header = F, col.names = c(&quot;chromosome&quot;, &quot;start&quot;, &quot;end&quot;, &quot;cn&quot;) ) %&gt;% mutate(value = cn) %&gt;% mutate(chromosome = str_c(&quot;organoid_&quot;, chromosome)) %&gt;% select(chromosome, start, end, value)) %&gt;% mutate(value = pmin(value, 4)) # 限制CNV值不超过4# 覆盖度数据cov_data &lt;- rbind( read.table(&quot;tumor.cnvkit.cov.cnn&quot;, sep=&quot;\\t&quot;, header = T) %&gt;% mutate(value = log2) %&gt;% mutate(chromosome = str_c(&quot;tumor_&quot;, chromosome)) %&gt;% select(chromosome, start, end, value), read.table(&quot;pdo.cnvkit.cov.cnn&quot;, sep=&quot;\\t&quot;, header = T) %&gt;% mutate(value = log2) %&gt;% mutate(chromosome = str_c(&quot;organoid_&quot;, chromosome)) %&gt;% select(chromosome, start, end, value)) 绘制Circos图设置颜色和初始化1234567891011121314151617181920212223# 颜色设置red &lt;- &quot;#FFC6D6&quot;blue &lt;- &quot;#bebcff&quot;green &lt;- &quot;#9CCF83&quot;orange &lt;- &quot;#fbd988ff&quot;purpule &lt;- &quot;#ff726dff&quot;black &lt;- &quot;#000000&quot;# 设置图形大小png(filename = &quot;demo.circos.png&quot;, width = 1200, height = 1200, res = 200)# 构建基础的circos框架chromosome.index = c( paste0(&quot;tumor_chr&quot;, c(1:22)), rev(paste0(&quot;organoid_chr&quot;, c(1:22))))circos.par(gap.after = c(rep(1, 22), rep(1, 22)))circos.initializeWithIdeogram( cytoband, plotType = NULL, chromosome.index = chromosome.index) 添加染色体轨道1234567891011121314# 设置染色体trackcircos.track( ylim = c(0, 1), panel.fun = function(x, y) &#123; circos.text(CELL_META$xcenter, CELL_META$ylim[2] + mm_y(2), gsub(&quot;.*chr&quot;, &quot;&quot;, CELL_META$sector.index), cex = 0.6, niceFacing = TRUE) &#125;, track.height = mm_h(1), cell.padding = c(0, 0, 0, 0), bg.border = NA)highlight.chromosome(paste0(&quot;tumor_chr&quot;, c(1:22)), col = red, track.index = 1)highlight.chromosome(paste0(&quot;organoid_chr&quot;, c(1:22)), col = blue, track.index = 1)circos.genomicIdeogram(cytoband) 添加覆盖度、CNV和突变密度轨道1234567891011121314151617181920212223# 测序覆盖度circos.genomicDensity(cov_data, col=orange, track.height = 0.1, window.size = 1e7)# CNV轨道circos.genomicTrackPlotRegion( cnv_data, ylim = c(0, 4), panel.fun = function(region, value, ...) &#123; cell.xlim = get.cell.meta.data(&quot;cell.xlim&quot;) for(h in c(0, 1, 2, 3, 4)) &#123; circos.lines(cell.xlim, c(h, h), col = black) &#125; col = ifelse(value[[1]] &gt; 2, &quot;red&quot;, ifelse(value[[1]] == 2, &quot;green&quot;, &quot;blue&quot;) ) i = getI(...) circos.genomicRect(region, value, col = col, ytop = value + 0.3, ybottom = value - 0.3 , border = NA) &#125;, track.height = 0.1)# 突变密度circos.genomicDensity(mut_data, col=purpule, track.height = 0.1, window.size = 1e7) 添加文本和图例123456789101112131415161718192021# 设置中间的文字text(0, 0.2, &quot;Demo&quot;, cex = 2, font = 2)# 设置两角的文字text(-0.9, -0.8, &quot;Tumor\\nGenome&quot;)text(0.9, 0.8, &quot;Organoid\\nGenome&quot;)# 设置中间文字下方的图例legend( x = 0, y = 0, legend = c(&quot;Coverage&quot;, &quot;CNV gain&quot;, &quot;CNV neutral&quot;, &quot;CNV loss&quot;, &quot;Mutation density&quot;), col = c(orange, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, purpule), pch = 15, pt.cex = 1, cex = 0.8, bty = &quot;n&quot;, xjust = 0.5,)circos.clear()dev.off() 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144library(circlize)library(dplyr)library(stringr)library(MutationalPatterns)library(BSgenome.Hsapiens.UCSC.hg38)tumor_cytoband &lt;- read.cytoband(species = &quot;hg38&quot;)$df %&gt;% filter(!(V1 %in% c(&#x27;chrX&#x27;, &#x27;chrY&#x27;)))organoid_cytoband &lt;- read.cytoband(species = &quot;hg38&quot;)$df %&gt;% filter(!(V1 %in% c(&#x27;chrX&#x27;, &#x27;chrY&#x27;)))tumor_cytoband[ ,1] &lt;- paste0(&quot;tumor_&quot;, tumor_cytoband[, 1])organoid_cytoband[ ,1] &lt;- paste0(&quot;organoid_&quot;, organoid_cytoband[, 1])cytoband &lt;- rbind(tumor_cytoband, organoid_cytoband)t_sample &lt;- &quot;tumor&quot;o_sample &lt;- &quot;pdo&quot;vcfs &lt;- read_vcfs_as_granges( c( &#x27;tumor.vcf&#x27;, &#x27;pdo.vcf&#x27; ), c(t_sample, o_sample), &quot;BSgenome.Hsapiens.UCSC.hg38&quot;)mut_data &lt;- rbind( data.frame(vcfs[[t_sample]]) %&gt;% mutate(value = 1) %&gt;% mutate(seqnames = str_c(&quot;tumor_&quot;, seqnames)) %&gt;% select(seqnames, start, end, value), data.frame(vcfs[[o_sample]]) %&gt;% mutate(value = 1) %&gt;% mutate(seqnames = str_c(&quot;organoid_&quot;, seqnames)) %&gt;% select(seqnames, start, end, value))cnv_data &lt;- rbind( read.table( &quot;tumor.cnvkit.call.cns&quot;, sep=&quot;\\t&quot;, header = T ) %&gt;% mutate(value = cn) %&gt;% mutate(chromosome = str_c(&quot;tumor_&quot;, chromosome)) %&gt;% select(chromosome, start, end, value), read.table( &quot;pdo.cnvkit.call.cns&quot;, sep=&quot;\\t&quot;, header = T ) %&gt;% mutate(value = cn) %&gt;% mutate(chromosome = str_c(&quot;organoid_&quot;, chromosome)) %&gt;% select(chromosome, start, end, value)) %&gt;% mutate(value = pmin(value, 4))cov_data &lt;- rbind( read.table(&quot;tumor.cnvkit.cov.cnn&quot;, sep=&quot;\\t&quot;, header = T) %&gt;% mutate(value = log2) %&gt;% mutate(chromosome = str_c(&quot;tumor_&quot;, chromosome)) %&gt;% select(chromosome, start, end, value), read.table(&quot;pdo.cnvkit.cov.cnn&quot;, sep=&quot;\\t&quot;, header = T) %&gt;% mutate(value = log2) %&gt;% mutate(chromosome = str_c(&quot;organoid_&quot;, chromosome)) %&gt;% select(chromosome, start, end, value))########################################### 绘图 ###########################################red &lt;- &quot;#FFC6D6&quot;blue &lt;- &quot;#bebcff&quot;green &lt;- &quot;#9CCF83&quot;orange &lt;- &quot;#fbd988ff&quot;purpule &lt;- &quot;#ff726dff&quot;black &lt;- &quot;#000000&quot;png(filename = &quot;demo.circos.png&quot;, width = 1200, height = 1200, res = 200)chromosome.index = c( paste0(&quot;tumor_chr&quot;, c(1:22)), rev(paste0(&quot;organoid_chr&quot;, c(1:22))))circos.par(gap.after = c(rep(1, 22), rep(1, 22))) # 设置区隔？circos.initializeWithIdeogram( cytoband, plotType = NULL, chromosome.index = chromosome.index)circos.track( ylim = c(0, 1), panel.fun = function(x, y) &#123; circos.text(CELL_META$xcenter, CELL_META$ylim[2] + mm_y(2), gsub(&quot;.*chr&quot;, &quot;&quot;, CELL_META$sector.index), cex = 0.6, niceFacing = TRUE) &#125;, track.height = mm_h(1), cell.padding = c(0, 0, 0, 0), bg.border = NA)highlight.chromosome(paste0(&quot;tumor_chr&quot;, c(1:22)), col = red, track.index = 1)highlight.chromosome(paste0(&quot;organoid_chr&quot;, c(1:22)), col = blue, track.index = 1)circos.genomicIdeogram(cytoband)circos.genomicDensity(cov_data, col=orange, track.height = 0.1, window.size = 1e7)circos.genomicTrackPlotRegion( cnv_data, ylim = c(0, 4), panel.fun = function(region, value, ...) &#123; cell.xlim = get.cell.meta.data(&quot;cell.xlim&quot;) for(h in c(0, 1, 2, 3, 4)) &#123; circos.lines(cell.xlim, c(h, h), col = black) &#125; col = ifelse(value[[1]] &gt; 2, &quot;red&quot;, ifelse(value[[1]] == 2, &quot;green&quot;, &quot;blue&quot;) ) i = getI(...) circos.genomicRect(region, value, col = col, ytop = value + 0.3, ybottom = value - 0.3 , border = NA) &#125;, track.height = 0.1)circos.genomicDensity(mut_data, col=purpule, track.height = 0.1, window.size = 1e7)text(0, 0.2, &quot;Demo&quot;, cex = 2, font = 2)text(-0.9, -0.8, &quot;Tumor\\nGenome&quot;)text(0.9, 0.8, &quot;Organoid\\nGenome&quot;)legend( x = 0, y = 0, legend = c(&quot;Coverage&quot;, &quot;CNV gain&quot;, &quot;CNV neutral&quot;, &quot;CNV loss&quot;, &quot;Mutation density&quot;), col = c(orange, &quot;red&quot;, &quot;green&quot;, &quot;blue&quot;, purpule), pch = 15, pt.cex = 1, cex = 0.8, bty = &quot;n&quot;, xjust = 0.5, )circos.clear()dev.off() 成品展示 这里使用的是一个样本生成的数据画了上下两圈，所以两边检测结果看上去是一样的，实际要是配对结果能这么一致，那高低得给佛祖多磕几个了。","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"circlize","slug":"circlize","permalink":"https://silenwang.github.io/tags/circlize/"},{"name":"基因组","slug":"基因组","permalink":"https://silenwang.github.io/tags/%E5%9F%BA%E5%9B%A0%E7%BB%84/"},{"name":"突变","slug":"突变","permalink":"https://silenwang.github.io/tags/%E7%AA%81%E5%8F%98/"},{"name":"CNV","slug":"CNV","permalink":"https://silenwang.github.io/tags/CNV/"}]},{"title":"FydeOS下编译ffmpeg-rockchip","slug":"FydeOS下编译ffmpeg-rockchip","date":"2025-10-02T16:50:39.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2025/10/02/FydeOS下编译ffmpeg-rockchip/","permalink":"https://silenwang.github.io/2025/10/02/FydeOS%E4%B8%8B%E7%BC%96%E8%AF%91ffmpeg-rockchip/","excerpt":"去年其实就使用Fydetab Duo压制过旅行中的视频，当时找的某个github上给的现成库，结果现在找不到这个库了… 于是这次我又尝试自己来编译了…","text":"去年其实就使用Fydetab Duo压制过旅行中的视频，当时找的某个github上给的现成库，结果现在找不到这个库了… 于是这次我又尝试自己来编译了… 编译参考了库作者dnyanmisaka的文档，整个过程还是相对顺利的~ 使用pixi准备编译环境这里相比原文档中提到的git,meson,cmake,pkg-config,gcc,libdrm-dev多了很多东西，毕竟fydeos&#x2F;chromeos并不是传统的linux，缺非常多常见库，因此要补充缺失的依赖程序。 12pixi initpixi add make gxx meson cmake pkg-config gcc libdrm libdrm-devel-conda-aarch64 pthread-stubs binutils diffutils awk 创建pixi环境后，需要pixi shell进入虚拟环境，进入后所有后续的编译安装目的地全部指向这个虚拟环境，这样安装后的依赖在最后的ffmpeg编译时才都找的到 编译rkmpp123456789101112git clone -b jellyfin-mpp --depth=1 https://github.com/nyanmisaka/mpp.git rkmppmkdir -p rkmpp/rkmpp_buildcd rkmpp/rkmpp_buildcmake \\ -DCMAKE_INSTALL_PREFIX=/usr/local/share/project/ffmpeg/.pixi/envs/default/ \\ -DCMAKE_BUILD_TYPE=Release \\ -DBUILD_SHARED_LIBS=ON \\ -DBUILD_TEST=OFF \\ ..make -j $(nproc)make install 编译RGA1234567891011git clone -b jellyfin-rga --depth=1 https://github.com/nyanmisaka/rk-mirrors.git rkrgameson setup rkrga rkrga_build \\ --prefix=/usr/local/share/project/ffmpeg/.pixi/envs/default/ \\ --libdir=lib \\ --buildtype=release \\ --default-library=shared \\ -Dcpp_args=-fpermissive \\ -Dlibdrm=false \\ -Dlibrga_demo=falsemeson configure rkrga_buildninja -C rkrga_build install 编译ffmpeg并安装1234567# ffmpeg部分git clone --depth=1 https://github.com/nyanmisaka/ffmpeg-rockchip.git ffmpegcd ffmpeg./configure --prefix=/usr/local/share/project/ffmpeg/.pixi/envs/default \\ --enable-gpl --enable-version3 --enable-libdrm --enable-rkmpp --enable-rkrgamake -j $(nproc)make install 后记执行上面所有的步骤后，虚拟环境内就有rockchip芯片专用的ffmpeg了，视频处理速度比cpu版本的快了10x有多~ 晚点考虑把上面的内容做一个带任务的Pixi环境，然后也学习下怎么用pixi打包和上传包。","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"FydeOS","slug":"FydeOS","permalink":"https://silenwang.github.io/tags/FydeOS/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://silenwang.github.io/tags/ffmpeg/"}]},{"title":"使用taipy开发一个数据面板以及遇到的坑","slug":"使用taipy开发一个数据面板以及遇到的坑","date":"2025-10-01T22:49:37.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/10/01/使用taipy开发一个数据面板以及遇到的坑/","permalink":"https://silenwang.github.io/2025/10/01/%E4%BD%BF%E7%94%A8taipy%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E9%9D%A2%E6%9D%BF%E4%BB%A5%E5%8F%8A%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/","excerpt":"Python下快速开发数据或AI相关应用的模块真的很多，我已经使用过的包括Dash、Streamlit、Gradio、NiceGUI，前段时间我甚至又发现了俩，正遇上我需要开发一个展示公司数据的简单数据看板，于是我再次不要命的用了新框架—-Taipy。","text":"Python下快速开发数据或AI相关应用的模块真的很多，我已经使用过的包括Dash、Streamlit、Gradio、NiceGUI，前段时间我甚至又发现了俩，正遇上我需要开发一个展示公司数据的简单数据看板，于是我再次不要命的用了新框架—-Taipy。 Taipy的使用页面布局Taipy设计了多种编写布局的方式，根据个人熟悉的语言，可以从Markdown、HTML以及Python语法中挑选一种，进行页面布局设定。不过感觉官方主推的是Markdown。是的，非常神奇，一个用Python写的库居然主推用Markdown写布局… 我当然是选Python语法了，它的用法跟Gradio基本一致，with以及对象用来控制元素的包含关系。 具体来说，通过taipy.gui.builder模块，我们可以使用Python语法来定义页面结构。 主要布局组件包括： tgb.layout()：创建布局容器，可以设置列数（columns）、间距（gap） tgb.part()：创建内容区块，用于组织相关组件 在我的数据面板中，我采用了三级布局结构： 顶部：公司Logo、标题和主题切换控件 中间：地图、饼图、折线图、柱状图等数据可视化组件 底部：关键指标卡片展示 布局示例： 123456with tgb.layout(columns=&quot;1 2 1&quot;, gap=&quot;10px&quot;): # 三列，宽度是1:2:1 # 左侧区块 with tgb.part(class_name=&quot;card&quot;): tgb.text(&quot;里程碑&quot;, class_name=&quot;h5&quot;) tgb.chart(figure=&quot;&#123;timeline&#125;&quot;, plot_config=&#123;&quot;staticPlot&quot;: True&#125;) # 中间和右侧区块类似 样式设定Taipy支持通过CSS文件和Stylekit来自定义样式。 CSS样式：CSS的使用跟一般写网页一样，创建了style.css文件来定义全局样式和组件样式：1234567.card &#123; --element-padding: 0.4rem;&#125;.scrollable-part &#123; overflow-y: auto; /* 垂直滚动 */&#125; 然后在项目创建时，指定要加载的额外CSS就行了。 12gui = Gui(page, css_file=&quot;style.css&quot;)gui.run() Stylekit主题：通过Python字典定义主题颜色，然后在启动GUI时传入：12345678STYLEKIT = &#123; &quot;color-primary&quot;: &quot;#E72410&quot;, &quot;color-secondary&quot;: &quot;#F28E2A&quot;, &quot;color-background-light&quot;: &quot;#EDEDED&quot;, &quot;color-paper-light&quot;: &quot;#FFFFFF&quot;,&#125;gui.run(stylekit=STYLEKIT, dark_mode=False) 注意，Stylekit能控制的内容远少于经典的设置class然后CSS文件内调整，可调整的内容见Taipy的文档。 除上述两种方式之外，Taipy的不同控件还可以通过class_name参数来设定一些模块预设的样式，每个控件能用的东西不同，具体需要参考各个控件的文档 数值绑定Taipy提供一种名为数值绑定的方式，来让界面内容的更新更为简单。 具体使用花括号&#123;&#125;语法将Python变量绑定到界面组件。举最简单的文字例子，我可以如下设置显示一段文字： 12text = &#x27;My Text&#x27;tgb.text(&quot;&#123;text&#125;&quot;) 在上面的设置中，先复制变量text，再在文字控件的内容部分用&quot;&#123;text&#125;&quot;将变量于内容绑定看上去有些多此一举，但是这在Taipy中非常重要。Taipy中，会将命名控件中定义过的所有对象&#x2F;变量，放在一个名为state的特殊对象中。在上面的代码中，实际上同时创造了state.text这个属性，而任何对state.text进行的改变，也会反映在tgb.text(&quot;&#123;text&#125;&quot;)这个文字控件上。于是，如果我想更新这里显示的文字，只要在能获取state的部分中，直接修改其内容，文字就会被修改，并显示在页面上了，比如下面这样： 1state.assign(text, &quot;Changed Text&quot;) 这样相较于常用的Dash&#x2F;Steamlit&#x2F;Gradio，其实就少写了更新控件内容部分的代码，使开发更快。尤其对于数据展示的App，很多时候其实图和表的绘制代码是固定的，我们只是重新整理数据框或计算指标，Taipy的这种设计能让开发者将时间着重放在更新数据上，而不用在展示部分画太多时间。 回调函数如其他框架一样，Taipy的各种控件也是可以设置回调函数的，比如最基础的按钮有on_action回调，就是按钮被按下时触发的回调。不同控件可用的回调不同，需要参考官方文档。 与其他框架不同的是，Taipy还可以设置全局的默认回调函数，我们可以直接定义名为on_action的函数，放在命名控件内，Taipy的逻辑是，如果一个控件可以触发on_action回调，且有名为on_action的函数在当前命名控件，则会直接触发回调。因此在Taipy中，用这种全局回调需要做好逻辑判断，误触回调。 后台任务Taipy虽然内置了定时调度方法，但却放在了付费版本中。不过好在，社区版本中可以通过invoke_long_callback这种高负载的任务回调来时间定时刷新数据的目的。我这边参考了官方给的一个例子 12345678910111213141516171819202122232425262728from random import randintfrom time import sleepdef countdown(): while True: sleep(10)def update_value(value): value = value + randint(1, 4) return valuedef update_display_value(state): state.total_client = update_value(state.total_client) state.total_visits = update_value(state.total_visits) state.total_reads = update_value(state.total_reads)def on_init(state): set_icon(state) invoke_long_callback( state, user_function = countdown, user_status_function = update_display_value, period = 3000 ) 上面的代码中，invoke_long_callback是Taipy提供的一个函数，我们通过它来设定一项高负载任务，也就是user_function，这个函数会单开线程执行，然后设定一个检查高负载任务结果的线程，调用user_status_function中传入的函数，来更新state中的数据。这样一旦数据更新，就能触发Taipy的数值绑定逻辑，更新页面上显示的内容了。 踩坑记录原本想，Taipy都有明确的商业化方案了，这个模块的基本功能应该做得相当不错了，但是在实际使用的过程中，还是碰到让我卡了一天以上的坑… 4.1.0版本的Toggle控件在Theme模式不触发在pixi&#x2F;conda能获取的4.1.0版本中，我发现Toggle控件在设置theme=True，即设置为主题转换按钮时，数值绑定和函数回调都是实效的… 这个问题苦恼了我一天半… 我试着让AI给了我很多解决方法，但是Taipy似乎并不是一个那么流行的模块，不能像其他之前的框架那样，直接注入Javascript来解决。因此我最后还是跑去看了源代码… 发现在4.1.0版本中，ThemeToggle.tsx中定义的主题切换控件，就没有数值绑定和回调的逻辑… 只有在最新的main分支中才有… 最后，靠从源代码安装Taipy解决了这个问题… Stylekit并不能一次性设定所有的颜色官方虽然在文档中说，使用Stylekit这个设计可以让开发者灵活和简洁的控制主题配色，但是实际使用后发现，它似乎并不能控制页面的总背景色，需要通过css额外解决： 1234/* Setting theme color */body &#123; background-color: var(--color-background);&#125; plotly 没有绘制时间线图的函数这个… 纯属对plotly吐槽以下了，虽然Python在数据科学方面应用甚广，但是不论是Plotly、matplotlib、seaborn还是altair，其图形的丰富程度，还是比不过R下的生态… 当然R下有人写了，但是包管理太混乱，我用不了别人写的代码，又是另一回事了… 不过还好里程碑时间线这种东西也就是点、线加个文字，最后还是靠AI手措出来了… 对Plotly的设定方式说明不足这个问题也卡了我很久，Taipy的文档中，有说明如何不使用Taipy提供的接口，而是直接传递Ploty对象，将图形绘制在页面上。但是如何对Plotly对象进行配置，文档就说参考Plotly文档了。然后我就体会到了Plotly这个文档、看上去写得很细，实际上内容很贫乏的问题了。在他们官方的文档中，很多的配置项，居然只有fig.show()的时候才能传入… 而不是直接对Plotly对象去配置… 然后我绕了一大圈，发现Taipy的chart控件有一个plot_config参数… 这里可以传入fig.show()时的参数…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"Taipy","slug":"Taipy","permalink":"https://silenwang.github.io/tags/Taipy/"}]},{"title":"尝试修改chromeos中的终端app(中)","slug":"尝试修改chromeos中的终端app-中","date":"2025-09-05T01:53:10.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2025/09/05/尝试修改chromeos中的终端app-中/","permalink":"https://silenwang.github.io/2025/09/05/%E5%B0%9D%E8%AF%95%E4%BF%AE%E6%94%B9chromeos%E4%B8%AD%E7%9A%84%E7%BB%88%E7%AB%AFapp-%E4%B8%AD/","excerpt":"书接上回，在成功编译libapp项目下的代码后，接下来是两部分：修改libapp的代码，以及将修改应用到镜像中","text":"书接上回，在成功编译libapp项目下的代码后，接下来是两部分：修改libapp的代码，以及将修改应用到镜像中 terminal app原理上次我已经成功在浏览器中看到了terminal app，要修改代码，先要大致理解这个应用的原理。 在进行了一点尝试后，我对终端应的理解如下： 终端用由几个页面组成，最外侧的界面实际上是 terminal.html 这个页面，页面调用，然后调用一系列项目内的js脚本加载页面内容 建立ssh链接时，应用实际上是，调用chromeos下才可调用的本地API（类似electron？），打开一个新的窗口，然后显示terminal_ssh.html 这个页面，该页面会调用nassh目录中的js脚本来进行实际的终端渲染 启动ssh连接，实际上是将ssh的参数传递给terminal_ssh.html页面，然后页面内的脚本拼凑出ssh命令，交由下游的api去建立ssh链接 设置也是独立的页面，对应terminal_settings.html 修改libapp代码了解了应用的工作原理，接下来就是尝试修改代码了。由于我并没有专门学习过html&#x2F;js&#x2F;css这些网站的技术栈，虽然大致能理解代码的逻辑，但是我并不打算自己从头设计并编写代码，主要还是参考现有的代码，组合出我需要的功能。 就我自己的使用体验来看，sftp挂载到本地的这一现有功能，逻辑上和我想要的快速端口转发有一定相似性： sftp挂载需要先设定ssh部分的端口、用户等信息 在已有的登录条目基础上，进行sftp挂载，点击挂载后，与ssh登录一样新跳出一个页面，但是不能操作，只提示挂载信息，和关闭窗口后挂载自动结束 我想要的功能就参照这个逻辑来增改： 端口转发需要先设定ssh部分的端口、用户等信息 在已有的登录条目基础上，端口转发，点击转发后，跳出窗口设置要转发哪个端口 与ssh登录一样新跳出一个页面，但是不能操作，只提示转发的端口，和关闭窗口后挂载自动结束 实际修改的文件主要是terminal个nassh目录下的js文件，主要是加入转发的按钮，然后是参考sftp的功能实现，改一个能执行端口转发的函数出来 将修改应用到镜像在chromeos的源代码中，libapp并不是包名，在检索项目后，发现这些内容的编译实际上在crosh-extention.ebuild中，找到这个ebuild的目录，使用git生成补丁，放到这个目录中 1git diff COMMIT_HASH_1 COMMIT_HASH_2 &gt; patchfile.patch 然后还要进一步的修改ebuild文件，加入下面的内容后，构建时会自动调用补丁，进行代码修改 123PATCHES=( &quot;$&#123;FILESDIR&#125;&quot;/0001-forward.patch) 重新编译包和镜像这里我碰到了一个坑，如果只修改文件，直接按照之前的方法进行编译，其实是无法应用改动的。 根据找到的这个内容，需要使用cros_sdk中的cros_workon命令，标记对特定包进行修改，才会使用我修改后的ebuild文件来进行编译，而不是获取特定版本的源代码进行编译。 编译的过程[参考以前的步骤]就可以了。在执行build-packages时，工具会自动识别有更改的包，自动重新构建，然后将更新后的包放到chroot环境中去。 刷机以及启动[刷机也没有什么变化]，就是上次随便改内核，导致测试用的工程机duo砖了，因此参考[fydetab duo wiki的说明](https://wiki.fydetabduo.com/unbrick_the_fydetab_duo)进maskrom模式来刷。 进行调试？这里其实留下了一个问题，不论做什么开发，在进行实机测试和调试之前，理论上都应该先在测试或者虚拟环境中完成测试才是，否则要来回编译、刷机，会浪费大量时间。我想这也是各种SDK和Studio套件存在的意义。 但是，我目前还真不知道… 我这样修改应该要如何在刷机前调试？根据找到的博客，似乎是可以利用cros_sdk的虚拟机功能的，调用QEMU的kvm虚拟机，似乎可以对编译后的镜像进行调试。 下次就是把功能调试好，展示成果了！这次先展示一下刷机后界面的改变！","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"chromeos","slug":"chromeos","permalink":"https://silenwang.github.io/tags/chromeos/"},{"name":"terminal","slug":"terminal","permalink":"https://silenwang.github.io/tags/terminal/"},{"name":"libapp","slug":"libapp","permalink":"https://silenwang.github.io/tags/libapp/"},{"name":"终端","slug":"终端","permalink":"https://silenwang.github.io/tags/%E7%BB%88%E7%AB%AF/"}]},{"title":"SteamOS确实日趋成熟","slug":"SteamOS确实日趋成熟","date":"2025-08-25T00:53:31.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2025/08/25/SteamOS确实日趋成熟/","permalink":"https://silenwang.github.io/2025/08/25/SteamOS%E7%A1%AE%E5%AE%9E%E6%97%A5%E8%B6%8B%E6%88%90%E7%86%9F/","excerpt":"去年到今年，我玩了两个PC游戏，黑神话和明末，都是首发日就下载开玩的。这在5年前，真的是很难想象的一件事。那时候我刚打完猛汉王的本体，使用的是Windows KVM虚拟机加显卡直通。等到冰原资料片发售的时候，Proton就已经能支持相当多的旧游戏了，但是最新的游戏，首发很难支持，冰原我记得PC正式发售后两三个月，才能进入游戏，同时还存在一些bug，且Proton一旦升级，游戏可能就进不去了…","text":"去年到今年，我玩了两个PC游戏，黑神话和明末，都是首发日就下载开玩的。这在5年前，真的是很难想象的一件事。那时候我刚打完猛汉王的本体，使用的是Windows KVM虚拟机加显卡直通。等到冰原资料片发售的时候，Proton就已经能支持相当多的旧游戏了，但是最新的游戏，首发很难支持，冰原我记得PC正式发售后两三个月，才能进入游戏，同时还存在一些bug，且Proton一旦升级，游戏可能就进不去了… 再后来我记得是2077发售的时候，依然没能赶上首发日，大概等了几个星期，2077才能运行在Proton兼容层上，当时我已经换了显卡，我还测试了一下，进去没有大问题，但是中文字体和部分内置视频播片有问题。这都挺能接受的了… 只是我对2077题材并不那么感兴趣，就没有真的玩。 之后好几年，我都没有再用PC玩游戏过，因为电脑主要用来做一些分析的测试，硬盘不够，装不了游戏，一直都是玩的Switch。 然后就到了黑神话发售的24年，刚好我换了工作，电脑不需要继续用，我就索性重装了系统，试了试Bazzite，因为这是当时唯一支持N卡的类SteamOS发行版了。说实话，运行效果超出我的预期，居然发售首日就能进游戏，虽然流畅度欠佳，但是作为马赛克猎人的我…540p，30帧不到也不是没玩过，1080p 40~60的效果，我完全能接受，游戏本身也不难，就跟着大伙一起通关了。 今年的明末则更出乎我的意料，我并没有保留Bazzite系统，只是Ubuntu 22.04装了N卡的闭源驱动，居然也直接能进游戏，运行效果接近去年黑猴，甚至我iPad串流玩(为了用NS的手柄)都不会卡… 这样一来，之后发售的国产游戏，我应该都能第一时间尝试上了… 感谢G胖，祝早日干翻Windows…","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"Steam","slug":"Steam","permalink":"https://silenwang.github.io/tags/Steam/"},{"name":"SteamOS","slug":"SteamOS","permalink":"https://silenwang.github.io/tags/SteamOS/"},{"name":"Bazzite","slug":"Bazzite","permalink":"https://silenwang.github.io/tags/Bazzite/"},{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/tags/Gaming/"}]},{"title":"尝试修改chromeos中的终端app(上)","slug":"尝试修改chromeos中的终端app-上","date":"2025-08-21T00:13:10.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2025/08/21/尝试修改chromeos中的终端app-上/","permalink":"https://silenwang.github.io/2025/08/21/%E5%B0%9D%E8%AF%95%E4%BF%AE%E6%94%B9chromeos%E4%B8%AD%E7%9A%84%E7%BB%88%E7%AB%AFapp-%E4%B8%8A/","excerpt":"我是用fydeos &#x2F; chromeos也有两年了, 系统中虽然提供了能用的终端app, 但是说真的, 还不是那么好用, 比如我在开发时, 常常会需要进行多个端口的转发. 虽然我可以通过输入端口转发的ssh命令来达成目的,但是这样一来会需要手动输入比较多的参数, 二来端口转发期间会一直需要保持ssh登录后的窗口, 对于我这种特别喜欢降低开启窗口数目的强迫症来说, 开着三四个不会前台使用的窗口真的很难受… 所以我就想, 我能不能自己动手, 在AI帮助下, 修改系统自带的默认终端客户端, 给他加上vscode那样的快捷转发功能呢?","text":"我是用fydeos &#x2F; chromeos也有两年了, 系统中虽然提供了能用的终端app, 但是说真的, 还不是那么好用, 比如我在开发时, 常常会需要进行多个端口的转发. 虽然我可以通过输入端口转发的ssh命令来达成目的,但是这样一来会需要手动输入比较多的参数, 二来端口转发期间会一直需要保持ssh登录后的窗口, 对于我这种特别喜欢降低开启窗口数目的强迫症来说, 开着三四个不会前台使用的窗口真的很难受… 所以我就想, 我能不能自己动手, 在AI帮助下, 修改系统自带的默认终端客户端, 给他加上vscode那样的快捷转发功能呢? 克隆代码百尺竿头第一步, 先得知道项目代码是否能获取, 这个deepseek, kimi 和 chatGPT 都能给我正确答案: https://chromium.googlesource.com/apps/libapps, 直接克隆这个项目到本地就行. 项目编译项目内几乎每个目录都自带说明, 有详细有简略的, 阅读一遍, 结合AI的回答可知, 关键的文件夹大致如下: hterm: js编写的终端模拟器, 登录后看到的终端所有内容都是它渲染的 nassh: chorme商店的终端模拟器插件, 结合了hterm和ssh_client的内容 ssh_client: 与openssh通信的部分 terminal: 我们看到的terminal app前端 在chromeos外尝试运行要开发&#x2F;修改一个应用, 首先需要部署相应的开发及调试环境, 这个是这次最为难我的地方了, 虽然项目的文档内容比较丰富, 但是仍然不至于丰富到让小白如我能轻易学会怎么构建一个可以进行调试的测试版本app, 所以借助AI, 找到了一个至少能看到界面的方案: 使用pixi创建一个虚拟环境(在我的机器上必须这么做, 否则下一步会提示文件无权限复制的错误)123456789[workspace]authors = [&quot;Sylens Wong &lt;qiumin14@163.com&gt;&quot;]channels = [&quot;conda-forge&quot;]name = &quot;fydeos_dev&quot;platforms = [&quot;linux-64&quot;]version = &quot;0.1.0&quot;[activation.env]PATH = &quot;$PIXI_PROJECT_ROOT/libapps/libdot/bin:$PATH&quot; pixi shell进入虚拟环境, 然后运行项目自带的kokoro/build脚本完成所有子项目的构建和测试(必须要跑完测试, 测试部分直接写进去了) 进入terminal目录, 然后将一些这个前端需要, 但是并不在这个项目内的文件复制过来123cp ../node_modules/xterm/css/xterm.css css/ # 缺少的csscp ../nassh/js/* js/ # 缺少的js脚本cp -r ../nassh/_locales ../ # 缺少的国际语言文件 在项目根目录运行npm run start启动http服务, 然后浏览器输入如下地址, 就能看到terminal的前端页面了: http://localhost:8080/terminal/html/terminal.html: 主页面 http://localhost:8080/terminal/html/terminal_settings.html: 配置页面 虽然页面上的一些内容是可以用的, 比如添加ssh配置, 但是基本的核心功能, 如实际进行ssh连接, 都是无法使用的, 因为这只是这个app的前端, 实际的连接&#x2F;终端渲染等内容都不在这里. 不过, 总算是往前进了一小步~","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"chromeos","slug":"chromeos","permalink":"https://silenwang.github.io/tags/chromeos/"},{"name":"terminal","slug":"terminal","permalink":"https://silenwang.github.io/tags/terminal/"},{"name":"libapp","slug":"libapp","permalink":"https://silenwang.github.io/tags/libapp/"},{"name":"终端","slug":"终端","permalink":"https://silenwang.github.io/tags/%E7%BB%88%E7%AB%AF/"}]},{"title":"我是什么天煞孤星体质么","slug":"我是什么天煞孤星体质么","date":"2025-07-27T19:57:09.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2025/07/27/我是什么天煞孤星体质么/","permalink":"https://silenwang.github.io/2025/07/27/%E6%88%91%E6%98%AF%E4%BB%80%E4%B9%88%E5%A4%A9%E7%85%9E%E5%AD%A4%E6%98%9F%E4%BD%93%E8%B4%A8%E4%B9%88/","excerpt":"人无语的时候，真的会笑出来，我的直接领导又又又又又又离职了，为什么这么多又，来来来，我们画个时间线盘一盘，我到底克过多少顶头上司。","text":"人无语的时候，真的会笑出来，我的直接领导又又又又又又离职了，为什么这么多又，来来来，我们画个时间线盘一盘，我到底克过多少顶头上司。 部分时间点可能不甚准确，可能偏差了一俩月，但克领导这件事，绝对确有其事… 2017.07-2018.01 公司: 天津某生信服务公司经过: 我的第一份工作，两个月转正后，我被分配到了专门做个性化的大项目组，然后我的组长，在次年出拿到年终之后就辞职去北京了，然后我就直接向总监管汇报了。之后我18年8月份也跑路了。 2018.08-2018.10 公司: 杭州某基因科技公司经过: 我的第二份工作，跑到了杭州，当时专程从天津跑到杭州来面试的，组长和部门领导人都非常好，所以决定过来。但是，还没等我过试用期，我的部门直接被拆掉了… 2018.10-2019.04左右 公司: 杭州某基因科技公司经过: 还是杭州这个公司，部门被拆开后，我被分到了隔壁部门负责算法开发的组，组长是个学数学的海归，人特别好，我还觉得这结果还不错，但是，后面我才知道部门领导对组长并不满意（当然组长从来没抱怨过这些），然后组长在4月份跑路，去做擅长的深度学习了（现在看来…无比正确的决定啊）。组长跑路后，我们组也并没有被合并的计划，我跟另外一个小伙伴快乐的什么正事也不干…还拿了好几个月的工资。但是最终觉得这样下去不是个事，又跑路了… 2019.07-2019.12 公司: 杭州某生物科技公司经过: 然后来到了，我干的最长的一间公司。招我进来的时候，说是准备招两个人，但是我入职后，一直都没招到下一个，组长说是领导不满意，都被卡掉了（为什么我没被卡呢，因为一些原因，领导没面我）。刚开始还挺开心，当时猛汉王上PC了，我这段时间还攒了电脑，打猛汉王打了100多小时。然后，组长突然就辞职了… 然后，我被老板指派顶替了组长… 2020.04-2021.04 公司: 杭州某生物科技公司经过: 这一个我具体的时间点记得不是那么清楚，但过程就是这样：首先，这间公司有两个生物信息相关的组，我的组是研发，隔壁组是生产。我继任研发组长后，由于研发向的任务并没有那么多，所以老板并不准备给我的组招人。在后续的一年期间，先是隔壁组的一个后备辞职结婚，然后老板一直对隔壁组的工作进度不是那么满意，矛盾比较多，所以先是组员自己离职，后来老板甚至直接把隔壁组组长也裁了… 甚至老板还找我讨论过这事… Woc这断人事业的事，在加上会让我工作翻倍，我当然说，可以先找接替的，找到再裁嘛… 然而未果… 于是，原本两个部门5个人干活，变成了我生产研发一把抓，然后就被拉去做临床实验申报了… 2022.01-2023.12 公司: 杭州某生物科技公司经过: 是的，居然还是这间公司… 干的久，克的人也就多。在接手申报工作后，人手明显是不够用了，早上九点半到晚上十二点，工作也难以干完，于是22年开始，开始允许我招人。印象中最多的时候，组里加我一共能到5人，然后因为申报并不顺利，资金链实在困难，在领导的要求下开始裁人… 缩减到3各人… 在此期间老板招我聊过人选，我从保证稳定的角度出发，因为我觉得有个组员明显有跑路的倾向，但是老板从能力的角度触发… 没有采纳我的方案… 于是果不其然，23年1月，组里就只剩下2个人…阿门。好在后续申报总算是成功，拿到了下一步投资，公司总算没黄。不然我就要达成克老板的成就了… 然后我自己在申报成功后离职了… 2024.04-2025.01 公司: 杭州某医学科技公司经过: 来到了现在的公司，是的故事并没有结束… 还是熟悉的配方。还算平静的度过了第一个半年，到了今年，部门突然就绷了，先是有同事被迫离职，然后我的部门领导自己辞职了… 不过这次有点不一样，我来的时候，部门里本来就是一个行政领导，一个技术领导，辞职的是行政领导。 2025.01-2025.07 公司: 杭州某医学科技公司经过: 终于走到了现在的时间线，又过了有惊无险的半年后，本周，技术领导也跟我说，他准备辞职了… 我，无语的笑了出来… 嗯，纵观我的整个职业生涯，我真是克了领导克同事，克完同事还能差点把公司克黄… Emmmm，这都是什么个事…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"生物信息","slug":"生物信息","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF/"},{"name":"职场","slug":"职场","permalink":"https://silenwang.github.io/tags/%E8%81%8C%E5%9C%BA/"},{"name":"离职","slug":"离职","permalink":"https://silenwang.github.io/tags/%E7%A6%BB%E8%81%8C/"},{"name":"职业生涯","slug":"职业生涯","permalink":"https://silenwang.github.io/tags/%E8%81%8C%E4%B8%9A%E7%94%9F%E6%B6%AF/"},{"name":"杭州","slug":"杭州","permalink":"https://silenwang.github.io/tags/%E6%9D%AD%E5%B7%9E/"},{"name":"career","slug":"career","permalink":"https://silenwang.github.io/tags/career/"},{"name":"job-hopping","slug":"job-hopping","permalink":"https://silenwang.github.io/tags/job-hopping/"},{"name":"bioinformatics","slug":"bioinformatics","permalink":"https://silenwang.github.io/tags/bioinformatics/"}]},{"title":"使用AI的能与不能----两次失败的尝试","slug":"AI能做和不能做的-两次失败的尝试","date":"2025-07-15T00:44:45.000Z","updated":"2026-02-10T14:03:13.673Z","comments":true,"path":"2025/07/15/AI能做和不能做的-两次失败的尝试/","permalink":"https://silenwang.github.io/2025/07/15/AI%E8%83%BD%E5%81%9A%E5%92%8C%E4%B8%8D%E8%83%BD%E5%81%9A%E7%9A%84-%E4%B8%A4%E6%AC%A1%E5%A4%B1%E8%B4%A5%E7%9A%84%E5%B0%9D%E8%AF%95/","excerpt":"相比俩年前在前司，现在的我用AI更加频繁了。如果说之前限制我使用AI的是工具本身的便捷性，现在的限制似乎已经不在AI，而是我自己的知识和技术了。","text":"相比俩年前在前司，现在的我用AI更加频繁了。如果说之前限制我使用AI的是工具本身的便捷性，现在的限制似乎已经不在AI，而是我自己的知识和技术了。 上周末做了两个尝试，一是尝试用Aider和Openhands帮我修改Theia的remote模块。因为根据AI的回答，Theia的设计是完全前后端分离的，前端只显示，后端则负责处理一切请求。如果这是正确的，那么开发一个在Browser版本的Theia中可以使用的remote版本应该是可行的。而有了这个，就能永久的解决我在Fydetab Duo上用VScode的痛点—-图形性能不足导致VScode过卡了。 然而，虽然两个Agent都能给我一定的指引，但是没有Node.js &#x2F; Electron的基本知识，只靠Agent写的代码和回答，我无法了解Agent写的代码是否靠谱，由于我也不知道应该如何调试Theia这么大型的Node.js项目，我也无法根据一些报错来判断问题是什么。最后就是，以我的知识和技术，依然无法在AI指导下完成开发。 另外一个尝试还是想解决一样的问题，只不过我换了一个方向，既然我发构建我要的IDE，那我是否可以设法提升当前Fydetab Duo的图形性能，具体来说，是设法更新内核，让Duo上的FydeOS能支持Vulkan，有了Vulkan，也许VScode的性能可以提升不少。 然后这个想法还是失败了，AI虽然指引我找到了可能适用于RK3588的新版内核源码，但是我不太看得懂在编译时替换&#x2F;修改内容的描述。于是我尝试了最简单粗暴的方式—-直接替换overlay中的内核项目repo，强行用6.12当原来的6.1来用。我想这最多会有一堆功能不能用吧？然后我想简单了，直接给工程机刷成砖了… 这么说，也是一样的问题以我的知识和技术，我不知道我在做的到底对不对，也很难从结果中得到有效的改进信息，我只知道这不行，但是，怎样能行呢？以这两年的使用经验，按AI的建议一条条试是不靠谱的，因为其中可能有大量专业人士一眼就知道不对的方案，而我因为什么也不知道，在无穷尽的枚举后，无法得到什么正向反馈。 所以，我觉得我现在能用到的AI真的是Copilot，不应该指望它来从头实现任何我没有概念东西，而是应该在自己学习和构建了基本的体系，在能获得有效的反馈后（起码能测试和信息丰富的报错后），才有可能最大程度发挥它作为Copilot的作用。 也就是，从0到1依旧困难，但是起步后，1到10，应该是比过去更容易了。10到100… 我没到100过，还真不知道… 但是我觉得… 这些可能会被上下文长度限制吧。","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"AI辅助开发","slug":"AI辅助开发","permalink":"https://silenwang.github.io/tags/AI%E8%BE%85%E5%8A%A9%E5%BC%80%E5%8F%91/"},{"name":"技术尝试","slug":"技术尝试","permalink":"https://silenwang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%B0%9D%E8%AF%95/"},{"name":"Theia","slug":"Theia","permalink":"https://silenwang.github.io/tags/Theia/"},{"name":"FydeOS","slug":"FydeOS","permalink":"https://silenwang.github.io/tags/FydeOS/"},{"name":"内核","slug":"内核","permalink":"https://silenwang.github.io/tags/%E5%86%85%E6%A0%B8/"},{"name":"aider","slug":"aider","permalink":"https://silenwang.github.io/tags/aider/"},{"name":"openfyde","slug":"openfyde","permalink":"https://silenwang.github.io/tags/openfyde/"}]},{"title":"再次尝试编译openfyde（下)","slug":"再次尝试编译openfyde-下","date":"2025-06-19T23:09:23.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2025/06/19/再次尝试编译openfyde-下/","permalink":"https://silenwang.github.io/2025/06/19/%E5%86%8D%E6%AC%A1%E5%B0%9D%E8%AF%95%E7%BC%96%E8%AF%91openfyde-%E4%B8%8B/","excerpt":"换了主板和CPU后，一切都顺畅了… 也不知道是原来主板还是CPU的问题，编译几十分钟就会报错，然后再进行编译又不会在上次的地方报错。着还是我人生第一次真遇到硬件不兼容这种问题… 再次活久见。 于是，编译openfyde的下篇这就来了，可惜在被破硬件折磨的过程中，r132-dev版本的 prebuilt image已经更新了… 没赶上热点呀…","text":"换了主板和CPU后，一切都顺畅了… 也不知道是原来主板还是CPU的问题，编译几十分钟就会报错，然后再进行编译又不会在上次的地方报错。着还是我人生第一次真遇到硬件不兼容这种问题… 再次活久见。 于是，编译openfyde的下篇这就来了，可惜在被破硬件折磨的过程中，r132-dev版本的 prebuilt image已经更新了… 没赶上热点呀… 其实我上次已经进行到最后几步了，只是在编译chorme这个庞然大物的时候因为我硬件的问题被卡住了。在完成编译后，就可以生成直接刷写到u盘的镜像了。 只是这一次我还真解决了一个上次的问题，即得到了chromiumos.bin之后，如何获得能够用Rockchip镜像工具刷写的镜像。按照起步走教程得到的是bin镜像，而官方的预编译都是img，明显格式不同。同时用Rockchip工具对官方的openfyde prebuilt镜像解包的话，似乎会得到一些不包含在bin中的内容。 其实官方是公布了工具的，它就是openFyde&#x2F;rk3588-image-maker，只是上次作为一个纯小白，都看不明白编译过程中到底在干些啥，也就更看不明白openfyde下的项目都是些啥了。 生成所需镜像的步骤很简单，还是先克隆这个项目，然后进根目录，跟着这个项目的说明运行下面的命令就行： 1234# 从bin中挂载需要的内容./map_chromiumos_image.sh /PATH/TO/CHROMIUMOS/IMAGE.bin --board fydetab_duo# 生成 update.img./rk3588-mkupdate.sh 须注意，在我这次编译的r132版本上，项目下的 Image/parameter.txt文件需要修改，即0xa0006d@0x00b02040(STATE)要改成0xa0006d@0x00b02040(STATE) 之后将生成的image拷贝下来，用rockchip官方工具刷写就好。这次编译的镜像触屏、蓝牙、Linux容器都正常，应该是没什么问题了。 接下来就可以试着往里头塞东西啦！","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"openfyde","slug":"openfyde","permalink":"https://silenwang.github.io/tags/openfyde/"},{"name":"fydeos","slug":"fydeos","permalink":"https://silenwang.github.io/tags/fydeos/"},{"name":"硬件兼容","slug":"硬件兼容","permalink":"https://silenwang.github.io/tags/%E7%A1%AC%E4%BB%B6%E5%85%BC%E5%AE%B9/"},{"name":"编译","slug":"编译","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E8%AF%91/"},{"name":"镜像生成","slug":"镜像生成","permalink":"https://silenwang.github.io/tags/%E9%95%9C%E5%83%8F%E7%94%9F%E6%88%90/"},{"name":"Rockchip","slug":"Rockchip","permalink":"https://silenwang.github.io/tags/Rockchip/"}]},{"title":"使用github_action编译arm版的theia_ide","slug":"使用github-action编译arm版的theia-ide","date":"2025-06-16T23:20:58.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/06/16/使用github-action编译arm版的theia-ide/","permalink":"https://silenwang.github.io/2025/06/16/%E4%BD%BF%E7%94%A8github-action%E7%BC%96%E8%AF%91arm%E7%89%88%E7%9A%84theia-ide/","excerpt":"自从第一次接触chromeos&#x2F;fydeos开始，我就一直在尝试各种不同的 vscode(-like) 编辑器，最近因为看到华为的CodeArt，知道了它的上游项目theia，又开始了折腾。奈何我手上的设备已经是只有8G内存的 fydeos 不是之前的16G Manjaro，也不是PixelBook 2017。在Linux容器下的可用内存十分受限，连编译个arm版的 theiaide-ide browser版都不得行… 那… 只有又来白嫖Github了","text":"自从第一次接触chromeos&#x2F;fydeos开始，我就一直在尝试各种不同的 vscode(-like) 编辑器，最近因为看到华为的CodeArt，知道了它的上游项目theia，又开始了折腾。奈何我手上的设备已经是只有8G内存的 fydeos 不是之前的16G Manjaro，也不是PixelBook 2017。在Linux容器下的可用内存十分受限，连编译个arm版的 theiaide-ide browser版都不得行… 那… 只有又来白嫖Github了 这次结合之前提到的 [白嫖codespace写博客] 和 [github action的使用] 。 首先在github上新建一个项目，然后找到右上角的Code创建该项目的codespace，即可在浏览器中使用vscode，直接进行代码编写和保存。我直接参照之前已经写过的certimate_win7项目，创建一个github workflow，注意Runner用Github提供的Arm Runner。 Theia-IDE的原项目还没有正式的Release，所以不能根据Tag下载打包好的Release，改成使用checkout来获得特定的代码。 然后按照项目下的browser.Dockerfile文件内容，设置编译步骤，接着将整个代码目录打包，上传到我自己项目的Release中。 下载编译文件后，容器内按照官方的说明安装好系统级别的依赖，yarn browser start就可以启动了。 因为我是fydeos用，直接编译的browser版，如果需要桌面版本，按照官方的说明生成Arm版就好了。","categories":[{"name":"Script","slug":"Script","permalink":"https://silenwang.github.io/categories/Script/"}],"tags":[{"name":"FydeOS","slug":"FydeOS","permalink":"https://silenwang.github.io/tags/FydeOS/"},{"name":"ChromeOS","slug":"ChromeOS","permalink":"https://silenwang.github.io/tags/ChromeOS/"},{"name":"ARM","slug":"ARM","permalink":"https://silenwang.github.io/tags/ARM/"},{"name":"GitHub Actions","slug":"GitHub-Actions","permalink":"https://silenwang.github.io/tags/GitHub-Actions/"},{"name":"Codespaces","slug":"Codespaces","permalink":"https://silenwang.github.io/tags/Codespaces/"},{"name":"theia-ide","slug":"theia-ide","permalink":"https://silenwang.github.io/tags/theia-ide/"}]},{"title":"再次尝试编译openfyde（上）","slug":"再次尝试编译openfyde-上","date":"2025-06-15T10:50:34.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2025/06/15/再次尝试编译openfyde-上/","permalink":"https://silenwang.github.io/2025/06/15/%E5%86%8D%E6%AC%A1%E5%B0%9D%E8%AF%95%E7%BC%96%E8%AF%91openfyde-%E4%B8%8A/","excerpt":"今年年初的时候，就尝试编译openfyde，想着学习下编译和修改openfyde系统，也利用一下我多余的一台工程机。然而半年都过去了… 上次编译出镜像的问题都还没解决…","text":"今年年初的时候，就尝试编译openfyde，想着学习下编译和修改openfyde系统，也利用一下我多余的一台工程机。然而半年都过去了… 上次编译出镜像的问题都还没解决… 看着最近最新的r132代码也在逐步更新了，那我先… 尝试再编译一次吧… 本次基本遵循[之前的步骤]，即装系统依赖，下载depot_tools，克隆代码，进入chroot环境然后开始编译。不同的是，目前 r132 版本的代码应该是还没有完整上传，因此编译中还会碰到一些问题： chromeos-kernel-6_1-6.1.115-r1676的克隆地址还没有修改，无法获取源代码因此无法编译 libv4lplugins-0.0.1代码还有Bug，需要再加一个补丁修复：1234567891011Index: libv4l-rkmpp/src/libv4l-rkmpp.c===================================================================--- libv4l-rkmpp.orig/src/libv4l-rkmpp.c+++ libv4l-rkmpp/src/libv4l-rkmpp.c@@ -1206,5 +1206,4 @@ .init = &amp;plugin_init, .close = &amp;plugin_close, .ioctl = &amp;plugin_ioctl,- .mmap = &amp;plugin_mmap, &#125;; 目前我的破电脑还在编译着编译着就死机的状态… 回头完成了再更新…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"openfyde","slug":"openfyde","permalink":"https://silenwang.github.io/tags/openfyde/"},{"name":"fydeos","slug":"fydeos","permalink":"https://silenwang.github.io/tags/fydeos/"},{"name":"系统编译","slug":"系统编译","permalink":"https://silenwang.github.io/tags/%E7%B3%BB%E7%BB%9F%E7%BC%96%E8%AF%91/"},{"name":"Linux系统","slug":"Linux系统","permalink":"https://silenwang.github.io/tags/Linux%E7%B3%BB%E7%BB%9F/"},{"name":"补丁修复","slug":"补丁修复","permalink":"https://silenwang.github.io/tags/%E8%A1%A5%E4%B8%81%E4%BF%AE%E5%A4%8D/"},{"name":"chroot环境","slug":"chroot环境","permalink":"https://silenwang.github.io/tags/chroot%E7%8E%AF%E5%A2%83/"}]},{"title":"使用playwright控制浏览器进行测试","slug":"使用playwright控制浏览器进行测试","date":"2025-06-09T00:44:33.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/06/09/使用playwright控制浏览器进行测试/","permalink":"https://silenwang.github.io/2025/06/09/%E4%BD%BF%E7%94%A8playwright%E6%8E%A7%E5%88%B6%E6%B5%8F%E8%A7%88%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%B5%8B%E8%AF%95/","excerpt":"对于要交互操作的网站，光使用pytest进行API测试是不够的，因为这不涉及前端。以前我使用过Selenium控制浏览器来完成爬虫任务，现在发现测试领域，微软的playwright也能控制浏览器以进行自动化的测试，且使用起来比Selenium还简单，因为它支持自动录制测试用例。","text":"对于要交互操作的网站，光使用pytest进行API测试是不够的，因为这不涉及前端。以前我使用过Selenium控制浏览器来完成爬虫任务，现在发现测试领域，微软的playwright也能控制浏览器以进行自动化的测试，且使用起来比Selenium还简单，因为它支持自动录制测试用例。 安装使用pixi可以快速完成playwright的安装，不过安装之后还需要调用playwright来安装浏览器依赖，这一点与Selenium不同，Selenium是直接调用系统中支持的浏览器的。 12# 安装 firfox和 chromiumplaywright install --with-deps firefox chromium 结合Pytest使用Playwright支持多种语言，同时还支持Python下的Pytest框架，在命令行中使用playwright codegen -b firefox http://127.0.0.1:8000 打开浏览器后，在录制窗口中选择Pytest，就可以录制Pytest代码了。录制后一个测试会长这样： 1234567891011121314151617BASE_URL = &#x27;http://127.0.0.1:8000&#x27;def test_add_sample(lab_mem_page): try: lab_mem_page.goto(f&quot;&#123;BASE_URL&#125;/page&quot;, wait_until=&quot;load&quot;) except TimeoutError: # 如果失败，进行一次重试 lab_mem_page.reload(wait_until=&quot;load&quot;) lab_mem_page.get_by_role(&quot;button&quot;, name=&quot;添加/修改样本&quot;).click() lab_mem_page.get_by_role(&quot;menuitem&quot;, name=&quot;添加样本&quot;).click() lab_mem_page.get_by_role(&quot;textbox&quot;, name=&quot;*内部编号&quot;).fill(&quot;CODE&quot;) lab_mem_page.get_by_role(&quot;textbox&quot;, name=&quot;*住院号&quot;).fill(&quot;6666&quot;) lab_mem_page.get_by_role(&quot;textbox&quot;, name=&quot;*姓名&quot;).fill(&quot;2222&quot;) lab_mem_page.get_by_role(&quot;textbox&quot;, name=&quot;*性别&quot;).click() lab_mem_page.get_by_role(&quot;listitem&quot;).filter(has_text=&quot;男&quot;).click() lab_mem_page.get_by_role(&quot;button&quot;, name=&quot;提交&quot;).click() expect(lab_mem_page.get_by_text(&quot;添加成功&quot;)).to_be_visible() 完成测试用例后，可以进行测试，然后看是否有内容需要删减和调整。 利用Pytest的特性在结合Pytest使用进行测试时，Pytest的fixture系统以及特殊的conftest.py文件都是可用的，可以像普通Pytest测试一样进行某些信息的共享，以让测试更高效和稳定。 录制系统的问题录制功能确实很大程度上加速了测试的编写，但是自动录制对页面元素的选取不是那么一劳永逸的，尤其当页面上要交互的元素是动态生成的时候。所以要写出稳定的测试用例，还是要懂一些前端知识，能自己找出目标元素在资源树中的唯一定位方式才行。","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"自动化测试","slug":"自动化测试","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"},{"name":"浏览器测试","slug":"浏览器测试","permalink":"https://silenwang.github.io/tags/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%B5%8B%E8%AF%95/"},{"name":"playwright","slug":"playwright","permalink":"https://silenwang.github.io/tags/playwright/"},{"name":"pytest","slug":"pytest","permalink":"https://silenwang.github.io/tags/pytest/"},{"name":"python","slug":"python","permalink":"https://silenwang.github.io/tags/python/"}]},{"title":"使用pytest进行测试网络API测试","slug":"使用pytest进行测试网络API测试","date":"2025-06-09T00:25:03.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/06/09/使用pytest进行测试网络API测试/","permalink":"https://silenwang.github.io/2025/06/09/%E4%BD%BF%E7%94%A8pytest%E8%BF%9B%E8%A1%8C%E6%B5%8B%E8%AF%95%E7%BD%91%E7%BB%9CAPI%E6%B5%8B%E8%AF%95/","excerpt":"这半年有相当一部分工作是维护公司的网站，由于是半路接手的代码，难保维护的时候不带来新的bug，因此根据领导的要求，学习了如何进行自动测试。","text":"这半年有相当一部分工作是维护公司的网站，由于是半路接手的代码，难保维护的时候不带来新的bug，因此根据领导的要求，学习了如何进行自动测试。 测试使用的是python下使用最多的测试框架，pytest。 框架使用非常简单，创建以test_开头的文件，然后在其中编写以test_开头的函数之后，在函数内写测试代码，并加上assert断言就能完成最基本的测试了： 123456789BASE_URL = &#x27;http://127.0.0.1:4567&#x27;def test_login_success(): login_data = &#123;&quot;username&quot;: &quot;USER&quot;, &quot;password&quot;: &quot;123456&quot;&#125; response = requests.post(f&quot;&#123;BASE_URL&#125;/login&quot;, json=login_data) # 断言关键结果 assert response.status_code == 200 assert &quot;accessToken&quot; in response.json().get(&quot;data&quot;) 在实际测试的过程中，我们可能会需要设置一些在不同测试间共用的信息，比如我要测试的API全都是要登录验证才能使用的，因此正好使用pytest的fixture系统，在测试开始前先获取登录token，然后每个测试函数都用同样的token来访问API： 1234567@pytest.fixture(scope=&#x27;session&#x27;)def prod_admin_auth_header(): return auth_header(&quot;admin&quot;, &quot;123456&quot;)def test_get_dictionary_id(prod_admin_auth_header): response = requests.get(f&quot;&#123;BASE_URL&#125;/GetDictionaryid&quot;, headers=lab_mem_auth_header) assert response.status_code == 200 这里，被设定为fixture的函数，其函数名可以作为测试函数的参数直接传到测试函数中去，不需要做额外的操作。 另外还可以在测试文件夹创建一个特殊文件conftest.py，将整个测试需要共享的fixture都放在里面，这样在其他测试文件中，不需要手动导入，也可以直接使用设定过的fixture。","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"自动化测试","slug":"自动化测试","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"},{"name":"pytest","slug":"pytest","permalink":"https://silenwang.github.io/tags/pytest/"},{"name":"python","slug":"python","permalink":"https://silenwang.github.io/tags/python/"},{"name":"测试","slug":"测试","permalink":"https://silenwang.github.io/tags/%E6%B5%8B%E8%AF%95/"},{"name":"API测试","slug":"API测试","permalink":"https://silenwang.github.io/tags/API%E6%B5%8B%E8%AF%95/"}]},{"title":"活久见...公司服务器被恶意程序攻击了","slug":"活久见公司服务器被恶意程序攻击了","date":"2025-06-07T00:32:44.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2025/06/07/活久见公司服务器被恶意程序攻击了/","permalink":"https://silenwang.github.io/2025/06/07/%E6%B4%BB%E4%B9%85%E8%A7%81%E5%85%AC%E5%8F%B8%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%94%BB%E5%87%BB%E4%BA%86/","excerpt":"从我大三（2011）开始玩当时远古版本的Linux Deepin起，到现在已经14年了。这么长的时间中，debian&#x2F;redhat&#x2F;arch系我都用过，但除了研三我自己把我的毕业论文误删了，我从来没有在Linux发行版下碰到过任何恶意程序或病毒。 然而上个星期，我公司的服务器… 居然中毒了…","text":"从我大三（2011）开始玩当时远古版本的Linux Deepin起，到现在已经14年了。这么长的时间中，debian&#x2F;redhat&#x2F;arch系我都用过，但除了研三我自己把我的毕业论文误删了，我从来没有在Linux发行版下碰到过任何恶意程序或病毒。 然而上个星期，我公司的服务器… 居然中毒了… 起初维护的服务商跟我说我们服务器可能中毒的时候，我还半信半疑，毕竟给我技术支持的人，看上去相当不靠谱。 我全程看着对方远程操作服务器… 对命令的熟悉程度… 甚至还不如我… 就开着TOP然后一个个翻进程名，甚至过滤用户、按CPU占用排序都不会的样子。还对着TOP问了我几个明显没问题的进程… 并在重启后对着TOP说，看上去没问题呀（看不到CPU还是100%的样子）… 最后捣鼓了半天，只留下一句，可能是挖矿病毒，重装吧，就不回复了… 虽然我们的数据和系统是分开的，重装还是会让我们花费额外的时间在重新配置上，况且病因都没确定就下药，满足不了我的好奇心 也不一一定就能解决问题不是… 于是我还是Google了一下先… 真是挖矿病毒啊起初的Google其实也没什么成果，因为除了CPU被100%占用，看不到占用进程这两点符合，netstat没有看到挖矿程序用来连接挖矿池的链接，然后systemctl莫名其妙出了问题，导致我没法安装一些博文里说到的软件。 但是到这时我其实还是没往病毒想，直到我翻到一个博文要用lsattr和chattr查看并修改systemctl的权限，以解决安装软件的问题时，我发现服务器上没有lsattr，同时运行chattr会给一个很奇怪的提示。我当时还想，也许是这个服务器本来没装这俩？ 直到我想起，我们特么还有一台一模一样的服务器呀… 然后登录上去看了看… woc, 另一台服务器是有lsattr和chattr的… 我这才想起翻回去看，出问题的服务器上的chattr是个什么玩意… cat一看，特么这程序明显是被替换了呀！ 接着我就反应过来了，特么top&#x2F;htop&#x2F;netstat这些，肯定全部被改了呀！ 发现恶意程序修改以及应对 lsattr: 直接被删除，无法查看文件状态，用另一台服务器上的文件替换 chattr: 被替换后，赋予了’i’和’a’，以保证root都无法删除这个文件，无法重新安装chattr进行修复，用另一台服务器上的文件替换 top&#x2F;htop: 应该被修改过，所以看不到恶意程序进程，top用另一台服务器的替换，htop重装 systemctl&#x2F;添加服务: 添加了一个启动恶意程序的服务，同时程序被替换后看不到恶意程序服务，用chattr移除不可动权限后重新安装systemd ls: 被替换后，无法看到恶意程序的可执行文件，以及服务文件，用另一台服务器上的文件替换 reboot: 应该被修改过，发现sha与另一台服务器不一样，用另一台服务器上的文件替换，但是修复回来后，依然不能正常重启 netstat: 被替换后，无法看到恶意程序开启的网络链接，重装net-tools 后记只能说，果然是见多才能识广，我怎么就没想到，恶意程序也是要进化的… 直接能看它的全修改一遍…另外，我这还… 真干上运维了呀…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Linux安全","slug":"Linux安全","permalink":"https://silenwang.github.io/tags/Linux%E5%AE%89%E5%85%A8/"},{"name":"服务器安全","slug":"服务器安全","permalink":"https://silenwang.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/"},{"name":"恶意程序","slug":"恶意程序","permalink":"https://silenwang.github.io/tags/%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F/"},{"name":"挖矿病毒","slug":"挖矿病毒","permalink":"https://silenwang.github.io/tags/%E6%8C%96%E7%9F%BF%E7%97%85%E6%AF%92/"},{"name":"系统工具","slug":"系统工具","permalink":"https://silenwang.github.io/tags/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E5%85%B7/"},{"name":"linux","slug":"linux","permalink":"https://silenwang.github.io/tags/linux/"},{"name":"security","slug":"security","permalink":"https://silenwang.github.io/tags/security/"},{"name":"malware","slug":"malware","permalink":"https://silenwang.github.io/tags/malware/"},{"name":"mining-virus","slug":"mining-virus","permalink":"https://silenwang.github.io/tags/mining-virus/"},{"name":"system-tools","slug":"system-tools","permalink":"https://silenwang.github.io/tags/system-tools/"}]},{"title":"使用aider辅助编程工作","slug":"使用aider辅助编程","date":"2025-04-25T00:42:46.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/04/25/使用aider辅助编程/","permalink":"https://silenwang.github.io/2025/04/25/%E4%BD%BF%E7%94%A8aider%E8%BE%85%E5%8A%A9%E7%BC%96%E7%A8%8B/","excerpt":"今年的deepseek着实让LLM又火了一把，虽然在chatGPT之后，copilot和cursor就一直在到处打广告，但是我其实一直没试过… 于是在今年，我… 试了试Cline，确实好用，但是也符合我的固有印象，没有那么方便，尤其是，我更需要一个能直接在命令行使用并能够快速迁入脚本的选项，以批量完成一些简单的编码初始化业务，于是我找到了aider…","text":"今年的deepseek着实让LLM又火了一把，虽然在chatGPT之后，copilot和cursor就一直在到处打广告，但是我其实一直没试过… 于是在今年，我… 试了试Cline，确实好用，但是也符合我的固有印象，没有那么方便，尤其是，我更需要一个能直接在命令行使用并能够快速迁入脚本的选项，以批量完成一些简单的编码初始化业务，于是我找到了aider… 安装软件安装比较简单，因为是一个python项目，使用pip就可以安装： 12python -m pip install aider-installaider-install 使用aider是一个CUI应用，输入aider就能进入。Aider 支持一系列以 / 开头的聊天命令，这些命令可以帮助你更高效地管理代码编辑任务、切换模式以及与代码库进行交互。以下是一些常用的命令及其功能： 文件管理命令 /add：将文件添加到聊天会话中，以便 Aider 可以编辑或详细审查这些文件。 /drop：从聊天会话中移除文件，释放上下文空间。 /ls：列出所有已知文件，并指示哪些文件已包含在聊天会话中。 编辑与代码操作命令 /code：请求对代码进行更改，如果没有提供提示信息，则切换到代码模式。 /diff：显示自上次消息以来的更改差异。 /commit：提交在聊天之外对代码库所做的更改（可选提交信息）。 /undo：撤销 Aider 执行的最后一次 Git 提交。 模式切换命令 /chat-mode：切换到新的聊天模式。 /architect：进入架构师&#x2F;编辑模式，使用两种不同的模型进行代码设计或编辑。 /ask：询问有关代码库的问题，而不编辑任何文件。 其他实用命令 /clear：清除聊天历史记录。 /copy：将上次助手的消息复制到剪贴板。 /model：切换到新的语言模型。 /help：获取有关 Aider 使用的帮助信息。 /exit 或 /quit：退出 Aider 应用程序。 嵌入shell脚本作为CUI程序，aider 也有直接从命名行运行的方式，通过指定参数，然后直接将 prompt 写在命名行中，就可以（这方式还挺类似ssh）。 用例1–批量翻译博客因为可以通过命令行运行，aider也就可以方便的潜入到shell中，批量完成一些工作量不太大的问题，比如将过过去的博客都翻译一遍… 虽然在chatGPT刚火的时候，我就想过用它来完成翻译，但是实际操作后才发现，手动工作量仍然不小。因为我的博客已经有上百个文件了… 每次输入prompt,然后把内容贴近贴出以及进行校对，也还是很繁琐和无趣的工作。 使用aider，至少能再多偷些懒。 1234567891011121314151617181920set -e DIR_A=blog_cn/source/_postsDIR_B=blog_en/source/_postsfor file in `ls $DIR_A/*`; do # 获取文件名（去掉路径部分） filename=$(basename &quot;$file&quot;) # 检查文件是否存在于目录B if [[ -e &quot;$&#123;DIR_B&#125;/$&#123;filename&#125;&quot; ]]; then echo &quot;文件 $&#123;filename&#125; 存在于目录$&#123;DIR_B&#125;，跳过&quot; else echo &quot;文件 $&#123;filename&#125; 不存在于目录$&#123;DIR_B&#125;，启动aider翻译...&quot; echo &quot;开始文稿校对&quot; aider \\ --no-show-model-warnings --yes --no-auto-commits \\ --message &quot;我这里有一篇blog，请把它翻译成英文，然后保存到 $&#123;DIR_B&#125;/$&#123;filename&#125; 文件中&quot; \\ $file fi 用例2–批量生成api测试与生成博客类似，根据openapi或者swagger文档理论上可以很快的编写出接口的测试代码，但是如果接口一多，实际写起来还是很麻烦的。这种时候，让aider来读取代码，并预先生成一个测试代码的框架，可以省下不少事情。 123456789for group in group1 group2 group3;do # 获取文件名（去掉路径部分） pytest=test/$&#123;group&#125;.py touch $pytest aider \\ --no-show-model-warnings --yes --no-auto-commits \\ --message &quot;这里有一份api的swagger描述文件 $&#123;group&#125;.swagger.json ，请根据它的内容，为这个api编写pytest测试脚本，并将写好的测试脚本放到 $&#123;pytest&#125; 文件中。&quot; \\ data/$&#123;group&#125;.swagger.json $pytestdone","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"aider","slug":"aider","permalink":"https://silenwang.github.io/tags/aider/"},{"name":"自动化","slug":"自动化","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"automation","slug":"automation","permalink":"https://silenwang.github.io/tags/automation/"},{"name":"AI编程","slug":"AI编程","permalink":"https://silenwang.github.io/tags/AI%E7%BC%96%E7%A8%8B/"},{"name":"命令行工具","slug":"命令行工具","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/"},{"name":"批量处理","slug":"批量处理","permalink":"https://silenwang.github.io/tags/%E6%89%B9%E9%87%8F%E5%A4%84%E7%90%86/"},{"name":"AI-assisted programming","slug":"AI-assisted-programming","permalink":"https://silenwang.github.io/tags/AI-assisted-programming/"},{"name":"command-line tool","slug":"command-line-tool","permalink":"https://silenwang.github.io/tags/command-line-tool/"}]},{"title":"Github Actions的基本使用","slug":"github-actions使用","date":"2025-04-13T16:40:47.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2025/04/13/github-actions使用/","permalink":"https://silenwang.github.io/2025/04/13/github-actions%E4%BD%BF%E7%94%A8/","excerpt":"在现代软件开发中，持续集成（CI）和持续部署（CD）是提高开发效率和质量的关键实践。GitHub Actions 作为 GitHub 提供的强大自动化工具，能够帮助开发者轻松实现 CI&#x2F;CD 以及更广阔的自动化工作流程。","text":"在现代软件开发中，持续集成（CI）和持续部署（CD）是提高开发效率和质量的关键实践。GitHub Actions 作为 GitHub 提供的强大自动化工具，能够帮助开发者轻松实现 CI&#x2F;CD 以及更广阔的自动化工作流程。 GitHub Actions 的作用GitHub Actions 是一个强大的自动化平台，允许开发者在 GitHub 仓库中定义和运行工作流。它可以根据特定的事件（如代码推送、拉取请求、标签发布等）自动执行一系列任务，例如代码构建、测试、部署等。通过 GitHub Actions，开发者可以实现从代码提交到部署的全流程自动化，从而节省时间和精力，减少人为错误。 GitHub Actions 的工作流结构GitHub Actions 的工作流由多个部分组成，其中最重要的部分是 jobs 和 steps。 Jobs一个工作流可以包含多个 jobs，每个 jobs 是一个独立的执行单元，可以在不同的环境中运行。 123jobs: build: # 工作名称 runs-on: [ubuntu-latest] # 运行环境，这里指定的是github hosted runners runs-on 指定了运行该 jobs 的环境，这里我们使用github准备的最新ubuntu环境。 Steps每个 jobs 可以包含多个 steps，每个 steps 是一个独立的任务，可以执行一系列命令或调用预定义的动作（actions）。预定义的动作可以在github marketplace搜索。 123- name: Get current tag # 步骤名称 id: get_tag # 步骤编号 uses: zingimmick/github-action-get-current-tag@v1 # 使用特定的已编写好的步骤 变量传递就如同我过去写的生物信息分析流程，不同的步骤之间，常常需要进行信息传递才能完成一项工作。yaml作为简单的配置文件，自然无法实现变量传递，因此我们需要以来github action框架中设置的一些环境变量来完成信息传递。 跨Steps信息传递在steps中执行代码时，可以通过向$GITHUB_OUTPUT这个特殊环境变量追加内容的方式来实现steps间信息传递的作用： 12345678- name: Save info id: save_info run: | echo &quot;tag=3&quot; &gt;&gt; $GITHUB_OUTPUT- name: Use info id: use_info run: | echo $&#123;&#123; steps.save_info.outputs.tag &#125;&#125; 跨Jobs信息传递在jobs中，可以规定将特定步骤的输出传递到jobs输入，方法如下： 1234567891011121314151617jobs: get_info: steps: - name: Save info id: save_info run: | echo &quot;tag=3&quot; &gt;&gt; $GITHUB_OUTPUT outputs: tag: $&#123;&#123; steps.save_info.outputs.tag &#125;&#125; use_info: needs: [get_info] # 设定依赖，以获得其他jobs的信息 steps: - name: Save info id: save_info run: | echo $&#123;&#123; needs.get_info.outputs.tag &#125;&#125; 编译项目并进行发布的例子123456789101112131415161718192021222324252627282930313233343536373839404142name: BUILDon: push: tags: - &quot;v*&quot; # 收到版本tag触发jobs: build: runs-on: [ubuntu-latest] permissions: # 需要写release的权限 contents: write steps: - name: Get current tag id: get_tag uses: zingimmick/github-action-get-current-tag@v1 - name: Checkout code uses: actions/checkout@v4 with: fetch-depth: 0 ref: $&#123;&#123; steps.get_tag.outputs.tag &#125;&#125; - name: Build frontend run: pixi run front_prod - name: Build backend run: pixi run backend - name: Pack to zip run: pixi run release - name: Release uses: ncipollo/release-action@v1.15.0 with: draft: false generateReleaseNotes: true #自动生成发行说明。 artifacts: &#x27;$&#123;&#123; github.workspace &#125;&#125;/release/*.zip&#x27; tag: $&#123;&#123; steps.get_tag.outputs.tag &#125;&#125; name: Release $&#123;&#123; steps.get_tag.outputs.tag &#125;&#125;","categories":[{"name":"Script","slug":"Script","permalink":"https://silenwang.github.io/categories/Script/"}],"tags":[{"name":"workflow","slug":"workflow","permalink":"https://silenwang.github.io/tags/workflow/"},{"name":"持续集成","slug":"持续集成","permalink":"https://silenwang.github.io/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"自动化","slug":"自动化","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"工作流","slug":"工作流","permalink":"https://silenwang.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81/"},{"name":"github actions","slug":"github-actions","permalink":"https://silenwang.github.io/tags/github-actions/"},{"name":"ci","slug":"ci","permalink":"https://silenwang.github.io/tags/ci/"},{"name":"cd","slug":"cd","permalink":"https://silenwang.github.io/tags/cd/"},{"name":"automation","slug":"automation","permalink":"https://silenwang.github.io/tags/automation/"}]},{"title":"编写R中的对象","slug":"编写R中的对象","date":"2025-04-13T15:57:55.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2025/04/13/编写R中的对象/","permalink":"https://silenwang.github.io/2025/04/13/%E7%BC%96%E5%86%99R%E4%B8%AD%E7%9A%84%E5%AF%B9%E8%B1%A1/","excerpt":"面向对象是编程时一种常用的范式，在我的实际工作中，使用面向对象主要是为了通过继承特性减少重复代码，和将常用数据封装到对象内，避免过多、重复、嵌套的传递参数。","text":"面向对象是编程时一种常用的范式，在我的实际工作中，使用面向对象主要是为了通过继承特性减少重复代码，和将常用数据封装到对象内，避免过多、重复、嵌套的传递参数。 R中不同的对象系统是的… R中有不同的对象系统，除了之前接触的S3（如ggplot）和S4（被很多单细胞包采用），还有本次着重说明的R6。 S3是R语言中最基础、使用最广泛的面向对象系统，采用泛型函数实现方法分派。S3的对象，感觉本质上是list的延伸，它的继承比较简单，方法是通过泛型函数来实现的，跟我更熟悉的python中的类型差别较大。 S4提供更正式的面向对象编程框架，适合需要严格类型检查的复杂应用，它比S3要复杂，且有更全面的继承机制，但是其方法同样是通过泛型函数来实现的。虽然还是跟python中的不太一样，但是有继承，有方法，同时使用S4也能比较方便的使用%&gt;%管道，勉强能用。 本来我想基于S4来完成我的开发，但是，没想到S4和box居然还有兼容性问题，box的作者2022年就说明，不会兼容S4… 于是最后，我使用了R6类型，它是第三方的包（又是第三方…），其提供的对象，非常类似python的对象，有继承、有方法，支持box::use，美中不足，还没有找到接入%&gt;%的方法。 使用R6对象R6的具体使用实例如下，方式确实非常类似python，不过R6不需要定义初始化函数。 12345678910111213141516171819202122box::use( R6[R6Class])Person &lt;- R6Class( &quot;Person&quot;, public = list( name = NULL, age = NULL, initialize = function(name, age) &#123; self$name &lt;- name self$age &lt;- age &#125;, greet = function() &#123; cat(&quot;Hello, my name is&quot;, self$name, &quot;and I am&quot;, self$age, &quot;years old.\\n&quot;) &#125; ))# 使用对象person &lt;- Person$new(&quot;John&quot;, 30) # 实例化person$greet() # 调用方法","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"面向对象","slug":"面向对象","permalink":"https://silenwang.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"rlang","slug":"rlang","permalink":"https://silenwang.github.io/tags/rlang/"},{"name":"R6","slug":"R6","permalink":"https://silenwang.github.io/tags/R6/"},{"name":"S3","slug":"S3","permalink":"https://silenwang.github.io/tags/S3/"},{"name":"S4","slug":"S4","permalink":"https://silenwang.github.io/tags/S4/"},{"name":"object-oriented","slug":"object-oriented","permalink":"https://silenwang.github.io/tags/object-oriented/"}]},{"title":"使用box包管理R脚本的依赖","slug":"使用box包管理R脚本的依赖","date":"2025-04-13T15:07:54.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2025/04/13/使用box包管理R脚本的依赖/","permalink":"https://silenwang.github.io/2025/04/13/%E4%BD%BF%E7%94%A8box%E5%8C%85%E7%AE%A1%E7%90%86R%E8%84%9A%E6%9C%AC%E7%9A%84%E4%BE%9D%E8%B5%96/","excerpt":"在习惯了python后，使用R进行脚本开发会让人感到十分痛苦，老声长谈的错误回溯不明确问题暂且不谈，当要写的脚本稍微复杂点，需要分文件的时候，才发现R的导入机制也挺蛋疼的…. 还好有box包，可以用类似python的逻辑来进行模块化导入。","text":"在习惯了python后，使用R进行脚本开发会让人感到十分痛苦，老声长谈的错误回溯不明确问题暂且不谈，当要写的脚本稍微复杂点，需要分文件的时候，才发现R的导入机制也挺蛋疼的…. 还好有box包，可以用类似python的逻辑来进行模块化导入。 R中默认的导入方式R中自带的导入方式有两种，source和library，前者本质是将指定R文件内的内容全部运行一遍，后者需要将代码打包成R包，安装后才能使用。 前者在要写的东西相对简单的时候还是比较好用的，但是一旦要实现的功能相对没那么简单，需要多拆几个文件时，就会出现问题了。 命名空间污染：source()会将脚本中的所有对象直接加载到当前环境，为防止冲突，需要额外配置。 依赖关系不明确：如果脚本之间存在依赖关系，导入顺序错误会导致错误。 后续阅读代码进行维护难度大：从source()的部分，很难看出到底引入了什么，当想找来源代码进行修改时，需要一级一级回溯，非常麻烦。 如果使用library, 每次都要打包非常麻烦不说，命名空间污染和找函数&#x2F;对象来源的问题也是存在的。 总的来说，R自带的导入虽然能用，但是确实不好用….. 使用BoxPython 式模块化：支持 box::use() 语法实现类似 Python 的模块导入机制，使用方式见下： 12345box::use( plots = ./modules/plot_functions, # 根据路径导入./modules/plot_functions.R文件 shiny_utils = shiny/utils, # 导入文件，并进行对象重命名 ggplot2[ggplot, aes] # 导入ggplot2中的ggplot和aes) 这种导入方式跟Python类似的地方在于，它一可以导入一个R文件中的特定内容，而不用全部引入，同时，它也可以想Python一样导入整个文件的内容到一个对象，然后通过mod$func()这样的方式来调用对象中的函数，实现python中使用对象内方法一样的使用方式。 除了上面的优势，使用box还可以实现相对路径解析，自动识别项目根目录，替代避免使用setwd()不停切换目录，这种使用方式也考虑了跨平台兼容，它可以自动统一处理 Windows&#x2F;Linux&#x2F;macOS 路径格式差异。 最后，使用box，也能解决导入时的溯源问题，不论是使用mod$func()还是ggplot2[ggplot, aes]这样的部分导入，都能一眼看出来使用函数&#x2F;对象的来源，避免在一堆文件中翻来翻去。","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"模块化开发","slug":"模块化开发","permalink":"https://silenwang.github.io/tags/%E6%A8%A1%E5%9D%97%E5%8C%96%E5%BC%80%E5%8F%91/"},{"name":"box包","slug":"box包","permalink":"https://silenwang.github.io/tags/box%E5%8C%85/"},{"name":"代码管理","slug":"代码管理","permalink":"https://silenwang.github.io/tags/%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86/"},{"name":"rlang","slug":"rlang","permalink":"https://silenwang.github.io/tags/rlang/"},{"name":"box","slug":"box","permalink":"https://silenwang.github.io/tags/box/"}]},{"title":"编译openfyde","slug":"编译openfyde","date":"2025-01-04T14:58:33.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2025/01/04/编译openfyde/","permalink":"https://silenwang.github.io/2025/01/04/%E7%BC%96%E8%AF%91openfyde/","excerpt":"综合官方说明、论坛文章的内容，整理编译Fydetab duo的openfyde镜像的方法, 目标是编译最新的R120版本镜像","text":"综合官方说明、论坛文章的内容，整理编译Fydetab duo的openfyde镜像的方法, 目标是编译最新的R120版本镜像 Fyde OS官方原本准备了国内的加速镜像，但是现在似乎已经不可用了，因此完成以下内容需要自备梯子 系统准备 编译系统为Ubuntu 22.04, AMD Ryzen 5 1600 Six-Core @ 12x 3.2GHz, 64G 安装必要软件: sudo apt-get install git gitk git-gui curl xz-utils python3-virtualenv python3-oauth2client lvm2 thin-provisioning-tools repo 安装depot_tools: 克隆项目: git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git &amp;&amp; cd depot_tools &amp;&amp; git checkout e121d14b12412e95ac833cfd31602b674499ea25 设置环境变量: export PATH=/mnt/hdd1/chromeos/openfyde/depot_tools:$PATH 可以同时设置export DEPOT_TOOLS_UPDATE=0避免工具更新，网络稳定也可以不设置 Api Key准备 由于我在Fydeos 下使用的还是Google账户，所以申请google api key，不申请fydeos的，步骤见官方说明文档 大致步骤: 加入chromium-dev开发群组 登录https://cloud.google.com/console 创建新项目，例如openfyde 选择API服务 &gt; 库，查找下面的所有API项目，逐一启用 Cloud Search API Google Drive API Safe Browsing API Time Zone API 进入API服务 &gt; 凭据，根据提示先配置Oauth信息，然后创建凭据 &gt; 创建 OAuth 客户端 ID，应用类型我选择了桌面应用（没有文档描述的Others） 创建凭据 &gt; 创建 API密钥，获得密钥 保存客户端ID、客户端密钥、API密钥三个信息，按照下面方式存储到~/.googleapikeys文件中 123&#x27;google_api_key&#x27;: &#x27;your api key&#x27;,&#x27;google_default_client_id&#x27;: &#x27;your client id&#x27;,&#x27;google_default_client_secret&#x27;: &#x27;your client secret&#x27;, 源代码获取 创建目录: mkdir -p r120/openfyde 配置Git，否则克隆代码会报错: 12git config --global user.name &quot;sylens&quot;git config --global user.email &quot;silenseek14@gmail.com&quot; 克隆源代码: R126版本的openFyde/manifest.git未更新，只能编译R120，repo sync -j8这里需要下载大量源代码内容，其中chromium最大，接近40G。如果网络问题导致下载失败，再次运行会重新下载，请确定梯子流量充足。 1234567repo init -u https://chromium.googlesource.com/chromiumos/manifest.git --repo-url https://chromium.googlesource.com/external/repo.git -b release-R120-15662.Bgit clone https://github.com/openFyde/manifest.git openfyde/manifest -b r120-devln -snfr openfyde/manifest .repo/local_manifestsrepo sync -j8cd openfyde/chromiumgclient sync 进入chroot环境 回到r120这一层目录，运行cros_sdk，开始下载sdk并准备环境, 该过程时间较久 开始编译 由于当前版本archero无法使用，为避免报错，需要修改文件 进入chroot后，默认处在/mnt/host/source/src/scripts，需要修改的文件有: /mnt/host/source/src/overlays/overlay-fydetab_duo-openfyde/metadata/layout.conf: 将第一行的archero、tablet、ai-dev删除 /mnt/host/source/openfyde/overlays/overlay-fydetab_duo-openfyde/profiles/base/parent: 将其中第二行的archero:base删除 注意: 编译的相关命令，都在chroot内执行 运行setup_board --board=fydetab_duo-openfyde 看上去设置工作没有全部完成, 但是目标目录已生成 安装capnproto: sudo emerge capnproto 修改/mnt/host/source/chromite/lib/dlc_allowlist.py: 第14行修改为DLC_FACTORY_INSTALL = (r&quot;termina-dlc&quot;, r&quot;sample-dlc&quot;,), 即加入r&quot;termina-dlc&quot; 继续运行cros build-packages --jobs=4 &#39;--board=fydetab_duo-openfyde&#39; --no-withautotest --autosetgov --no-use-any-chrome 运行完成后构建镜像cros build-image --board=fydetab_duo-openfyde --noenable_rootfs_verification 编译过程中的其他问题 编译异常中断: 遇到过一次异常中断，中断后直接进入环境再编译会有莫名其妙的问题，要从头开始需要删除chroot以及out文件夹，然后再次cro_sdk后从头再来。 虚拟硬盘设置: 经过论坛大佬提示，还需要进行一项设置: 打开/etc/sysctl.conf添加vm.max_map_count=524288 运行sudo sysctl -p","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"openfyde","slug":"openfyde","permalink":"https://silenwang.github.io/tags/openfyde/"},{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"chromeos","slug":"chromeos","permalink":"https://silenwang.github.io/tags/chromeos/"},{"name":"fydeos","slug":"fydeos","permalink":"https://silenwang.github.io/tags/fydeos/"},{"name":"开发环境","slug":"开发环境","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"name":"编译","slug":"编译","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E8%AF%91/"},{"name":"Fydetab duo","slug":"Fydetab-duo","permalink":"https://silenwang.github.io/tags/Fydetab-duo/"},{"name":"Chromium OS","slug":"Chromium-OS","permalink":"https://silenwang.github.io/tags/Chromium-OS/"}]},{"title":"关于FydeTab Duo的碎碎念","slug":"在搭载FydeOS的FydetabDuo上用Pixi配置工作环境","date":"2024-09-24T23:30:45.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2024/09/24/在搭载FydeOS的FydetabDuo上用Pixi配置工作环境/","permalink":"https://silenwang.github.io/2024/09/24/%E5%9C%A8%E6%90%AD%E8%BD%BDFydeOS%E7%9A%84FydetabDuo%E4%B8%8A%E7%94%A8Pixi%E9%85%8D%E7%BD%AE%E5%B7%A5%E4%BD%9C%E7%8E%AF%E5%A2%83/","excerpt":"","text":"我当初参加Indintogo上的众筹时，已经在纯Linux的电脑上学习&#x2F;工作至少六年了。主役系统换了又换：Ubuntu、Linux Deepin（现在的Deepin OS的远古版本，当时是Ubuntu的下游）、Linux Mint、Manjaro。 Manjaro一轮下来最不容易出问题，且持续更新的系统了。却也免不了在升级后碰上依赖爆炸，导致重要工作软件打不开，耽误工作。 故，在看过FydeOS的网站后，有了再次尝试用一台稳定、不崩溃的”上网本”来工作的想法。毕竟不论从计算稳定，还是从信息保密角度，将全部的生物信息分析工作放在服务器或者云端，是更理想的解决方案。本地机器只要具备连通到服务器的最基本工具（SSH），然后能最低限度的处理文档、表格和幻灯，便足矣。 于是当时抱着一点点支持新国产方向的想法，参加了Fydetab的众筹。并在等待中开始了解ChromeOS系统，甚至后来真的用Chromebook 2017工作了整整一年。 经历漫长的等待后，在2024年的五月份，我终于拿到2024版本的Fydetab Duo，一台使用RK3588s处理器的开源平板，正式用上了FydeOS系统（其实2个月前已经从咸鱼淘到了二手工程版就是）。 老实来讲，即使不与完整的Linux发行版做比，只单单比较ChromeOS，这块开源平板上的FydeOS目前也存在一些令人难受的问题。 其中一部分来向自于Linux子系统。目前最大的问题有二，一是子系统有概率会在黑屏重点亮后，失去网络连接，一旦失去，我需要重启子系统内的网络服务，以及重启虚拟机。我没找到这个问题的规律，并且重启虚拟机很多时候会需要三五分钟。这就比较恼人，因为子系统内可能正跑着一个计算进程，然后在等待的时候，我会进行一些程序编译和其他环境准备的工作，而这些工作很多时候都需要网络。如果这时候，网络突然抽风了…..T T 另外一部分，就来自于硬件了，我目前拥有两个版本的FydeTab，一个是红色的工程版，一个是灰色的2024正式版。两个版本磁吸键盘套上的触控板都会被识别成鼠标，无法使用ChromeOS下的一系列手势，让已经用了一年ChromeOS的我非常不习惯。同时触控板的灵敏度有待调整，当前及其容易误触，打字的时候鼠标老乱动，同样的问题在Chromebook 2017在不曾出现过。 不过即使如此，公司还在，设备也拿到手了已实属不易，只希望后续能慢慢把这些问题都解决掉了。","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"FydeOS","slug":"FydeOS","permalink":"https://silenwang.github.io/tags/FydeOS/"},{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"},{"name":"FydeTab Duo","slug":"FydeTab-Duo","permalink":"https://silenwang.github.io/tags/FydeTab-Duo/"},{"name":"Linux子系统","slug":"Linux子系统","permalink":"https://silenwang.github.io/tags/Linux%E5%AD%90%E7%B3%BB%E7%BB%9F/"},{"name":"Chromebook","slug":"Chromebook","permalink":"https://silenwang.github.io/tags/Chromebook/"}]},{"title":"fydetab duo 下使用 pixi部署hexo博客","slug":"fydetab-duo-下使用-pixi部署hexo博客","date":"2024-08-04T13:04:05.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2024/08/04/fydetab-duo-下使用-pixi部署hexo博客/","permalink":"https://silenwang.github.io/2024/08/04/fydetab-duo-%E4%B8%8B%E4%BD%BF%E7%94%A8-pixi%E9%83%A8%E7%BD%B2hexo%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"Fydetab duo 也拿到了一个多月了，目前还在持续想办法把设备用起来的阶段。最起码，我希望能用这个设备来抽空谢谢博客。因此有了下面的折腾。 老实说，fydeos作为中国版本的chromeos，推荐的使用linux方法本应该是直接使用linux子系统的。但是在这一个月内，linux子系统似乎还存在一些影响使用的问题，比如唤醒后会莫名其妙的连不了网、子系统内鼠标显示不正常、子系统启动相对慢等比较影响使用的小毛病。加之fydeos团队对宿主系统的限制暂时还是比chromeos宽松的（至少使用sudo不需要切tty），因此我还是尝试在宿主系统部署我需要的工具。 安装pixi 安装pixi需要进行额外的环境变量配置，因为chromium os体系下，不是所有地方都可以存放并运行可执行文件，只有/usr/local/share下可以，因此需要在环境变量文件中增加下面的内容，然后再运行curl -fsSL https://pixi.sh/install.sh | bash 12export PATH=/usr/local/share/pixi/bin:$PATHexport PIXI_HOME=/usr/local/share/pixi 安装code-server和git原本首选的是微软官方给的vscode-cli工具，但可能是因为fydeos的文件结构和环境配置跟一般linux发行版还是有比较大的差异，因此实际上连接到服务时，会一直卡在下载vscode服务端的步骤，无法实际使用，因此暂时使用pixi安装code-server 另外fydeos的宿主系统已经自带了 arm平台特殊配置 fydeos tab是arm架构的设备，所以pixi的配置中需要增加linux-aarch64平台，同时实际测试下来yarn安装以来会出现无法识别子环境的python问题，因此fydetab duo不使用yarn，用回npm，同时由于fydeos中默认并没有make、gcc、gxx这些，因此也要将这些内容补充到linux-aarch64的依赖中 fydeos的系统信息文件与常规linux有小差别，这会导致hexo的模块解析系统信息时错误，导致hexo -v和会调用它的hexo g无法运行，因此需要在部署任务中增加修复的语句 12[target.linux-aarch64.tasks]build_blog = &#123;cmd = &quot;npm install -g hexo-cli &amp;&amp; npm install --python=$PWD/.pixi/envs/default/bin/python2 &amp;&amp; sed -i &#x27;34s/distro\\\\[1\\\\]/distro/&#x27; $PWD/.pixi/envs/default/lib/node_modules/hexo-cli/dist/console/version.js&quot;, cwd = &quot;.&quot;&#125; 克隆代码并部署要额外进行的配置就是这些了，把项目克隆下来直接部署，就可以继续写博客了 12git clone https://github.com/SilenWang/silen_blogpixi run build_blog","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"FydeOS","slug":"FydeOS","permalink":"https://silenwang.github.io/tags/FydeOS/"},{"name":"hexo","slug":"hexo","permalink":"https://silenwang.github.io/tags/hexo/"},{"name":"arm","slug":"arm","permalink":"https://silenwang.github.io/tags/arm/"},{"name":"Fydetab Duo","slug":"Fydetab-Duo","permalink":"https://silenwang.github.io/tags/Fydetab-Duo/"},{"name":"Linux环境配置","slug":"Linux环境配置","permalink":"https://silenwang.github.io/tags/Linux%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"}]},{"title":"使用新的R语言jupyter内核解决monocle3无法在notebook上选发育起始点的问题","slug":"使用新的R语言jupyter内核解决monocle3无法在notebook上选发育起始点的问题","date":"2024-06-23T01:47:03.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2024/06/23/使用新的R语言jupyter内核解决monocle3无法在notebook上选发育起始点的问题/","permalink":"https://silenwang.github.io/2024/06/23/%E4%BD%BF%E7%94%A8%E6%96%B0%E7%9A%84R%E8%AF%AD%E8%A8%80jupyter%E5%86%85%E6%A0%B8%E8%A7%A3%E5%86%B3monocle3%E6%97%A0%E6%B3%95%E5%9C%A8notebook%E4%B8%8A%E9%80%89%E5%8F%91%E8%82%B2%E8%B5%B7%E5%A7%8B%E7%82%B9%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"看一看这个草稿的创建时间，居然是2024年06月了… 现在都2025年6月了，突然理解了为什么那么多UP主会成为鸽子，挖坑一时爽，填坑火葬场啊… 这篇是我位数不多的纯生物信息内容了… 问题起因是去年要运行 monocle3 进行拟时间分析，但是分析到最后发现一个很蛋疼的问题，monocle3 中的拟时间轨迹起点，是需要分析者来手动指定的，R代码执行过程中会自动开启浏览器，用户需要在浏览器打开的临时网站中指定起点，然后关闭页面，分析继续进行。 但是jupyter的irkernel内核并不支持这一特性。也就是说，我无法在juputer notebook中直接完成分析。这一问题在2019年就被提出过，但是直到我需要进行分析的2024年，5年过去，依然没有解决方案…","text":"看一看这个草稿的创建时间，居然是2024年06月了… 现在都2025年6月了，突然理解了为什么那么多UP主会成为鸽子，挖坑一时爽，填坑火葬场啊… 这篇是我位数不多的纯生物信息内容了… 问题起因是去年要运行 monocle3 进行拟时间分析，但是分析到最后发现一个很蛋疼的问题，monocle3 中的拟时间轨迹起点，是需要分析者来手动指定的，R代码执行过程中会自动开启浏览器，用户需要在浏览器打开的临时网站中指定起点，然后关闭页面，分析继续进行。 但是jupyter的irkernel内核并不支持这一特性。也就是说，我无法在juputer notebook中直接完成分析。这一问题在2019年就被提出过，但是直到我需要进行分析的2024年，5年过去，依然没有解决方案… 不过我当时还真偶然发现了解决方案，因为github给我推荐了一个项目，jupyter-xeus，这个项目旨在重新开发一系列Jupyter内核，其中就包括新的R内核，xeus-r，这个新的内核支持交互模式，可以在运行 monocle3 的时候生成一个链接，用户点进链接完成选点后，再退出页面就能继续分析了。 xeus-r 在conda上就有，用 conda &#x2F; mamba &#x2F; pixi 就能快速安装。安装完后，在jupyter的界面会看到对应的xr内核，选择使用就好 需要执行的代码如下： 1234library(monocle3)cds &lt;- readRDS(&quot;/Your/rds/contain/monocle3/object.RDS&quot;)options(browser=&quot;firefox&quot;)cds &lt;- order_cells(cds) 运行后在单元格下面就可以看见需要打开的链接，打开后，选择起点，再后关闭即可。","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"jupyter","slug":"jupyter","permalink":"https://silenwang.github.io/tags/jupyter/"},{"name":"单细胞分析","slug":"单细胞分析","permalink":"https://silenwang.github.io/tags/%E5%8D%95%E7%BB%86%E8%83%9E%E5%88%86%E6%9E%90/"},{"name":"拟时间分析","slug":"拟时间分析","permalink":"https://silenwang.github.io/tags/%E6%8B%9F%E6%97%B6%E9%97%B4%E5%88%86%E6%9E%90/"},{"name":"monocle3","slug":"monocle3","permalink":"https://silenwang.github.io/tags/monocle3/"},{"name":"xeus-r","slug":"xeus-r","permalink":"https://silenwang.github.io/tags/xeus-r/"}]},{"title":"新工具解决老问题----使用pixi进行生物信息环境配置","slug":"新工具解决老问题-使用pixi进行生物信息环境配置","date":"2024-06-22T01:26:08.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2024/06/22/新工具解决老问题-使用pixi进行生物信息环境配置/","permalink":"https://silenwang.github.io/2024/06/22/%E6%96%B0%E5%B7%A5%E5%85%B7%E8%A7%A3%E5%86%B3%E8%80%81%E9%97%AE%E9%A2%98-%E4%BD%BF%E7%94%A8pixi%E8%BF%9B%E8%A1%8C%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","excerpt":"生物信息是一门交叉学科，而生物信息学中使用的工具集或技术栈，也是相当的“交叉”，其碎片化的程度，我绝对不亚于Linux发行版… 这也带来了大家都会面临的难题：生物信息分析环境部署。","text":"生物信息是一门交叉学科，而生物信息学中使用的工具集或技术栈，也是相当的“交叉”，其碎片化的程度，我绝对不亚于Linux发行版… 这也带来了大家都会面临的难题：生物信息分析环境部署。 生信环境部署是个麻烦事一般来说，用什么语言做开发，那就部署那个语言的开发环境，然后使用相应的环境&#x2F;包管理软件对库的依赖管理就好了。但是生物信息跟我之前学的医学统计一样，应用成分极重，有啥用啥，没有再写… 因此，接触多种语言这种事是极大概率事件。就我个人来说，由于前公司的研究领域较前沿… 很多时候都要使用大学里的研究者们遵循会啥用啥—–这一抓到老鼠就是好猫一般的原则写出来的工具。因此，我已经接触过一堆语言了：C、C++、Java、Scala、Perl、Python、R、Go、Julia、Nim、Js… 如果再要算上一些数据库语言、配置文件语法之类的… 数量还能再翻个一倍… 这么杂乱的技术栈，就让部署和设置生物信息开发环境，或者部署生物信息分析流程成了一件非常繁琐的事情。要知道生物信息学中有相当比例的工具或软件，在一年左右就不一定会再有人去维护了，这意味着软件需要的编译器和库会一直停留在过时的版本，然后逐渐开始和后续版本打架，造成比Linux发行版的跨版本升级更可怕的依赖爆炸问题。然后这个依赖还不是只有一个语言下的工具集会爆炸，是所有语言下的工具集都有爆炸的可能，且由于Python、R等一些脚本语言底层有C，所以还能交叉爆炸… 分分钟搞得人心态爆炸。 然而… 问题远不止步于此，出于一些大人的原因… 不是所有人都能拿到系统级别的权限，配置环境时仅能使用普通用户的权限，因此一些用发行版的包管理器装个包就能解决的问题，最后可能只能选择将整个软件的依赖从头编译一遍… 这又够人爆炸一个月的了… 基于前述种种令人恼火的问题，当我第一次知道有conda这么个工具的时候，真的是感觉救我狗命啊… 大量的生物信息学软件都已预编译后打包上传，下载解压缩即用，还能自动计算依赖是否打架，保证不同语言下工具的基本使用，简直是太完美了！ 不过用过一周之后就会了解到… 由于基于python，conda的依赖计算速度… 是真的慢，10个左右的工具可能就会算个20分钟了，这在依赖会有问题的时候尤其令人恼火… 约等于跑了20分钟的计算，发现变量名称写得有问题，又没有设好断点，只能从头再来一遍… 可能也就是这个缺点大到影响一般使用，就有人开发了Conda的C++实现：Mamba，然后又有了micromamba，再后来有了今天的主角，pixi pixi简介简单来说，pixi是一个为开发者设计的多语言软件包管理程序，目的在于使开发者能够轻松的创建和锁定多语言开发环境，使计算结果更容易被重复。 pixi的简单使用方法(通过命令行)可以参见它的官方文档，这里不多说，因为对我来说主要会用它进行环境部署，会一次性安装一大堆的东西，因此一般都是用配置文件来进行配置的。 pixi基本使用pixi使用toml格式的配置文件(得，又多了一种)，其格式有点类似ini…但是语法更复杂，能支持更多的东西。 想使用toml来管理的话，安装好pixi后，使用pixi init就可以创建一个管理项目，并在当前目录生成一份配置文件了，刚生成的文件包含如下内容。 1234567891011[workspace]name = &quot;demo&quot;version = &quot;0.1.0&quot;description = &quot;Add a short description here&quot;authors = [&quot;silenwang &lt;silenseek14@gmail.com&gt;&quot;]channels = [&quot;conda-forge&quot;]platforms = [&quot;linux-aarch64&quot;][tasks][dependencies] 其中已经包含了项目基本信息、任务、依赖这三块最重要，也最主要的内容。任务不使用直接留空就可以了，在依赖块内写上需要的安装的内容（内容将从conda获取），保存后就可以使用pixi install 来安装需要的内容了，安装过程中还会生成一个lock文件，这个文件的作用跟nodejs中npm或yarn生成的lock文件作用类似，用于记录被安装的软件版本。将这个lock文件随项目一起管理，就能保证再次部署时能安装一模一样的依赖，保证软件可运行或计算可重复了。 多种依赖一次性处理pixi的软件虽然主要从conda获取，但是它同时支持从pypi获取python包。如果有conda上没有，但是可以从pypi获取的包，可额外在配置文件中增加pypi区块。区块内的软件将会在conda依赖处理完成后自动从pypi获取软件包并进行安装，获取的包同样会记录到lock文件中。 12[pypi-dependencies]spats-shape-seq = &quot;*&quot; 如果还有其他包要单独进行编译安装，或者下载后用脚本进一步处理，则可以使用task特性来设置任务。 在task块中设置好的任务可以通过pixi run TASK_NAME的方式来进行运行。当前官方虽然没有给在依赖处理完成后，直接运行特定任务的方式，但是可以通过下面的写法来通过任务执行pixi install -a命令以先处理依赖，从而达到在依赖处理完成后自动进行后续编译安装任务的目的： 1234567891011121314151617181920212223[workspace]name = &quot;demo&quot;version = &quot;0.1.0&quot;description = &quot;Add a short description here&quot;authors = [&quot;silenwang &lt;silenseek14@gmail.com&gt;&quot;]channels = [&quot;conda-forge&quot;, &quot;bioconda&quot;, &quot;milaboratories&quot;, &quot;main&quot;]platforms = [&quot;linux-64&quot;][tasks]install = &#123;cmd = &#x27;pixi install -a&#x27;&#125;deploy = &#123;cmd = &#x27;echo &quot;Deploy done&quot;&#x27;, depends-on = [&quot;instal&quot;] &#125;[feature.python3.dependencies]python = &quot;3.11.*&quot;pip = &quot;*&quot;jupyter = &quot;*&quot;ipykernel = &quot;*&quot;numpy = &quot;*&quot;pandas = &quot;*&quot;statsmodels = &quot;*&quot;scipy = &quot;*&quot;tensorflow = &quot;*&quot;keras = &quot;*&quot; 多种环境一次性部署pixi还支持了多环境一次性部署，大概的写法如下： 12345678910111213141516171819202122232425262728293031323334[feature.python3.dependencies]python = &quot;3.11.*&quot;pip = &quot;*&quot;jupyter = &quot;*&quot;ipykernel = &quot;*&quot;numpy = &quot;*&quot;pandas = &quot;*&quot;statsmodels = &quot;*&quot;scipy = &quot;*&quot;tensorflow = &quot;*&quot;keras = &quot;*&quot;[feature.python2.dependencies]python = &quot;2.7.*&quot;pip = &quot;*&quot;jupyter = &quot;*&quot;ipykernel = &quot;*&quot;[feature.bioinfo.dependencies]bwa = &quot;*&quot;samtools = &quot;*&quot;bedtools = &quot;*&quot;[feature.rlang.dependencies]r-base = &quot;*&quot;r-irkernel = &quot;*&quot;r-ggplot2 = &quot;*&quot;bioconductor-limma = &quot;*&quot;[environments]python3 = [&quot;python3&quot;]python2 = [&quot;python2&quot;]bioinfo = [&quot;bioinfo&quot;]rlang = [&quot;rlang&quot;] 即在environments中指定环境的名称，然后使用名字类似[feature.rlang.dependencies]的块来处理环境内的依赖情况。配置好后，使用pixi install -a来安装所有的环境（使用pixi intall只会检查依赖是否有问题，但是不会实际安装） 环境使用pixi虽然使用来自conda的包，但是其环境激活和使用方式却采用了poetry和pipenv的方式，激活环境需要在目录下运行pixi shell，如果有多个环境，则加-e指定环境名。同时pixi也支持pixi run的方式来运行环境内的软件（对，pixi run既用来运行任务，也用来运行环境内命令）。 举个栗子下面的 pixi.toml 来自于一个真实的单细胞分析项目，该项目定义多个环境（rplot、analy 和 label），并在 label 环境中使用了 Seurat、azimuth 等 R 包。与前面提到的情形类似，即使显式声明了 r-BiocManager，依然会遇到 GenomeInfoDbData、BSgenome.Hsapiens.UCSC.hg38 等数据包缺失的问题。因此，我们在 [feature.label.tasks] 中同样配置了四个独立的安装任务，并通过 r_dep 任务将它们串联起来。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667[workspace]authors = [&quot;Sylens Wong &lt;silenseek14@gmail.com&gt;&quot;]channels = [&quot;conda-forge&quot;, &quot;bioconda&quot;, &quot;dnachun&quot;]name = &quot;Single Cell&quot;platforms = [&quot;linux-64&quot;]version = &quot;0.1.0&quot;[environments]rplot = [&#x27;kernel&#x27;, &#x27;rplot&#x27;]analy = [&#x27;kernel&#x27;, &#x27;analy&#x27;]label = [&#x27;kernel&#x27;, &#x27;label&#x27;][feature.kernel.dependencies]ipykernel = &#x27;*&#x27;r-irkernel = &#x27;*&#x27;jupyterlab = &#x27;*&#x27;[feature.rplot.dependencies]r-ggpubr = &#x27;*&#x27;r-ggforce = &#x27;*&#x27;r-ggh4x = &#x27;*&#x27;bioconductor-complexheatmap = &#x27;*&#x27;[feature.label.dependencies]r-base = &#x27;*&#x27;r-azimuth = &#x27;*&#x27;r-seurat = &#x27;5.2.*&#x27;r-SeuratObject = &#x27;5.0.*&#x27;r-BiocManager = &#x27;*&#x27;r-SeuratDisk = &#123;version = &quot;*&quot;, channel = &quot;dnachun&quot;&#125;[feature.label.tasks]GenomeInfoDbData = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;GenomeInfoDbData\\&quot;)&quot;&#x27;&#125;BSgenome = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;BSgenome.Hsapiens.UCSC.hg38\\&quot;)&quot;&#x27;&#125;EnsDb = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;EnsDb.Hsapiens.v86\\&quot;)&quot;&#x27;&#125;JASPAR2020 = &#123;cmd = &#x27;Rscript -e &quot;BiocManager::install(\\&quot;JASPAR2020\\&quot;)&quot;&#x27;&#125;r_dep = &#123;cmd = &#x27;echo &quot;bio dep for R done&quot;&#x27;, depends-on=[&#x27;GenomeInfoDbData&#x27;, &#x27;BSgenome&#x27;, &#x27;EnsDb&#x27;, &#x27;JASPAR2020&#x27;]&#125;[feature.analy.dependencies]snakemake = &#x27;9.8.*&#x27;python = &#x27;3.11.*&#x27;jupyter = &#x27;*&#x27;scanpy = &#x27;*&#x27;gseapy = &#x27;*&#x27;gprofiler-official = &#x27;*&#x27;altair = &#x27;*&#x27;scipy = &#x27;*&#x27;pip = &#x27;*&#x27;pandas = &#x27;*&#x27;openpyxl = &#x27;*&#x27;leidenalg = &#x27;*&#x27;numpy = &#x27;*&#x27;loompy = &#x27;*&#x27;pixi-kernel = &#x27;*&#x27;vegafusion-python-embed = &quot;*&quot;vegafusion = &quot;*&quot;vl-convert-python = &quot;*&quot;pypairs = &#x27;*&#x27;harmonypy = &#x27;*&#x27;upsetplot = &#x27;*&#x27;[feature.analy.pypi-dependencies]singler = &#x27;*&#x27;celldex = &#x27;*&#x27;[tasks]install = &#123;cmd = &#x27;pixi install -a&#x27;&#125; 在该配置中，执行 pixi run r_dep 即可自动完成上述四个数据包的安装，从而确保 Seurat 等包能够正常加载所需的基因组注释信息。这种模式可以方便地扩展到其他需要额外数据包的 Bioconductor 依赖场景。","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"依赖管理","slug":"依赖管理","permalink":"https://silenwang.github.io/tags/%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"},{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"},{"name":"生物信息","slug":"生物信息","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF/"},{"name":"环境配置","slug":"环境配置","permalink":"https://silenwang.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"mamba","slug":"mamba","permalink":"https://silenwang.github.io/tags/mamba/"}]},{"title":"还活着就是比较累","slug":"还活着就是比较累","date":"2023-12-24T14:47:47.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2023/12/24/还活着就是比较累/","permalink":"https://silenwang.github.io/2023/12/24/%E8%BF%98%E6%B4%BB%E7%9D%80%E5%B0%B1%E6%98%AF%E6%AF%94%E8%BE%83%E7%B4%AF/","excerpt":"","text":"过的真的很快…2023已经没有几天了，然而我从8月到12月什么都没写… 其实这几个月新学的东西还挺多的，不论是工作上还是工作外，但是什么也没来得及整理，估计过段时间会忘掉了… 所以之前看到某个博主写的确实很对（出处找不到了hhhh），技术博客容易拼命去折腾各种博客框架，炫库的插件等等，而最后在折腾及其他失误的干扰中，忽略了写博客本身。 我以后也还是要继续坚持记录，不管双链笔记和其他什么多么好用，继续写，继续整理本身，才是最重要的。毕竟公司的事情不存在告一段落，只有忙和更忙，该焦虑还是焦虑，甚至因为生活琐事变多只会越来越焦虑…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"技术博客","slug":"技术博客","permalink":"https://silenwang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"},{"name":"写作困境","slug":"写作困境","permalink":"https://silenwang.github.io/tags/%E5%86%99%E4%BD%9C%E5%9B%B0%E5%A2%83/"},{"name":"时间管理","slug":"时间管理","permalink":"https://silenwang.github.io/tags/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/"},{"name":"焦虑","slug":"焦虑","permalink":"https://silenwang.github.io/tags/%E7%84%A6%E8%99%91/"},{"name":"持续记录","slug":"持续记录","permalink":"https://silenwang.github.io/tags/%E6%8C%81%E7%BB%AD%E8%AE%B0%E5%BD%95/"},{"name":"tech-blog","slug":"tech-blog","permalink":"https://silenwang.github.io/tags/tech-blog/"},{"name":"writing","slug":"writing","permalink":"https://silenwang.github.io/tags/writing/"},{"name":"time-management","slug":"time-management","permalink":"https://silenwang.github.io/tags/time-management/"}]},{"title":"chromebook折腾报告","slug":"chromebook折腾报告","date":"2023-08-16T11:11:11.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2023/08/16/chromebook折腾报告/","permalink":"https://silenwang.github.io/2023/08/16/chromebook%E6%8A%98%E8%85%BE%E6%8A%A5%E5%91%8A/","excerpt":"去年的时候，我突然看躺在床上的杂牌笔记本电脑特别不爽。好歹也是当年1999买回来的（对毕业半年的我来说是非常大件的消费），后续还因为键盘和触控板问题修了两次花了又快又1000块。这么贵重的东西，不给他安排点活，着时对不起自己的血汗钱。于是我又捣鼓起了几年前关注过，但是当时特别不能用的fydeos。这一捣鼓，我才发现，这几年不仅是deepin发展的很快（快到都有钱和时间把做好的框架和UI又推了重来），fydeos也进化了很多，不仅有了android，还有了linux子系统，日常使用突然就变得不再遥远了，于是！我，斥、重、金————————海鲜市场捡垃圾买了个lenovo chromebook duet..","text":"去年的时候，我突然看躺在床上的杂牌笔记本电脑特别不爽。好歹也是当年1999买回来的（对毕业半年的我来说是非常大件的消费），后续还因为键盘和触控板问题修了两次花了又快又1000块。这么贵重的东西，不给他安排点活，着时对不起自己的血汗钱。于是我又捣鼓起了几年前关注过，但是当时特别不能用的fydeos。这一捣鼓，我才发现，这几年不仅是deepin发展的很快（快到都有钱和时间把做好的框架和UI又推了重来），fydeos也进化了很多，不仅有了android，还有了linux子系统，日常使用突然就变得不再遥远了，于是！我，斥、重、金————————海鲜市场捡垃圾买了个lenovo chromebook duet.. 芯片架构于设备可及性请不要怀疑我的精神状态，虽然前面的内容和后面的标题看上去像喝了假酒，但这————————都是有逻辑的！首先，我知道fydeos和原版的chromeos已经越来越不一样了，fydeos觉得不错转头跑去买chromebook并不可取，可是fydeos的公司作为一家不主要面对普通消费者，而是主营企业业务的公司，他们并没有太多他们自主设计并长期维护的硬件产品，在我有玩一票这个想法的当时，旧的ITNs设备已经不卖了，fydetab duo只说会有但是众筹都没开，for you版本的二手设备又偏贵一些。所以我最后还是决定接盘个便宜的chromeos平板试试水，毕竟海鲜市场上那叫一个一大堆，好用则自用，不好哪来的卖哪去（然后血亏200）。 试水设备的选择上，我也考虑了好久，最终才选了arm架构的duet。这主要是为了获得更好的安卓体验。试用fydeos的时候发现，这一类系统下的安卓并不是于宿主系统完全隔离的模拟器，安卓产生的文件从宿主系统重相对方便的读取，宿主系统的文件图片也可以直接右键分享到安卓应用中，比想象的方便很多，另外宿主机的一切设备包括摄像头，都是可以直接被安卓应用调用的，相当于是可以直接运行全功能的安卓应用补足生态问题。然而国内很多应用完全不做x86的适配，导致很多应用打开旧闪退，完全不能用。因此我想，如果买一个arm架构的设备，没准技能直接替代我日常的笔记本，还能更轻薄，岂不美哉。 设备定位与旧爱新欢然而事实证明我真的很容易在电子产品上上手，过去如此，现在如此，未来估计还是如此。 在上手的两天内，我就感觉到了Chrome duet极大的问题。一个廉价上网本定位的设备，其配置自然不会好到哪里去，虽然arm架构的cpu确实让安卓app能够顺利流畅的打开并运行，但是想要作为一个办公设备试用，同时只能流畅运行一个应用，显然是完全不够看的…chrome duet确实能很好的运行微信与钉钉，但是当我打开浏览器之后，微信和钉钉，必然被干掉一个或者都被干掉，再次唤醒，应用就要重开，然后chrome连切换个标签页都能卡30秒… 这个卡顿程度，就算我领导不觉得我摸鱼，我自己都能急的治好低血压了。4G的内存对一个移动设备来说本来应该不算小，但是就国内应用的这个臃肿程度…感觉已经可以宣告尝试失败了。 在显而易见的应用问题之外，还有硬件问题。chrome duet是一台二合一的平板，如果只算本体，它的重量和续航甚至比我曾经持有的华为平板更好一些。但是…当加上了键盘套后…设备的总体重量，着时让人疑惑…所以你说轻，它真没多轻。而在打字使用方面，由于是键盘套支架形式的二合一，这个设备并方便直接摆在腿上，因此没有桌子的场景就直接给毙了…感觉失去了一个编写办公社会的灵魂。最最最麻烦的，还有它的尺寸——————————10.1英寸意味着这个设备的配套键盘比一般的笔记本小很多很多。回弹这种东西我从来就不在意，但是让我在10.1英寸的小键盘和14英寸的普通尺寸键盘上来回切换，真的相当折磨，有种NS上玩了赛尔达，然后转头PC上又Xbox手柄打怪猎的那种，重新适应自己刚装上的十指的感觉… 总之，从硬件到软件都没能完成我预期的duet，最终被我自刀送走了，但是我并没有停止作死。因为即使有上面那么多的问题，我依然在这次试水中发现了一个惊人的事实：我的绝大多数工作，真的只要一个浏览器就能做了。 我的工作需求我是一名生物信息学从业人员，我自己平时工作就四大法宝： 写脚本的: VScode &#x2F; Jupyter 抄代码的: Chrome浏览器 登终端的: 发行版带啥就用啥 写文件的: WPS &#x2F; Office全家桶 在跟Duet相杀（没有相爱）期间，我逐渐发现，在Web技术快速进化的今天，以上所有内容，都是可以通过浏览器来实现的。Jupyter和Vscode都能在浏览器运行，Vscode内部有集成的终端模拟器，WPS&#x2F;Office早就开始布局网页端的应用了。 虽然，有不等于全功能，否则也没有Linux和安卓什么事了，但是相比于chromeos起步的快10年前，已经完善了太多了。就好象我大学第一次用logo还是绿色，活像mint山寨的初版deepin时，linux发行版弄个中文支持都费劲… 现在不仅好多发行版中文有了，软件也多了，要配置的越来越少了，甚至manjaro这种晚steam都能算轻松惬意了… 所以，我选择继续作，前脚送走了duet，后脚入了pixelbook2017——————————————然后就翻车了（触控板发过来就是坏的，不想继续加钱的我选了个屏幕有亮点的治疗我的强迫症） pixelbook2017的应用兼容性不同于duet，pixelbook2017，以及其他一众品牌的高配chromebook，都是用intel芯片的（虽然不解但是我也没有办法），于是我就拿着这台外观确实出众（需要自行忽略B面航母跑道和发黄的掌托），但是续航只有宣称的一办的机器，开始了深度使用。 不出所料，四大法宝都是能相对轻松惬意解决的，但是问题最终还是落在了通讯软件上…和当年的Linux发行办面临的最大问题一毛一样。 X86架构的Pixelbook虽然可以通过Play安装国际版的微信以及钉钉，但是这两个软件…兼容性毕竟不是太行，一来容易假死，而来很多基于web做的必要功能完全不能用，最后还是得靠linux下的软件来救场。然而Linux又带来的新的问题，小问题是Linux应用不必安卓应用，Linux应用至今调用不了设备的摄像头与宿主机的桌面，性质上更接近虚拟机里单独跑App，大问题则是，如果…我这么的依赖Linux，那么我为什么不直接把chromeos格了，在这个设备上装Manjaro呢？ So Why Dunit于是兜兜转转，在获得了能用，但是又不那么好用的体验后，我开始怀疑自己，为啥要持有这么一个设备呢？为了装逼么？（不然呢？） 是图他接口少，图他发热大，还是图他续航比想的拉垮？ 我思考良久，拿起这个1.1kg的本子，对着着这12.3英寸的2.5K屏幕……恩，还是高清的屏幕好呀！","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"chromebook","slug":"chromebook","permalink":"https://silenwang.github.io/tags/chromebook/"},{"name":"二合一设备","slug":"二合一设备","permalink":"https://silenwang.github.io/tags/%E4%BA%8C%E5%90%88%E4%B8%80%E8%AE%BE%E5%A4%87/"},{"name":"安卓应用兼容性","slug":"安卓应用兼容性","permalink":"https://silenwang.github.io/tags/%E5%AE%89%E5%8D%93%E5%BA%94%E7%94%A8%E5%85%BC%E5%AE%B9%E6%80%A7/"},{"name":"chromeos","slug":"chromeos","permalink":"https://silenwang.github.io/tags/chromeos/"},{"name":"fydeos","slug":"fydeos","permalink":"https://silenwang.github.io/tags/fydeos/"},{"name":"arm","slug":"arm","permalink":"https://silenwang.github.io/tags/arm/"}]},{"title":"使用singularity构建一个基于chatglm.cpp项目的ChatGLM2服务","slug":"使用singularity构建一个基于chatglm-cpp项目的ChatGLM2服务","date":"2023-08-16T07:08:46.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2023/08/16/使用singularity构建一个基于chatglm-cpp项目的ChatGLM2服务/","permalink":"https://silenwang.github.io/2023/08/16/%E4%BD%BF%E7%94%A8singularity%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8Echatglm-cpp%E9%A1%B9%E7%9B%AE%E7%9A%84ChatGLM2%E6%9C%8D%E5%8A%A1/","excerpt":"其实很早之前就知道singularity这个东西了，作为有别于docker，专门为HPC开发的容器，一直都想试试。奈何就像Illumina以外的其他NGS技术一样，singularity虽然没有挂，但是至今都没有什么声量，而且在k8s这种容器集群管理方案被绝大多数云厂商采纳后，singularity要竞争似乎更难了… 当然这跟我现在没什么关系… 咱目前离上云感觉至少还有三五年的距离，因此在本地集群启用这个感觉完全合乎情理。","text":"其实很早之前就知道singularity这个东西了，作为有别于docker，专门为HPC开发的容器，一直都想试试。奈何就像Illumina以外的其他NGS技术一样，singularity虽然没有挂，但是至今都没有什么声量，而且在k8s这种容器集群管理方案被绝大多数云厂商采纳后，singularity要竞争似乎更难了… 当然这跟我现在没什么关系… 咱目前离上云感觉至少还有三五年的距离，因此在本地集群启用这个感觉完全合乎情理。 那么还是从最基础的构建镜像开始，singularity的镜像构建文件（Definition File）和Dockerfile还是很不一样的，不是另一种从前往后执行的脚本，感觉更像是ini这种分区进行配置的配置文件。 构建一个镜像所必要的关键字包括： Bootstrap: 用于定义base镜像从哪里来，有多种类型，可以是dockerhub可以是singularity维护的镜像lirary From: 构建base镜像的名称 %post: 构建镜像时下载文件，安装软件，编译软件等的一系列命令 鉴于chatglm.cpp本身的依赖做的非常好，其实只要准备好c++编译器，用pip命令就能装了，所以写起来特别简单： 1234567Bootstrap: libraryFrom: debian%post apt-get update -y &amp;&amp; apt-get upgrade -y apt-get install -y cmake gcc g++ pip pip install &#x27;chatglm-cpp[api]&#x27; 除了这些必要的内容，以后可能还用得上的东西包括： %files：构建时向容器内拷贝文件用的部分 %environment：用于规定换纪念馆变量 %runscript：用于指定使用run子命令运行容器时会使用的脚本 %startscript：用于指定使用instance（似乎是开机启动服务）子命令运行容器时会使用的脚本 %test：指定容器构建完成后在容器内运行的命令（用于检查构建是否完成） %labels：填写镜像的meta信息 %help：填写镜像的使用说明 有了def文件，接下来运行命令就可以开始构建（使用fakeroot是使用非root用户构建，还需要作一定设置参见官方文档），构建完成的镜像不像docker是自己存储起来，而是会生成一个sif文件。 1singularity build --fakeroot chatglm.cpp.singularity.sif build.def 构建好的镜像用如下命令就可以启用啦： 12345singularity exec \\ --bind model:/model/ \\ --env MODEL=/model/chatglm2-ggml.q4_0.bin \\ chatglm.cpp.singularity.sif \\ uvicorn chatglm_cpp.openai_api:app --host 0.0.0.0 --port 8877","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"容器技术","slug":"容器技术","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"singularity","slug":"singularity","permalink":"https://silenwang.github.io/tags/singularity/"},{"name":"ChatGLM2","slug":"ChatGLM2","permalink":"https://silenwang.github.io/tags/ChatGLM2/"},{"name":"chatglm.cpp","slug":"chatglm-cpp","permalink":"https://silenwang.github.io/tags/chatglm-cpp/"},{"name":"容器构建","slug":"容器构建","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8%E6%9E%84%E5%BB%BA/"},{"name":"HPC","slug":"HPC","permalink":"https://silenwang.github.io/tags/HPC/"}]},{"title":"使用singularity部署Rstudio并指定conda环境下的R","slug":"使用singularity部署Rstudio并指定conda环境下的R","date":"2023-07-26T16:13:50.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2023/07/26/使用singularity部署Rstudio并指定conda环境下的R/","permalink":"https://silenwang.github.io/2023/07/26/%E4%BD%BF%E7%94%A8singularity%E9%83%A8%E7%BD%B2Rstudio%E5%B9%B6%E6%8C%87%E5%AE%9Aconda%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84R/","excerpt":"今天需要部署个Rstudio给别人用, 记录一下部署的步骤以及要点","text":"今天需要部署个Rstudio给别人用, 记录一下部署的步骤以及要点 前言Rstudio的运行是必须要靠Root权限来运行的, 不能像Jupyter那样conda或者mamba直装, 因此本次的部署使用了Singularity这种容器(也是我第一次实操使用). Sigularity与Docker或者Podmon在设计上有较大的不同, 主要为HPC环境下的应用而生, 权限管理有较大的不同. 不过这些都不太影响本次使用就是. Sigularity的安装在Rocky Linux下比较简单, 我记得是直接包管理器就能安装了, 因此不作记录 1. 容器准备虽然与Docker是不同的容器技术, Sigularity却提供了完善的Docker镜像兼容支持, 构建好的Docker容器可以很方便的被转换到Sigularity使用的sif格式镜像. 本次部署参考的是rstudio-server-conda项目中的说明, 直接使用singularity pull docker://rocker/rstudio:4.2拉取docker镜像转换为sif镜像使用 2. 必要文件准备使用如下的bash脚本生成需要的若干目录和配置文件 12345mkdir -p run var-lib-rstudio-serverprintf &#x27;provider=sqlite\\ndirectory=/var/lib/rstudio-server\\n&#x27; &gt; database.confecho &quot;auth-minimum-user-id=100&quot; &gt; rserver.confecho &quot;session-default-working-dir=/home/silen/Rstudio/Workspace&quot; &gt; rsession.confecho &quot;session-default-new-project-dir=/home/silen/Rstudio/Workspace&quot; &gt;&gt; rsession.conf 这样一来将生成run, var-lib-rstudio-server两个文件夹, 以及database.conf, rserver.conf, rsession.conf三个配置文件. 其中rserver.conf里的auth-minimum-user-id=100配置非常重要, 因为在使用的容器中, Rstudio是以uid为999的rstudio用户来运行的, 如果没有这个用户或者没有切换到该用户的权限, 容器无法正常运行. 因此我参考网上帖子中的说法使用--server-user参数制定用当前用户运行服务. 然而好巧不巧, 当前用户的uid小于513, 而auth-minimum-user-id这一参数默认为1000, 即禁止用户uid小于1000的用户运行服务(似乎是出于安全考虑). 因此就需要在rserver.conf里变更参数数值, 来让服务能正常的启动. 3. 指定参数启动容器使用如下命令启动服务即可, 运行的命令主要是将前面创建的目录和配置文件绑定到容器中供服务读取, 另外就是指定了ip与端口方便访问. 由于是担任使用, 就没有弄验证的东西了. 另外还参照rstudio-server-conda项目中的内容制定了使用的conda环境, 这样就不用在容器中重复安装R包了. 1234567891011singularity exec \\ --bind run:/run \\ --bind var-lib-rstudio-server:/var/lib/rstudio-server \\ --bind database.conf:/etc/rstudio/database.conf \\ --bind rserver.conf:/etc/rstudio/rserver.conf \\ --bind rsession.conf:/etc/rstudio/rsession.conf \\ --bind /home/silen/R-Plot:/etc/R-Plot \\ --env CONDA_PREFIX=/etc/R-Plot \\ --env RSTUDIO_WHICH_R=/etc/R-Plot/bin/R \\ rstudio_4.2.sif \\ /usr/lib/rstudio-server/bin/rserver --www-address=0.0.0.0 --www-port=7788 --server-user=$(whoami) 启动后界面如下: 4. 注意Sigularity感觉上会更类似snap和flathub这种软件打包的项目, 宿主机和容器间并不是被那么完全的被隔开. Rstudio启动后, 直接可以访问到宿主机用户的Home目录, 不知道这是这个容器的特殊表现还是Sigularity都是如此? 之后我们需要对内部的分析流程做依赖梳理和容器话… 看来还需要更多的了解Sigularity的原理和使用方式.","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"容器技术","slug":"容器技术","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"singularity","slug":"singularity","permalink":"https://silenwang.github.io/tags/singularity/"},{"name":"Rstudio部署","slug":"Rstudio部署","permalink":"https://silenwang.github.io/tags/Rstudio%E9%83%A8%E7%BD%B2/"},{"name":"conda环境","slug":"conda环境","permalink":"https://silenwang.github.io/tags/conda%E7%8E%AF%E5%A2%83/"},{"name":"rstudio-server","slug":"rstudio-server","permalink":"https://silenwang.github.io/tags/rstudio-server/"}]},{"title":"白嫖codespace用来写hexo博客","slug":"白嫖codespace用来写hexo博客","date":"2023-07-23T17:10:23.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2023/07/23/白嫖codespace用来写hexo博客/","permalink":"https://silenwang.github.io/2023/07/23/%E7%99%BD%E5%AB%96codespace%E7%94%A8%E6%9D%A5%E5%86%99hexo%E5%8D%9A%E5%AE%A2/","excerpt":"最近出于…..emmmmmm心有不甘？我卖掉了之前拍的lenovo chrome duet2，但是转头又买了pixelbook 2017…..既然设备到手了，还是想要继续折腾一阵，力求找到用这台pixelbook 2017代替我的工作电脑进行一般办公的方式。然后找着找着，主要矛盾没解决，倒是诞生了几个实用的副产品…. 使用codespace写hexo博客是其一。","text":"最近出于…..emmmmmm心有不甘？我卖掉了之前拍的lenovo chrome duet2，但是转头又买了pixelbook 2017…..既然设备到手了，还是想要继续折腾一阵，力求找到用这台pixelbook 2017代替我的工作电脑进行一般办公的方式。然后找着找着，主要矛盾没解决，倒是诞生了几个实用的副产品…. 使用codespace写hexo博客是其一。 在哪都能写博客啦Github codespace本来是云时代，github推出的一项纯云开发服务，这个服务可以为用户分配一个容器（可以自定义），然后直接将github上的项目代码拉入到容器中，给用户分配一个可以访问容器内容的vscode web客户端，这样就能直接在github提供的服务器上直接进行代码的编写和调试，也就是完全在云端进行开发了。项目的实现我猜和coder类似。 这么好的东西，当然不会是免费的，目前github提供15G的免费空间，以及120h的核心时间（详细见官方）。这个存储和时间看上去不多，但是根据目前的使用来看，核心时间应该是不作计算就不算的，因此如果是非常轻量的项目，其实还是很充裕的。 这不就正适合用来写博客嘛！ 我的Hexo博客代码量还没用的主题多，需要的计算也就是生成一下静态网页，要不了几秒。云上操作还能解决以前的博客只能在办公电脑上写的窘境（只有办公电脑我配置了环境，懒得再来一次），打开即用。而且试了一下，hexo s生成的静态网页预览甚至都可以正常访问！这样就能跟那种博客平台一样，有浏览器就能写啦～（虽然我鸽显然不是因为没有设备能写 使用上的问题目前唯二的问题就是网络以及博客内的图片管理了。 1. 图片问题原来写博客用过picgo和upgit两个工具进行图片上传和自动链接获取，目前实测下来，原本最方便的vscode-picgo插件并不能使用，即使安装xclip后，也识别不到剪贴板里的图像内容，大概是因为它是在云端容器中，而有图像的剪贴板，是我本地的吧… upgit倒是有办法使用，将软件下载到chromeos下的linux容器中，做好配置就可以了。 2. 网络这个问题不用多说… 国外的服务想访问到都有一样的问题，目前来说编辑器的部分其实还好，应为不是即时响应的，因此码字相当流畅…就是不知道会不会写着写着发现保存不了。 但是命令行的部分还是感觉得到明显卡顿的，好在命令行也不多，就是个hexo g和hexo d，忍一忍也就过去了，大不了就现在不发布，改天再说嘛。","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://silenwang.github.io/tags/Hexo/"},{"name":"云端开发","slug":"云端开发","permalink":"https://silenwang.github.io/tags/%E4%BA%91%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"博客写作","slug":"博客写作","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E5%86%99%E4%BD%9C/"},{"name":"Github","slug":"Github","permalink":"https://silenwang.github.io/tags/Github/"},{"name":"Codespace","slug":"Codespace","permalink":"https://silenwang.github.io/tags/Codespace/"}]},{"title":"在chatGPT的指导下写一个调用chatGPT的API进行文献解析的工具","slug":"在chatGPT的指导下写一个调用chatGPT的API进行文献解析的工具","date":"2023-03-27T01:26:48.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2023/03/27/在chatGPT的指导下写一个调用chatGPT的API进行文献解析的工具/","permalink":"https://silenwang.github.io/2023/03/27/%E5%9C%A8chatGPT%E7%9A%84%E6%8C%87%E5%AF%BC%E4%B8%8B%E5%86%99%E4%B8%80%E4%B8%AA%E8%B0%83%E7%94%A8chatGPT%E7%9A%84API%E8%BF%9B%E8%A1%8C%E6%96%87%E7%8C%AE%E8%A7%A3%E6%9E%90%E7%9A%84%E5%B7%A5%E5%85%B7/","excerpt":"这个标题有点点套娃… 但是事实确实如此. 在之前认识到chatGPT确实能比较好的回答代码问题之后, 我突然觉得我行了! 我终于有可能做全栈了! 于是为了展示chatGPT加持下的个人实力, 我准备写个用chatGPT读论文的程序(其实有考虑用这个辅助做meta分析)!","text":"这个标题有点点套娃… 但是事实确实如此. 在之前认识到chatGPT确实能比较好的回答代码问题之后, 我突然觉得我行了! 我终于有可能做全栈了! 于是为了展示chatGPT加持下的个人实力, 我准备写个用chatGPT读论文的程序(其实有考虑用这个辅助做meta分析)! 开始挖坑大概是两个星期前想到做这个东西的, 之前注册了号, 试用它辅助写了一个带token验证的静态服务, 后面就看到了同事分享的chatPDF, 以及同事说他靠chatGPT来快速阅读文献并写综述. 当时我就回忆起了在这里工作三年看文献的痛苦, 想着何不开发个工具用chatGPT加速我的阅读呢? 以来辅助自己工作, 而来有了demo可以蹭热度, 要是收获个几十上百的star, 那我也离自己想了很久的全栈独立开发者又更近了. 加之之前做不了是因为很多东西从头学根本没那个时间和能力, 现在有chatGPT辅助那还不是事半功倍? 各种踩坑然后说干就干!(三分钟热度最擅长这个), 我想着有了此等外挂, 开发个简单的demo还不就三两天的事? 然后这两周就开始各种踩坑…. 想给钱都这么难…我也没想到, 第一个坑居然是付钱… 之前新注册的OpenAI账号都会送30刀的免费API额度用于体验, 但可能是用户太多… 后面就减少甚至不送了… 我当时注册完… 账号上就是一个子没有的… 核心功能的API调用不了那怎么行… 就只能自掏腰包解决了… 吗? 还真没有这么简单, 因为OpenAI是不对中国大陆开发服务的… 因此我的Visa卡都没法登记… 只能办虚拟信用卡… 然后这个虚拟信用卡… 我也不知道它到底是不是个合法玩意… 最大的Depay要求用一种虚拟货币充值??? 虚拟货币我听着就发憷… 不敢乱碰, 最后只能找了个首付金额大, 但是我能直接付款的(多的钱大不了之后买塞尔达了…), 才解决了问题(最后好像还是靠钱解决了), 充上值, 开始开发! emmmmmm, 然后此时已经过了半天…. chatGPT当前的局限性chatGPT能执行各种各样的任务, 但是这改变不了它是一个文本生成AI的事实, 它本质上的功能是生成一段通顺的, 最好是没有错误的自然语言文字. 我在初期使用它的时候确实比较少碰到问题(可能是问题简单), 但是随着使用频率上升, 出问题的频率和严重程度就越来越大了… 总的来说, 我感觉由于我问的过于泛泛, 或者是我问的一些问题并不可能有答案, 因此会收到它的各种胡说八道的答案. 这会产生两个问题: 实际开发时并没有想的那么飞速, 因为我好死不死采用了一个非常新的开发框架(Pynecone), 它的介绍很美好, 一次开发, 前端&#x2F;后端&#x2F;API全部都有, 多平台快捷部署. 然而由于太新, chatGPT完全不能给我任何建议, 我还是得自己学习文档和官方的示例来完成必要功能的实现. 而且在一些很基本的功能上都花了非常多的时间… 让chatGPT稳定的执行特定的任务不是一件那么简单的事情… 而且我用的是gpt-3.5-turbo(起步时还没有4, 当然现在我也排不上队), 因此并不如gpt4那样能轻易指定返回答案格式(我想用json格式返回便于解析). 所以说…面向prompts编程… 还真不是一句玩笑… 要使用得好, 调试prompts还是非常必要的 总之, chatGPT很强, 但… 即使是gpt4, 我相信也没有微软宣传片里的那么强… 要使用得顺畅, 还是要具备使用的技巧, 把自己变成chatGPT的形状(误 开发框架切换接前文… Pynecone真的是还不成熟… 导致我在一个半星期后真的受不了了, 还是切到了Gradio… 怎么说呢… 工具和框架的马太效应不要随意违背啊… 尤其是我本意是蹭热度, 那就更是应该找最快的实现方式, 切忌想太多 HuggingFace你罪大恶极!虽然只是句玩笑, 但是我真的没想到… 我会在demo的上线卡了整整一个下午加一个晚上, HuggingFace是很好的平台(一个space提供8核16G, 这什么石油佬开的慈善平台), 但是你这个新建项目不让全空真的是为难我这种小白… 我经历了手动合并冲突, 强制推送代码, 最后还是妥协选择把原项目的代码和传到HuggingFace的分开弄了… 这个问题上我真的问题都问不到点, 没从chatGPT上获得什么有效的帮助… 时间不够用屋漏偏逢连夜雨, 说多了都是泪, 该肝还是要肝… (在成为国宝的路上一去不复返 chatGPT带来的帮助虽然前面也吐槽了chatGPT也没有那么的好用, 但是它带来的增益还是实打实的, 在这个项目中对我的帮助包括但不限于: 帮忙解读类似的开源代码, 让我快速了解别人的实现方式 解答Gradio的各种使用问题(成熟的工具就能给出很多实用建议) 帮助生成英文README(然而还是没人看) 增加”我能做到!”的信心 体会到”独立”开发的痛苦这两周我也深刻体会过独立开发者的, 或者说个人自媒体的痛苦了… 同样是文献阅读辅助, chatPaper项目和我的内容都是两周前开始陆续在github上开始披露代码的(当然我的不是披露, 是做一点就传一点…), 现在人家已经是4000+star了… 我特么最开始构想的两个功能和基本的app页面才刚完成… 对方是6个中科院的博士… 我… 这感觉大概就是兴致冲冲干自媒体, 然后视频发出来没人看时候的焦虑感了吧… 项目地址不过不管如何, 项目本身的目的之一就是开发自己觉得好用的东西… 热度要是蹭不到… 那就罢了吧… 我的项目叫 ResearchGPT, Demo挂在了Huggingface上, 有兴趣可以试用哟~ 当然这个博文也做了Demo的嵌入就是了…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"ChatGPT","slug":"ChatGPT","permalink":"https://silenwang.github.io/tags/ChatGPT/"},{"name":"API开发","slug":"API开发","permalink":"https://silenwang.github.io/tags/API%E5%BC%80%E5%8F%91/"},{"name":"文献解析","slug":"文献解析","permalink":"https://silenwang.github.io/tags/%E6%96%87%E7%8C%AE%E8%A7%A3%E6%9E%90/"},{"name":"独立开发","slug":"独立开发","permalink":"https://silenwang.github.io/tags/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91/"},{"name":"Gradio","slug":"Gradio","permalink":"https://silenwang.github.io/tags/Gradio/"},{"name":"HuggingFace","slug":"HuggingFace","permalink":"https://silenwang.github.io/tags/HuggingFace/"}]},{"title":"chatGPT确实好用","slug":"chatGPT确实好用","date":"2023-02-23T18:24:06.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2023/02/23/chatGPT确实好用/","permalink":"https://silenwang.github.io/2023/02/23/chatGPT%E7%A1%AE%E5%AE%9E%E5%A5%BD%E7%94%A8/","excerpt":"chatGPT火了这么久, 我昨天才正式因为想用它生成一些东西才弄了个号, 就像网上很多人说的, 虽然在专业问题上他确实可能是大忽悠, 但是对于写代码来说, 反正我最后是要自己跑和自己测试的, 实践出真知, 给个大致正确的方向也好呀!","text":"chatGPT火了这么久, 我昨天才正式因为想用它生成一些东西才弄了个号, 就像网上很多人说的, 虽然在专业问题上他确实可能是大忽悠, 但是对于写代码来说, 反正我最后是要自己跑和自己测试的, 实践出真知, 给个大致正确的方向也好呀! 这个问题的背景是这样: 我用mkdocs生成了一份公司内容用的技术文档(就像我手册的那种), 这是一个静态网页, 因此加上一个http服务器就能直接看了 我想把这个文档使用iframe嵌入到现有的系统中 由于这个文档比较重要, 所以有一定的保密需求, 所以这个文档不可以直接访问, 需要有一定验证 经过与IT同时讨论, 最终讨论方案时, 他首次请求的时候给我一个token, 我用这个token去他给的API里做一个验证, 返回是true了再给内容. 我自己只会基本的flask和fastAPI, 然后flask用起来更简单一点, 所以小结下来, 我需要写这么个程序: 用flask构建一个和python下simple http.server有同等功能的http服务器, 他能让用户访问mkdocs创建好的静态网站 这个服务器需要有验证更能, 即接受请求中的token后去进行验证, 判断用户是不是合法用户 第一次验证之后, 在静态网站内部跳转的请求是这个服务自己来处理的, 因此要持续验证的话需要我自己设法保存token, 然后自己完成验证 我之前虽然有使用过flask和dash, 但是对web相关的技术其实基本是没有太多概念的, 之前测试caddy反代理的经验让我觉得上面这个程序肯定是能实现的, 但是具体怎么实现, 则没有太多实际想法, 而同时跟我说的自己保存token也是明白意思, 不明白如何操作的 这时就是chatGPT起作用的地方了, 我按照我的理解进行了大致的描述, 询问如何编写我想要的代码. 它并没有给我一个完全符合我要求的结果, 但是给了我一个代码示例, 让我可以边测试边猜这个程序应该怎么写, 然后对于不懂的地方则追加询问, 或者要求专门讲解, 它给的回答不说完全正确(当然也有我问的不明确的问题), 但是在讨论的过程中我确实逐步找到了我想要的实现方案. 最后我一个上午就完成了这个简单的程序, 虽然程序简单, 但是如果放在以前, 我自己可能先要找好几个中文网页看看有没有现成的例子可以参考, 然后猜一下英文的描述方法, 再在stackoverflow上翻阅10个左右的英文帖子, 找寻我想要的部分问题的答案, 然后自己尝试组出一个能用的方案… 这个过程不能说很痛苦, 毕竟是阅读学习的过程, 但是效率上来说肯定不咋样… 而现在只要我能基本描述清楚我要什么, chatGPT就可以直接给我一段代码示例让我来调试和学习, 等于节省了绝大部分查中文材料和英文材料的时间, 直接跳到用例子来调试, 效率上无疑是质变的… 瞬间感觉借助它学个前端的一招半式… 自己写网站和App不是梦了… update20220227今天chatGPT的请求过多,暂时没法使用了(不知道付费用户们如何), 看来还是早用早享受… 玩了可能免费使用都莫得了… 附: 关于这个问题的完整对话过程You:如何使用flask搭建一个使用token进行验证的http 服务器?ChatGPT:要使用 Flask 搭建一个使用 token 进行验证的 HTTP 服务器，您可以使用 Flask 的 Flask-JWT 扩展。此扩展为 Flask 应用程序提供了 JSON Web Token（JWT）身份验证机制。下面是一个简单的 Flask 应用程序示例，用于验证用户 token：首先安装所需的扩展：12pip install Flaskpip install Flask-JWT接下来，编写 Flask 应用程序代码，如下所示：123456789101112131415161718192021222324252627282930313233343536373839404142434445from flask import Flask, jsonify, requestfrom flask_jwt import JWT, jwt_required, current_identityfrom werkzeug.security import safe_str_cmp# 定义用户类class User(object): def __init__(self, id, username, password): self.id = id self.username = username self.password = password# 创建用户列表users = [ User(1, &#x27;user1&#x27;, &#x27;password1&#x27;), User(2, &#x27;user2&#x27;, &#x27;password2&#x27;)]# 定义 authenticate 和 identity 方法def authenticate(username, password): for user in users: if user.username == username and safe_str_cmp(user.password.encode(&#x27;utf-8&#x27;), password.encode(&#x27;utf-8&#x27;)): return userdef identity(payload): user_id = payload[&#x27;identity&#x27;] return next((user for user in users if user.id == user_id), None)# 创建 Flask 应用程序实例app = Flask(__name__)# 设置 JWT 密钥app.config[&#x27;SECRET_KEY&#x27;] = &#x27;super-secret&#x27;# 创建 JWT 对象jwt = JWT(app, authenticate, identity)# 创建受保护的路由@app.route(&#x27;/protected&#x27;)@jwt_required()def protected(): return jsonify(&#123;&#x27;user_id&#x27;: current_identity.id, &#x27;username&#x27;: current_identity.username&#125;)# 运行应用程序if __name__ == &#x27;__main__&#x27;: app.run()在这个应用程序中，我们定义了一个 User 类来表示用户，然后创建了一个用户列表 users，其中包含两个用户的用户名和密码。我们还定义了 authenticate 和 identity 方法，用于在验证时查找用户。在 Flask 应用程序实例中，我们设置了一个 SECRET_KEY，并创建了一个 JWT 对象。我们还定义了一个受保护的路由 /protected，只有在用户提供有效的 JWT 令牌时才能访问该路由。最后，我们运行 Flask 应用程序。当您访问 /protected 路由时，您将需要提供有效的 JWT 令牌才能访问该路由。You:这个flask服务器在接收请求时会收到一个token, 我需要用这个token去某个服务器进行验证, 验证通过再返回静态内容出去, 要如何编写呢?ChatGPT:要在 Flask 应用程序中使用传入的 token 去验证另一个服务器，您可以使用 Python 的 requests 库，该库可以方便地向其他服务器发送 HTTP 请求并获取响应。下面是一个简单的 Flask 应用程序示例，它将收到的 token 发送到其他服务器进行验证，并返回静态内容：123456789101112131415161718192021222324252627import requestsfrom flask import Flask, request# 创建 Flask 应用程序实例app = Flask(__name__)# 定义验证 token 的方法def verify_token(token): # 向其他服务器发送 HTTP 请求进行验证 response = requests.get(&#x27;https://example.com/verify-token&#x27;, headers=&#123;&#x27;Authorization&#x27;: &#x27;Bearer &#x27; + token&#125;) if response.status_code == 200: return True else: return False# 创建路由@app.route(&#x27;/&#x27;)def index(): token = request.headers.get(&#x27;Authorization&#x27;).split(&#x27; &#x27;)[1] if verify_token(token): return &#x27;Hello, world!&#x27; else: return &#x27;Invalid token&#x27;# 运行应用程序if __name__ == &#x27;__main__&#x27;: app.run()在这个应用程序中，我们定义了一个 verify_token 方法，它将传入的 token 发送到其他服务器进行验证，并根据响应确定该 token 是否有效。我们还定义了一个根路由 /，它将从传入请求的 headers 中获取 token，并将其传递给 verify_token 方法进行验证。如果传入的 token 有效，则返回 &#39;Hello, world!&#39;，否则返回 &#39;Invalid token&#39;。请注意，此示例仅用于演示目的。在实际应用程序中，您需要将 verify_token 方法与实际的验证逻辑相匹配，并确保使用正确的验证头和其他参数。You:如果我要返回的不是简单的网站, 而是已经生成好了静态网页, 如mkdocs或者gitbook生成好的静态页面, 如何实现呢?ChatGPT:如果您要返回已经生成好的静态网页，可以使用 Flask 的 send_from_directory 方法。该方法可用于从特定目录中返回指定的文件，以供客户端下载或查看。假设您已经生成了静态网页，并将其存储在 static 目录下的 docs 子目录中，可以使用以下 Flask 应用程序代码来提供该网页：12345678910111213from flask import Flask, send_from_directory# 创建 Flask 应用程序实例app = Flask(__name__)# 创建路由@app.route(&#x27;/docs/&lt;path:filename&gt;&#x27;)def serve_docs(filename): return send_from_directory(&#x27;static/docs&#x27;, filename)# 运行应用程序if __name__ == &#x27;__main__&#x27;: app.run()在这个应用程序中，我们定义了一个 serve_docs 路由，它将根据客户端请求的文件名从 static/docs 目录中返回相应的文件。例如，如果您要返回 static/docs/index.html 文件，可以使用以下 URL：1http://localhost:5000/docs/index.html请注意，这只是一个基本示例。在实际应用程序中，您可能需要添加其他逻辑，例如身份验证和访问控制，以确保只有授权用户可以访问您的静态网页。You:flask在接收请求的时候如何获取get请求给的参数?ChatGPT:在 Flask 中获取 GET 请求的参数非常简单。您可以使用 request.args 对象来获取 GET 请求中的参数。这个对象是一个字典，它包含了 GET 请求中的所有参数和它们的值。例如，如果您的 URL 是 http://localhost:5000/search?q=python&amp;page=1，那么您可以使用以下代码来获取 q 和 page 参数的值：123456789101112131415from flask import Flask, request# 创建 Flask 应用程序实例app = Flask(__name__)# 创建路由@app.route(&#x27;/search&#x27;)def search(): query = request.args.get(&#x27;q&#x27;) page = request.args.get(&#x27;page&#x27;) return f&#x27;Searching for &quot;&#123;query&#125;&quot; on page &#123;page&#125;&#x27;# 运行应用程序if __name__ == &#x27;__main__&#x27;: app.run()在这个应用程序中，我们定义了一个 search 路由，它将获取 GET 请求中的 q 和 page 参数，并将它们包含在返回的字符串中。请注意，request.args.get 方法返回的是字符串类型。如果您需要获取其他类型的参数值（例如整数或布尔值），则需要进行适当的转换。You:123456789101112131415161718import requestsfrom flask import Flask, request, send_from_directory# 创建 Flask 应用程序实例app = Flask(__name__)# 创建路由@app.route(&#x27;/&lt;path:filename&gt;&#x27;)def serve_docs(filename): if filename == &#x27;&#x27;: filename = &#x27;index.html&#x27; return send_from_directory(f&#x27;static/docs/&#x27;, filename)# 运行应用程序if __name__ == &#x27;__main__&#x27;: app.run()ChatGPT:这段代码的作用是创建一个 Flask 应用程序，并使用 send_from_directory 方法从 static/docs 目录中返回指定的文件，以响应客户端的请求。这个应用程序监听根路由 &#39;/&#39;，并使用 filename 参数来指定要返回的文件名。在这个应用程序中，我们还添加了一些额外的逻辑。如果客户端请求的是根路由 &#39;/&#39;，则默认返回 index.html 文件。请注意，如果您使用这个代码示例来返回您自己生成的静态网页，请确保将文件存储在 static/docs 目录中。您可以通过将 static/docs 替换为您存储静态网页的实际目录来修改代码。如果您需要实现身份验证和访问控制等更高级的功能，则需要添加更多的逻辑代码。例如，您可以使用 Flask 提供的 login_required 装饰器来要求用户在访问受保护的页面之前进行身份验证。You:上面的代码只能访问static&#x2F;docs&#x2F;下的一级文件, 怎样写能访问子目录下的文件呢ChatGPT:如果您想要访问 static/docs 目录及其子目录中的文件，可以将 send_from_directory 函数的第一个参数更改为 static，并将 filename 参数作为子目录和文件名的组合。具体来说，您可以使用 os.path.join 函数将子目录和文件名拼接起来，然后将其作为 send_from_directory 函数的第二个参数。以下是一个示例代码，它可以访问 static/docs 目录及其子目录中的所有文件：1234567891011121314151617import osfrom flask import Flask, send_from_directory# 创建 Flask 应用程序实例app = Flask(__name__)# 创建路由@app.route(&#x27;/&lt;path:filename&gt;&#x27;)def serve_docs(filename): if filename == &#x27;&#x27;: filename = &#x27;index.html&#x27; path = os.path.join(&#x27;static&#x27;, filename) return send_from_directory(path, filename)# 运行应用程序if __name__ == &#x27;__main__&#x27;: app.run()在这个应用程序中，我们定义了一个 serve_docs 路由，它可以处理所有路径的请求，包括子目录和文件名。我们使用 os.path.join 函数将路径中的子目录和文件名组合起来，并将结果传递给 send_from_directory 函数的第一个参数。由于这个函数可以处理子目录，因此它可以在 static 目录中查找任何子目录和文件名的组合。请注意，这个代码示例仅提供了基本的路由和文件服务逻辑。如果您需要实现身份验证和访问控制等更高级的功能，您需要在代码中添加相应的逻辑。You:flask中如果请求的是’&#x2F;‘想重定向到’&#x2F;index.html’怎么写?ChatGPT:要将根路径 / 重定向到 /index.html，您可以使用 Flask 中提供的 redirect 函数。以下是一个示例代码，它可以实现这个功能：12345678910111213from flask import Flask, redirect# 创建 Flask 应用程序实例app = Flask(__name__)# 创建路由@app.route(&#x27;/&#x27;)def redirect_to_index(): return redirect(&#x27;/index.html&#x27;)# 运行应用程序if __name__ == &#x27;__main__&#x27;: app.run()在这个应用程序中，我们定义了一个名为 redirect_to_index 的路由，它会将根路径 / 重定向到 /index.html。我们使用 Flask 中提供的 redirect 函数来实现重定向。该函数的参数是重定向目标的 URL。当客户端请求根路径 / 时，该路由函数将调用 redirect 函数，并将其参数设置为 /index.html。这将导致客户端被重定向到 /index.html 页面。请注意，重定向功能是基于 HTTP 协议中的 3xx 状态码实现的。因此，客户端会收到一个状态码为 302（Found）的响应，并被要求重定向到新的 URL。You:请给我一个flask @app.route的使用方法参考文章ChatGPT:以下是一些 Flask @app.route 的使用方法参考文章，您可以参考其中的代码和示例：https://flask.palletsprojects.com/en/2.1.x/quickstart/#routingFlask 官方文档提供了详细的路由使用说明，包括基本路由、动态路由、HTTP 方法、URL 构建和重定向等方面的内容。https://www.pythondoc.com/flask/index.html这是一份中文的 Flask 入门教程，其中包括了路由、模板、表单处理、数据库访问等方面的内容。对于初学者来说，这是一个很好的学习资源。https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world这是一篇英文的 Flask 教程，其中包括了从简单的 “Hello, World!” 程序到复杂的 Web 应用程序开发的全部过程。其中的第二部分介绍了路由的基本使用方法。https://auth0.com/blog/flask-by-example-series-part-1-new-to-flask-should-i-stay-or-should-i-go/这是一系列的英文博客文章，旨在通过示例演示 Flask 的各种功能。其中的第一篇文章介绍了路由的基本使用方法，并提供了一些示例代码。希望这些参考文章能够对您学习 Flask 路由的使用方法有所帮助。如果您还有其他问题，请随时提问。You:如何使用flask建立一个类似python下simple https.erver的服务器, 可以自动访问建立好的静态网站?ChatGPT:要使用 Flask 建立一个类似 Python 下的 SimpleHTTPServer 的服务器，您可以使用 Flask 提供的 send_from_directory 函数来提供静态文件的访问。以下是一个简单的 Flask 应用程序示例，它可以实现这个功能：1234567891011121314151617from flask import Flask, send_from_directory# 创建 Flask 应用程序实例app = Flask(__name__)# 创建路由@app.route(&#x27;/&#x27;)def serve_index(): return send_from_directory(&#x27;static&#x27;, &#x27;index.html&#x27;)@app.route(&#x27;/&lt;path:path&gt;&#x27;)def serve_static(path): return send_from_directory(&#x27;static&#x27;, path)# 运行应用程序if __name__ == &#x27;__main__&#x27;: app.run(ssl_context=&#x27;adhoc&#x27;)在这个应用程序中，我们定义了两个路由：/ 路由：当客户端访问根路径时，会调用 serve_index 函数，并返回位于 static 文件夹中的 index.html 文件。/&lt;path&gt; 路由：当客户端访问任何其他路径时，会调用 serve_static 函数，并返回位于 static 文件夹中的相应文件。其中 &lt;path&gt; 参数可以是任何路径，包括子目录路径。在应用程序启动时，我们使用 ssl_context=&#39;adhoc&#39; 参数来启用自签名 SSL 证书，以实现 HTTPS 访问。这将使应用程序监听 443 端口，并使用自签名 SSL 证书进行加密通信。请注意，在上面的示例代码中，我们将所有静态文件都存放在 static 文件夹中。如果您的静态文件存放在其他文件夹中，您需要相应地修改 send_from_directory 函数中的文件路径。希望这个示例能够帮助您实现自己的 Flask 静态文件服务器。如果您还有其他问题，请随时提问。You:这里的path:path和path:filename有什么区别?ChatGPT:path:path 和 path:filename 的区别在于它们的用途和语义。在 Flask 应用程序中，路由可以使用动态路由参数，以允许在 URL 中包含动态值。例如，我们可以在路由中使用 &lt;filename&gt; 作为动态参数，以允许客户端访问 http://example.com/docs/index.html 或 http://example.com/docs/about.html 等文件。在 Flask 中，动态路由参数的格式为 &lt;parameter_name&gt;[:&lt;converter&gt;]，其中 parameter_name 是参数的名称，converter 是可选的转换器，用于将参数值转换为特定的类型。如果未指定转换器，则默认为字符串类型。因此，path:filename 中的 filename 是一个动态路由参数，它表示请求的文件名。使用 path: 前缀可以将该参数视为一个包含路径信息的字符串。例如，如果客户端请求的 URL 为 http://example.com/docs/path/to/file.html，则 filename 的值为 path/to/file.html。相反，path:path 中的 path 是参数名称，表示一个包含路径信息的字符串。与 path:filename 不同的是，这个路由参数没有特定的名称，因此我们可以将它命名为任何有效的 Python 变量名。例如，我们可以将路由定义为 @app.route(&#39;/&lt;path:file_path&gt;&#39;)，并将参数命名为 file_path，以表示请求的文件路径。在这种情况下，如果客户端请求的 URL 为 http://example.com/docs/path/to/file.html，则 file_path 的值为 path/to/file.html。总之，path:path 和 path:filename 的区别在于它们的名称和语义。path:filename 表示请求的文件名，而 path:path 表示请求的文件路径。You:flask服务器如何保存用户的状态? 第一访问时会收到一个token, 我需要将它保存下来, 保证这一次访问的期间这个token都可用ChatGPT:在 Flask 中，可以使用会话（Session）来保存用户的状态信息。会话是一种在服务器端存储用户数据的技术，可以让 Flask 应用程序在多个请求之间共享数据。在 Flask 中，会话数据被存储在客户端的 Cookie 中，而 Cookie 的内容则由服务器端签名和加密，以保证其不被篡改。要在 Flask 应用程序中使用会话，可以使用 Flask 的 session 对象。在每个会话中，Flask 会为每个客户端生成一个唯一的 Session ID，并将 Session ID 存储在 Cookie 中。可以将任意 Python 对象存储在 Flask 的 session 对象中，这些数据会被自动序列化为字符串，并存储在 Cookie 中。要从 session 中获取数据，可以使用 session.get(key, default=None) 方法或 session[key] 语法。在你的情况下，当客户端第一次访问服务器时，你可以将客户端提供的 token 存储在会话中，以便在之后的请求中使用。例如，以下是一个使用 Flask 会话来保存 token 的示例：123456789101112131415161718192021from flask import Flask, request, sessionapp = Flask(__name__)app.secret_key = &#x27;your-secret-key&#x27; # 设置密钥，用于签名和加密 Cookie@app.route(&#x27;/login&#x27;, methods=[&#x27;POST&#x27;])def login(): token = request.form.get(&#x27;token&#x27;) session[&#x27;token&#x27;] = token # 将 token 存储在会话中 return &#x27;Logged in successfully.&#x27;@app.route(&#x27;/protected&#x27;)def protected(): token = session.get(&#x27;token&#x27;) if token is None: return &#x27;You are not logged in.&#x27; # 在这里使用 token 进行验证，验证通过则返回静态内容 return &#x27;Protected content.&#x27;if __name__ == &#x27;__main__&#x27;: app.run()在这个例子中，当客户端向 /login 路由发送 POST 请求时，服务器会将客户端提供的 token 存储在会话中。然后，当客户端请求 /protected 路由时，服务器会从会话中获取存储的 token，并使用它进行验证。如果验证通过，则返回受保护的内容；否则，返回未经授权的消息。注意，为了使用 Flask 会话，你需要在应用程序中设置一个密钥（即 app.secret_key），用于签名和加密 Cookie。这个密钥应该是一个随机的字符串，并且不应该被泄露。You:你有什么推荐的方法来生成这个密钥么ChatGPT:生成一个随机的密钥可以使用 Python 的 secrets 模块，这个模块提供了生成安全随机数的函数。在 Flask 应用程序中，可以使用 secrets.token_hex(nbytes) 函数生成一个指定长度的随机字符串，这个字符串可以用作 app.secret_key 的值。例如，以下是一个使用 secrets 模块生成随机密钥的示例：1234import secretsapp = Flask(__name__)app.secret_key = secrets.token_hex(16) # 生成一个长度为 16 字节的随机字符串作为密钥在这个例子中，我们使用 secrets.token_hex(16) 函数生成了一个长度为 16 字节的随机字符串，并将其用作 Flask 应用程序的密钥。另外，如果你使用 Flask-WTF 或 Flask-Session 等 Flask 扩展，这些扩展会自动使用 Flask 应用程序的密钥来签名和加密数据，因此你不需要为这些扩展单独生成密钥。You:我想给上面这个密钥设置一个过期时间, 要怎么实现呢?ChatGPT:在 Flask 中，应用程序的密钥（app.secret_key）并不是一种具有过期时间的对象，它通常是在应用程序启动时生成的，并在应用程序运行期间保持不变。如果你想实现一个具有过期时间的密钥，可以考虑使用第三方库（如 cryptography）来生成一个带有过期时间的 JWT（JSON Web Token）。JWT 是一种基于 JSON 的开放标准，用于在网络上安全地传输信息。它可以包含有关用户身份验证和授权的信息，同时还可以包含过期时间等元数据。例如，以下是一个使用 cryptography 库生成带有过期时间的 JWT 的示例：1234567891011121314151617181920212223import datetimeimport jwtapp = Flask(__name__)app.config[&#x27;JWT_SECRET_KEY&#x27;] = &#x27;mysecretkey&#x27; # 设置 JWT 密钥app.config[&#x27;JWT_EXPIRATION_DELTA&#x27;] = datetime.timedelta(seconds=3600) # 设置 JWT 过期时间为 1 小时@app.route(&#x27;/login&#x27;)def login(): # 进行用户身份验证 if authenticated: # 如果身份验证成功，则生成 JWT 并返回给客户端 payload = &#123;&#x27;sub&#x27;: &#x27;1234567890&#x27;, &#x27;exp&#x27;: datetime.datetime.utcnow() + app.config[&#x27;JWT_EXPIRATION_DELTA&#x27;]&#125; token = jwt.encode(payload, app.config[&#x27;JWT_SECRET_KEY&#x27;], algorithm=&#x27;HS256&#x27;) return &#123;&#x27;access_token&#x27;: token.decode(&#x27;UTF-8&#x27;), &#x27;token_type&#x27;: &#x27;Bearer&#x27;&#125; else: return &#123;&#x27;error&#x27;: &#x27;Authentication failed&#x27;&#125;@app.route(&#x27;/protected&#x27;)@jwt_required()def protected(): # 如果 JWT 验证通过，则返回受保护的资源 return &#123;&#x27;data&#x27;: &#x27;Protected resource&#x27;&#125;在这个示例中，我们使用 jwt.encode() 函数生成 JWT，并将其返回给客户端。JWT 的有效期是通过设置 JWT_EXPIRATION_DELTA 配置项实现的，这里设置为 1 小时。在访问受保护的资源时，我们使用 @jwt_required() 装饰器来验证 JWT 的有效性。如果 JWT 验证通过，则返回受保护的资源，否则返回错误信息。需要注意的是，JWT 的安全性取决于密钥的保密性，因此在实际应用中应该采取措施保护密钥的安全性。同时，JWT 也有一些安全风险，如 CSRF 攻击等问题，需要在实现过程中注意安全性。","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"https://silenwang.github.io/tags/Flask/"},{"name":"chatGPT","slug":"chatGPT","permalink":"https://silenwang.github.io/tags/chatGPT/"},{"name":"编程辅助","slug":"编程辅助","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E7%A8%8B%E8%BE%85%E5%8A%A9/"},{"name":"静态网站","slug":"静态网站","permalink":"https://silenwang.github.io/tags/%E9%9D%99%E6%80%81%E7%BD%91%E7%AB%99/"}]},{"title":"钉钉Linux版本次的更新喜忧参半","slug":"钉钉Linux版本次的更新喜忧参半","date":"2023-02-03T17:27:49.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2023/02/03/钉钉Linux版本次的更新喜忧参半/","permalink":"https://silenwang.github.io/2023/02/03/%E9%92%89%E9%92%89Linux%E7%89%88%E6%9C%AC%E6%AC%A1%E7%9A%84%E6%9B%B4%E6%96%B0%E5%96%9C%E5%BF%A7%E5%8F%82%E5%8D%8A/","excerpt":"钉钉Linux版虽然更新的不算勤, 但是确实一直在解决问题, 只是如果在解决问题的同时不引入新的大问题就好了…","text":"钉钉Linux版虽然更新的不算勤, 但是确实一直在解决问题, 只是如果在解决问题的同时不引入新的大问题就好了… 目前我更新到了AUR上最新的1.6.0.230113-2, 更新之后, 不需要原本的环境变量设置也能正常进行中文输入了(程序本身及小程序都无问题), 界面缩放在非50%整数倍下也不再有锯齿了… 但是… 引入的更大的问题… 会议界面完全打不开了, 不论是发起会议或者是进入已经存在的会议, 点了都是毫无反应… 这个严重影响正常使用了… 希望能尽快解决吧…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"钉钉","slug":"钉钉","permalink":"https://silenwang.github.io/tags/%E9%92%89%E9%92%89/"},{"name":"中文输入","slug":"中文输入","permalink":"https://silenwang.github.io/tags/%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5/"},{"name":"界面缩放","slug":"界面缩放","permalink":"https://silenwang.github.io/tags/%E7%95%8C%E9%9D%A2%E7%BC%A9%E6%94%BE/"},{"name":"会议功能","slug":"会议功能","permalink":"https://silenwang.github.io/tags/%E4%BC%9A%E8%AE%AE%E5%8A%9F%E8%83%BD/"}]},{"title":"新年的Flag倒了","slug":"新年的Flag倒了","date":"2023-02-02T16:25:13.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2023/02/02/新年的Flag倒了/","permalink":"https://silenwang.github.io/2023/02/02/%E6%96%B0%E5%B9%B4%E7%9A%84Flag%E5%80%92%E4%BA%86/","excerpt":"上个月还在吐槽一年不如一年, 并期望今年会更好, 没想到Flag这么快就倒了, Fxxk… 真是糟心永不停歇…","text":"上个月还在吐槽一年不如一年, 并期望今年会更好, 没想到Flag这么快就倒了, Fxxk… 真是糟心永不停歇…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Daily","slug":"Daily","permalink":"https://silenwang.github.io/tags/Daily/"},{"name":"生活","slug":"生活","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"新年","slug":"新年","permalink":"https://silenwang.github.io/tags/%E6%96%B0%E5%B9%B4/"},{"name":"期望","slug":"期望","permalink":"https://silenwang.github.io/tags/%E6%9C%9F%E6%9C%9B/"},{"name":"沮丧","slug":"沮丧","permalink":"https://silenwang.github.io/tags/%E6%B2%AE%E4%B8%A7/"},{"name":"New Year","slug":"New-Year","permalink":"https://silenwang.github.io/tags/New-Year/"},{"name":"Expectation","slug":"Expectation","permalink":"https://silenwang.github.io/tags/Expectation/"},{"name":"Frustration","slug":"Frustration","permalink":"https://silenwang.github.io/tags/Frustration/"}]},{"title":"给Github首页做点面子工作","slug":"给Github首页做点面子工作","date":"2023-01-27T22:15:30.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2023/01/27/给Github首页做点面子工作/","permalink":"https://silenwang.github.io/2023/01/27/%E7%BB%99Github%E9%A6%96%E9%A1%B5%E5%81%9A%E7%82%B9%E9%9D%A2%E5%AD%90%E5%B7%A5%E4%BD%9C/","excerpt":"给博客升级了, 那也要给Github首页也做点面子工程…","text":"给博客升级了, 那也要给Github首页也做点面子工程… Github目前可以创建一个特殊的Repo, 该Repo和用户的名称一致, 比如我的就是SilenWang/SilenWang, 在该Repo下的README.md可以显示在用户的Gtihub首页上, 可以理解给了一个可以自定义的看板 目前我在上面放了一个Github的统计和我常用的工具图标 Github统计 这个很简单, 是用一个API实现的: 1&lt;img width=&quot;500px&quot; alt=&quot;GitHub Stats&quot; src=&quot;https://github-readme-stats.vercel.app/api?username=SilenWang&amp;count_private=true&amp;show_icons=true&quot;/&gt; 工具图标 这个使用了Shilds.io这个工具, 可以通过get请求从网站API处请求回各种带图标的标签, 比如Jupyter的标签就用: 1&lt;img alt=&quot;Jupyter&quot; src=&quot;https://img.shields.io/badge/-Jupyter-f37524?style=flat-square&amp;logo=Jupyter&amp;logoColor=white&quot; /&gt; 我把我用过的… 能查到有图标的都挖出来了… 可用的图标很丰富, 但也是不是什么都有, 目前已有的可以参见simple-icons下的这个文件 渲染效果 后记这边装饰好后, 我尝试把同样的标签用在关于我页面了, 然而Hexo渲染HTML Tag的时候似乎会强制加换行符, 导致所有标签拍成一列, 巨壮观 (nán kàn) … 我找了半小时没找到什么方法解决… 于是就摆烂用表格把每个标签框起来了… 以后找到如何解决再说吧…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Github","slug":"Github","permalink":"https://silenwang.github.io/tags/Github/"},{"name":"个人主页","slug":"个人主页","permalink":"https://silenwang.github.io/tags/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/"},{"name":"美化","slug":"美化","permalink":"https://silenwang.github.io/tags/%E7%BE%8E%E5%8C%96/"},{"name":"Github Stats","slug":"Github-Stats","permalink":"https://silenwang.github.io/tags/Github-Stats/"},{"name":"Shields.io","slug":"Shields-io","permalink":"https://silenwang.github.io/tags/Shields-io/"},{"name":"README","slug":"README","permalink":"https://silenwang.github.io/tags/README/"}]},{"title":"个人博客2023年升级","slug":"个人博客2023年升级","date":"2023-01-26T03:28:32.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2023/01/26/个人博客2023年升级/","permalink":"https://silenwang.github.io/2023/01/26/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A22023%E5%B9%B4%E5%8D%87%E7%BA%A7/","excerpt":"时隔… 已经不记得几年了, 本博客再次进行了主题升级, 主题依然使用了Volantis, 是一款使用简单, 但集成功能相当丰富的主题!","text":"时隔… 已经不记得几年了, 本博客再次进行了主题升级, 主题依然使用了Volantis, 是一款使用简单, 但集成功能相当丰富的主题! 更新内容一栏 Volantis升级到最新的稳定版本5.7.7 按照主题升级后的方式更新了关于页面, 现在能正常显示两位基 (sǔn) 友的链接了 启用了基于Github issue的评论插件utterances, 现在登陆Github账号后就可以给我留言啦! 安装插件启用站内文章链接 安装插件改变b站视频链接形式(由潜入播放器变成跳转卡片) 安装插件改变Github Repo的展现形式(卡片形式) 更新关于我页面, 使用主题自带的各种标签对页面进行了小小的美化 添加了一个类似萌娘百科的注音插件, 用来皮一下让自己开心~ 新装插件使用1. utterances评论Volantis主题下提供了14种不同的评论系统, 在_config.volantis.yml中按照文档说明的方式进行配置后即可使用 本来打算使用utterances的本地化版本beaudar的, 但是出现了我完全看不懂的问题, 所以还是放弃了. 配置好首次使用时, Github会提示要安装utterances的Github App才能使用, 这个应用的作用是代替你在Github发表Issue, 不知道是我作为所有者安装一次就好, 还是每个评论的人都要安装… 2. B站视频卡片之前也有在博客中插入一些自己的视频, 但是实际上插入窗口的播放非常受限制, 随便点两下还是会跳到B站去, 那不如就还是用链接得了, 使用hexo-bilibili-card能让链接好看一点点 (fēi cháng duō) , 插入起来也简单的多: 原来是: 1&lt;iframe src=&quot;//player.bilibili.com/player.html?aid=91147423&amp;cid=155618081&amp;page=1&quot; width=&quot;700&quot; height=&quot;500&quot; scrolling=&quot;no&quot; border=&quot;0&quot; frameborder=&quot;no&quot; framespacing=&quot;0&quot; allowfullscreen=&quot;true&quot;&gt; &lt;/iframe&gt; 现在是: 1&#123;% bilicard av91147423 %&#125; 3. Github Repo卡片在关于我的页面… 很简陋的展示了一下自己几个不那么拿得出手的Repo…. 所以使用主题自带的标签实现: 1&#123;% ghcard &#x27;SilenWang/silenwang.github.io&#x27; %&#125; 额外安装插件实现 在关于我的页面… 很简陋的展示了一下自己几个不那么拿得出手的Repo…. 所以找了个插件让它能稍微好看那么一丢丢丢丢…. 插件名称为hexo-github-repo-tag, 使用方式是:1&#123;% githubrepo &#x27;SilenWang/silenwang.github.io&#x27; %&#125;部署的时候遇到个小问题… 这个插件是利用API去项目页面抓取必要信息生成对应卡片的, 因此hexo g时需要访问github… 此时如果网络不好… 那只能多试几次了…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"博客升级","slug":"博客升级","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E5%8D%87%E7%BA%A7/"},{"name":"Hexo","slug":"Hexo","permalink":"https://silenwang.github.io/tags/Hexo/"},{"name":"Volantis主题","slug":"Volantis主题","permalink":"https://silenwang.github.io/tags/Volantis%E4%B8%BB%E9%A2%98/"},{"name":"插件配置","slug":"插件配置","permalink":"https://silenwang.github.io/tags/%E6%8F%92%E4%BB%B6%E9%85%8D%E7%BD%AE/"},{"name":"utterances","slug":"utterances","permalink":"https://silenwang.github.io/tags/utterances/"},{"name":"B站卡片","slug":"B站卡片","permalink":"https://silenwang.github.io/tags/B%E7%AB%99%E5%8D%A1%E7%89%87/"},{"name":"Github卡片","slug":"Github卡片","permalink":"https://silenwang.github.io/tags/Github%E5%8D%A1%E7%89%87/"}]},{"title":"我这3年玩过的游戏","slug":"我这3年玩过的游戏","date":"2023-01-24T02:18:48.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2023/01/24/我这3年玩过的游戏/","permalink":"https://silenwang.github.io/2023/01/24/%E6%88%91%E8%BF%993%E5%B9%B4%E7%8E%A9%E8%BF%87%E7%9A%84%E6%B8%B8%E6%88%8F/","excerpt":"2019年, 我为了玩怪物猎人XX买了3DS, 从此之后我开始为了玩特定的游戏买各种各样的设备… 为猛汉王组了PC, 为P4G买了PSV, 为崛起买了NSL, 最贵的是为节奏光剑买了Quest2. 本来19年底我就打算每年记录一下自己一年都玩了些啥… 然而人算不如天算… 疫情来了, 我的工作也突然繁重了好几个等级… 连打游戏都要靠半夜氪命, 也就没有精力去做很么回顾了, 只是对个别游戏表达了一丢丢感想.","text":"2019年, 我为了玩怪物猎人XX买了3DS, 从此之后我开始为了玩特定的游戏买各种各样的设备… 为猛汉王组了PC, 为P4G买了PSV, 为崛起买了NSL, 最贵的是为节奏光剑买了Quest2. 本来19年底我就打算每年记录一下自己一年都玩了些啥… 然而人算不如天算… 疫情来了, 我的工作也突然繁重了好几个等级… 连打游戏都要靠半夜氪命, 也就没有精力去做很么回顾了, 只是对个别游戏表达了一丢丢感想. 于是, 三年就这么过去了… 自从买了NSL后, 我基本就不玩3DS, PSV以及PC了, 莫名其妙就从电脑+手机玩家, 变成了主机玩家… 三年间玩过的游戏大概有: 游戏 平台 时间 通关 怪物猎人世界:冰原 PC 2020 只解禁 女神异闻录4G PSV 2020 是 奥丁领域 PSV 2020 是 胧村正 PSV 2020 是 龙之王冠 PSV 2020 否 伊苏4:塞尔塞塔树海 PSV 2020 是 伊苏8:丹娜的陨涕日 PSV 2020 否 勇气默示录 3DS 2020 否 节奏天国 3DS 2020 否 密特罗德:归来 3DS 2020 是 极限脱出2:善人死亡 3DS 2020 是 煮糊了2 PC 2021 否 隐形守护者 PC 2021 是 双人成行 PC 2021 是 猫咪斗恶龙 PC 2021 是 极限脱出3:零时困境 3DS 2021 是 大逆转裁判2 3DS 2021 是 怪物猎人崛起 NS 2021 是 异度神剑 NS 2021 是 无尽宇宙 NS 2021 是 血污:夜之仪式 NS 2021 是 AI:梦境档案 NS 2021 是 塞尔达传说:荒野之息 NS 2021 否 暗黑破坏神3 NS 2021 否 节奏光剑 Quest2 2021 否 仙剑奇侠传7 PC 2022 否 怪物猎人崛起:曙光 NS 2022 只解禁 密特罗德:生存恐惧 NS 2022 是 哈迪斯 NS 2022 否 斯普拉顿3 NS 2022 是 马里奥赛车8 NS 2022 无 十三机兵防卫圈 NS 2022 是 昆特牌:王权陨落 NS 2022 否 雨中冒险2 NS 2022 是 尼尔:机械纪元 NS 2022 否 异度神剑2 NS 2022 是 异度神剑3 NS 2022 是 魔法使之夜 NS 2022 否 女神异闻录5R NS 2022 否 emmmm… 这么看来… 不论工作忙不忙… 我玩游戏的时间… 估计都不会太少(毕竟熬夜用命玩… 这些游戏里, 最有感触的大逆转裁判2, 女神异闻录, 密特罗德已经写过了, 尼尔, 仙剑, 异度神剑, 斯普拉顿就等通关或段位上去了再来填坑好了","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"3DS","slug":"3DS","permalink":"https://silenwang.github.io/tags/3DS/"},{"name":"主机游戏","slug":"主机游戏","permalink":"https://silenwang.github.io/tags/%E4%B8%BB%E6%9C%BA%E6%B8%B8%E6%88%8F/"},{"name":"游戏回顾","slug":"游戏回顾","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E5%9B%9E%E9%A1%BE/"},{"name":"游戏平台","slug":"游戏平台","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E5%B9%B3%E5%8F%B0/"},{"name":"PSV","slug":"PSV","permalink":"https://silenwang.github.io/tags/PSV/"},{"name":"NS","slug":"NS","permalink":"https://silenwang.github.io/tags/NS/"},{"name":"PC","slug":"PC","permalink":"https://silenwang.github.io/tags/PC/"},{"name":"Quest2","slug":"Quest2","permalink":"https://silenwang.github.io/tags/Quest2/"}]},{"title":"女神异闻录4和5","slug":"女神异闻录4和5","date":"2023-01-22T23:30:08.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2023/01/22/女神异闻录4和5/","permalink":"https://silenwang.github.io/2023/01/22/%E5%A5%B3%E7%A5%9E%E5%BC%82%E9%97%BB%E5%BD%954%E5%92%8C5/","excerpt":"女神异闻录大概是第二个让我为了游戏买游戏机的系列了, 最开始被P5天下第一的梗洗脑洗了一年, 后来又看了Lex的P4推荐视频, 一个没忍住, 就买了PSV, 如果不是P4G后来登陆了PC, 给女神异闻录跨平台留了念想(去年也确实登陆了), 我大概还会为了P5在未来的某天买个二手PS4…","text":"女神异闻录大概是第二个让我为了游戏买游戏机的系列了, 最开始被P5天下第一的梗洗脑洗了一年, 后来又看了Lex的P4推荐视频, 一个没忍住, 就买了PSV, 如果不是P4G后来登陆了PC, 给女神异闻录跨平台留了念想(去年也确实登陆了), 我大概还会为了P5在未来的某天买个二手PS4… 去年拿到P5后, 我也是几度氪着命也想去年内把P5给打完, 奈何… 内容是真的多… 没进第三学期都将近80个小时, 至今也没有把最后通关(绝对不是因为中途跑去玩喷喷3了!)… 不过即使没有通关, 我也能感受到, 我跟大多数人感觉一样, 论系统P5完胜, 论故事确实P4更得我心. 我到不是觉得皇家版的剧情加的没有黄金版好, 而是觉得从题材或者立意上, P5就不是那么讨我喜欢. 可能因为我已经是个肮脏的大人了… 我在很多地方其实不是太能带入到主角团的视角上. 主角们的能力都觉醒自反抗的意志, 不希望被世俗所压迫、定义、以及束缚, 渴望展现真实的自己. 但是比较大的问题在于, P5里面的反派们写得特别的脸谱化和偏极化, 一群丑陋的大人为了自己的欲望无所不用其极, 解决问题的方式虽然很帅气, 但是也过于超现实和粗暴: 直接扭曲对方的心智和思想. 这种手段其实细想来, 跟传统RPG里的靠力量说话, 也即本质上的以暴制暴其实并没有什么分别, 所以其实我觉得明智最开始在电视上发表的观点并没有什么问题(虽然这人问题大了去了), 怪盗团确实可以非常的危险. 我觉得这种能力本质上跟夜神月拿到死亡笔记性质类似, 若非持有者本身觉悟够硬, 迟早会被用作不良用途, 当然剧情中的一些内容其实也提到了这个问题(比如三岛, 以及龙司) P4在相应的部分上则好接受很多, 因为P4的主题是接纳与成长, 主角们的力量都觉醒自对真实自我的接纳, 敌人则来自角色对自己的否定与拒绝(虽然少不了人们的偏见), 角色们每打倒一个暗影, 都是让角色自己更全面的认识自己, 同时也让同伴们互相更为了解, 自然而然的加深羁绊, 而不是P5那样凭力量获得所谓正义的胜利, 然后角色们并无实际的成长(成长全靠刷COOP) 不过, 这也是没办法的事, 好的故事P4已经用过了… 总不能再来一次, 也只能期望下代作品, 两方面都能把握得更好了~","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"游戏评测","slug":"游戏评测","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E8%AF%84%E6%B5%8B/"},{"name":"女神异闻录","slug":"女神异闻录","permalink":"https://silenwang.github.io/tags/%E5%A5%B3%E7%A5%9E%E5%BC%82%E9%97%BB%E5%BD%95/"},{"name":"P4G","slug":"P4G","permalink":"https://silenwang.github.io/tags/P4G/"},{"name":"P5R","slug":"P5R","permalink":"https://silenwang.github.io/tags/P5R/"},{"name":"JRPG","slug":"JRPG","permalink":"https://silenwang.github.io/tags/JRPG/"},{"name":"Persona","slug":"Persona","permalink":"https://silenwang.github.io/tags/Persona/"}]},{"title":"在Jupyter中注册新的Python或R内核","slug":"在Jupyter中注册新的Python或R内核","date":"2023-01-17T12:53:40.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2023/01/17/在Jupyter中注册新的Python或R内核/","permalink":"https://silenwang.github.io/2023/01/17/%E5%9C%A8Jupyter%E4%B8%AD%E6%B3%A8%E5%86%8C%E6%96%B0%E7%9A%84Python%E6%88%96R%E5%86%85%E6%A0%B8/","excerpt":"进行测试时经常要新建一个conda环境, 然后将环境装上jupyter内核后用notebook进行测试. 每次注册新内核都要重查, 所以还是做个记录好了…","text":"进行测试时经常要新建一个conda环境, 然后将环境装上jupyter内核后用notebook进行测试. 每次注册新内核都要重查, 所以还是做个记录好了… Python内核准备和注册 进入要注册的环境中后, 再进行注册 123conda activate YOUR_ENVconda install jupyter ipykernelpython -m ipykernel install --user --name ENV_NAME R内核准备和注册 进入要注册的环境中后, 再进行注册 12conda activate YOUR_ENVconda install jupyter r-irkernel 1IRkernel::installspec(name = &#x27;REG_NAME&#x27;, displayname = &#x27;ENV_NAME&#x27;)","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"Jupyter","slug":"Jupyter","permalink":"https://silenwang.github.io/tags/Jupyter/"},{"name":"内核注册","slug":"内核注册","permalink":"https://silenwang.github.io/tags/%E5%86%85%E6%A0%B8%E6%B3%A8%E5%86%8C/"},{"name":"技术教程","slug":"技术教程","permalink":"https://silenwang.github.io/tags/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/"}]},{"title":"夭寿啦!腾讯官方做新的LinuxQQ了?","slug":"腾讯官方做新LinuxQQ了","date":"2023-01-15T17:22:50.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2023/01/15/腾讯官方做新LinuxQQ了/","permalink":"https://silenwang.github.io/2023/01/15/%E8%85%BE%E8%AE%AF%E5%AE%98%E6%96%B9%E5%81%9A%E6%96%B0LinuxQQ%E4%BA%86/","excerpt":"曾几何时, 阻碍我日常使用Linux发行版的最大问题之一就是没有QQ, 当时还是大三, QQ还是学习生活的必备软件, 虽然已经有了智能手机这个东西, 但是当时在手机和Linux电脑间进行文件传输多有不便, 加之当时还没有WPS Linux版… 所以我最终还是用回了Windows.","text":"曾几何时, 阻碍我日常使用Linux发行版的最大问题之一就是没有QQ, 当时还是大三, QQ还是学习生活的必备软件, 虽然已经有了智能手机这个东西, 但是当时在手机和Linux电脑间进行文件传输多有不便, 加之当时还没有WPS Linux版… 所以我最终还是用回了Windows. 在去年年末, 出于不明原因, 腾讯居然出了官方的linuxqq, 虽然基于Electron, 但似乎并不是把网上的开源项目抄来用, 而是用了Mac版本的布局? 目前界面还挺好看的: 功能上, 最基本的聊天和文件传输没问题, 表情包显示也没问题, 空间和短视频也有了, 其他花里胡哨的一概没有, 暂时还挺小而美的… 那么… 曾经标榜自己小而美的那位… 什么时候能有动作呢?","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"腾讯","slug":"腾讯","permalink":"https://silenwang.github.io/tags/%E8%85%BE%E8%AE%AF/"},{"name":"QQ","slug":"QQ","permalink":"https://silenwang.github.io/tags/QQ/"},{"name":"Electron","slug":"Electron","permalink":"https://silenwang.github.io/tags/Electron/"},{"name":"Tencent","slug":"Tencent","permalink":"https://silenwang.github.io/tags/Tencent/"}]},{"title":"Pandas下Apply和R下的一项重要区别","slug":"Pandas下Apply和R下的一项重要区别","date":"2023-01-15T00:30:41.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2023/01/15/Pandas下Apply和R下的一项重要区别/","permalink":"https://silenwang.github.io/2023/01/15/Pandas%E4%B8%8BApply%E5%92%8CR%E4%B8%8B%E7%9A%84%E4%B8%80%E9%A1%B9%E9%87%8D%E8%A6%81%E5%8C%BA%E5%88%AB/","excerpt":"我目前在工作中已经几乎不用R做数据处理或者数据清洗了, 因为日常工作的数据整理工作涉及大量的字符串提取&#x2F;处理工作, 这些用R弄起来很难受. 另外R的错误追踪实在是很吃对代码的熟练度和编写经验, 让我这种只是写写简单脚本, 没什么编程规范意识的人编写和维护R代码简直要命(上间公司尝试过了…), 但是最近有同学要求我使用R语言来完成这类工作(因为他只会R), 于是在艰难抄代码的过程中我发现了一条新的不用R做这种工作的理由…","text":"我目前在工作中已经几乎不用R做数据处理或者数据清洗了, 因为日常工作的数据整理工作涉及大量的字符串提取&#x2F;处理工作, 这些用R弄起来很难受. 另外R的错误追踪实在是很吃对代码的熟练度和编写经验, 让我这种只是写写简单脚本, 没什么编程规范意识的人编写和维护R代码简直要命(上间公司尝试过了…), 但是最近有同学要求我使用R语言来完成这类工作(因为他只会R), 于是在艰难抄代码的过程中我发现了一条新的不用R做这种工作的理由… 需要完成的内容无非是对数据框取子集, 然后根据子集的行内容解析生成新的列, 再将解析的几个子集拼接起来. 这些内容我在Pandas做过无数次了… 也因此慢慢掌握了pandas里apply, group, pivot_table, melt这几个函数的使用, 目前完全没有碰到过这几个东西解决不了的处理, 唯一的问题… 就是代码编写的能力不太行, 因此有些东西写出来以后效率实在堪忧… 但是同样的操作在R下那要费了老命了… 毕竟是两种不同的语言, 想在R下找到对等物或者类似物来按照用Pandas的思路处理数据, 是非常困难的一件事, 就连有对等物的apply, 在这次编写中都出现了我无法解决的问题, 导致最后用回了for循环… 要进行的处理, 大概是从数据集data中选取子集sub, 这个sub实际包含两部分内容: A和B. 需要进行的处理是逐行进行判断, 如果A部分的内容没有缺失, 则返回A部分, 反之返回B部分, 每一行的返回值形成一个新的数据框. 这个用Pandas很好实现, 对子集apply, 然后编写函数对得到的行判断后, 返回行结果, apply完成后直接就是想要的数据框了. 但是在R下就不是这么回事了, 我最开始是这么弄的: 1234567891011121314# 编写函数用于返回需要的内容mkSel &lt;- function(rec)&#123; mkA &lt;- rec[[&#x27;MarkerA&#x27;]] mkB &lt;- rec[[&#x27;MarkerB&#x27;]] if (is.na(mkB)) &#123; row &lt;- c(mkA, rec[[&#x27;ColA1&#x27;]], rec[[&#x27;ColA2&#x27;]], rec[[&#x27;ColA3&#x27;]]) &#125; else &#123; row &lt;- c(mkB, rec[[&#x27;ColB1&#x27;]], rec[[&#x27;ColB2&#x27;]], rec[[&#x27;ColB3&#x27;]]) &#125; names(row) &lt;- c(&#x27;Marker&#x27;,&#x27;Tag1&#x27;, &#x27;Tag2&#x27;,&#x27;Tag3&#x27;) return(row)&#125;# 原代码没有文件记录，下面这个可能会有问题, 印象中用apply出来的只能是列，拼接成数据框， 所以转置sub[,c(&#x27;Marker&#x27;,&#x27;Tag1&#x27;, &#x27;Tag2&#x27;,&#x27;Tag3&#x27;)] &lt;- data.frame(t(apply(sub, 1, mkSel, simplify=T))) 这段代码完全是按照用Pandas的处理在弄, 最后也确实能够运行. 但是这里面有个巨大的问题: 向量内元素的数据类型必须是相同的, 我在将收集的数值放到同一个向量中时, 非字符串元素的类型就被自动变成字符串了, 因此虽然能运行, 但是新生成的4列已经全部是字符串了. 为了尝试解决这个问题, 我用list来替代函数内的向量, 有了一个中间版本, 然后我想到第二个问题: t()的转置是把数据当作矩阵来处理的, 因为R的列是一个个向量, 如果不这么做, 转置后一列就有多个数据类型了… 因此我不私心的去网上翻了半天, 抄了一段代码避免使用t(), 有了如下版本: 1234567891011121314# 编写函数用于返回需要的内容mkSel &lt;- function(rec)&#123; mkA &lt;- rec[[&#x27;MarkerA&#x27;]] mkB &lt;- rec[[&#x27;MarkerB&#x27;]] if (is.na(mkB)) &#123; row &lt;- list(mkA, rec[[&#x27;ColA1&#x27;]], rec[[&#x27;ColA2&#x27;]], rec[[&#x27;ColA3&#x27;]]) &#125; else &#123; row &lt;- list(mkB, rec[[&#x27;ColB1&#x27;]], rec[[&#x27;ColB2&#x27;]], rec[[&#x27;ColB3&#x27;]]) &#125; names(row) &lt;- c(&#x27;Marker&#x27;,&#x27;Tag1&#x27;, &#x27;Tag2&#x27;,&#x27;Tag3&#x27;) return(row)&#125;sub[,c(&#x27;Marker&#x27;,&#x27;Tag1&#x27;, &#x27;Tag2&#x27;,&#x27;Tag3&#x27;)] &lt;- do.call(rbind.data.frame, apply(sub, 1, mkSel, simplify=T)) 但是测试完后我才发现了最大的问题… apply这个函数… 他根本就不能返回数据框, 只能返回矩阵, 矩阵本来就是行列同类型的… 甚至整个函数家族就没有一个是能完成我的需求的, 所以我无论怎么努力, 只要用apply这个目标就是无法实现的. 于是我最后还是用回了质朴的for循环解决了问题… 生成一个空数据框, 规定每一列的类型, 然后读取sub数据框的每一行来生成新数据框, 最后根据编号将两个数据框合并… 所以总结下来, R里的apply在设计的时候就没想我这么去用吧… 只能用基础函数… 通过比较麻烦(需要多写好几行, 同时代码效率和可复用性上似乎不太好)的方式来实现我用Pandas时的做法… 当然平心而论, 我对R的熟练度已经远不如Pandas了, 很多好用的R包我都没有怎么使用过(如dplyr), 所以也许R也能很好的完成这些工作… 只是… 我搜索不到相关的材料?","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"数据处理","slug":"数据处理","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"},{"name":"数据清洗","slug":"数据清洗","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"name":"Pandas","slug":"Pandas","permalink":"https://silenwang.github.io/tags/Pandas/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"}]},{"title":"clash_nps自建内网穿透用vpn","slug":"clash-nps自建内网穿透用vpn","date":"2023-01-08T22:03:20.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2023/01/08/clash-nps自建内网穿透用vpn/","permalink":"https://silenwang.github.io/2023/01/08/clash-nps%E8%87%AA%E5%BB%BA%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E7%94%A8vpn/","excerpt":"自疫情开始, 我就多少有一点远程办公的需求, 今天终于组合处了一个相对方便, 近似内网vpn使用体验的方案.","text":"自疫情开始, 我就多少有一点远程办公的需求, 今天终于组合处了一个相对方便, 近似内网vpn使用体验的方案. 过去使用过的方案我最开始的需求很简单, 只是通过ssh登陆目标服务器就好, 因此最开始的直接买了个VPS, 用这个VPS做跳板机, 在目标机器上用ssh或者autossh开启反向代理, 使得我可以经由VPS下的端口访问目标机器的22端口, 从而远程登陆目标机器. 这个方案最大的好处就是简单, ssh是所有linux系统必然会带的东西, 同时ssh能连通后, 可以通过ssh进行反代理, 因此理论上也能实现访问任意的内网ip和端口. 不过其弊端是, 当需要访问的内容越来越多, 每访问一个ip&#x2F;端口就要通过跳板登陆目标机器, 在该机器上再运行一条反代理命令, 就与简单易用没什么关系了… 而且万一断电要重启… 这些东西都要再来一次… 极其的麻烦 之后IT的同时开始启用NPS, 这是个用Go编写的内网穿透工具, 安装使用极其简单, 在设置好服务端和客户端后, 如果有新的访问需求, 在NPS自带的管理页面作相应设置新建一个私密链接就好, 如果遇到重启, 只要重启NPS的客户端就好, 另外如果有管理员权限, NPS客户端还能自己设置自启动服务. 这样就节省了很大一部分工作, 不过当要访问的东西实在是太多, 每一个端口还是要在本地运行一个NPC进程, 且因为是端口映射到本地, 内网地址会变成127.0.0.1, 有些服务访问起来会出问题(Gitea的部分内容就是) 前段时间在查看NPS管理界面时, 界面介绍Socks代理模式可用于访问各种内网资源, 实现VPN的功能, 于是我就又尝试了一下, 最后靠Socks模式和Clash客户端实现了内网资源的访问, 同时又不影响访问外网的流量 当前Linux下的方案需要准备的软&#x2F;硬件 一台有公网IP的VPS, 后面简称VPS, 同时需能够配置这台VPS的端口开放权限 一台位于目标内网中的, 能够访问到VPS的主机(系统没太大限制, 因为NPS的客户端是跨平台的), 改机器后面简称跳板, 访问内网的请求实际上是到达跳板后发出的 NPS服务端&#x2F;客户端软件, 可从github获取 可以进行截取全局流量的Clash客户端软件, Linux下可以使用Clash For Windows的Linux版本或者Clash Verge, 不过Clash Verge之前开Tun模式似乎存在权限问题, 不知道目前修复了没有 实施方法 在VPS搭建好NPS, 在跳板上开启VPS的客户端, 然后在NPS服务界面进行Socks代理设置, 具体操作方式可参见这个博客, 注意记录下socks服务的账户密码 安装好Clash For Windows, 然后按照官方文档开启Tun模式(全局模式, 将创建虚拟网卡截取本机的所有流量) 由于我已经通过转换服务产生了Clash配置文件, 因此需要打开已有的配置文件, 手动添加VPS上的Socks5服务, 同时自行填写访问内网资源的Clash规则, 示例配置段如下(规则中的rules要写在最前, 因为前面匹配到了后面就不继续匹配了): 12345678910111213141516171819proxies: - name: NPS_SOCKS server: 11.11.11.111 port: 2233 type: socks5 username: socks5 password: socks123456proxy-groups: - name: SOCKS5 type: select proxies: - NPS_SOCKS - DIRECTrules: - IP-CIDR,192.168.0.111/32,NPS_SOCKS tips: 另外, ip规则如果匹配单个地址, 写法为XXX.XXX.XXX.XXX/32, 如果匹配整个网段, 则为XXX.XXX.XXX.0/16, 当然如果写了个具体地址配上/16, 整个网段都会被代理 重启Clash服务即可访问 当前Chromeos &#x2F; ChromiumOS &#x2F; 安卓下的方案这些系统下只有使用的Clash客户端发生变化, 用商店里的Clash for Android就好, chromeos需要先开启安卓子系统然后从商店安装(安装前设置系统代理, 之后关闭系统代理通过Clash客户端走流量), 由于安卓的VPN本来就是截取所有流量的, 所以不需要作模式的设置, 直接配置好规则就行, 不过客户端默认设置下内网ip段的请求是不走代理的, 找到设置 &gt; 网络 &gt; 绕过私有网络选项, 把选项关闭即可 后续由于使用了Clash进行规则分流, 所以这套方案其实可以设置同时访问多个内网的资源, 当然前提是ip不能冲突, 之后把家里的ip段直接改掉好了…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"内网穿透","slug":"内网穿透","permalink":"https://silenwang.github.io/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"VPN","slug":"VPN","permalink":"https://silenwang.github.io/tags/VPN/"},{"name":"socks5代理","slug":"socks5代理","permalink":"https://silenwang.github.io/tags/socks5%E4%BB%A3%E7%90%86/"},{"name":"远程办公","slug":"远程办公","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E5%8A%9E%E5%85%AC/"},{"name":"流量代理","slug":"流量代理","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E9%87%8F%E4%BB%A3%E7%90%86/"},{"name":"nps","slug":"nps","permalink":"https://silenwang.github.io/tags/nps/"},{"name":"clash","slug":"clash","permalink":"https://silenwang.github.io/tags/clash/"},{"name":"socks5","slug":"socks5","permalink":"https://silenwang.github.io/tags/socks5/"}]},{"title":"一年更比一年糟","slug":"一年比一年糟糕","date":"2023-01-08T21:27:46.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2023/01/08/一年比一年糟糕/","permalink":"https://silenwang.github.io/2023/01/08/%E4%B8%80%E5%B9%B4%E6%AF%94%E4%B8%80%E5%B9%B4%E7%B3%9F%E7%B3%95/","excerpt":"回忆起来2022真是基本没好事, 工作更累了, 收获更少了, 身体更差了, 精神更抑郁了, 自由时间马上要更少了, 连想吃个烧烤居然也会好几次找不到店… 这还能不能好了… 希望新的一年不要更糟糕了吧…","text":"回忆起来2022真是基本没好事, 工作更累了, 收获更少了, 身体更差了, 精神更抑郁了, 自由时间马上要更少了, 连想吃个烧烤居然也会好几次找不到店… 这还能不能好了… 希望新的一年不要更糟糕了吧…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"},{"name":"年度总结","slug":"年度总结","permalink":"https://silenwang.github.io/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"name":"负面情绪","slug":"负面情绪","permalink":"https://silenwang.github.io/tags/%E8%B4%9F%E9%9D%A2%E6%83%85%E7%BB%AA/"},{"name":"2023","slug":"2023","permalink":"https://silenwang.github.io/tags/2023/"},{"name":"life-reflection","slug":"life-reflection","permalink":"https://silenwang.github.io/tags/life-reflection/"},{"name":"year-summary","slug":"year-summary","permalink":"https://silenwang.github.io/tags/year-summary/"}]},{"title":"chromebook入坑记?","slug":"chromebook入坑","date":"2022-10-16T21:44:36.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2022/10/16/chromebook入坑/","permalink":"https://silenwang.github.io/2022/10/16/chromebook%E5%85%A5%E5%9D%91/","excerpt":"我一直有关注国产Linux系统的状态(虽然除了上古版本的Linux Deepin没有一个长时间使用过), 所以在Fyde OS还叫Flint OS的时候我就关注过这个基于Chromium OS的特别发行版, 也因为这个了解了在国外份额莫名其妙高(在过去的我看来)的Chrome OS","text":"我一直有关注国产Linux系统的状态(虽然除了上古版本的Linux Deepin没有一个长时间使用过), 所以在Fyde OS还叫Flint OS的时候我就关注过这个基于Chromium OS的特别发行版, 也因为这个了解了在国外份额莫名其妙高(在过去的我看来)的Chrome OS Chrome OS由Google推出, 其特点在于轻量, 简单以及大量使用云服务. 通俗点说这是个专为性能低下的上网本设备构建的发行版, 其理念还挺时髦的, 它认为绝大部分用户并不需要很强的性能以运行大量专业的本地软件, 他们只需要一台可以通过网络访问到所需服务的入口设备而已. 因此, Chrome OS最开始被设计为完全不在本地运行服务, 所有功能都需要通过网站服务的, 浏览器 Pro Max Plus系统(然后喜提大量吐槽). 从后面的发展来看, 这个理念可能并不完全错, 但是… 从后面又是加Linux子系统又是加安卓子系统的操作来看… 完全的云端化, 到目前来说都还太早了. 不过这不代表对我的工作来说太早… 我的工作中需要处理大量的基因测序数据, 这些数据过于巨大, 以至于完全使用移动设备来处理这些东西还为时过早, 因此我的工作本来就有将实际计算工作和其他工作分离的需求. 另一方面我现在用的很多重要工具, 像Jupyter, Rstudio, VsCode本来也都有了成熟的服务器版本, 搭建好相应服务后, 所以我就产生了尝试一下使用搭载Chrome OS或者类Chrome OS(上文说的Fyde)的设备是否能较好完成日常工作需求的念头. 于是, 我在之后的日子里, 先尝试了FydeOS(x86), 后在海鲜市场入了Lenovo Duet, 开始入了Chromebook的坑… 之前尝试搭建自部署的云端服务, 也是为了尝试只使用Chromebook办公作准备, 不过就像我用了Linux发行版10年里踩了无数的坑, 甚至经历过要命的损失后, 现在才能用的比较顺畅一样… 用这么一个过于精简的系统来办公, 现阶段来说问题也还是挺多的… 后面我再一一整理出来…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"FydeOS","slug":"FydeOS","permalink":"https://silenwang.github.io/tags/FydeOS/"},{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"ChromeOS","slug":"ChromeOS","permalink":"https://silenwang.github.io/tags/ChromeOS/"},{"name":"云办公","slug":"云办公","permalink":"https://silenwang.github.io/tags/%E4%BA%91%E5%8A%9E%E5%85%AC/"},{"name":"chromebook","slug":"chromebook","permalink":"https://silenwang.github.io/tags/chromebook/"},{"name":"远程开发","slug":"远程开发","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/"}]},{"title":"搭建云端工作环境","slug":"搭建远程开发环境","date":"2022-09-24T21:55:29.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2022/09/24/搭建远程开发环境/","permalink":"https://silenwang.github.io/2022/09/24/%E6%90%AD%E5%BB%BA%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","excerpt":"很早之前就关注过国内做的一个很特殊的操作系统, 叫FydeOS, 他是基于ChromiumOS构建的中国版的ChromeOS, 这种操作系统主打的理念是, 很多人在工作中其实并不需要性能多好的终端计算机设备, 而是需要一个能访问工作必备的服务的入口型设备就好, 具体到目前的情况, 就是终端设备只要能鱼形浏览器, 然后通过浏览器来访问云端的服务完成操作就好.","text":"很早之前就关注过国内做的一个很特殊的操作系统, 叫FydeOS, 他是基于ChromiumOS构建的中国版的ChromeOS, 这种操作系统主打的理念是, 很多人在工作中其实并不需要性能多好的终端计算机设备, 而是需要一个能访问工作必备的服务的入口型设备就好, 具体到目前的情况, 就是终端设备只要能鱼形浏览器, 然后通过浏览器来访问云端的服务完成操作就好. 这个概念确实非常有意思, 让我想到了git和svn这两种版本管理软件的不同理念, git的理念是分布式, 每个开发者都会保留一份完整的项目代码, 并且保有不同人对这份代码做的不同分支的修改. 而svn则是集中式, 用户只需要通过服务访问他需要访问的那一部分即可. 我个人觉得分布式和集中式并无优劣之分, 而是有各自事宜的应用场景. 而具体到我的工作上, 目前的工作方式应该属于是没有任何备份的分布式, 工作环境和工作内容都位于我自己的或者公司里的个人电脑上, 如果哪天不好彩我的设备报废了…那…要恢复工作估计会相当花时间, 同时如果有一天我要紧急处理东西但是这台设备并不在身边或者并没有电…除了干着急也没什么辄 所以我也很像试试, 我现在的工作, 有没有可能完全云端化呢? 即部署一系列的自部署服务, 然后完全通过浏览器或其他支持连接远程项目的开发工具来完成工作, 编写调试都在服务端进行实际执行. 我的工作需要用到的所有软件生信的工作, 简练一些, 那就是: 写脚本, 画统计图, 图形精修, 撰写各种乱七八糟的文档, 实际会用到的软件包括: 代码编写&#x2F;测试: VScode, Jupyter 环境部署: conda, docker 文件整理: 系统自带的文件管理器 文档处理: WPS系列 文献查阅: Zotero 图片处理: GIMP 搭建一个云端开发环境所需要的为了实现一个完全云端的工作环境, 最理想的情况下上述所有软件都得找到可自部署的云端软件项目, 能解决的包括: 代码编写&#x2F;测试: code-server, Jupyter本来就是服务, 可以远程访问 环境部署: 远程SSH登陆再操作就是, 或者找一个web的终端模拟器 文件整理: Nextcloud, firerun 文档处理: only office server 文献查阅: paperpile(要钱) 那么数下来, 其实也就是修图这个…还真没找到能自部署的东西, 后续可以再持续关注 进行尝试ML-Hub &#x2F; ML-Workspace配置ML-Hub &#x2F; ML-Workspace是基于容器的多重网络服务集成项目, 其中包含了装好一大堆插件的JupyterHub, code-server和一个简单的文件管理器, 如果不是Docker运行有用户权限的问题需要处理, 瞬间就能完美解决六七成的问题了… 两者的使用都比较简单, 装了Docker或者Podman之后直接启动赴服务就好 内网穿透(nps)nps是一个用go语言实现的…复合网络工具? 其中一项就是实现内网穿透, nps包括服务端和客户端. 需要注意的是nps的服务端是作为中转站来使用的, 其作用是作为皮条客(不是)将各个客户端互联互通起来, 因此实际设置的时候, 先要找一个有公网ip的主机, 上面部署上nps, 然后被访问的机器需要通过客户端npc连接到nps服务端, 然后其他的客户端再公国nps这个中转站连接到要被访问的客户端. 总之…跟vnc, rdp以及SSH这种, 开服务的机器就是被访问的机器方式是挺不一样的. https代理设置如果想把搭建的服务挂在某个域名下, 通过域名直接访问, 那处于安全考虑, https总还是要用的. 域名申请自然是找个最便宜的先买者, 然后就是使用Caddy进行反代理了, 在折腾了许久后, 我最后用的配置写法是这样的. 1234567891011121314&#123; http_port 8888 https_port 8384&#125;:8384 &#123; reverse_proxy localhost:7788 tls /etc/caddy/domain.top.cer /etc/caddy/domain.top.key&#125;your.domain.top:8384 &#123; reverse_proxy localhost:7788 tls /etc/caddy/domain.top.cer /etc/caddy/domain.top.key&#125; 防火墙设置(iptables)同前…为了其安全…防火墙还是应该开起来意思一下…所以我也找了点教程来学怎么用iptables(CENTOS 8开启iptables), 不过这玩意也是老古董了… 好些新系统直接用别的防火墙管理程序了都… Docker访问宿主机端口方法 1234iptables -I INPUT -p tcp --dport 80 -j ACCEPTiptables -I INPUT -p tcp --dport 443 -j ACCEPT iptables -I INPUT -p tcp --dport 7788 -j REJECTiptables -I INPUT -p tcp -s 127.0.0.1 --dport 7788 -j ACCEPT","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"nps","slug":"nps","permalink":"https://silenwang.github.io/tags/nps/"},{"name":"jupyter","slug":"jupyter","permalink":"https://silenwang.github.io/tags/jupyter/"},{"name":"云端开发","slug":"云端开发","permalink":"https://silenwang.github.io/tags/%E4%BA%91%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"远程工作","slug":"远程工作","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E5%B7%A5%E4%BD%9C/"},{"name":"自部署服务","slug":"自部署服务","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1/"},{"name":"code-server","slug":"code-server","permalink":"https://silenwang.github.io/tags/code-server/"},{"name":"https","slug":"https","permalink":"https://silenwang.github.io/tags/https/"},{"name":"iptables","slug":"iptables","permalink":"https://silenwang.github.io/tags/iptables/"}]},{"title":"倒腾图数据库时想到的","slug":"倒腾图数据库时想到的","date":"2022-08-25T01:44:46.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2022/08/25/倒腾图数据库时想到的/","permalink":"https://silenwang.github.io/2022/08/25/%E5%80%92%E8%85%BE%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%B6%E6%83%B3%E5%88%B0%E7%9A%84/","excerpt":"最近整理我们使用图数据库的资料时想到的一个问题, 其实如果单纯从性能上看, 图数据库未必就能达到更好的性能, 对我们来说其意义其实在于简化了数据库设计能力的要求.","text":"最近整理我们使用图数据库的资料时想到的一个问题, 其实如果单纯从性能上看, 图数据库未必就能达到更好的性能, 对我们来说其意义其实在于简化了数据库设计能力的要求. 我们要存的数据存在比较多的相互关联, 对我们这种不是专业数据库相关行业的人来说, 理清需要记录的信息之间的实际逻辑关系虽然也会费功夫, 但是这是必须切能做到的, 但是设计一套适合的库和表格来存储这些东西… 那可真是要了老命了… 这时候图数据库就有绝对的优势了, 因为… 只要逻辑关系理清楚了, 那直接按照这个逻辑关系去存储的就好了… 所以… 用这东西最大的意义… 就是省了数据库结构设计, 同时万一觉得自己的逻辑还不对, 改节点也更容易… 以上","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"图数据库","slug":"图数据库","permalink":"https://silenwang.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据库设计","slug":"数据库设计","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/"},{"name":"关系型数据库","slug":"关系型数据库","permalink":"https://silenwang.github.io/tags/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Neo4j","slug":"Neo4j","permalink":"https://silenwang.github.io/tags/Neo4j/"},{"name":"Graph Database","slug":"Graph-Database","permalink":"https://silenwang.github.io/tags/Graph-Database/"}]},{"title":"Marp的使用","slug":"Marp的使用","date":"2022-06-22T15:40:28.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2022/06/22/Marp的使用/","permalink":"https://silenwang.github.io/2022/06/22/Marp%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"日常工作中总有需要做一个演示文档展示项目进度或项目结果的时候, 但做PPT其实是个比较花时间的工作(强迫症总是控制不住自己调字体和位置的手), 然后我每次展示的东西都只有一些简单的文字和图表, 从来没用过PPT那些高端大气上档次的元素和功能, 所以找了Marp来偷懒…","text":"日常工作中总有需要做一个演示文档展示项目进度或项目结果的时候, 但做PPT其实是个比较花时间的工作(强迫症总是控制不住自己调字体和位置的手), 然后我每次展示的东西都只有一些简单的文字和图表, 从来没用过PPT那些高端大气上档次的元素和功能, 所以找了Marp来偷懒… Marp是一个用markdown语法生成演示文档的项目, 用最基本的markdown语法即可快速生成一份还能看(其实有点丑)的掩饰文档出来, 支持生成pptx, pdf以及网页, 用了有一个月了体验还是很好的(看的人可能会觉得眼瞎?) Marp_VScode 基本使用Marp项目下有多个可用程序, 但是用起来最方便的当然还是VScode下的插件了, 不需要特别设置, 安装即用. 安装完成后打开markdown文件时编辑器右上角就会多出一个按钮, 可以切换当前文件为Marp模式 之后就可以开心的写的了… 因为都是基本markdown语法, 除了用---将每页的内容分隔开, 也没啥要注意的. 有啥看官方文档就行了 用例备查插入图片左&#x2F;右置我的展示中经常需要放一张图然后对图片做一些说明, 这种事后图片在一侧, 文字在一侧的方式看上去比较合理, 但是markdown的基本语法显然没这么个东西… 可以通过Marp的背景图片语法来实现. 这里的contain是让图形自动调整大小, 否则一般都会超出幻灯范围, 例子用了右置, 用left也可以丢左边, 然后上下的话似乎contain就没效果了… 12345678---marp: true---## 右侧是一张统计图- 图是乱找的![bg contain right](https://seaborn.pydata.org/_images/grouped_barplot.png) 脚标和页码在开头增加两个设置项就能打开脚标和页码, 不过位置好像用markdown的语法没法调 123456---marp: truefooter: 20220610---## 展示页码用","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"Marp","slug":"Marp","permalink":"https://silenwang.github.io/tags/Marp/"},{"name":"VSCode","slug":"VSCode","permalink":"https://silenwang.github.io/tags/VSCode/"},{"name":"Markdown","slug":"Markdown","permalink":"https://silenwang.github.io/tags/Markdown/"},{"name":"演示文档","slug":"演示文档","permalink":"https://silenwang.github.io/tags/%E6%BC%94%E7%A4%BA%E6%96%87%E6%A1%A3/"}]},{"title":"关于我这两年工作看论文比读研还多这件事","slug":"关于我这两年工作看论文比读研还多这件事","date":"2022-04-05T16:10:03.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2022/04/05/关于我这两年工作看论文比读研还多这件事/","permalink":"https://silenwang.github.io/2022/04/05/%E5%85%B3%E4%BA%8E%E6%88%91%E8%BF%99%E4%B8%A4%E5%B9%B4%E5%B7%A5%E4%BD%9C%E7%9C%8B%E8%AE%BA%E6%96%87%E6%AF%94%E8%AF%BB%E7%A0%94%E8%BF%98%E5%A4%9A%E8%BF%99%E4%BB%B6%E4%BA%8B/","excerpt":"这是一个看论文看到想吐的夜晚(2022&#x2F;03&#x2F;29), 我再一次浏览着我Zotero中凌乱的目录树… 猛然想到, 我这几年到底看了多少文献了? 邮件导出…我自己都惊了… 561个文献条目, 419篇pdf下载论文… 真的… 如果我当年直博, 估计都不会看这么多论文.","text":"这是一个看论文看到想吐的夜晚(2022&#x2F;03&#x2F;29), 我再一次浏览着我Zotero中凌乱的目录树… 猛然想到, 我这几年到底看了多少文献了? 邮件导出…我自己都惊了… 561个文献条目, 419篇pdf下载论文… 真的… 如果我当年直博, 估计都不会看这么多论文. 于是我又只要不是工作都有点兴趣的… 简单捣鼓了一下我看的这些论文的信息. 捣鼓步骤 使用Zotero导出文献目录为ris文件 使用rispy解析ris文件为数据框, 保留文献类型, 作者, 入库年份, 摘要, 刊发杂志的信息. 保留文献类型为杂志论文的条目 使用wordcloud对作者, 刊发杂志构建词云 将文献摘要做字符串合并后, 使用wordcloud自行分词并构建词云 对文献的入库年份做柱状图 大概结果见下: 作者词云 对图形上看得到比较显眼的几位作者进行下简单的回顾: Griffith Malachi, Griffith Obi L.: 其中两位比较显眼的Griffith是双胞胎, 来自Griffith Lab, 该实验室是专门主攻生物信息技术在癌症各方面应用的. 他们开发了一系列与相关的软件&#x2F;数据库. Sette Alessandro: 来自Sette Lab, 是免疫学方面的专家. 其研究主攻的是病原体(尤其是病毒)的免疫研究. 自新冠爆发后, 参与发表的研究似乎基本都是新冠了… Morten Nielsen: 来自丹麦技术大学(DTU)的研究者, 主攻方向应该是免疫识别相关的算法开发, 在图里显眼应该是我收录了多篇跟亲和力预测有关的研究吧, 学校的展示主页见此 Nir Hacohen: Broad Institute的研究者, 看介绍是主攻免疫方向的, 暂对该作者无特别印象 Bjoern Peters: 来自Peters Lab, 主攻方向是免疫领域的生信利用. 与前面的Sette Alessandro同属La Jolla Institute For Immunology Eilon Barnea: 来自Meytal Landau’s Lab, 主攻似乎是免疫肽的计算和实验识别? Arie Admon: 来自Arie Admon Lab, 主要研究领域是蛋白组学, 应该是我收录了一些质谱鉴定相关的文章吧… Michal Bassani-Sternberg: 肿瘤生物和肿瘤免疫学的专家, 看介绍好像是以质谱为主要技术手段的? Anthony Purcell: 看介绍, 研究方向是生信在肿瘤免疫, 自体免疫疾病上的应用 Anne Searls De Groot: EpiVax的联合创始人. 名字会这么大… 应该是当时查阅的他们公司的文献里都有他吧… Ugur Sahin: BioNTech的CEO… emmm, 也是查阅公司文献时带进来的应该 Catherine J Wu: 主攻新生抗原领域的研究者, 最近被塞过好几篇他主导的研究结果文献… 另外这位也有协助Broad Institute进行抗肿瘤免疫相关的研究 刊发杂志词云 杂志上…果然还是以生信的为主, 然后因为应用方向的问题, 生物技术和免疫技术也有一大堆的样子… 摘要词云 摘要词里大大的肽, 新生抗原, T细胞… 已经很明确的说明近几年的工作方向了… 入库年份统计 至于入库年份的统计…很明显能看出我为很么最近觉得看文章看得想吐了… 以上~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"论文","slug":"论文","permalink":"https://silenwang.github.io/tags/%E8%AE%BA%E6%96%87/"},{"name":"免疫学","slug":"免疫学","permalink":"https://silenwang.github.io/tags/%E5%85%8D%E7%96%AB%E5%AD%A6/"},{"name":"肿瘤研究","slug":"肿瘤研究","permalink":"https://silenwang.github.io/tags/%E8%82%BF%E7%98%A4%E7%A0%94%E7%A9%B6/"},{"name":"文献管理","slug":"文献管理","permalink":"https://silenwang.github.io/tags/%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/"},{"name":"zotero","slug":"zotero","permalink":"https://silenwang.github.io/tags/zotero/"},{"name":"rispy","slug":"rispy","permalink":"https://silenwang.github.io/tags/rispy/"},{"name":"wordcloud","slug":"wordcloud","permalink":"https://silenwang.github.io/tags/wordcloud/"}]},{"title":"R绘图问题记录","slug":"使用ggpubr做图的一些问题","date":"2022-03-13T03:12:07.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2022/03/13/使用ggpubr做图的一些问题/","permalink":"https://silenwang.github.io/2022/03/13/%E4%BD%BF%E7%94%A8ggpubr%E5%81%9A%E5%9B%BE%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/","excerpt":"前段时间帮同事做图, 又解锁了一些新的问题和解决方式, 涉及ggpubr, 生存分析包, 做个记录.","text":"前段时间帮同事做图, 又解锁了一些新的问题和解决方式, 涉及ggpubr, 生存分析包, 做个记录. survminer绘制出图形的保存问题survminer中包含一个很方便的函数ggsurvplot, 使用该函数可很方便的绘制生存曲线并加上分组的显著性检验, 还能在图形下方加上频数表. 但是这个函数跟一般的ggplot系函数的返回并不同, 他返回的并不是一个ggplot()对象, 而是ggsurvplot对象, 这个对象中包含survObj$plot为生存图形本地, survObj$table为频数表图形. 所以如果需要自己使用ggplot的一些语法对图形进行调整修饰的话, 应该对这两个对象内包含的对象进行操作. ggpubr至今存在分面图显著性检验标注bug截止到去年12月, ggpubr的箱线图(其他未测试, 可能也有)的在分面后附加显著性检验时, 依然存在一定bug, 包括分面后数据不正确, 显著性检验标注位置不正确. 需要手动绘制单个图形然后把他们组合起来 图内表格标注挖坑待补充 多种显著性标注实现方式由于某次甲方的图形提出了比较麻烦的要求, 即进行显著性检验的时候, 以某组作为参考进行, 然后这个某组, 有两个而不是一个, 因此ggpubr本身自带的函数无法满足需求, 我花了好大功夫查找如何手动进行绘制, 不同要求对应的不同实现方法记录在此: 挖坑待补充","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"数据可视化","slug":"数据可视化","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"ggplot2","slug":"ggplot2","permalink":"https://silenwang.github.io/tags/ggplot2/"},{"name":"ggpubr","slug":"ggpubr","permalink":"https://silenwang.github.io/tags/ggpubr/"},{"name":"survminer","slug":"survminer","permalink":"https://silenwang.github.io/tags/survminer/"},{"name":"显著性检验","slug":"显著性检验","permalink":"https://silenwang.github.io/tags/%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E9%AA%8C/"},{"name":"生存分析","slug":"生存分析","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90/"}]},{"title":"Dash实现从图形上取数据点进行计算","slug":"Dash交互处理数据","date":"2022-03-13T03:09:08.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2022/03/13/Dash交互处理数据/","permalink":"https://silenwang.github.io/2022/03/13/Dash%E4%BA%A4%E4%BA%92%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE/","excerpt":"之前用dash实现了一个比较有趣的交互数据处理案例, 这里记录一下","text":"之前用dash实现了一个比较有趣的交互数据处理案例, 这里记录一下 大概的问题是有很多条的数据, 需要基于数据进行指标计算, 但是甲方并不想使用所有数据, 而是需要将数据条目画成一张点图上, 然后从图形上圈出一部分数据点来, 用这些数据点对应的数据条目完成指标计算, 即交互式的选择部分数据来进行指标计算. 我看到这个要求的第一反应是去翻Dash有没有相关功能, 没想到还真有, INVALID POST SLUG PROVIDED 最终写起来也比较简单, 给函数加上对选择事件的反馈就行了: 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 绘制图形mport plotly.express as pxdata_b1_p1 = pd.read_csv(&#x27;1st.part1.fmt.csv&#x27;)fig_b1_p1 = px.scatter(data_b1_p1, x=&#x27;FFPE_X&#x27;, y=&#x27;FFPE_Y&#x27;, color = &#x27;Pos&#x27;, opacity=0.5)fig_b1_p1 = fig_b1_p1.update_layout( width=600, height=600).update_traces( mode=&#x27;markers&#x27;, marker_size=2)# 设定dash app组建的框架结构, 我这里只放一个div用来放前面的图app.layout = html.Div([ html.Div([ dcc.Markdown(&quot;demo titile&quot;), dcc.Graph( id=&#x27;fig_b1_p1&#x27;, figure=fig_b1_p1 ), html.Pre(id=&#x27;sel_b1_p1&#x27;) ],])# 定义数据处理函数def show_mean(selectedData, base): if selectedData: selData = pd.DataFrame(selectedData[&#x27;points&#x27;]).rename(columns=&#123;&#x27;x&#x27;: &#x27;FFPE_X&#x27;,&#x27;y&#x27;: &#x27;FFPE_Y&#x27;&#125;) selData = selData.merge(base, how=&#x27;left&#x27;, on=[&#x27;FFPE_X&#x27;, &#x27;FFPE_Y&#x27;]).drop( columns=[&#x27;curveNumber&#x27;,&#x27;pointNumber&#x27;,&#x27;pointIndex&#x27;,&#x27;FFPE_X&#x27;,&#x27;FFPE_Y&#x27;, &#x27;Pos&#x27;, &#x27;OID&#x27;, &#x27;Marker&#x27;] ) mean = nanmean(selData[&#x27;col1&#x27;]) return f&quot;&#123;mean&#125;&quot; else: return &#x27;等待选择&#x27;# 设定响应函数@app.callback( Output(&#x27;sel_b1_p1&#x27;, &#x27;children&#x27;), [Input(&#x27;fig_b1_p1&#x27;, &#x27;selectedData&#x27;)])def parse1(selectedData): return show_mean(selectedData, data_b1_p1) 具体来说就是, 用plotly绘制的交互图形, 本来就有region select和lasso select两个功能, 这两个功能选取数据点后, 图形数据会直接存到selectedData这个属性的值中去, 用内置的装饰器可让函数得到这部分数据. 不过需要注意的是, 返回得到的只有用来绘制图形的数据, 比如我这里是点图, 所以通过selectedData能拿到的就是x, y坐标, 且数据以列表套字典的形式存储, 我需要将其数据框化后, 将原始数据根据坐标再次合并进来(向左合并), 这样就知道选择的点对应哪些数据条目, 之后计算出指标返回就好了. 原数据不好写示例, 之后找个别的数据写了例子后再更新本blog 以上~","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"数据可视化","slug":"数据可视化","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"交互式分析","slug":"交互式分析","permalink":"https://silenwang.github.io/tags/%E4%BA%A4%E4%BA%92%E5%BC%8F%E5%88%86%E6%9E%90/"},{"name":"Dash","slug":"Dash","permalink":"https://silenwang.github.io/tags/Dash/"},{"name":"Plotly","slug":"Plotly","permalink":"https://silenwang.github.io/tags/Plotly/"},{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"}]},{"title":"Scrapy基本使用","slug":"Scrapy使用","date":"2022-03-13T03:01:14.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2022/03/13/Scrapy使用/","permalink":"https://silenwang.github.io/2022/03/13/Scrapy%E4%BD%BF%E7%94%A8/","excerpt":"之前曾经尝试过Scrapy爬用药网站的信息, 但是没有做记录, 这次又帮同学爬了点东西所以趁机记录一下.","text":"之前曾经尝试过Scrapy爬用药网站的信息, 但是没有做记录, 这次又帮同学爬了点东西所以趁机记录一下. 简介Scrapy是Python下的一个专门用来爬网站的爬虫框架. 相比自己使用request的等比较基础的报来发送请求与解析信息, Scrapy自带了请求处理, 返回解析, 异常处理, 任务队列管理等等一系列功能, 使我们能更好更专业的进行数据爬取工作. 当然代价就是… 上手门槛变高了一丢丢, 因为得先理解这个框架里的一些基本概念和工作原理. 我当初直接看菜鸟教程给的图… 反正是一脸蒙逼的: 案例操作本着简化的原则… 我只记录实际操作中需要了解的部分. 1. 新建项目首先, Scrapy作为框架, 不需要使用者从头开始一行一行写代码, 而是在既有模板下编写操作相关的方法就行. 开启一个新项目时, 使用scrapy startproject demo创建新的项目. 创建完成后, 项目目录下有一堆东西, 不用所有文件都了解, 知道下面几个就行了: demo/spiders: 存放爬虫文件的目录, 刚刚建立项目而没有创建爬虫的话, 这个目录下除了__init__.py是没有东西的, 爬虫的具体内容后面介绍 demo/settings.py: 爬虫的配置文件, 请求头, 反爬协议, 任务间隔, COOKIE设置等等等的设置全在里头, 大部分设置看文件内的注释条目就能看懂, 对应设置就行 demo/pipelines.py: 对应上面示例图里的Item Pipeline, 这里是定义对Item处理方案的地方, 当需要使用item这一内置的对象来收集目标信息时需要设置 demo/items.py: 定义Item的文件, 同上, 需要使用item的时候需要在文件内定义item(主要是定义一个item里头要存啥) 2. 新建爬虫爬虫文件需要进一步运行scrapy genspider来生成, 比如项目下scrapy genspider dSpider www.sample.com就会在demo/spiders/文件夹下生成一个名字为dSpider.py的爬虫文件, 里面的内容大概是这样: 12345678910import scrapyclass DspiderSpider(scrapy.Spider): name = &#x27;dSpider&#x27; allowed_domains = [&#x27;www.sample.com&#x27;] start_urls = [&#x27;http://www.sample.com/&#x27;] def parse(self, response): pass 使用改爬虫本质上就是对生成的这个爬虫内的方法进行改写, 比如我这次写的: 12345678910111213141516171819202122import scrapyimport jsonfrom JsDemo.items import JsdemoItemfrom math import ceilclass DemoSpider(scrapy.Spider): name = &#x27;demo&#x27; allowed_domains = [&#x27;www.cssn.net.cn&#x27;] start_urls = [f&#x27;http://www.cssn.net.cn:8000/standards/?a104=IX-ISO&amp;orderby=&amp;post_publicyear=&#123;year&#125;&#x27; for year in range(1960, 2021)] def parse(self, response): pMax = ceil(json.loads(response.text)[&#x27;count&#x27;] / 20) for pNum in range(1, pMax+1): yield scrapy.Request(f&#x27;&#123;response.request.url&#125;&amp;page=&#123;pNum&#125;&#x27;, callback=self.parse_next) def parse_next(self, response): obj = json.loads(response.text) item = JsdemoItem() item[&#x27;raw&#x27;] = obj[&#x27;results&#x27;] yield item 方法parse的写的是爬虫在访问url获取页面信息后如何进行处理. 这里就有多种处理方式了. 如果想按照Scrapy推荐的方式来, 可以像上面一样, 将需要的信息从响应内容中提取出来, 然后存到item中并返回, 这样获取到的信息就会以打包好的item的方式进入千米您提到的Item Pipeline中, 在那里就可以编写获取到Item后最终如何处理和保存数据. 如果嫌麻烦, 想自己处理, 也可以在parse方法内就直接处理掉, 比如直接建立数据框, 然后直接将这些内容写到文件. 这样就不用走后面的东西了. 具体采取哪种方式视任务需要而定就好. 3. 处理Item如果采取使用item的方式, 那就还要去demo/pipelines.py中编写处理数据的部分: 123456789101112131415161718192021222324252627282930313233343536373839404142434445# Define your item pipelines here## Don&#x27;t forget to add your pipeline to the ITEM_PIPELINES setting# See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html# useful for handling different item types with a single interfacefrom itemadapter import ItemAdapterfrom pandas import DataFrameimport jsonclass JsdemoPipeline: def __init__(self): self.full = [] self.col_map = &#123; &#x27;yf001&#x27;: &#x27;识别号&#x27;, &#x27;a000&#x27;: &#x27;状态&#x27;, &#x27;a104&#x27;: &#x27;发布单位&#x27;, &#x27;a104name&#x27;: &#x27;发布单位名称&#x27;, &#x27;a100&#x27;: &#x27;标准号&#x27;, &#x27;yf100&#x27;: &#x27;其他标准号&#x27;, &#x27;a298&#x27;: &#x27;中文题名(仅供参考)&#x27;, &#x27;a301&#x27;: &#x27;原文题名&#x27;, &#x27;a826&#x27;: &#x27;ICS分类号&#x27;, &#x27;a101&#x27;: &#x27;发布日期&#x27; &#125; def open_spider(self, spider): self.file = open(&#x27;items.jl&#x27;, &#x27;w&#x27;) def process_item(self, item, spider): self.full.extend(item[&#x27;raw&#x27;]) line = json.dumps(item[&#x27;raw&#x27;]) + &quot;\\n&quot; self.file.write(line) return item def close_spider(self, spider): print(&quot;#########run##########&quot;) df = DataFrame(self.full)[self.col_map.keys()].rename(columns=self.col_map) df.to_csv(&#x27;full.data.csv&#x27;, index=0) self.file.close() open_spider 方法是爬虫启动时会执行的代码, 一般是打开需要写的文件或者与需要写入的数据库进行连接和初始化 process_item 部分则是爬虫每返回一个item时, 对这个item进行何种处理, 我这里做的是把原始得到的json字串存到文件中, 另外是把key做替换后, 存到一个字典中 close_spider 方法是当爬虫获取完所有信息后, 执行的内容, 比如我这里有将字典内的信息转换为数据框, 然后数据框内容写入文件, 另外就是把之前打开的文件句柄给关掉 4. 其他设置如果有更改请求头, 挂代理, 设置访问间隔防止被封IP之类的需要, 那就回到demo/setting.py文件里去更改就好了. 5. 运行爬虫这个最简单了, 项目目录里scrapy crawl demo, 然后就可以观察运行状况了, 工作日志会直接打印在屏幕上, 可以根据日志进行调试 小结以上就是基本的使用了, 对Scrapy的工作方式进行小结的话, 就是我们需要自己定义爬虫要爬取什么网站, 然后在parse方法中写明如何解析请求返回的内容, 扩展本次记录的爬虫案例有一个前提, 就是通过简单的get或post请求获得的响应就能包含我们想要获取的数据. 但是随着网页技术的发展, 月来越多网站不再是只有html的静态网站了… 大部分网站都多少有通过js加载的内容, 甚至整个网页都是js或其他框架渲染出来的, 这种时候简单的请求是无法取回想要的数据的, 也就要结合splash这样的渲染引擎一并使用了. 关于这个下次再记录. 以上~","categories":[{"name":"Script","slug":"Script","permalink":"https://silenwang.github.io/categories/Script/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://silenwang.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"框架","slug":"框架","permalink":"https://silenwang.github.io/tags/%E6%A1%86%E6%9E%B6/"},{"name":"数据采集","slug":"数据采集","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"},{"name":"Scrapy","slug":"Scrapy","permalink":"https://silenwang.github.io/tags/Scrapy/"}]},{"title":"钉钉Linux版能正常用了","slug":"钉钉Linux版能正常用了","date":"2022-02-22T22:22:22.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2022/02/22/钉钉Linux版能正常用了/","permalink":"https://silenwang.github.io/2022/02/22/%E9%92%89%E9%92%89Linux%E7%89%88%E8%83%BD%E6%AD%A3%E5%B8%B8%E7%94%A8%E4%BA%86/","excerpt":"虽然钉钉某种程度上确实是个压榨人的工具, 但是毕竟工作要用到, 与又被压榨又被恶心… 能去掉一个恶心已经算不错了(说的就是你腾讯)","text":"虽然钉钉某种程度上确实是个压榨人的工具, 但是毕竟工作要用到, 与又被压榨又被恶心… 能去掉一个恶心已经算不错了(说的就是你腾讯) 感谢FlyInWind在AUR上给出的解决方案, 钉钉Linux版本在Arch系下也可以正常使用了, 目前我所有要用的组件都正常(聊天, 工作台的审批, 文档, 项目管理, 在线文档分析), 视频会议本周应该会试用到, 如果也正常…可就齐活了 目前开发者应该是已经把FlyInWind提出的方案直接写到构建文件里了, 使用AUR安装的钉钉直接就把libgtk-x11-2.0.so等两个文件删除了, 只要按照dbh625说的在启动脚本加入以下代码即可完美使用. 123export XMODIFIERS=&quot;@im=fcitx&quot;export QT_IM_MODULE=&quot;fcitx&quot;export QT_QPA_PLATFORM=xcb 期待所有国产常用软件都能有功能完整的Linux版本的一天","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"钉钉","slug":"钉钉","permalink":"https://silenwang.github.io/tags/%E9%92%89%E9%92%89/"},{"name":"AUR","slug":"AUR","permalink":"https://silenwang.github.io/tags/AUR/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://silenwang.github.io/tags/Arch-Linux/"},{"name":"办公软件","slug":"办公软件","permalink":"https://silenwang.github.io/tags/%E5%8A%9E%E5%85%AC%E8%BD%AF%E4%BB%B6/"}]},{"title":"Graphviz配合draw.io使用","slug":"Graphviz配合draw-io使用","date":"2021-10-20T01:48:35.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2021/10/20/Graphviz配合draw-io使用/","permalink":"https://silenwang.github.io/2021/10/20/Graphviz%E9%85%8D%E5%90%88draw-io%E4%BD%BF%E7%94%A8/","excerpt":"自从会了Graphviz后, 经常会用它来做流程图或者简单的示意图, 大部分使用它都是比较好用的, 因为流程图比较小, 同时也只用来示意, 并不用于展示. 但是当流程图较复杂, 同时有美化和展示的需要, 就会比较麻烦了.","text":"自从会了Graphviz后, 经常会用它来做流程图或者简单的示意图, 大部分使用它都是比较好用的, 因为流程图比较小, 同时也只用来示意, 并不用于展示. 但是当流程图较复杂, 同时有美化和展示的需要, 就会比较麻烦了. 因此我找到了一个折中的办法, 先用graphviz确定草图, 然后使用graphviz2drawio来对写好的graphviz进行格式转换, 转换好的草图再导入drawio来手动进行编排 实际用下来这个方案也并不是特别好用… 导入的流程图大致框架是有, 但是原来graphviz中的图形不会保留(圆啊方块什么的), 同时部分graphviz里的对象在drawio中并不存在, 所以用graphviz做草图的话, 最多只能保留基本的骨架, 需要继续调整的东西还是挺多的. 所以之后还是要么再学一个使用drawio的语言, 要么找一个别的类似drawio的工具来导入graphviz后进行进一步的编辑.","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"流程图","slug":"流程图","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E7%A8%8B%E5%9B%BE/"},{"name":"图表工具","slug":"图表工具","permalink":"https://silenwang.github.io/tags/%E5%9B%BE%E8%A1%A8%E5%B7%A5%E5%85%B7/"},{"name":"graphviz","slug":"graphviz","permalink":"https://silenwang.github.io/tags/graphviz/"},{"name":"drawio","slug":"drawio","permalink":"https://silenwang.github.io/tags/drawio/"}]},{"title":"密特罗德","slug":"密特罗德","date":"2021-10-18T00:17:50.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2021/10/18/密特罗德/","permalink":"https://silenwang.github.io/2021/10/18/%E5%AF%86%E7%89%B9%E7%BD%97%E5%BE%B7/","excerpt":"对我来说, 密特罗德是个很神奇的游戏, 因为我虽然知道其是银河城的鼻祖之一, 但是我从小就只玩过恶魔城, 对于这个系列却比较没兴趣…","text":"对我来说, 密特罗德是个很神奇的游戏, 因为我虽然知道其是银河城的鼻祖之一, 但是我从小就只玩过恶魔城, 对于这个系列却比较没兴趣… 直到20年初的新冠疫情, 当时在广州多待了两个星期, 笔记本上没有啥游戏可玩, 只带了3DS回家, 实在不知道玩啥所以下了3DS上的萨姆斯归来试试. 其实刚玩上的时候, 我也没觉得有啥特别, 毕竟玩过这个类型, 而且3DS玩动作类确实手累… 但是, 这个游戏神奇就神奇在, 我虽然不觉得有多么好玩, 但是我不知不觉… 就给它打通关了… 这一点跟3DS上的塞尔达三角力量如出一辙. 两者都不是我会心心念念想继续打的游戏, 但是一旦玩上了, 就… 直接给打通关了… 然后再一次让我重新认识这个系列的神奇, 是上手玩了血污之后… 血污是经典的月下+晓月的结合, 发售后大家也直呼去nmd精神续作, 这就是恶魔城正统续作. 但是在我实际玩之后, 我发现我没有当年喜欢晓月一样那么喜欢血污, 刨去它在NS上至今读盘表现欠佳之外, 我明确感受到了血污较重的RPG成分以及较重的战斗比例. 同时我也发现相比于战斗… 我其实更喜欢这类游戏的探索部分… 所以我就原价购买了生存恐惧… 同时在花了一星期通关后… 感觉到它的体验对我来说比血污好了太多… 希望横版的密特罗德以后还能有续作吧…","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"密特罗德","slug":"密特罗德","permalink":"https://silenwang.github.io/tags/%E5%AF%86%E7%89%B9%E7%BD%97%E5%BE%B7/"},{"name":"银河城","slug":"银河城","permalink":"https://silenwang.github.io/tags/%E9%93%B6%E6%B2%B3%E5%9F%8E/"},{"name":"恶魔城","slug":"恶魔城","permalink":"https://silenwang.github.io/tags/%E6%81%B6%E9%AD%94%E5%9F%8E/"},{"name":"3DS","slug":"3DS","permalink":"https://silenwang.github.io/tags/3DS/"},{"name":"Metroid","slug":"Metroid","permalink":"https://silenwang.github.io/tags/Metroid/"},{"name":"Samus","slug":"Samus","permalink":"https://silenwang.github.io/tags/Samus/"}]},{"title":"大逆转裁判2，精彩的同时让人不知道说什么好","slug":"大逆转裁判2","date":"2021-10-17T23:48:59.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2021/10/17/大逆转裁判2/","permalink":"https://silenwang.github.io/2021/10/17/%E5%A4%A7%E9%80%86%E8%BD%AC%E8%A3%81%E5%88%A42/","excerpt":"中秋的时候不想加班, 一口气把大逆2后两个案子打完了, 剧本真的不输成步堂三部曲, 同时相比最后一个案子, 倒数第二的“未来科学与亡灵归还”更让我印象深刻…","text":"中秋的时候不想加班, 一口气把大逆2后两个案子打完了, 剧本真的不输成步堂三部曲, 同时相比最后一个案子, 倒数第二的“未来科学与亡灵归还”更让我印象深刻… 这个案子里涉及到了两个研究人员, 其中一位在学生期间, 为了生存和研究经费, 跑去盗尸以卖给大学的医学院… 另外一位研究人员, 深信自己的理论没有问题, 然而苦于没有经费去验证, 结果被别有用心的商人利用来骗取政府提供的研究经费. 让我印象深刻的点有两个: 学生盗取尸体以进行医学研究, 甚至老师指示学生去盗取尸体进行医学研究, 这在医学发展过程中是确实存在的, 制作组考证到了这一点, 并把这一点融入了故事, 挺用心的. 两个研究人员经历的事完全不一样, 但是都反映了一个问题, 对年轻的研究者来说, 科学研究不仅需要才华, 还需要资源或者大量的金钱, 这个矛盾至今都是存在的… 不知道制作组从哪取的材, 写出了这么一个有点影射现实的故事. 其实虽然个人觉得大逆的剧本精彩程度跟成步堂三部曲差不多, 但是如果再去想现实意义的话… 感觉大逆还是更深刻和黑暗的多. 成步堂三部曲中存在不少的非现实元素, 什么审鹦鹉审电话这种情节, 加之大量有各种夸张表现的角色, 作为游戏, 让人玩的开心没有啥问题. 大逆转则非常不一样了, 除了最后一个案子里面的情节我觉得比较脱线… 其余很多案子中的情节感觉多少有些影射的意义: 与英国刺客相关案子中的外交困境, 夏目漱石两个案子里反映出身在异乡的留学生面临的非议, 前面说的青年研究者的困境, 以及本系列中强调的, 法庭上证据, 尤其是物证的重要性. 这一切都让大逆转更有解决疑难案件的感觉, 而不是精心设计的法庭辩论游戏. 希望以后还有续作吧~","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"大逆转裁判","slug":"大逆转裁判","permalink":"https://silenwang.github.io/tags/%E5%A4%A7%E9%80%86%E8%BD%AC%E8%A3%81%E5%88%A4/"},{"name":"成步堂三部曲","slug":"成步堂三部曲","permalink":"https://silenwang.github.io/tags/%E6%88%90%E6%AD%A5%E5%A0%82%E4%B8%89%E9%83%A8%E6%9B%B2/"},{"name":"游戏评论","slug":"游戏评论","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E8%AF%84%E8%AE%BA/"},{"name":"医学伦理","slug":"医学伦理","permalink":"https://silenwang.github.io/tags/%E5%8C%BB%E5%AD%A6%E4%BC%A6%E7%90%86/"},{"name":"科研困境","slug":"科研困境","permalink":"https://silenwang.github.io/tags/%E7%A7%91%E7%A0%94%E5%9B%B0%E5%A2%83/"}]},{"title":"ssh默认不支持rsa了","slug":"ssh默认不支持rsa了","date":"2021-10-11T21:06:49.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2021/10/11/ssh默认不支持rsa了/","permalink":"https://silenwang.github.io/2021/10/11/ssh%E9%BB%98%E8%AE%A4%E4%B8%8D%E6%94%AF%E6%8C%81rsa%E4%BA%86/","excerpt":"今天升级manjaro后最基本的ssh登陆突然出问题了, 提示有几种: 1234Unable to negotiate with UNKNOWN port 65535: no matching host key type found. Their offer: ssh-rsa,ssh-dsslost connectionsign_and_send_pubkey: no mutual signature supported 一查发现…好嘛, openssh觉得ssh-rsa加密方式不安全, 直接从8.8开始默认不允许这种密钥用于登陆了…","text":"今天升级manjaro后最基本的ssh登陆突然出问题了, 提示有几种: 1234Unable to negotiate with UNKNOWN port 65535: no matching host key type found. Their offer: ssh-rsa,ssh-dsslost connectionsign_and_send_pubkey: no mutual signature supported 一查发现…好嘛, openssh觉得ssh-rsa加密方式不安全, 直接从8.8开始默认不允许这种密钥用于登陆了… 本来想这manjaro落后arch一定版本, 所以又跑去archwiki找解决办法, 没想到还没写到里面去…兜兜转转查了半小时, 发现可以在~/.ssh/config里面加这么一段解决: 123Host * PubkeyAcceptedKeyTypes +ssh-rsa HostKeyAlgorithms +ssh-rsa 第一行说明对所有主机生效, 第二行是将ssh-rsa加会允许使用的范围, 第三行是指定所有主机使用的都是ssh-rsa算法的key.实测两行都得要写才行, 没有第二行提示没有ssh-rsa这么个类型, 没有第三行就提示sign_and_send_pubkey: no mutual signature supported. 以上~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://silenwang.github.io/tags/ssh/"},{"name":"openssh","slug":"openssh","permalink":"https://silenwang.github.io/tags/openssh/"},{"name":"manjaro","slug":"manjaro","permalink":"https://silenwang.github.io/tags/manjaro/"},{"name":"rsa加密","slug":"rsa加密","permalink":"https://silenwang.github.io/tags/rsa%E5%8A%A0%E5%AF%86/"},{"name":"ssh配置","slug":"ssh配置","permalink":"https://silenwang.github.io/tags/ssh%E9%85%8D%E7%BD%AE/"},{"name":"密钥认证","slug":"密钥认证","permalink":"https://silenwang.github.io/tags/%E5%AF%86%E9%92%A5%E8%AE%A4%E8%AF%81/"}]},{"title":"基于dash与flask搭建一个任务监控web-app","slug":"基于dash与flask搭建一个任务监控web-app","date":"2021-06-21T01:24:23.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2021/06/21/基于dash与flask搭建一个任务监控web-app/","permalink":"https://silenwang.github.io/2021/06/21/%E5%9F%BA%E4%BA%8Edash%E4%B8%8Eflask%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E4%BB%BB%E5%8A%A1%E7%9B%91%E6%8E%A7web-app/","excerpt":"鸽了都快大半年了, 自从接锅以来, 事情一直都多得做不完… 也就没那个兴致写东西, 不过这一次算是将半年来新学的一些东西做了综合应用, 写了我人生中第一个带数据库操作的Web-App, 所以还是应该纪念一下, 不过时间有限, 先写文本, 图片以后再补…","text":"鸽了都快大半年了, 自从接锅以来, 事情一直都多得做不完… 也就没那个兴致写东西, 不过这一次算是将半年来新学的一些东西做了综合应用, 写了我人生中第一个带数据库操作的Web-App, 所以还是应该纪念一下, 不过时间有限, 先写文本, 图片以后再补… 这个app实现的是类似NCBI Blast那种分析服务, 目的是让用户能通过Web界面提交分析任务, 并从监控列表中了解已提交任务的分状态, app提供了一个极其简陋的分析界面, 用户可在界面选择必要的输入文件和配置文件(事先登录到数据库)后, 开始分析任务, 并通过监控栏了解已提交任务的运行状态. 当然这个Web见面其实不是给用户用的, 而是作为与前端IT交流的Demo, 并在日后供我自己测试使用, 真正派上用场的是内建的Web-API, 应用通过响应前端发来的Web请求来完成实际的业务工作 模块介绍本次的Web-App功能虽然简陋, 但是实现起来其实用了不少东西, 同时也花了不少时间在一些内容的组合实现上, 本次只着重于实际实现过程中一些问题的解决方式, 一些新模块的基本操作(dash, python操作mongoDB之类)之后可能会单独再水一次 Web APIAPI基于Flask构建, 之所以不采用Django是因为介绍里说Flask更轻量简洁, 毕竟我们也不是搭什么巨型高并发高计算量的API, 我觉得用这个更简单 Web操作界面Web界面基于Dash构建, Dash与R语言中的Shiny是完全同性质的东西, 只不过这东西在中文生信群体中似乎完全没有存在感, 中文材料基本都是英文机翻. 当然英文材料似乎也不如Shiny来的多, 主要还是以官方的文档和官方的Q&amp;A为主. 不过我既然现在主语言是Python, 使用基于Python的东西肯定比和R混编简单得多. 另外虽然我的App很简单, 但是相对过去写的生信小脚本那还是复杂了好几个量级的… 因此Python的错误追踪还是及其救命的, 不至于让我在Debug上浪费巨量的时间 另外值得一提的是, Dash是从Plotly这个绘图包发展而来的, 同时Dash提供的Web-App也是在Flask基础上实现的, 所以Dash界面+Flask处理Web请求在我当前的应用场景下极佳的组合, 因为我可以在一个主程序文件内同时写Dash函数和Flask函数, 减少重复工作, 同时也保证我测试展现的东西和同事通过API获取的东西是一致的 后端任务控制任务控制基于Snakemake进行, 这个就不多说了, 值得一提的是用了这么长时间之后, 我对Snakemake文档里面的那句, Snakemake is python code这句话有了更好的理解, 因为这个特性的存在, 我能在Snakemake里面通过自编写的一些函数实现Snakemake当前没有实现的特性. 比如在这个应用中的任务状态自动更新 文件记录与任务记录(数据库)任务和文件记录使用了mongoDB进行数据存储, 其实如果单单只是要构建这个App的话, 并不需要用到任何数据库, 使用简单的文件做存储, 或者直接将内容存储在设定好结构的目录里也可以, 使用数据库纯粹是为了进行简单的数据库操作练习, 因为后面有别的工作会用. 而选择mongoDB, 不使用之前已经用过的SQLite, 也是出于后面工作的考虑, 因此提前拿简单的内容进行mongoDB练手 Api文档Api文档这个其实最开始并不在应用规划内容里面, 是因为近期搭建了非常多简单的Web服务以实现公司内部的分析上系统, Api一多了, 一个Api准备一份文档存和查询起来相当不方便, 同时因为预计不同的Api会交给不同人, 另外维护一份总的文档也比较烦, 因此我想是否有方式能把Api文档直接生成在单个Web-App下面, 最后就选定了flasgger, 这个模块的作用是在flask内引入一系列API, 方便作者直接在Python代码内编写Api文档, 编写的文档可以调用Swagger UI直接在应用路径下形成一份Api文档 应用总览本App其实逻辑很简单, 就是前端接受请求, 将请求转发到后端启动分析进程, 分析进程在运行过程中不断将状态更新到数据库, 然后前端定时或者根据请求从数据库获取程序运行状态就好, 大概的信息流见下图 实现要点虽然这个应用简单, 但是实际实施过程中还是有问题是要额外想办法解决的: 保证Dash-App处理和Flask-API处理的一致性, 即使用Dash-App完成测试后不需要额外对Flask-API部分进行改动 Dash-App&#x2F;Flask-App&#x2F;API文档的混用, 即让所有这些东西都在同一个App下, 而不是搭建多个Web-App然后相互跳转 利用Snakemake控制进程本身将运行状态更新到数据库, 而不另外设立单独的监控进程 Dash-App和Flask-API处理的一致性这一点其实很好实现了… 就是把实际的业务处理函数跟Dash和Flask的函数分开就好, 也就是Dash和Flask的响应函数将数据处理成统一的格式, 然后交由一个实际的业务函数来执行数据处理, 两个响应函数得到处理的数据后再分别格式化为Dash需要的内容或API中设定好的格式: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@app.callback( [ Output(&#x27;info-div&#x27;, &#x27;children&#x27;) ], [ Input(&#x27;upload-info&#x27;, &#x27;contents&#x27;) ], [ State(&#x27;upload-info&#x27;, &#x27;filename&#x27;) ] )def step2_dash(content, filename): &#x27;&#x27;&#x27; dash响应函数 &#x27;&#x27;&#x27; # 需要从文件解析目标路径 if content: _, content_stream = content.split(&#x27;,&#x27;) info_data = step2(content_stream, filename) json_fmt = dumps(info_data, sort_keys=True, indent=4, separators=(&quot;,&quot;, &quot;:&quot;), ensure_ascii=False) return [html.Pre(f&#x27;解析成功, 从信息表中提取的信息:\\n&#123;json_fmt&#125;&#x27;)] else: return [html.Pre(&#x27;无解析结果&#x27;)]@app.server.route(&#x27;/step2&#x27;, methods=[&#x27;POST&#x27;])def step2_flask(): &#x27;&#x27;&#x27; flask响应函数 &#x27;&#x27;&#x27; data = loads(flask.request.form.get(&#x27;data&#x27;)) fileUrl = f&#x27;&#123;data[&quot;dowloadFileUrl&quot;]&#125;?type=&#123;data[&quot;type&quot;]&#125;&amp;fileName=&#123;data[&quot;fileName&quot;]&#125;&#x27; filename = re.findall(r&#x27;fileName=(.+)&#x27;, fileUrl)[0] r = requests.get(fileUrl) info_data = step2(r.content, filename, decode=False) res_data = &#123;&#x27;errCode&#x27;:0, &#x27;data&#x27;: info_data, &#x27;msg&#x27;: &#x27;&#x27;&#125; json_fmt = dumps(res_data, sort_keys=True, ensure_ascii=False) return json_fmt.encode(encoding=&quot;UTF-8&quot;)def step2(content_stream, filename, decode=True): &#x27;&#x27;&#x27; step2的实际处理部分, 拆分出来分别接收不同的请求 &#x27;&#x27;&#x27; if decode: decoded = base64.b64decode(content_stream) else: decoded = content_stream info_data = data_format(decoded, filename) return info_data Dash-App&#x2F;Flask-App&#x2F;API文档混用Flask和Api文档的混用其实比较简单, 因为flasgger本来就是个flask加API文档的. 而Dash和Flask的混用其实也不难, Dash对象有一个server属性, 这里面存的就是Flask App对象, 所以其实需要用到该对象的部分直接app.server就好了: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import dashapp = dash.Dash(&quot;Demo&quot;)app.server.config[&#x27;SWAGGER&#x27;] = &#123; &#x27;title&#x27;: &#x27;质谱信息录入/报告生成服务文档&#x27;, &#x27;uiversion&#x27;: 2&#125;swagger = Swagger(app.server)app.layout = html.Div( [ html.H1(&#x27;Demo&#x27;), html.Div([ dcc.Upload( id=&#x27;upload-info&#x27;, children=html.Div([ &#x27;upload here&#x27;, ]), ), html.Div([ html.Pre(&#x27;&#x27;), ], id=&#x27;info-div&#x27;) ]) ],)@app.callback( [ Output(&#x27;info-div&#x27;, &#x27;children&#x27;) ], [ Input(&#x27;upload-info&#x27;, &#x27;contents&#x27;) ], [ State(&#x27;upload-info&#x27;, &#x27;filename&#x27;) ] )def step2_dash(content, filename): &#x27;&#x27;&#x27; dash响应函数 &#x27;&#x27;&#x27; return [html.Pre(&#x27;parsed&#x27;)]@app.server.route(&#x27;/step2&#x27;, methods=[&#x27;POST&#x27;])def step2_flask(): &#x27;&#x27;&#x27; flask响应函数 --- tags: - Step2 parameters: - name: dowloadFileUrl in: query type: string required: true description: 文件下载地址 responses: 200: description: 返回解析完成的数据 schema: properties: errorCode: type: number description: 状态码 default: 0 data: type: string description: 投递任务的key default: parsed msg: type: string description: 正常时为空字串, 状态码不为0时会附带错误信息 default: &quot;&quot; &#x27;&#x27;&#x27; return &#x27;parsed&#x27; 利用Snakemake控制进程本身更新运行状态最开始我是考虑用Snakemake自带的onstart和onerror特性来实现的, 毕竟我要的其实就是任务开始和结束的时候向数据库提交最新的运行信息.但实际操作以后发现这两个特性是针对整个Snakefile起效的, 也就是总任务开始前执行一次, 然后总任务失败的时候执行一次, 并不提供单个任务的响应, 那就只能自己动手了… 这时候就要利用Snakemake is python code的特性了. 在一条规则(rule)内, 指定shell关键字时其实是在调用snakemake内部Api中的shell函数执行系统级的命令, 所以其实写run: shell(&#39;BASH_SCRIPT&#39;)的方式是一样的(程序表现上还有一点额外差异, 这里忽略), 但是改用这种方式之后, 我就可以在系统命令的前后来额外增加其他的python代码来实现我要的功能了, 比如执行前后都更新一次任务状态: 1234567891011121314rule step1: input: done = &#x27;&#123;rid&#125;/analysis.done&#x27; output: txt = &#x27;&#123;rid&#125;/done.txt&#x27;, run: # update_status是更新状态的函数, rid是任务编号 update_status(rid, &#x27;step1&#x27;, &#x27;running&#x27;) shell( &#x27;&#x27;&#x27; cp &#123;input.done&#125; &#123;output.txt&#125; &#x27;&#x27;&#x27; ) update_status(rid, &#x27;step1&#x27;, &#x27;done&#x27;) 如此就方便的实现了目的了. 另外, 对于错误时的处理不需要这么进行, 因为错误状态在本应用中不需要精确到规则, 利用onerror就可以了 不过还需要注意一点, 就是Sanakemake其实支持一项名为papernote的服务, 该服务可专门收集主控流程的任务状态的, 也就是说Snakemake其实内建有类似的东西, 不过这就需要去读一读相关部分的代码来了解怎么实现的了, 也许内部API有更好用的方式呢? 后续去年的时候我面试过一个生信工程师, 他在疫情期间回不了公司, 就自己在家自学代码然后写了个分析提交&#x2F;监控服务. 现在我总算是也会了… 回看一下的话, 其实真的不难, 只是需要时间和一定的外部动力推着我学… 另外就是实践还是重要的, 只有实践才能发现实际的问题, 然后解决了问题, 能力也就随之提高了, 我以后还是要多加油…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"snakemake","slug":"snakemake","permalink":"https://silenwang.github.io/tags/snakemake/"},{"name":"python","slug":"python","permalink":"https://silenwang.github.io/tags/python/"},{"name":"任务监控","slug":"任务监控","permalink":"https://silenwang.github.io/tags/%E4%BB%BB%E5%8A%A1%E7%9B%91%E6%8E%A7/"},{"name":"Web应用","slug":"Web应用","permalink":"https://silenwang.github.io/tags/Web%E5%BA%94%E7%94%A8/"},{"name":"flask","slug":"flask","permalink":"https://silenwang.github.io/tags/flask/"},{"name":"dash","slug":"dash","permalink":"https://silenwang.github.io/tags/dash/"},{"name":"mongoDB","slug":"mongoDB","permalink":"https://silenwang.github.io/tags/mongoDB/"},{"name":"flasgger","slug":"flasgger","permalink":"https://silenwang.github.io/tags/flasgger/"}]},{"title":"给我的坚果Pro刷魔趣","slug":"给我的坚果Pro刷魔趣","date":"2021-02-12T20:56:03.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2021/02/12/给我的坚果Pro刷魔趣/","permalink":"https://silenwang.github.io/2021/02/12/%E7%BB%99%E6%88%91%E7%9A%84%E5%9D%9A%E6%9E%9CPro%E5%88%B7%E9%AD%94%E8%B6%A3/","excerpt":"手上的坚果pro用了3年多了, 什么程序都卡, 空间成天不够用, 是在有些扶不住, 故趁此佳节… 做最后挣扎… 死马做活马医, 刷个机试试, 要是刷成了… 那再撑个一年半载, 要是不行壮烈了… 那就忍痛用年终奖买个新的吧…","text":"手上的坚果pro用了3年多了, 什么程序都卡, 空间成天不够用, 是在有些扶不住, 故趁此佳节… 做最后挣扎… 死马做活马医, 刷个机试试, 要是刷成了… 那再撑个一年半载, 要是不行壮烈了… 那就忍痛用年终奖买个新的吧… 工具准备说起上次刷机, 真的是很久远的事情了… 那时候安卓机刚兴起, 大家除了玩手机软件, 也喜欢玩手机系统, 所以各种各样的定制rom层出不穷. 现在的话, 不是出于个人的特殊需求或者像我这样原生系统实在用不下去的, 大概不会刷机了吧? 现在刷机似乎也没有原来简单了… 至少我这台需要专门的线才行… 当然也得感谢有人在编译和维护这台机器的rom. 那么所有需要的东西如下: 9008刷机线一根(淘宝10块) INVALID POST SLUG PROVIDED 刷入TWRP用工具(QPST for win, qdl for linux, 需要yay -S qdl, 是AUR的包) 坚果Pro对应的底包(RADIO-odin*和系统包(MK90.0-odin*) 操作步骤操作步骤基本是按开发者给的教程来的, 不过我不是windows用户, 所以用的刷入工具不太一样(当然其实我这次两种都试了, 但是windows上的工具反而不行, 只是让我确定了机器处于9008模式). 另外了能因为买到的9008线和教程中提到的不一致, 因此实际进9008的方式跟教程不是很一致(我买的线上的按钮是按一下就会卡住, 再按一次会弹回的). 至于刷机前文件备份什么的… 我只备份了微信聊天记录… 其他随便吧… 反正我很久不打电话发短信了… 然后我的手机刷机前更新到的官方最新的系统, 之前没有进行过任何刷机. 底包和系统包放入SD卡我的手机有个32g的SD卡, 我是直接把底包和系统包都放SD卡上了, 放内置存储应该是可以的, 因为后面刷的时候有看到选项, 不过因为没有实操暂且未知. 电脑运行qdl, 等待手机插入下载好TWRP, 安装好qdl, 把TWRP解压出来进入解压的目录, 运行下面命令见到Waiting for QDL tty...就可以了. 当然如果失败了再尝试要再运行一次 1sudo qdl prog_emmc_firehose_8953_ddr.mbn rawprogram_unsparse.xml 手机进9008模式, 自动开始刷机 长按电源关机 9008线连接电脑USB口 同时按住音量+-两个键 保持9008线按钮处于未按下的状态, 然后插入到手机上. 正面左上角的提示灯会短暂闪红色, 看到红色后立刻按下按键, 之后手机的提示灯会保持红色闪烁, 代表进入9008模式, 此时按住音量键的手可以松开了 如果一切顺利, 电脑终端上应该能看到在刷入TWRP, 等待结束就行了 卡刷魔趣后面的完全按照教程就行了, 我是完全照着做没有做任何多余的东西的… 印象中5-10分钟就结束了. 之后重启进入系统做好设置就能用了 短期使用体验&#x2F;小问题短期使用了2天, 感觉大部分时候还是比原声系统流畅了不少, 但是没有预想的那么好吧… 看来真的是CPU跟不上国内App暴涨的性能需求了… 不过由于App可以放到内存卡了, 撑个一年应该问题不大. 目前碰到的问题: 指纹删除时, 需要先对待删除的指纹重命名, 然后才能删除 杀进程非常厉害, 如果一段时间不操作, 程序非后台进程肯定会挂. 当然这一点我专门看了一些评论… 说是国内厂商不按google要求开发app导致的… 凡是类原声安卓用国内App的通病. 小卡顿依然存在, 尤其是某些时候B站弹幕多了会卡 后记刷机后系统层面非常流畅, 但是常用应用内偶尔还是会一言难尽… 然后突然想到了微信的”进化”过程… emmmm 于是尝试了用旧版App替换… 好吧… 真就好了, B战不卡了, 支付宝启动速度肉眼可见的增加了. 哎… 我说什么好… 之后水一个历史版本App的列表吧…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"安卓","slug":"安卓","permalink":"https://silenwang.github.io/tags/%E5%AE%89%E5%8D%93/"},{"name":"android","slug":"android","permalink":"https://silenwang.github.io/tags/android/"},{"name":"手机","slug":"手机","permalink":"https://silenwang.github.io/tags/%E6%89%8B%E6%9C%BA/"},{"name":"刷机","slug":"刷机","permalink":"https://silenwang.github.io/tags/%E5%88%B7%E6%9C%BA/"},{"name":"魔趣","slug":"魔趣","permalink":"https://silenwang.github.io/tags/%E9%AD%94%E8%B6%A3/"},{"name":"坚果Pro","slug":"坚果Pro","permalink":"https://silenwang.github.io/tags/%E5%9D%9A%E6%9E%9CPro/"},{"name":"Mokee","slug":"Mokee","permalink":"https://silenwang.github.io/tags/Mokee/"},{"name":"custom ROM","slug":"custom-ROM","permalink":"https://silenwang.github.io/tags/custom-ROM/"}]},{"title":"主题升级","slug":"主题升级","date":"2021-02-12T20:26:57.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2021/02/12/主题升级/","permalink":"https://silenwang.github.io/2021/02/12/%E4%B8%BB%E9%A2%98%E5%8D%87%E7%BA%A7/","excerpt":"2020年实在太忙… 年中就发现使用的material-x主题已经大升级了, 但是一直没有抽出时间来进行更新, 这一拖…都2021了…","text":"2020年实在太忙… 年中就发现使用的material-x主题已经大升级了, 但是一直没有抽出时间来进行更新, 这一拖…都2021了… 再一看作者的文档… 好家伙… 时代真是面目全非了, 我也就放弃从原来的主题直接升级, 直接根据文档新开项目迁移了. hexo安装和设置好家伙… 原来新电脑连hexo都没有装… 正好测试上次说的hexo-cli&#x2F;hexo到底哪个是必要的问题. 实测下来其实有hexo-cli就好了: 1234sudo pacman -S npmsudo npm install -g hexo-climkdir neo_bloghexo init volantis主题及其他插件安装根据官方文档的内容, 主题安装方式也不一样了, 现在直接使用npm进行, 之前是把项目用git clone放到博客项目的themes目录下, 不过这倒也方便就是了… 12npm i hexo-theme-volantisnpm i hexo-generator-search hexo-generator-json-content 编辑配置文件配置文件同样有了变化(似乎是hexo升级后的改动?), 主要是主题配置不推荐直接更改themes/yourTheme/_config.yml或node_modules/yourTheme/_config.yml, 而是在_config.yml同级目录下直接创建_config.yourTheme.yml文件, 然后把主题配置文件中需要更改的部分写到这个文件中, 这样文件里的内容会覆盖主题配置文件中的内容(感觉很像vscode中的配置json文件). 文档说这样的好处是更新主题后, 对主题的配置更改不会消失. 当然实际使用中发现volantis的主题配色相关内容在_config.yourTheme.yml更改后本地预览有用, 但部署后无效… 最后还是改了主题的配置文件才生效 在主题内容更改好后, 把原来的_config.yml复制过来, 然后整个目录的内容替换掉原来的博客目录, 就可以像之前一样部署了. 手册添加另外本次把手册又加了进来, 内容完全没有更新… 只是测试用软链是否能直接把生成的手册上传… 实测无效… 我也暂时懒得学习如何更新博客同时更新手册… 先这样手动来吧… 以后再说…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://silenwang.github.io/tags/hexo/"},{"name":"主题升级","slug":"主题升级","permalink":"https://silenwang.github.io/tags/%E4%B8%BB%E9%A2%98%E5%8D%87%E7%BA%A7/"},{"name":"volantis","slug":"volantis","permalink":"https://silenwang.github.io/tags/volantis/"},{"name":"npm","slug":"npm","permalink":"https://silenwang.github.io/tags/npm/"},{"name":"配置文件","slug":"配置文件","permalink":"https://silenwang.github.io/tags/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"}]},{"title":"mSINGS的安装和使用","slug":"mSINGS的安装和使用","date":"2020-09-06T16:46:00.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2020/09/06/mSINGS的安装和使用/","permalink":"https://silenwang.github.io/2020/09/06/mSINGS%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","excerpt":"mSINGS是一个用来检测MSI的软件, 其优势似乎是可以用于tumor only的样品.","text":"mSINGS是一个用来检测MSI的软件, 其优势似乎是可以用于tumor only的样品. mSINGS项目挂在bitbucket而不是github, 项目是一直都有在更新… 不过这个安装指引写的稍微硬核了一点… 然后它也没有一键安装之类的东西, 所以看着文档安装会有点绕… 这个项目的核心是用Python写的, 其核心是读取samtools生成的mpileup文件进行分析, 因此本质上的依赖应该是Python3.6和samtools就好了(里面的git应该是克隆项目用的吧?). 然后因为作者指定Python版本, 所以他才会建议使用Python虚拟环境(防止日后爆炸). 不过因为我不会用virtualenv, 所以用上手更简单的miniconda代替, 总的来说就是: 创建环境&#x2F;安装必要依赖 -&gt; 安装模块 -&gt; 测试. 创建环境&#x2F;安装必要依赖 1conda create -p /path/to/soft/mSINGS/conda python=3.6 git samtools 安装模块 1234conda activate /path/to/soft/mSINGS/conda # 进入环境准备安装模块本体git clone https://bitbucket.org/uwlabmed/msings.git # 项目克隆, 这个按作者建议来cd msings # 进入目录python setup.py install # 安装软件本体 测试 作者在readme中提到了如何创建baseline(应该是根据已有数据确定哪些MSI位点需要扫), 但我只是测试, 所以直接用项目下准备好的文件进行(doc/目录下). 另外需要注意的是, 作者明确说了输入的bam需要比对到region不带chr字符串的参考基因组(GATK有提供的亚子), 所以我找了个fq数据从比对开始, 如果bam已经符合要求了可以跳过. 另外需要注意的是, 作者在运行脚本run_msings.sh, 指定了虚拟环境激活, 因为我没有按他的来, 所以脚本内的# source msings-env/bin/activate这一句需要注释掉. 12345678910111213141516171819set -e# 不要做sort, 因为mSINGS的分析过程带了sort.../path/to/apps/bwa-0.7.12/bwa mem \\ -R &#x27;@RG\\tID:group1\\tSM:TUMOR\\tPL:illumina\\tLB:lib1\\tPU:unit1&#x27; \\ -M -t 16 \\ /path/to/Human_Genome_GRCh37_FASTA/human_g1k_v37.fasta \\ /path/to/soft/mSINGS/run_test/test.fq.R1.gz \\ /path/to/soft/mSINGS/run_test/test.fq.R2.gz \\| /usr/local/bin/samtools view \\ -Sb - \\&gt; test.bamecho &quot;test.bam&quot; &gt; bam_list # 因为给的脚本指定一定要给写了bam路径的文件, 所以只能这么指定sh /path/to/mSINGS/msings/scripts/run_msings.sh \\ bam_list \\ /path/to/mSINGS/msings/doc/mSINGS_TCGA.bed \\ /path/to/mSINGS/msings/doc/mSINGS_TCGA.baseline \\ /path/to/Human_Genome_GRCh37_FASTA/human_g1k_v37.fasta 最终的结果会在Combined_MSI.txt这个文件中, 这里面应该是将每个bam的结果放到了一起, 当然我只测试给一个bam, 所以合并的结果会不会有啥特殊结构未知… 我测试的这个样品目标MSI位点1166个, 27个检测到不稳定, 不稳定的2%, 总体是MSS. 12345Position testunstable_loci 27passing_loci 1166msing_score 0.0232msi status NEG 最后来看一下作者的运行脚本run_msings.sh: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#!/bin/bashset -e# source msings-env/bin/activate#BAM_LIST is a file of absolute paths to each bam fileBAM_LIST=$1;BEDFILE=$2;MSI_BASELINE=$3;REF_GENOME=$4;#Check for required variables:if [ -z &quot;$BAM_LIST&quot; ]; then echo &quot;BAM_LIST is unset&quot; &amp;&amp; exit ; else echo &quot;BAM_LIST is set to &#x27;$BAM_LIST&#x27;&quot;; fiif [ -z &quot;$BEDFILE&quot; ]; then echo &quot;BEDFILE is unset&quot; &amp;&amp; exit ; else echo &quot;BEDFILE is set to &#x27;$BEDFILE&#x27;&quot;; fiif [ -z &quot;$MSI_BASELINE&quot; ]; then echo &quot;MSI_BASELINE is unset&quot; &amp;&amp; exit ; else echo &quot;MSI_BASELINE is set to &#x27;$MSI_BASELINE&#x27;&quot;; fiif [ -z &quot;$REF_GENOME&quot; ]; then echo &quot;REF_GENOME is unset&quot; &amp;&amp; exit ; else echo &quot;REF_GENOME is set to &#x27;$REF_GENOME&#x27;&quot;; fi#&quot;multiplier&quot; is the number of standard deviations from the baseline that is required to call instabilitymultiplier=2.0 #&quot;msi_min_threshold&quot; is the maximum fraction of unstable sites allowed to call a specimen MSI negative msi_min_threshold=0.2#&quot;msi_max_threshold&quot; is the minimum fraction of unstable sites allowed to call a specimen MSI positivemsi_max_threshold=0.2for BAM in `sed &#x27;/^$/d&#x27; $BAM_LIST`; do SAVEPATH=$(dirname $BAM) BAMNAME=$(basename $BAM) PFX=$&#123;BAMNAME%.*&#125; mkdir -p $SAVEPATH/$PFX echo “Starting Analysis of $PFX” &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; date +&quot;%D %H:%M&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; echo &quot;sorting bam of $PFX&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; date +&quot;%D %H:%M&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; samtools sort -o $SAVEPATH/$PFX/$PFX.sorted.bam $BAM &amp;&amp; samtools index $SAVEPATH/$PFX/$PFX.sorted.bam echo &quot;Making mpileups&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; date +&quot;%D %H:%M&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; samtools mpileup -f $REF_GENOME -d 100000 -A -E -l $BEDFILE $SAVEPATH/$PFX/$PFX.sorted.bam | awk &#x27;&#123;if($4 &gt;= 6) print $0&#125;&#x27; &gt; $SAVEPATH/$PFX/$PFX.mpileup echo &quot;MSI Analyzer start&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; date +&quot;%D %H:%M&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; msi analyzer $SAVEPATH/$PFX/$PFX.mpileup $BEDFILE -o $SAVEPATH/$PFX/$PFX.msi.txt echo &quot;MSI calls start&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; date +&quot;%D %H:%M&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; msi count_msi_samples $MSI_BASELINE $SAVEPATH/$PFX -m $multiplier -t $msi_min_threshold $msi_max_threshold -o $SAVEPATH/$PFX/$PFX.MSI_Analysis.txt echo “Completed Analysis of $PFX” &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt; date +&quot;%D %H:%M&quot; &gt;&gt; $SAVEPATH/$PFX/msi_run_log.txt;doneecho &quot;Creating summary analysis file for all samples&quot; &gt;&gt; $SAVEPATH/msi_run_log.txt;msi count_msi_samples $MSI_BASELINE $SAVEPATH -m $multiplier -t $msi_min_threshold $msi_max_threshold -o $SAVEPATH/Combined_MSI.txt 看着有点长, 其实内容还是比较简单的, 作者也给了一些基本的注释. 本质上就是将输入的bam一个一个去sort然后生成mpileup文件, 然后使用msi这个程序(之前python setup.py install装的东西)来进行分析和数据汇总.","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"微卫星不稳定性","slug":"微卫星不稳定性","permalink":"https://silenwang.github.io/tags/%E5%BE%AE%E5%8D%AB%E6%98%9F%E4%B8%8D%E7%A8%B3%E5%AE%9A%E6%80%A7/"},{"name":"MSI","slug":"MSI","permalink":"https://silenwang.github.io/tags/MSI/"},{"name":"mSINGS","slug":"mSINGS","permalink":"https://silenwang.github.io/tags/mSINGS/"},{"name":"samtools","slug":"samtools","permalink":"https://silenwang.github.io/tags/samtools/"}]},{"title":"Flask使用记录","slug":"Flask使用记录","date":"2020-08-09T01:25:45.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2020/08/09/Flask使用记录/","permalink":"https://silenwang.github.io/2020/08/09/Flask%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/","excerpt":"因项目需要, 最近终于是实际看了下Flask怎么用, 照例来个记录.","text":"因项目需要, 最近终于是实际看了下Flask怎么用, 照例来个记录. 由于我这次的任务比较简单, 只要用Flask做个服务器, 能接受请求然后调用Python代码计算结果就行, 因此我这次只涉及最基本的使用. 当然由于我本身并不熟HTML和js, 因此这里记录的东西纯属我自己的理解…可能包含大量不准确和有误导性的描述… 创建一个Flask服务(App)所有的操作从创建个Flask App开始, 创建也比较简单, 把Flask对象实例化就行了. 12345from flask import Flaskapp = Flask(__name__)if __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;) 上述代码保存为Python文件, 然后python app.py就能启动服务了. host参数设到0.0.0.0是为了所有ip都能访问这个服务. 将访问与函数绑定Flask可以将对页面的请求转换成对Python函数的调用. 具体在对应函数前用@app.route装饰器就行. &#39;/&#39;的话对应的是index.html, 如果是&#39;/login&#39;这种的话则对应login.html, 当然我实测下来对应的html文件不需要存在, 在返回值里直接写html字串就行. 我这里是准备好了一个说明API使用方法的页面, 读进来直接返回就好. 12345@app.route(&#x27;/&#x27;)def index(): with open(&#x27;index.html&#x27;) as f: content = f.read() return content 处理POST请求我这次的程序需要接收一些参数和上传的文件内容以进行进一步处理, 文件的内容自然不能走GET, 所以只处理POST. Flask内置的request对象可以方便的获取请求中带有的所有信息. 1234567891011from io import BytesIOfrom flask import requestfrom iNeo_MS import sheet_parse@app.route(&#x27;/parse&#x27;, methods=[&#x27;POST&#x27;])def parse(): args = request.args method = args[&#x27;method&#x27;] byteData = request.files.get(&#x27;file&#x27;) data = sheet_parse(BytesIO(byteData.read()), method) return str(data.to_dict(&#x27;records&#x27;)) 用Python进行API测试进行POST服务测试是不能直接靠浏览器的, 得安装专门的插件… 然而家里网络堪忧… 于是还是靠Python了. 具体的方法当然是用requests模块的post方法了, 将参数放到params参数中, 文件则读入内容后通过files参数送出. 1234567891011121314151617import requestsparams = &#123; &#x27;method&#x27;: &#x27;pNovo&#x27;,&#125;with open(&quot;data/results.res&quot;, &quot;rb&quot;) as f: content = f.read()files = &#123; &quot;file&quot; :(&#x27;result.res&#x27;, content),&#125;response = requests.post( &#x27;http://127.0.0.1:5000/parse&#x27;, params=params, files=files","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"Flask","slug":"Flask","permalink":"https://silenwang.github.io/tags/Flask/"},{"name":"Web开发","slug":"Web开发","permalink":"https://silenwang.github.io/tags/Web%E5%BC%80%E5%8F%91/"},{"name":"后端","slug":"后端","permalink":"https://silenwang.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"API","slug":"API","permalink":"https://silenwang.github.io/tags/API/"}]},{"title":"水一发:hexo一次性多仓库部署","slug":"hexo一次性多仓库部署","date":"2020-08-02T01:19:38.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2020/08/02/hexo一次性多仓库部署/","permalink":"https://silenwang.github.io/2020/08/02/hexo%E4%B8%80%E6%AC%A1%E6%80%A7%E5%A4%9A%E4%BB%93%E5%BA%93%E9%83%A8%E7%BD%B2/","excerpt":"最近github的访问越来越不行了, 有时候想查自己博客里的博文都费劲…所以在国内的git托管服务商gitee也托管了一份, 但是问题就来了…如何一次更新多地部署呢?","text":"最近github的访问越来越不行了, 有时候想查自己博客里的博文都费劲…所以在国内的git托管服务商gitee也托管了一份, 但是问题就来了…如何一次更新多地部署呢? 首先要设置在gitee上的仓库, 基本方式和github一致啦, 唯一需要注意的是gitee的默认展示项目和github不一样, github用USERNAME.github.io, 而gitee使用的是USERNAME. 由于gitee本身有fork github项目的功能, 因此在创建项目的时候选择fork原来在github上的博客仓库, 然后把仓库名改成USERNAME就可以(图里是迁移完成后举例的…所以显示已创建). 之后再项目页面选服务菜单进行一下设置, 就能从USERNAME.gitee.io访问博客了. 然后就是设置通过ssh等度gitee了, 这个也跟github的一致就不展开. 最后就是设置项目的_config.yaml文件, 在部署的部分如下配置, 这样就能部署的时候一次性传两次了. 123456789deploy: - type: git repo: git@github.com:SilenWang/silenwang.github.io.git branch: master - type: git repo: git@gitee.com:silenwang/silenwang.git branch: master 本来这样就该结束了…但是测试的时候发现另外一个问题…就是家里的网已经完全不能直连github, 导致部署不到github上了… 因此又搜索了下给git加代理的方式. 由于我配置里走的是ssh协议连接github, 经查需要通过ssh的配置文件添加一个ProxyCommand的设置, 如下: 1234Host github.com User git HostName github.com ProxyCommand nc -x 127.0.0.1:1080 %h %p 添加之后再次尝试hexo d, 确实成功部署了. 以上, 水完~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://silenwang.github.io/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://silenwang.github.io/tags/github/"},{"name":"博客部署","slug":"博客部署","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2/"},{"name":"gitee","slug":"gitee","permalink":"https://silenwang.github.io/tags/gitee/"},{"name":"git代理","slug":"git代理","permalink":"https://silenwang.github.io/tags/git%E4%BB%A3%E7%90%86/"}]},{"title":"pandas常用操作记录","slug":"pandas常用操作记录","date":"2020-07-26T00:36:49.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2020/07/26/pandas常用操作记录/","permalink":"https://silenwang.github.io/2020/07/26/pandas%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%95/","excerpt":"","text":"因为现在的工作有大量数据统计&#x2F;处理要求, 且论错误处理及第三方扩展性, Python方便得多, 因此目前我数据处理也开始从R移动到Pandas了. 在此记录一些实际工作中常用的操作及需要注意的问题: 1. apply相关1.1. 基本使用同Pandas与R一样有apply函数, 不过仅此一个, 没有apply家族. apply本质上就是对表格进行按行循环, 而之所以用apply而不是直接itterrow, 则是出于并行的考虑. 有非常多的第三方模块可以直接将apply操作并行化, 因此最初写代码时就按照apply的写法来, 可以省下日后并行化时重写函数的过程. 当然另外一点就是将主处理逻辑和细部的详细执行内容分开, 一定程度上可以提高代码可读性, 不过个人感觉还是个习惯问题… 如果读代码的人从不这么写… 那用apply其实是提高读代码人的阅读难度… 目前我使用的方式一般是实际计算的部分写成通用函数, 然后套apply时使用匿名函数传参数. 1234def plus(x, y): return x+ydata[&#x27;applyed&#x27;] = data[&#x27;2apply&#x27;].apply(lambda x: plus(x[&#x27;x&#x27;], x[&#x27;y&#x27;])) 当然, 如果同时要对同一行做很多行内操作, 那就单独写个func_apply()的函数, 防止反复对数据遍历. 1.2. 返回多列结果apply的常规用法是返回一个数值形以形成一列数据, 但是实际应用中我其实会有返回多列的需要, 因此从网上找了一种解决方案: 12345def plus(x, y): return x+y, x-ydata[&#x27;x+y&#x27;], data[&#x27;x-y&#x27;] = zip(*data[&#x27;2apply&#x27;].apply(lambda x: plus(x[&#x27;x&#x27;], x[&#x27;y&#x27;]))) 2. Groupby相关2.1. 多行并为单行数据这个操作主要是用来将多行的数据统计为一行结果, 我印象中R里面有专门的处理方式, pandas应该也有…然而我一时没找到, 所以目前自己想了一种处理, 这种方式本质上是按待处理单位获取数据子集, 根据子集统计后生成新的数据行填入新表. 这种方式目前来看效率堪忧, 且因为本质是用了for循环, 并行化就没有apply那么简单了. 123456789result_list = []for k, sub_data in data.groupby(by=[&#x27;Grp1&#x27;, &#x27;Grp2&#x27;]): grp1, grp2 = k result_list.append(&#123; &#x27;Stat1&#x27;: sum(sub_data[&#x27;Var1&#x27;]), &#x27;Stat2&#x27;: min(sub_data[&#x27;Var1&#x27;]), &#125;)result = pd.DataFrame(result_list) 3. 缺失处理相关3.1. 读入时缺失指定通过na_values参数可以将多种数值替换为缺失: 1df = pd.read_table(FILE, sep=&quot;\\t&quot;, header=0, na_values=[&#x27;.&#x27;, &#x27;&#x27;]) 3.2. 输出时缺失指定输出时可通过参数指定缺失值用什么来填充： 1df.to_csv(FILE, sep=&quot;\\t&quot;, header=0, na_values=[&#x27;.&#x27;, &#x27;&#x27;]) 3.3 是否缺失判定pandas内如果产生缺失, 会使用numpy内置的nan对象, 这个对象在判定上和R中存在的NA或NULL以及Python内置的None都不太一样, 因为从类型上nan居然是float… 通过A==nan这种逻辑判断是得不到True的结果的… 原因我暂时没有找到. 不过要判断是否缺失的话, 最好还是用pandas下面的isnull方法. 其他模块像math, numpy虽然也有内置缺失判断函数, 但是这些函数有个致命的缺陷…他们接受的参数类型只能是float… 所以如果用他们的我还得自己加一层类型判断, 着实有点麻烦, 所以还是用pandas下的isnull最方便. 4. 最常用的输出参数因为个人习惯性输出tsv文件, 因此用pandas输出文件的话最经常这么写: 1df.to_csv(FILE_PATH, sep=&quot;\\t&quot;, index=0, na_rep=&quot;.&quot;) 需要注意的是, 如果输出的结果表是数据透视表, 很大概率是要将index输出的, 这种时候index=0就要去掉了 5. 其他可能需要的操作5.1 列类型转换1df.astype(&#123;&#x27;col1&#x27;: &#x27;int32&#x27;&#125;)","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"数据处理","slug":"数据处理","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"},{"name":"Pandas","slug":"Pandas","permalink":"https://silenwang.github.io/tags/Pandas/"},{"name":"缺失值处理","slug":"缺失值处理","permalink":"https://silenwang.github.io/tags/%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86/"}]},{"title":"猛汉王狩猎日记-冰原开荒完结纪念","slug":"猛汉王狩猎日记-冰原开荒完结纪念","date":"2020-02-23T22:21:16.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2020/02/23/猛汉王狩猎日记-冰原开荒完结纪念/","permalink":"https://silenwang.github.io/2020/02/23/%E7%8C%9B%E6%B1%89%E7%8E%8B%E7%8B%A9%E7%8C%8E%E6%97%A5%E8%AE%B0-%E5%86%B0%E5%8E%9F%E5%BC%80%E8%8D%92%E5%AE%8C%E7%BB%93%E7%BA%AA%E5%BF%B5/","excerpt":"本来想着春节期间好好肝一把… 结果大部分时间都加班了, 现在才开荒完毕… 而且在可以预期的未来工作也会比较繁忙… 趁没有正式复工, 留个几年bia…","text":"本来想着春节期间好好肝一把… 结果大部分时间都加班了, 现在才开荒完毕… 而且在可以预期的未来工作也会比较繁忙… 趁没有正式复工, 留个几年bia…","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"怪物猎人","slug":"怪物猎人","permalink":"https://silenwang.github.io/tags/%E6%80%AA%E7%89%A9%E7%8C%8E%E4%BA%BA/"},{"name":"冰原DLC","slug":"冰原DLC","permalink":"https://silenwang.github.io/tags/%E5%86%B0%E5%8E%9FDLC/"},{"name":"Monster Hunter World","slug":"Monster-Hunter-World","permalink":"https://silenwang.github.io/tags/Monster-Hunter-World/"},{"name":"Iceborne","slug":"Iceborne","permalink":"https://silenwang.github.io/tags/Iceborne/"}]},{"title":"破解了一个apk","slug":"破解了一个apk","date":"2020-02-02T21:51:39.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2020/02/02/破解了一个apk/","permalink":"https://silenwang.github.io/2020/02/02/%E7%A0%B4%E8%A7%A3%E4%BA%86%E4%B8%80%E4%B8%AAapk/","excerpt":"果然, 从小到大, 我最大的动力来源就是玩游戏耍帅… 今天本来是想打猎了但是回不去广州, 只好玩3ds上的4G, 然而这毕竟5年前的老游戏了, 那时怪猎在中文圈可能也不火… 基本找不到任何想要的中文资料(Ping’s Dex因为系统原因用着不太方便), 所以为了好好打游戏…我把黑手伸向了一个需要看广告才能好好用的app….","text":"果然, 从小到大, 我最大的动力来源就是玩游戏耍帅… 今天本来是想打猎了但是回不去广州, 只好玩3ds上的4G, 然而这毕竟5年前的老游戏了, 那时怪猎在中文圈可能也不火… 基本找不到任何想要的中文资料(Ping’s Dex因为系统原因用着不太方便), 所以为了好好打游戏…我把黑手伸向了一个需要看广告才能好好用的app…. 这个App的收费点在于看广告换积分, 然后凭积分兑换配装器的特定功能次数. 因此我原本的目标是让积分无限或者让兑换的使用次数无限. 我本来想的是程序代码里应该有这么个变量, 没使用一次变量数值就会下降, 我把下降的这一行代码去掉, 那就可以无限使用了. 那么就来操作上. 解包和解析Apk实际上一个Apk文件就是个压缩包, 直接unzip就可以了, 解压后的软件包应该会包括很多部分, 其中实际的执行文件会是*.dex, 这是编译后的执行文件, 解析的话需要先把这个文件转换为jar, 我使用的是enjarify, 来自github, 克隆下来就能用. 12unzip your.apk/path/tool/enjarify.sh classes.dex 接下来就是查看java代码了, 我使用的是jd-gui, AUR上可以能找到(aur/jd-gui-bin), 将文件拖进去就行. 这里就纯粹是代码阅读了, 由于代码不是咱写的, 而且作者为了保护自己也可能会加上一些混淆的东西, 可能会难定位. 所以我就想到了靠日志定位的方式: 首先使用adb shell连接手机终端, pm list packages查看目标app的名称 根据名称抓取指定app的日志adb logcat device_id|grep you.app.name 在手机上操作这个app, 比如我就进入了app的付费页面, 就能从日志上看到是调用了什么class了 完成定位后就很枯燥了… 猜指定文件中的代码逻辑怎样(毕竟我根本不懂java…), 然后尝试想一个解决方案, 反编译Apk并对代码进行修改我使用的是apktools, 加了archlinuxcn源之后直接sudo pacman -S android-apktool就行, 安装好了之后apktool d your.apk进行反编译就行了. 反编译后进入产生文件夹的smali文件夹内, 这个文件夹和jar里面的看到的java项目的目录结构是一样的, 只不过里面的是smali这种汇编语言的代码, 而不是java. 虽然语言不一样(甚至里面部分实现逻辑都是不太一样的), 但是实现一样的东西, 所以根据前面看过的java代码, 可以对应去文件里找相应的部分, 找到之后就可以按照smali的语法对代码进行更改了. 重打包与签名修改完代码文件就可以用修改后的文件夹重新生成Apk文件了: apktool b -o your.mod.apk your_path. 不过重新打包的Apk是不能直接用的, 还得签名… 这个签名完整的过程是要先给信息生成密钥, 然后再签名, 我觉得太麻烦就直接github上找了一个快速签名用的项目uber-apk-signer, 直接给未注册的Apk文件, 他会用内置的测试签名快速签, 然后就能装来用了. 1java -jar uber-apk-signer-1.1.0.jar --apks your.mod.apk 之后就是对修改后的App进行测试, 如果没有达到效果就再改就是了. 然后我实际上没有达到最初预想的效果, 因为我并没有在代码中找到那个数值下降的位置(因为实在看不懂java), 但是我却在购买的位置找到了判断积分是否充足的部分, 于是我直接跳过这个判断, 直接让积分兑换完成, 换了个方式实现了我要的效果… 唯一不足的就是… 我还得进购买页面疯狂兑换去… 嘛, 毕竟这么做对原作者不好… 所以我就不给App名称和实际的代码了… 不知道这次的技能以后会不会又在奇怪的地方有奇效…","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"adb","slug":"adb","permalink":"https://silenwang.github.io/tags/adb/"},{"name":"APK破解","slug":"APK破解","permalink":"https://silenwang.github.io/tags/APK%E7%A0%B4%E8%A7%A3/"},{"name":"反编译","slug":"反编译","permalink":"https://silenwang.github.io/tags/%E5%8F%8D%E7%BC%96%E8%AF%91/"},{"name":"Android逆向","slug":"Android逆向","permalink":"https://silenwang.github.io/tags/Android%E9%80%86%E5%90%91/"},{"name":"Apktools","slug":"Apktools","permalink":"https://silenwang.github.io/tags/Apktools/"},{"name":"enjarify","slug":"enjarify","permalink":"https://silenwang.github.io/tags/enjarify/"},{"name":"jd-gui","slug":"jd-gui","permalink":"https://silenwang.github.io/tags/jd-gui/"},{"name":"uber-apk-signer","slug":"uber-apk-signer","permalink":"https://silenwang.github.io/tags/uber-apk-signer/"}]},{"title":"从ggplot的箱线图中提取离群值并进行去除","slug":"从ggplot图形中提取数据","date":"2020-01-05T17:56:20.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2020/01/05/从ggplot图形中提取数据/","permalink":"https://silenwang.github.io/2020/01/05/%E4%BB%8Eggplot%E5%9B%BE%E5%BD%A2%E4%B8%AD%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE/","excerpt":"今天碰到一个做图问题, 学到了一个新的小技巧, 记录一下","text":"今天碰到一个做图问题, 学到了一个新的小技巧, 记录一下 ggplot提供了很多常用的图形的绘制函数, 相当方便, 且图形可以按照各种各样的分组进行绘制, 但是有的时候我有些特殊要求, ggplot无法满足, 所以需要自行进行一些操作. 比如我今天需要绘制一个分组的箱线图, 每一组的数据中都有自己的离群值, 这些离群值会使图形挤在某一测, 难以观察, 因此需要去除. geom_boxplot虽然有离群值处理的参数, 但是很可惜是这些参数并不会把离群点从数值中去除, 而是不在图形上显示, 这么一来该挤一起的图形还是挤一起, 达不到效果. 网上能查到的关于离群值去除的方案最多是利用内置boxplot函数里面$out的内容提取离群数值并进行去除, 可惜不巧的是这这种方案似乎不能分组给出离群值结果, 它给的是总体离群值, 如果需要分组去除的话还需要自己手动拆分数据集然后挨个处理. 那么有没有更偷懒一点的方式呢? 还真被我发现了… ggplot的图形和内置函数一样, 是可以提取实际绘图用数据的: 123plot &lt;- ggplot(data=data,mapping=aes(x=data$label, y=data[,tag])) + geom_boxplot()plot_data &lt;- layer_data(plot) layer_data函数是提取的方式之一, 使用build_plot(plot)$data效果一样. plot_data中就存储这ggplot绘制图形时使用的一切数据. 其中我们需要的部分存储在outliers中. 并且顺序是按照图形上展示的顺序排列的. 因此只要在前期绘图时对分组手动指定factor level, 就可以对应从图形中拿到特定组的离群值. 然后利用ggplot绘图时自动去NA的特性, 将对应列的离群值以NA替换, 就能轻松的创造一个去过离群值的数据集, 然后再次画图就能解决问题啦~ 完整的绘图代码与图形对比: 12345678910111213141516171819202122232425library(&#x27;ggplot2&#x27;)data &lt;- read.csv(&quot;plot_data.tsv&quot;, sep=&quot;\\t&quot;, stringsAsFactors=F, na.strings = &#x27;.&#x27;)# 对分组数据自定义等级, 后续对应必须data$grp &lt;- factor(data$grp, levels=c(&quot;Grp1&quot;,&quot;Grp2&quot;))# 准备一个vector作映射classV &lt;- c(1,2)names(classV) &lt;- c(&quot;Grp1&quot;,&quot;Grp2&quot;)# 第一轮, 利用ggplot获取离群值plot &lt;- ggplot(data=data,mapping=aes(x=data$grp, y=data[,&#x27;value&#x27;])) + geom_boxplot()print(layer_data(plot))outlier_data &lt;- layer_data(plot)[&#x27;outliers&#x27;]# 利用获取数值改变原数据集的离群值为NApdata&lt;-datafor (grp in names(classV)) &#123; pdata[pdata$grp==grp, &#x27;value&#x27;] &lt;- replace(pdata[pdata$grp==grp, &#x27;value&#x27;], pdata[pdata$grp==grp, &#x27;value&#x27;] %in% outlier_data[classV[grp], ][[1]], NA)&#125;# 准备比较组向量, 利用变更后的和数据作图comb_list &lt;- list()comb &lt;- combn(c(&quot;Negative&quot;, &quot;Unkown&quot;,&quot;Weak&quot;, &quot;Medium&quot;,&quot;Strong&quot;),2)for (id in seq(dim(comb)[2])) &#123; comb_list[[id]] &lt;- comb[, id]&#125;pplot &lt;- ggplot(data=pdata,mapping=aes(x=pdata$grp, y=pdata[,&#x27;value&#x27;])) +geom_boxplot()","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"数据可视化","slug":"数据可视化","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"ggplot","slug":"ggplot","permalink":"https://silenwang.github.io/tags/ggplot/"},{"name":"ggplot2","slug":"ggplot2","permalink":"https://silenwang.github.io/tags/ggplot2/"},{"name":"箱线图","slug":"箱线图","permalink":"https://silenwang.github.io/tags/%E7%AE%B1%E7%BA%BF%E5%9B%BE/"},{"name":"离群值处理","slug":"离群值处理","permalink":"https://silenwang.github.io/tags/%E7%A6%BB%E7%BE%A4%E5%80%BC%E5%A4%84%E7%90%86/"}]},{"title":"爬虫内容学习","slug":"爬虫内容学习","date":"2019-12-18T17:44:21.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2019/12/18/爬虫内容学习/","permalink":"https://silenwang.github.io/2019/12/18/%E7%88%AC%E8%99%AB%E5%86%85%E5%AE%B9%E5%AD%A6%E4%B9%A0/","excerpt":"之前没有系统对爬虫相关的东西学习过, 边看视频边做个笔记.","text":"之前没有系统对爬虫相关的东西学习过, 边看视频边做个笔记. request &#x2F; responserequest是浏览器&#x2F;程序向服务器发出的一些信息, 用于请求需要展示的内容, resoponse则是服务器对接收到的请求给出的回应信息. request的内容信息 请求方式: GET &#x2F; POST(最常用) POST相对GET多了form data GET的参数直接包含在URL中, 而POST请求则包含在表单中 请求URL: URL是统一资源定位符, 就是文件&#x2F;对象的链接 请求头: 重要的配置信息, 以键值对方式存储 请求体: GET时一般无信息, POST需要 response的内容信息 响应状态码: 用来表示请求情况的数字代码 响应头 相应体: 请求的结果 python request模块使用requests基于urllb3, 使用更方便功能更丰富 GET请求相关请求参数添加 params参数可以方便的给请求增加参数, 省去手动编写URL 12345data = &#123; &#x27;arg1&#x27;: &#x27;1&#x27;, &#x27;arg2&#x27;: &#x27;2&#x27;&#125;response = request.get(&#x27;url&#x27;, params=data) json解析 提供了json方法, 可直接把返回的json字符串变成json对象 12response = request.get(&#x27;url&#x27;, params=data)response.json() 二进制数据获取 使用get请求直接请求图片即可, 然后写入的时候以’wb’形式写入文件即可 添加header 主要是为了保证获取成功, 有些网站会识别User-Agent以防止机器爬取 1234headers = &#123; &#x27;User-Agent&#x27;: &#x27;XXXX&#x27;&#125;response = requests.get(&#x27;url&#x27;, headers = headers) POST请求相关请求参数 &#x2F; 头添加 同GET部分(见上) response属性 常用属性包括: status_code headers cookies url history 状态码分析 requests库本身内置了状态码的分类情况, 所以直接调用内置的信息就可以快速判断请求是否正常&#x2F;成功, 比如response.status_code.ok就相当于200 12response = requests.get(&#x27;url&#x27;)exit() if response.status_code != response.status_code.ok else print(&#x27;All Right&#x27;) 代理设置123456proxy = &#123; &#x27;http&#x27;: &#x27;http://127.0.0.1:9743&#x27; &#x27;https&#x27;: &#x27;https://user:passwd@127.0.0.1:9743&#x27;&#125;response = requests.get(&#x27;url&#x27;, proxies=proxy) 如果要使用ss, 则需要另外安装插件 1pip install &#x27;requests[socks]&#x27; 12345proxy = &#123; &#x27;socks5&#x27;: &#x27;http://127.0.0.1:9743&#x27;&#125;response = requests.get(&#x27;url&#x27;, proxies=proxy) 超时设置可以结合try进行异常处理 1response = requests.get(&#x27;url&#x27;, timeout = 1) Selenium部分对于通过js获取数据并进行渲染展示的内容, 在分析页面请求的时候可能会有些东西找不到. 此时可以通过Selenium控制浏览器来进行操作. 虽然这样的效率不高, 但是对于我这种对Web相关的东西不熟的人来说非常适用. 元素查找模拟网页操作首先要找到需要操作元素的位置, Selenium提供了多种元素定位的方式, 当使用的是find_elememt会返回第一个找到的符合要求的元素, 而使用find_elememts则会以列表返回所有对象 12345678910browser = webdriver.Firefox()browser.get(&#x27;url&#x27;)browser.find_element_by_id(&#x27;123&#x27;)browser.find_element_by_name(&#x27;123&#x27;)browser.find_element_by_xpath(&#x27;123&#x27;)browser.find_element_by_link_text(&#x27;123&#x27;)browser.find_element_by_partial_link_text(&#x27;123&#x27;)browser.find_element_by_tag_name(&#x27;123&#x27;)browser.find_element_by_class_name(&#x27;123&#x27;)browser.find_element_by_css_selector(&#x27;123&#x27;) iframe定位一个网页可能是分了好几块的, 大的框架中可能内嵌了一个或多个iframe, 当位于大框架中时, 是无法搜索&#x2F;定位小框架内的内容的, 也就无法进行相应操作, 因此需要在操作前进行框切换 1234567browser = webdriver.Firefox()browser.get(&#x27;url&#x27;)# 根据名称切换到iframebrowser.switch_to.frame(&#x27;analyzeFrame&#x27;)# 切换回主框架browser.switch_to.default_content()# 没有测试在iframe内是否可切换到其他iframe 弹窗操作有时候部分操作会弹出一个警示框, 需要切换到这个框进行相应操作, 然后才能继续后续步骤 1234# 切换到弹窗al = browser.switch_to_alert()# 点击窗口的接受al.accpet() 浏览器设置变更有时需要对浏览器进行特殊设置后才能完成所需操作, 比如我某次爬取的数据可以通过点击一个下载按钮获得, 但是正常情况下点击下载按钮浏览器会弹出下载窗口并 12345678options = Options()# 前面一项是设置项名称, 后面的是对应值, 可设置的项目可以浏览器输入&#x27;about:config&#x27;查看options.set_preference(&quot;browser.download.folderList&quot;, 2)browser = webdriver.Firefox(firefox_options=options)# 下面这个是设置使用socks代理chrome_options = webdriver.ChromeOptions()chrome_options.add_argument(&#x27;--proxy-server=socks5://localhost:1080&#x27;)browser = webdriver.Chrome(chrome_options=chrome_options) 等待设定Selenium的所有操作会在页面加载完成之后才进行, 但是由于网络的问题, 如果等到加载完毕再执行非常影响效率(Selenium与纯靠代码发送请求的方式相比本来就比较没效率了), 所以可以通过一些设定在满足特定条件后立即执行相关操作. 比如下面就是等待一个特定的搜索按钮可以点击后, 再输入搜索内容并点击搜索. 123button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, &#x27;search-bar-btn&#x27;)))browser.find_element_by_class_name(&#x27;search-input&#x27;).send_keys(tar)button.click() 下载文件检查Selenium本身并不能完成下载文件的管理, 因此只能通过别的方式来进行下载文件管理&#x2F;重命名. 对于可以通过网页代码解析出下载链接的, 可以通过调用别的工具进行下载 对于解析不出下载链接的, 可以通过os模块的相关内容监视下载文件, 并在下载后进行移动及重命名 我当时使用的是下面俩部分代码加起来的: 123456789101112131415161718import os# 抄来的一段代码, 这个函数每隔5s时间检查文件的大小情况, 如果大小跟上一次检查时没有变化, 则判定下载完毕, 会关闭浏览器对象def wait_download(file_path, browser, rep_name): current_size = getSize(file_path) print(&quot;&#123;&#125; Downloading&quot;.format(str(current_size))) while current_size != getSize(file_path) or getSize(file_path)==0: current_size =getSize(file_path) print(&quot;current_size:&quot;+str(current_size)) time.sleep(5)# wait download print(&quot;Downloaded&quot;) os.rename(file_path, rep_name) browser.close()# 因为下载启动本身需要时间, 目标文件出现后才启动上面的函数while not os.path.exists(file_path): print(&#x27;waiting for download to start...&#x27;) time.sleep(5)wait_download(file_path, browser, rep_name) 关于模拟点击的坑Selenium可以模拟对按钮, 链接, 复选框等的点击, 但是点击的前提是, 这些元素必须处于可见范围, 否则点击会无效或者会抛出异常. 因此, 在实际操作时, 需要自己测试一下是否要滚动页面, 以及滚动多少能保证元素可以被点击得到. 123456# 切出iframebrowser.switch_to.default_content()# 滚动浏览器到底部browser.execute_script(&quot;window.scrollTo(0,document.body.scrollHeight)&quot;)# 切回iframebrowser.switch_to.frame(&#x27;analyzeFrame&#x27;) 杂项 一般第一个get请求得到的是网页的框架, 然后解析框架时再发出新的请求把需要的内容填充到页面 如果需要获得相应信息需要分析ajax请求 Selenium&#x2F;WebDriver Splash","categories":[{"name":"Script","slug":"Script","permalink":"https://silenwang.github.io/categories/Script/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://silenwang.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"requests","slug":"requests","permalink":"https://silenwang.github.io/tags/requests/"},{"name":"selenium","slug":"selenium","permalink":"https://silenwang.github.io/tags/selenium/"},{"name":"网页抓取","slug":"网页抓取","permalink":"https://silenwang.github.io/tags/%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96/"},{"name":"Web自动化","slug":"Web自动化","permalink":"https://silenwang.github.io/tags/Web%E8%87%AA%E5%8A%A8%E5%8C%96/"}]},{"title":"Python中的一些魔术方法","slug":"Python中的一些魔术方法","date":"2019-11-25T23:34:06.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2019/11/25/Python中的一些魔术方法/","permalink":"https://silenwang.github.io/2019/11/25/Python%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/","excerpt":"原来之前使用的__enter__和__exit__就是以前耳闻的魔术方法, 这次我的程序开发因为以面向对象为主, 为了实现一些python中好用的功能所以涉及到了更多方法, 这里做个小笔记","text":"原来之前使用的__enter__和__exit__就是以前耳闻的魔术方法, 这次我的程序开发因为以面向对象为主, 为了实现一些python中好用的功能所以涉及到了更多方法, 这里做个小笔记 __len__定义之后, 可以对实例使用len()函数. 12345def __len__(self): &#x27;&#x27;&#x27; 定义长度 &#x27;&#x27;&#x27; return len(self.Seq) __getitem__定以后, 可以对实例进行[]索引和切片操作 12345def __getitem__(self, key): &#x27;&#x27;&#x27; 添加切片索引 &#x27;&#x27;&#x27; return self.d[key] __str__定义后, 使用print()打印实例时会打印这个方法内返回的内容 12def __str__(self): return str(self.__dict__) __iter__定以后, 可对对象进行迭代操作, 比如for i in object这种. 需要注意的是, 这个方法必须要返回迭代器(可迭代对象不行). 12def __iter__(self): return (mut for mut in self.muts) __eq__和__hash__这两个放一起是因为把实例放在set()中, 想要自动去重时, 这两个都要有, 否则无法达到目的效果. 其中__eq__是使对象可被比较是否相同(==和!=, is好像不可以). 注意这个方法里的other好像是固定的, 不要改动. 12345def __eq__(self, other): &#x27;&#x27;&#x27; 保证利用set特性去重 &#x27;&#x27;&#x27; return self.muts == other.muts __hash__则本质上是对象可被哈希化, 哈希化时的哈希值会是这个方法给的哈希值 12345def __hash__(self): &#x27;&#x27;&#x27; 保证利用set特性去重 &#x27;&#x27;&#x27; return hash(self.muts) 暂时就这么多, 以后有用到新的继续水~","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"魔术方法","slug":"魔术方法","permalink":"https://silenwang.github.io/tags/%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/"},{"name":"面向对象","slug":"面向对象","permalink":"https://silenwang.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"特殊方法","slug":"特殊方法","permalink":"https://silenwang.github.io/tags/%E7%89%B9%E6%AE%8A%E6%96%B9%E6%B3%95/"}]},{"title":"Snakemake的动态解析特性","slug":"Snakemake的动态解析特性","date":"2019-11-24T23:00:31.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2019/11/24/Snakemake的动态解析特性/","permalink":"https://silenwang.github.io/2019/11/24/Snakemake%E7%9A%84%E5%8A%A8%E6%80%81%E8%A7%A3%E6%9E%90%E7%89%B9%E6%80%A7/","excerpt":"特么我终于成功使用这个特性了…我真是太南了…","text":"特么我终于成功使用这个特性了…我真是太南了… 在实际的流程中, 我们的流程可能会有一些”动态”的要求. 比如对fq进行比对, 或者对bam进行变异检测, 对应的比对&#x2F;检测软件可能并没有完善的多线程机制, 同时原始数据文件过分的大, 直接进行运算非常耗时. 这时候, 使用源文件拆分-&gt;多进程并行-&gt;结果文件合并就是一种非常实用的策略. 那么, 怎么拆呢? 我可以将文件按固定的方式来拆, 比如变异检测时经常会将bam按照染色体拆分开. 但是这种固定的拆分模式难免会出现效率不尽如人意的问题. 比如不同染色体的数据量是完全不一样的, 按染色体并行, 速度必然受数据量最大的那个染色体的限制. 但是如果不按照固定策略拆, 生成的拆分文件个数很可能是不固定的, 这与snakemake先解析要做什么再分配运行的逻辑冲突, 因此开发者在较新的版本中引入了动态解析机制(Data-dependent conditional execution). 这个机制的核心是checkpoint, 检查点是一种特殊的rule, 其在运行时与rule没有太大不同, 但是, 在流程运行到检查点后, 整个依赖图(DAG)会重新进行解析. 设计者的用意很明显: 将产生不定结果的规则设定为检查点, 在不定的文件实际产生后重新决定需要进行的步骤. 由于这个动态机制十分特殊, 因此检查点使用起来也比较麻烦, 无法像rule一样简单的使用. 首先checkpoint必须配合function input使用, 因为虽然加了新机制, 但是这个程序的运行逻辑依然是决定做什么然后分配. 而决定做什么这一点不是程序能自己决定的, 需要我们手动设计, 因此必须使用一个函数去获取检查点生成的文件, 然后将这些文件交给下游rule去解析. 我这有一个比官网那个稍微好理解点的例子: 123456789101112131415161718192021222324252627282930313233343536373839404142from os import pathfrom glob import globrule all: input: &quot;&#123;sample&#125;.all.stat&quot;.format(sample=&quot;NL180614-2_S12_L001_R1_001&quot;)checkpoint split: input: &quot;&#123;sample&#125;.fastq.gz&quot; output: touch(&quot;&#123;sample&#125;.splt.done&quot;) shell: &quot;split -l 1000000 &#123;input&#125; &#123;wildcards.sample&#125;.split. &quot;rule wc: input: &quot;&#123;sample&#125;.split.&#123;split&#125;&quot; output: &quot;&#123;sample&#125;.split.&#123;split&#125;.stat&quot; shell: &quot;wc -l &#123;input&#125; &gt; &#123;output&#125;&quot;def get_split_files(wildcards): split_output = checkpoints.split.get(**wildcards).output[0] split_dir = path.split(split_output)[0] split_files = glob(f&quot;*.split.*&quot;) tar_files = [f&quot;&#123;f&#125;.stat&quot; for f in split_files] return tar_filesrule cat: input: get_split_files output: &quot;&#123;sample&#125;.all.stat&quot; shell: &#x27;&#x27;&#x27; cat &#123;input&#125; &gt; &#123;output&#125; &#x27;&#x27;&#x27; 这个例子实现的是使用split将fq文件拆分成多个子文件, 分别计数行数然后将结果合并成一个文件. checkpoint的部分是拆分, 同时这个rule产生了一个不交由下游解析的结果, 也就是完全依赖无关. 真正有用的其实是checkpoint本身. get_split_files()函数中使用了checkpoints对象, 并且使用了其下split这个检查点的内容, 因此以这个函数作为输入的cat规则上游依赖是checkpoint split, 同时其也不会进行真正的依赖解析, 而是等待它的checkpoint split完成后再解析(也就是动态解析). 官方文档的例子基本也是这个原理, 只不过其checkpoint生成了目录结果, 以方便重解析生成的动态文件. 最后再补充一个bwa的例子: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from os import pathfrom glob import globwildcard_constraints: sample=r&quot;[A-Z,a-z,0-9,-]+&quot;rule all: input: &quot;&#123;sample&#125;.srt.bam&quot;.format(sample=&quot;NL180614-2&quot;)checkpoint split: input: fq1=&quot;&#123;sample&#125;_S12_L001_R1_001.fastq.gz&quot;, fq2=&quot;&#123;sample&#125;_S12_L001_R2_001.fastq.gz&quot;, output: directory(&quot;&#123;sample&#125;_tmp&quot;) shell: &#x27;&#x27;&#x27; mkdir -p &#123;output&#125;/R1 mkdir -p &#123;output&#125;/R2 zcat &#123;input.fq1&#125; | split -l 1000000 /dev/stdin &#123;output&#125;/R1/split. zcat &#123;input.fq2&#125; | split -l 1000000 /dev/stdin &#123;output&#125;/R2/split. &#x27;&#x27;&#x27;rule bwa: input: r1=&quot;&#123;sample&#125;_tmp/R1/split.&#123;split&#125;&quot;, r2=&quot;&#123;sample&#125;_tmp/R2/split.&#123;split&#125;&quot;, output: &quot;&#123;sample&#125;_tmp/split.&#123;split&#125;.srt.bam&quot; shell: &#x27;&#x27;&#x27; bwa mem -t 4 -M \\\\ -R &quot;@RG\\\\tID:&#123;wildcards.sample&#125;\\\\tPL:Illumina\\\\tPU:&#123;wildcards.sample&#125;\\\\tSM:&#123;wildcards.sample&#125;&quot; \\\\ /home/silen/git/Bio_Test/hg38-bwa/hg38.fa \\\\ &#123;input.r1&#125; \\\\ &#123;input.r2&#125; \\\\ | samtools view -Sb -@ 4 \\\\ | samtools sort -@ 4 \\\\ &gt; &#123;output&#125; &#x27;&#x27;&#x27;def get_split_files(wildcards): split_dir = checkpoints.split.get(**wildcards).output[0] split_files_r1 = glob(f&quot;&#123;split_dir&#125;/R1/split.*&quot;) split_tag = [s.split(&quot;.&quot;)[-1] for s in split_files_r1] split_bams = [path.join(split_dir,f&quot;split.&#123;tag&#125;.srt.bam&quot;) for tag in split_tag] return split_bamsrule cat: input: get_split_files output: &quot;&#123;sample&#125;.srt.bam&quot; shell: &#x27;&#x27;&#x27; samtools merge -f &#123;output&#125; &#123;input&#125; &#x27;&#x27;&#x27; 目前已经在自己的一些项目中使用过这个特性了, 实际使用的感受是, 看上去很简单通用, 但是实际上碰到不同的问题还要结合软件情况不同考虑… 比如上面这个bwa的例子就尚有一个问题要解决: 这里生成的目录其实是临时目录, 我希望能在使用后删去, 但是现在temp和directory两个关键字是冲突的, 而临时文件夹中的文件是动态的, 没有办法直接指定, 因此暂时没法利用snakemake自有的特性自动删除.","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"并行计算","slug":"并行计算","permalink":"https://silenwang.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"},{"name":"snakemake","slug":"snakemake","permalink":"https://silenwang.github.io/tags/snakemake/"},{"name":"工作流管理","slug":"工作流管理","permalink":"https://silenwang.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%AE%A1%E7%90%86/"},{"name":"checkpoint","slug":"checkpoint","permalink":"https://silenwang.github.io/tags/checkpoint/"},{"name":"DAG","slug":"DAG","permalink":"https://silenwang.github.io/tags/DAG/"}]},{"title":"让自写的对象可以用上with","slug":"让自写的对象可以用上with","date":"2019-11-14T18:56:24.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2019/11/14/让自写的对象可以用上with/","permalink":"https://silenwang.github.io/2019/11/14/%E8%AE%A9%E8%87%AA%E5%86%99%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%8F%AF%E4%BB%A5%E7%94%A8%E4%B8%8Awith/","excerpt":"with open是python中特别方便的一种写法, 对于支持的函数来说, 有了with这个语句可以很方便的在操作完成时自动关闭对象. 对于自己编写的对象其实也可以实现with语法的支持.","text":"with open是python中特别方便的一种写法, 对于支持的函数来说, 有了with这个语句可以很方便的在操作完成时自动关闭对象. 对于自己编写的对象其实也可以实现with语法的支持. 具体的做法就是在自己的class中定义__enter__和__exit__两个方法: 1234567class MyClass(object): def __init__(self): pass def __enter__(self): print(&quot;Start&quot;) def __exit__(self, exc_type, exc_val, exc_tb): print(&quot;End&quot;) 如此一来, 在使用with时就会先执行__enter__内的内容, 在代码块结束的时候则自动执行__exit__的内容了. 123456&gt;&gt;&gt; with MyClass() as tClass:... print(&quot;test&quot;)...StarttestEnd","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"魔术方法","slug":"魔术方法","permalink":"https://silenwang.github.io/tags/%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/"},{"name":"上下文管理器","slug":"上下文管理器","permalink":"https://silenwang.github.io/tags/%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8/"},{"name":"with语句","slug":"with语句","permalink":"https://silenwang.github.io/tags/with%E8%AF%AD%E5%8F%A5/"},{"name":"__enter__","slug":"enter","permalink":"https://silenwang.github.io/tags/enter/"},{"name":"__exit__","slug":"exit","permalink":"https://silenwang.github.io/tags/exit/"}]},{"title":"猛汉王狩猎日记_历战爆鳞龙","slug":"猛汉王狩猎日记-历战爆鳞龙","date":"2019-10-30T22:47:37.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2019/10/30/猛汉王狩猎日记-历战爆鳞龙/","permalink":"https://silenwang.github.io/2019/10/30/%E7%8C%9B%E6%B1%89%E7%8E%8B%E7%8B%A9%E7%8C%8E%E6%97%A5%E8%AE%B0-%E5%8E%86%E6%88%98%E7%88%86%E9%B3%9E%E9%BE%99/","excerpt":"男人的浪漫除了爆炸…还有社保! 沉迷狩猎…荒废事业ing…","text":"男人的浪漫除了爆炸…还有社保! 沉迷狩猎…荒废事业ing…","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"Monster Hunter World","slug":"Monster-Hunter-World","permalink":"https://silenwang.github.io/tags/Monster-Hunter-World/"},{"name":"怪物猎人世界","slug":"怪物猎人世界","permalink":"https://silenwang.github.io/tags/%E6%80%AA%E7%89%A9%E7%8C%8E%E4%BA%BA%E4%B8%96%E7%95%8C/"},{"name":"历战爆鳞龙","slug":"历战爆鳞龙","permalink":"https://silenwang.github.io/tags/%E5%8E%86%E6%88%98%E7%88%86%E9%B3%9E%E9%BE%99/"},{"name":"狩猎","slug":"狩猎","permalink":"https://silenwang.github.io/tags/%E7%8B%A9%E7%8C%8E/"},{"name":"Bazelgeuse","slug":"Bazelgeuse","permalink":"https://silenwang.github.io/tags/Bazelgeuse/"}]},{"title":"猛汉王狩猎日记_樱火龙","slug":"猛汉王狩猎日记-樱火龙","date":"2019-10-06T12:11:48.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2019/10/06/猛汉王狩猎日记-樱火龙/","permalink":"https://silenwang.github.io/2019/10/06/%E7%8C%9B%E6%B1%89%E7%8E%8B%E7%8B%A9%E7%8C%8E%E6%97%A5%E8%AE%B0-%E6%A8%B1%E7%81%AB%E9%BE%99/","excerpt":"果然就像我当年买了平板看了两天书之后就开始玩PSP模拟器一样…这次买了电脑也没有用来做软件测试太久…直接就被我用来打猛汉王了…我甚至还折腾了如何在宿主机上录客户机的视频…在折腾了一整天后最终选择了视频音频双串流…分别通过looking-glass和scream两个项目将视频和音频都串回宿主机, 然后在宿主机使用OBS进行录制. 至于你问我为啥不客户机直接录…那就不能体现抖m的本质了鸭! 奉上测试用的, 打得没有任何技术含量的樱火龙…","text":"果然就像我当年买了平板看了两天书之后就开始玩PSP模拟器一样…这次买了电脑也没有用来做软件测试太久…直接就被我用来打猛汉王了…我甚至还折腾了如何在宿主机上录客户机的视频…在折腾了一整天后最终选择了视频音频双串流…分别通过looking-glass和scream两个项目将视频和音频都串回宿主机, 然后在宿主机使用OBS进行录制. 至于你问我为啥不客户机直接录…那就不能体现抖m的本质了鸭! 奉上测试用的, 打得没有任何技术含量的樱火龙…","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"怪物猎人世界","slug":"怪物猎人世界","permalink":"https://silenwang.github.io/tags/%E6%80%AA%E7%89%A9%E7%8C%8E%E4%BA%BA%E4%B8%96%E7%95%8C/"},{"name":"樱火龙","slug":"樱火龙","permalink":"https://silenwang.github.io/tags/%E6%A8%B1%E7%81%AB%E9%BE%99/"},{"name":"视频录制","slug":"视频录制","permalink":"https://silenwang.github.io/tags/%E8%A7%86%E9%A2%91%E5%BD%95%E5%88%B6/"},{"name":"looking-glass","slug":"looking-glass","permalink":"https://silenwang.github.io/tags/looking-glass/"},{"name":"scream","slug":"scream","permalink":"https://silenwang.github.io/tags/scream/"},{"name":"OBS","slug":"OBS","permalink":"https://silenwang.github.io/tags/OBS/"}]},{"title":"大逆转裁判, 通关撒花\\(￣▽￣)/","slug":"大逆转裁判","date":"2019-10-05T18:49:39.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2019/10/05/大逆转裁判/","permalink":"https://silenwang.github.io/2019/10/05/%E5%A4%A7%E9%80%86%E8%BD%AC%E8%A3%81%E5%88%A4/","excerpt":"大逆转裁判通关了, 个人感觉这一作甚至在之前的成步堂三部曲之上, 因为与它们相比, 这一作没有超自然的元素, 故事中关于证据的部分更合理了一些(不是随便搬个物品&#x2F;人出来就能当证据). 当然, 在一个以推理的游戏性为重心的游戏里寻找合理性…我可能也是搞错了什么吧~","text":"大逆转裁判通关了, 个人感觉这一作甚至在之前的成步堂三部曲之上, 因为与它们相比, 这一作没有超自然的元素, 故事中关于证据的部分更合理了一些(不是随便搬个物品&#x2F;人出来就能当证据). 当然, 在一个以推理的游戏性为重心的游戏里寻找合理性…我可能也是搞错了什么吧~","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"游戏评测","slug":"游戏评测","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E8%AF%84%E6%B5%8B/"},{"name":"大逆转裁判","slug":"大逆转裁判","permalink":"https://silenwang.github.io/tags/%E5%A4%A7%E9%80%86%E8%BD%AC%E8%A3%81%E5%88%A4/"},{"name":"推理游戏","slug":"推理游戏","permalink":"https://silenwang.github.io/tags/%E6%8E%A8%E7%90%86%E6%B8%B8%E6%88%8F/"},{"name":"成步堂三部曲","slug":"成步堂三部曲","permalink":"https://silenwang.github.io/tags/%E6%88%90%E6%AD%A5%E5%A0%82%E4%B8%89%E9%83%A8%E6%9B%B2/"},{"name":"game-review","slug":"game-review","permalink":"https://silenwang.github.io/tags/game-review/"},{"name":"ace-attorney","slug":"ace-attorney","permalink":"https://silenwang.github.io/tags/ace-attorney/"},{"name":"the-great-ace-attorney","slug":"the-great-ace-attorney","permalink":"https://silenwang.github.io/tags/the-great-ace-attorney/"}]},{"title":"编写Dockerfile构建docker镜像","slug":"编写Dockerfile构建docker镜像","date":"2019-10-05T16:58:54.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2019/10/05/编写Dockerfile构建docker镜像/","permalink":"https://silenwang.github.io/2019/10/05/%E7%BC%96%E5%86%99Dockerfile%E6%9E%84%E5%BB%BAdocker%E9%95%9C%E5%83%8F/","excerpt":"从过去的经验来看…我有很多的技能都属于副产物…今天这个也是, 我的本意在于使用网易提供的NemuBox源代码编译出一个网易改进过的Virtualbox, 结果…我学了几样跟docker有关的技能…","text":"从过去的经验来看…我有很多的技能都属于副产物…今天这个也是, 我的本意在于使用网易提供的NemuBox源代码编译出一个网易改进过的Virtualbox, 结果…我学了几样跟docker有关的技能… 镜像的构建是docker的基本, 虽然也可以每次创建好基础镜像后进入手动构建或者通过类似dockerhub这样的平台直接拉取, 但是前者耗时且重复性差, 后者对网络有一定要求且自定义性差. 掌握编写和修改Dockerfile这一构建图纸的使用方法还是很必要的. 况且…其实这东西也非常简单. 我在Dockerfile中可能会用的比较多的关键字有: FROM: 指定构建的基础镜像, 在构建开始前会pull指定的镜像作为构建基础. COPY: 从外部(宿主流经)复制文件到镜像内, 第一个参数是外部路径, 第二个参数是内部路径, 具体参数用法类似cp, 似乎不能多个文件同时使用, 没有尝试过通配符是否有效 ADD: 类似COPY, 但是ADD可以获取网络上的文件, 这在向其他地方部署容器时非常有用 RUN: 需要执行的命令 WORKDIR: 构建好的镜像在启动时进入的目录 CMD: 构建好的镜像在启动时运行的命令 这里COPY和RUN两个命令需要特别注意: COPY这个关键字在复制外部路径时, 只能获取docker build制定的构建路径下以及其下层的文件. 这个时是受docker运行时**上下文(context)**的限制. RUN命令每运行一次都会产生一层新镜像, 如果不是必须的, 最好精简需要运行的命令, 并将其以&amp;&amp;连接在同一个RUN下, 防止构建的镜像又大又慢. 这里我写一个之前工作时需要部署的R包sscClust的例子: 123456789101112131415161718192021222324252627282930313233## sscClust Dockerfile## https://github.com/dockerfile/fpm## Pull base image.FROM centos:7# Install dep-packagesRUN yum install -y epel-release wget \\ &amp;&amp; mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak \\ &amp;&amp; mv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.bak \\ &amp;&amp; wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo \\ &amp;&amp; wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo \\ &amp;&amp; yum clean all \\ &amp;&amp; yum makecache -y \\ &amp;&amp; yum install -y R openssl-devel libcurl-devel libxml2-devel gsl-devel \\ &amp;&amp; mkdir -p /install_script# Install R packagesCOPY install.r /install_script/install.rRUN Rscript /install_script/install.r# Define working directory.WORKDIR /# Define default command.CMD /bin/bash 其中涉及的R脚本为: 12345options(&quot;repos&quot; = c(CRAN=&quot;https://mirrors.ustc.edu.cn/CRAN/&quot;))options(BioC_mirror=&quot;http://mirrors.ustc.edu.cn/bioc/&quot;)install.packages(c(&quot;BiocManager&quot;, &quot;devtools&quot;))BiocManager::install(c(&#x27;SingleCellExperiment&#x27;, &#x27;scran&#x27;, &#x27;SC3&#x27;, &#x27;zinbwave&#x27;, &#x27;BiocParallel&#x27;))devtools::install_github(&quot;Japrin/sscClust&quot;) 执行docker build -t=test_docker .使用上面文件构建镜像 当然现在已经不保证这个例子能顺利构建了, 因为软件总是在不断更新, 而我的构建过程没有任何指定特定版本软件的内容, 随着时间的推进, 很有可能会出现各种依赖爆炸…不过作为使用记录还是阔以哒~","categories":[{"name":"Script","slug":"Script","permalink":"https://silenwang.github.io/categories/Script/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://silenwang.github.io/tags/Docker/"},{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"Dockerfile","slug":"Dockerfile","permalink":"https://silenwang.github.io/tags/Dockerfile/"},{"name":"容器化","slug":"容器化","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8%E5%8C%96/"},{"name":"镜像构建","slug":"镜像构建","permalink":"https://silenwang.github.io/tags/%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA/"}]},{"title":"在Linux系统中添加自定义服务","slug":"在Linux系统中添加自定义服务","date":"2019-10-05T16:00:31.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2019/10/05/在Linux系统中添加自定义服务/","permalink":"https://silenwang.github.io/2019/10/05/%E5%9C%A8Linux%E7%B3%BB%E7%BB%9F%E4%B8%AD%E6%B7%BB%E5%8A%A0%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1/","excerpt":"使用Linux系统的时候经常会需要设置一些开机自启动的东西, 对于使用systemd的发行版, 自行编写服务文件并启用是个非常不错的选择.","text":"使用Linux系统的时候经常会需要设置一些开机自启动的东西, 对于使用systemd的发行版, 自行编写服务文件并启用是个非常不错的选择. 服务文件采用类似ini格式的配置文件编写, 一个基本的服务配置文件包含如下内容: Unit: 定义的部分, 比如说明什么的 Service: 实际执行执行内容, 包括这个服务是啥类型, 启动时要做什么, 结束时要做什么, 重启要做什么之类的 Install: 基本都是以来关系, 比如服务什么时候启动, 或者在XX之前&#x2F;之后启动 下面是一个v2ray服务的例子: 12345678910[Unit]Description=Daemon to start V2ray[Service]Type=simpleExecStart=/usr/bin/v2ray -config /home/silen/script/v2ray/v2ray.json[Install]Alias=v2rayWantedBy=default.target 这个服务如果开启了, 则默认自动启动(WantedBy=default.target), 启动时执行命令/usr/bin/v2ray -config /home/silen/script/v2ray/v2ray.json, 也就是开启v2ray代理. 对于服务的其他动作, 比如重启停止之类没有作定义. 写好上面的文件后就可以把这个文件命名为v2ray.service放到指定的位置(/etc/systemd/system或/usr/lib/systemd/system), 然后以root权限使用systemctl enable v2ray.service就可以激活服务(开机后根据配置情况启动), 使用systemctl start v2ray.service则可立刻启动服务. 需要注意的是, 调用root权限去启动服务, 那么执行用户也自然是root, 这在某些情况下并不是一个好选择. 因此我之前的同步服务和这次的v2ray服务实际都是以个人用户的权限去开启的. 也就是将上面的服务文件放到/home/&lt;user&gt;/.config/systemd/user下, 然后直接systemctl start --uesr v2ray.service来启动服务. 这种情况下的服务只会在我当前用户登入后才开始执行, 并且也不需要root权限(用户需要不需要在root group中我倒不清楚). 示例中使用的v2ray程序属于占着前台不放的类型, 因此可以直接使用simple类型. 除了该类型还有: simple, forking, oneshot, notify, dbus, idle 当然我自定义的服务一般也就很简单, sample和oneshot应该够用了. 至于ExecStart, ExecStop, 和ExecReload, 前者是必须的, 后两者则可根据启动命令的情况选择是否需要编写. 最后是Install里的WantedBy=default.target这个根据我的尝试是必须加的, 因为不加服务不会自动启动…不知道是不是只有user层面的服务才会这样","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"systemd","slug":"systemd","permalink":"https://silenwang.github.io/tags/systemd/"},{"name":"服务管理","slug":"服务管理","permalink":"https://silenwang.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"},{"name":"自定义服务","slug":"自定义服务","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1/"},{"name":"service","slug":"service","permalink":"https://silenwang.github.io/tags/service/"}]},{"title":"台式机置备计划(下)","slug":"台式机置备计划-2","date":"2019-09-08T12:35:13.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2019/09/08/台式机置备计划-2/","permalink":"https://silenwang.github.io/2019/09/08/%E5%8F%B0%E5%BC%8F%E6%9C%BA%E7%BD%AE%E5%A4%87%E8%AE%A1%E5%88%92-2/","excerpt":"在千辛万苦搞定了硬件之后, 接下来就是软件了.","text":"在千辛万苦搞定了硬件之后, 接下来就是软件了. 按照我之前的规划, 我的机器需要达到一机多用的效果: 宿主机linux用来做计算, 虚拟机windows用来打游戏. 但凡用过虚拟机的人应该都知道…虚拟机的性能一直是个的问题, 就算牛X如vmware和mac专属的parallel, 其图形性能也还是不如原生硬件. 因此也就有了PCI Passthrough这种技术, 即将PCI插槽上的设备从宿主机屏蔽, 直接分配给虚拟机使用. 获得了实际的硬件, 没有中间商, 性能也就几乎与原生无异了. 这也是我当初买了个有两条显卡PCI插槽主板的原因, 因为如果日后要虚拟出两台打游戏用的电脑, 必须给每台机器都分配一张显卡, 然后宿主机启动也是要显卡的, 所以CPU需要有内建显卡. 本次虚拟化配置我使用的宿主系统为Manjaro, 参考的文档&#x2F;视频包括: ArchWiki上的GPU Passthrough教程 Linus Tech Tips的虚拟MacOS视频 INVALID POST SLUG PROVIDED 由于这份配置是在基于Arch的发行版上进行的, 因此具体设置用的命令和组件会和中文网站中搜索到的材料比较不一样(基本都是基于Ubuntu的). 操作步骤1. 准备系统盘 宿主系统: manjaro-architect-18.0.4-stable, 基于Arch的衍生发行版, 特点是简单易上手, 虽然被Arch教派认为是邪道, 单阻止不了其越来越高的人气(甚至我昨天看到Manjaro的社区和Ubuntu一样开了个公司). 使用architect而不是预搭载桌面的livecd主要是因为镜像小, 所有软件包全程联网下载就好. 子系统: 与宿主系统不一样, 子系统除了准备一份要安装到宿主机中的windows之外, 可能还需要准备一份支持EFI启动的ISO镜像. 因为ArchWiki上的教程使用了OVMF(这会让直通更简单, 少一些在虚拟BIOS上配置的过程), 用了这东西之后虚拟机内使用的就是EFI(only), 而不是BIOS了. 这就要求安装系统的ISO镜像一定要支持EFI启动. 但是我下载了很多个系统安装镜像都不支持…因此只好专门找了个支持UEFI的PE镜像, 用这个镜像引导启动, 然后安装另外一份安装镜像上的系统. 2. 安装宿主系统使用宿主系统盘在电脑上安装好Manjaro, 详细步骤其他地方找得到, 我这里就先略了, 以后有空再补截图(咕咕咕). 3. 进行GPU隔离设置进行直通就是让虚拟机直接使用被直通的硬件, 因此需要防止宿主机对硬件进行访问. 具体设置为: 启动IOMMU 打开配置文件(/etc/default/grub)更改内核参数, 以启用IOMMU: 1234...GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet udev.log_priority=3 audit=0 amd_iommu=on iommu=pt&quot;GRUB_CMDLINE_LINUX=&quot;&quot;... 进行上面的编辑后需要重新生成生成&#96;grub.cfg: 1sudo grub-mkconfig -o /boot/grub/grub.cfg 编辑配置文件使用vcfio屏蔽准备隔离的显卡组件 使用lspci -nnk命令查看所有的PCI硬件信息, 从中找到需要直通的硬件, 并记录其ID: 1234567801:00.0 VGA compatible controller [0300]: Advanced Micro Devices, Inc. [AMD/ATI] Baffin [Radeon RX 460/560D / Pro 450/455/460/555/555X/560/560X] [1002:67ef] (rev e5) Subsystem: Tul Corporation / PowerColor Baffin [Radeon RX 460/560D / Pro 450/455/460/555/555X/560/560X] [148c:2385] Kernel driver in use: vfio-pci Kernel modules: amdgpu01:00.1 Audio device [0403]: Advanced Micro Devices, Inc. [AMD/ATI] Baffin HDMI/DP Audio [Radeon RX 550 640SP / RX 560/560X] [1002:aae0] Subsystem: Tul Corporation / PowerColor Baffin HDMI/DP Audio [Radeon RX 550 640SP / RX 560/560X] [148c:aae0] Kernel driver in use: vfio-pci Kernel modules: snd_hda_intel 上面的信息是我屏蔽之后的信息, 因此两个设备的Kernel driver in use都显示为vfio-pci, 代表屏蔽成功, 屏蔽前应该是安装系统时安装的开源驱动; 需要记录的ID跟在设备名称的中括号中, 在上面的例子中分别是显示设备[148c:2385]和音频设备[1002:aae0](现在的显卡很多都带音频输出…所以会显示为两个设备实际是要一起屏蔽的) 创建/etc/modprobe.d/vfio.conf, 并在其中加入options vfio-pci ids=&lt;id to block&gt; 编辑/etc/mkinitcpio.conf, 在其中找到下面项目并添加如相应内容: 12345...MODULES=(... vfio_pci vfio vfio_iommu_type1 vfio_virqfd ...)...HOOKS=(... modconf ...)... 编辑完成之后, 更改是不会生效的, 需要重新生成initramfs: 注意: 由于我对这个东西是什么并没有概念, 并且ArchWiki上相关的内容我也看不懂, 所以这里记录的是我进行的实际操作, 并不保证是最正确的操作 执行命令重新生成/boot下的启动用img文件: sudo mkinitcpio -g /boot/initramfs-4.19-x86_64.img(建议把原来的备份) 覆盖原来的img后, 需要重新启动宿主机, 如果设置成功, 则对应设备的驱动应该为vfio-pci 在进行覆盖后, 宿主系统无法访问被屏蔽的硬件, 如果有需要访问的, 可以在启动时在grub菜单选择通过initramfs-4.19-x86_64-fallback.img启动, 这个没有被改动过, 可以正常访问硬件. 4. 安装并配置虚拟机在做好硬件的设置后, 下面就要进行软件的配置了. 安装虚拟机管理软件 tip: 这里安装的是使用虚拟机的软件QEMU和简化QEMU设置的VirtManager和libvirt, kvm本身是linux内核中的一个模块, 只要在主板中设置开启虚拟化就可以使用了, 无须另外安装什么 1sudo pacman -S qemu libvirt virt-manager ovmf 创建虚拟机 打开virt-manager, 点击创建虚拟机 选择安装镜像(非启动用), 由于下载的镜像不是官方的, 无法自动识别是啥系统, 所以去掉自动检测然后手动选择Win10然后进入下一步 CPU和内存分配 选择创建镜像(没啥特殊图略…) 确认信息, 选择网络为桥接, 并选择进一步编辑 分配需要直通的设备 由于我手头的安装镜像不支持UEFI启动, 因此另外找了一个支持但是里面没有安装文件的启动镜像, 需要对启动顺序做点小设置, 保证挂载启动镜像并从它启动 编辑CPU信息, 主要是勾选复制主机CPU配置(等同于host-model) 编辑使用的BIOS为OVMF(具体参照ArchWiki, 图忘截了…) 点击左上角的开始安装正常安装系统即可 5. 音频设备BUG修复及其他在完成上述步骤安装好系统后, 一台有物理显卡的虚拟机就搞定了, 将显卡的显示接口接到任意显示设备就能快乐的玩游戏了. 但是这时依然存在一个问题, 虽然显卡是自带音频设备的, 理论上一条HDMI线就可以把音频传到我显示器的扬声器上播放才是. 但是实际上在虚拟机里面连没有找到显卡附带的音频设备. 这个问题苦恼了我一个星期, 最后在Promox(一个专门用来作虚拟化宿主的发行版)的论坛上看到了类似的问题, 说这个问题是Q35 4.0的一个Bug导致的, 可以在虚拟机配置文件中将版本回退到3.1来解决. 因此我们需要手动编辑虚拟机的XML配置文件(需要打开直接编辑的选项), 找到对应的条目改成如下配置: 123...&lt;type arch=&quot;x86_64&quot; machine=&quot;pc-q35-3.1&quot;&gt;hvm&lt;/type&gt;... 终于…可以坐下来好好玩游戏了~~~~~ 后记: 一篇9.8就开始写的博文硬生生被我鸽到了快10.8……猛汉王果然魅力巨大….","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Manjaro","slug":"Manjaro","permalink":"https://silenwang.github.io/tags/Manjaro/"},{"name":"显卡直通","slug":"显卡直通","permalink":"https://silenwang.github.io/tags/%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A/"},{"name":"KVM","slug":"KVM","permalink":"https://silenwang.github.io/tags/KVM/"},{"name":"QEMU","slug":"QEMU","permalink":"https://silenwang.github.io/tags/QEMU/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://silenwang.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"AMD显卡","slug":"AMD显卡","permalink":"https://silenwang.github.io/tags/AMD%E6%98%BE%E5%8D%A1/"},{"name":"Windows虚拟机","slug":"Windows虚拟机","permalink":"https://silenwang.github.io/tags/Windows%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"音频设备","slug":"音频设备","permalink":"https://silenwang.github.io/tags/%E9%9F%B3%E9%A2%91%E8%AE%BE%E5%A4%87/"}]},{"title":"台式机置备计划(上)","slug":"台式机置备计划_1","date":"2019-09-02T22:24:41.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2019/09/02/台式机置备计划_1/","permalink":"https://silenwang.github.io/2019/09/02/%E5%8F%B0%E5%BC%8F%E6%9C%BA%E7%BD%AE%E5%A4%87%E8%AE%A1%E5%88%92_1/","excerpt":"本年年初的时候, 本来存了2000块, 准备用来买个二手服务器, 用来在测试软件之余顺便打打游戏. 但是看来看去, 感觉服务器还是太麻烦了…耗电大, 噪音也大, 如果要加装显卡还得改造…毕竟我在硬件方面毫无经验…所以最后还是改为了买个够用且够便宜的台式机. 本来我618都要下手了…可是碰上工作变动, 没有时间精力折腾, 于是作罢…前端时间看上的主板又在京东打特价, 终于没忍住剁了手…可是一查才发现…看中的CPU全网都很难买到全新了…(怕不是618全清完了), 几经周折, 最后好不容易把所有东西买全, 组起了我人生第一台自主组装的台式机~","text":"本年年初的时候, 本来存了2000块, 准备用来买个二手服务器, 用来在测试软件之余顺便打打游戏. 但是看来看去, 感觉服务器还是太麻烦了…耗电大, 噪音也大, 如果要加装显卡还得改造…毕竟我在硬件方面毫无经验…所以最后还是改为了买个够用且够便宜的台式机. 本来我618都要下手了…可是碰上工作变动, 没有时间精力折腾, 于是作罢…前端时间看上的主板又在京东打特价, 终于没忍住剁了手…可是一查才发现…看中的CPU全网都很难买到全新了…(怕不是618全清完了), 几经周折, 最后好不容易把所有东西买全, 组起了我人生第一台自主组装的台式机~ 配件列表我的配置思路有点特别, 因为我对这台机器的预期有些特别. 我希望用它来满足一下所有需求: 个人生信计算测试(多核心+大内存+linux) 个人基本游戏需要(入门显卡+win) 一机虚拟化为多机, 和女票一起打游戏(入门显卡x2+linux+显卡直通+win虚拟机) 机箱不要太大, 尽量小而美观 综上, 我最后选了一个4内存插槽, 2显卡插槽的M-ATX的主板, 为的就是日后能上32G甚至64G内存(一些研究机构开发的原型软件内存开销巨大), 并且能上双显卡以虚拟化出两台Win机器. CPU方面就比较糟心, 因为宿主机需要, 集成显卡是必须的, 我又想支持AMD…所以本质上没得选, 现阶段只有2400G一个型号能用… 完整配件清单如下: 组件 型号 平台 价格 备注 处理器 AMD Ryzen 2400G 淘宝 760 二手散片 显卡 迪兰恒进 RX560d 4G 淘宝 245 二手矿卡 主板 技嘉 B450M DS3H 京东 499 买完又降了50… 内存 十铨 火神DDR4 3000 8G x 2 京东 498 机箱 Thermaltake 启航者S3 京东 129 电源 Thermaltake Smart RGB 600W 京东 278 没看清…买了非模组化… 散热器 Thermaltake 彩虹D400P 京东 85 没看清…65W的CPU上了150W的散热器… 总计 2494 (760+245+499+498+129+278+85&#x3D;2494) 确实挺便宜的… 买台式配件真的是比买笔记本复杂很多…我买的过程中就碰到了: CPU没货只好买二手散片, 结果二手散片也全网缺货, 来回找了三家才买到, 还从第一家那赚了30块的申诉赔偿(没货却不下架)… 显卡虽然知道是矿卡…但是没注意我买的这块是单DVI接口的…无奈后续补了个转换器 主板虽然有双显卡槽, 但是没法直接插俩显卡, 因为下面的显卡插槽会挡住PIN线和USB3.0的线, 需要额外转接头 看中的电源没货, 买替代的时候没注意替代的是非模组化电源…后续理线头疼 散热器的尺寸超出我想象…还好机箱买的比较大… 机箱比想象大好多…没想到跟散热歪打正着… 买配件就够复杂了…后续装机坑也是一个接一个: 散热器风扇装反, 重装卡歪了…以后有点难取下来… 非模组电源理线糟心 硬盘架装反, 差点拔不出来 没注意看风散热器说明书, 散热器装了两个半小时 在前前后后折腾了将近两个星期后, 终于是把一切弄好了…作为缓冲, 先装了win10测试玩猛汉王. 比较惊喜的是原来2400G已经可以720p低画质流畅游戏了…而且我用的房东的电视…720p和1080p在这个电视上其实没有特别明显的差别…也就是说如果我只是买一台机器玩猛汉王, 砍掉8G内存(250), CPU直接买2200G加A320M的套装(1000以诶), 电源用100多块机箱送的300W电源, 甚至1500左右都可以玩猛汉王了…如此依赖…猛汉王真是亲民… 以上微制备计划的硬件篇, 回头更新更糟心的软件篇~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"台式机","slug":"台式机","permalink":"https://silenwang.github.io/tags/%E5%8F%B0%E5%BC%8F%E6%9C%BA/"},{"name":"硬件配置","slug":"硬件配置","permalink":"https://silenwang.github.io/tags/%E7%A1%AC%E4%BB%B6%E9%85%8D%E7%BD%AE/"},{"name":"装机经验","slug":"装机经验","permalink":"https://silenwang.github.io/tags/%E8%A3%85%E6%9C%BA%E7%BB%8F%E9%AA%8C/"},{"name":"AMD处理器","slug":"AMD处理器","permalink":"https://silenwang.github.io/tags/AMD%E5%A4%84%E7%90%86%E5%99%A8/"},{"name":"二手配件","slug":"二手配件","permalink":"https://silenwang.github.io/tags/%E4%BA%8C%E6%89%8B%E9%85%8D%E4%BB%B6/"},{"name":"PC-building","slug":"PC-building","permalink":"https://silenwang.github.io/tags/PC-building/"},{"name":"hardware-configuration","slug":"hardware-configuration","permalink":"https://silenwang.github.io/tags/hardware-configuration/"},{"name":"AMD-Ryzen","slug":"AMD-Ryzen","permalink":"https://silenwang.github.io/tags/AMD-Ryzen/"},{"name":"used-parts","slug":"used-parts","permalink":"https://silenwang.github.io/tags/used-parts/"}]},{"title":"使用Syncthing进行文件同步","slug":"使用Syncthing进行文件同步","date":"2019-08-18T00:03:33.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2019/08/18/使用Syncthing进行文件同步/","permalink":"https://silenwang.github.io/2019/08/18/%E4%BD%BF%E7%94%A8Syncthing%E8%BF%9B%E8%A1%8C%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5/","excerpt":"只要使用多台设备进行工作, 就一定会涉及到不同设备之前互相同步的问题. 现在已经不是七八年前云服务刚兴起, 便宜又大碗的时代了. 一个实惠好用又不会突然跑路或改用户协议的服务商怕是并不存在, 所以还是要靠自己来搭了…","text":"只要使用多台设备进行工作, 就一定会涉及到不同设备之前互相同步的问题. 现在已经不是七八年前云服务刚兴起, 便宜又大碗的时代了. 一个实惠好用又不会突然跑路或改用户协议的服务商怕是并不存在, 所以还是要靠自己来搭了… Syncthing在小众软件和异次元软件都有介绍, 是一款使用简单且开源的同步软件. 由于官方已经提供了打包好的可执行文件, 三大平台都是下载运行文件后即可使用, 因此我就不再重复了. 这里主要记录如何在我的电脑和VPS上将其设置为服务来运行. CentOS7和Manjaro都有systemd, 且操作命令都是systemctl, 所以操作一样的. 首先找到Syncthing执行文件包, 里面的Syncthing/etc/下有已经准备好的各种服务配置文件实例. 我使用的是Syncthing/etc/linux-systemd/user/syncthing.service. 打开这个文件, 将其中的[Service]部分的ExecStart项目中的程序路径改成自己的程序位置. 我是将这个服务作为当前用户的服务而不是系统级服务使用, 所以将这个文件复制到~/.config/systemd/user/, 然后运行命令启动服务即可: 12systemctl --user enable syncthing.servicesystemctl --user start syncthing.service 启动后可像其他服务一样用ststemctl来查看服务运行状态.","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"文件同步","slug":"文件同步","permalink":"https://silenwang.github.io/tags/%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5/"},{"name":"跨设备同步","slug":"跨设备同步","permalink":"https://silenwang.github.io/tags/%E8%B7%A8%E8%AE%BE%E5%A4%87%E5%90%8C%E6%AD%A5/"},{"name":"Syncthing","slug":"Syncthing","permalink":"https://silenwang.github.io/tags/Syncthing/"},{"name":"systemd","slug":"systemd","permalink":"https://silenwang.github.io/tags/systemd/"},{"name":"开源工具","slug":"开源工具","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E6%BA%90%E5%B7%A5%E5%85%B7/"}]},{"title":"Git钩子使用","slug":"Git钩子使用","date":"2019-08-17T19:33:27.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2019/08/17/Git钩子使用/","permalink":"https://silenwang.github.io/2019/08/17/Git%E9%92%A9%E5%AD%90%E4%BD%BF%E7%94%A8/","excerpt":"虽然我也用Git进行部分项目的代码管理, 但是其实很多Git的特性我都还不熟悉, 也没有用, 今天尝试了一下Githook的使用.","text":"虽然我也用Git进行部分项目的代码管理, 但是其实很多Git的特性我都还不熟悉, 也没有用, 今天尝试了一下Githook的使用. Hook, 直译就是钩子, 指的是预先定义好的一系列脚本. 这些脚本在我们使用特定的Git命令完成一些代码管理操作时自动执行, 以达到减少重复操作, 提高效率的目的. 比如我的博客源代码就是用Git管理的. 我现在写一篇博客并发布的步骤是: hexo new post创建一篇新的博客文章的makrdown草稿 打开新建的markdown文件, 编写内容 编写完成后运行hexo g和hexo d将博客内容生成并推送到Gitpages的源上去 运行git commit提交博客源代码的修改, 然后git push到源代码源上去 其中, 撰写博客的过程可能会有一些不固定的操作, 但是最后两部的内容其实是每次写博客一定会重复且不太会变动的步骤. 这些步骤就可以利用钩子来执行. 首先要来判断这些东西应该在什么时候执行: 我的博客源代码在commit之前, 我会首先确认内容. 所以理论上, 我使用任何一个git commit会触发的钩子都可以. 实际选用的钩子为post-commit, 这个钩子会在commit后执行, 所以我就把如下内容写到项目的.git/hooks/post-commit文件中(名字不要改, 特定的名称才会被执行). 1234#!/bin/bashcd /home/silen/git_proj/silen_blog/hexo ghexo d 然后给这个文件加上可执行权限, 这样一来, 每次我对这个项目完成一次commit后, 就会调用这个脚本自动进行博客的生成和推送了. 当然现在这里举的例子可能没啥吸引力, 因为这两步其实也并不多…省不了太多功夫. 但是我现在的站点除了主站, 我还在子站里弄了个个人的速查手册. 这个手册使用mkdocs进行编写, 是另外一个独立项目. 如果想要达到两个项目其中一个更新就同步更新到博客的话, 钩子应该就很实用了. 最后需要注意的是, git钩子是分为客户端和服务端的, 我现在使用的是客户端的一种钩子. 客户端钩子的一个缺陷是无法在项目的不同副本间同步(不同副本是不同的客户端), 这个问题我之后再找方法解决好了… 以上~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Git钩子","slug":"Git钩子","permalink":"https://silenwang.github.io/tags/Git%E9%92%A9%E5%AD%90/"},{"name":"自动化部署","slug":"自动化部署","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"name":"博客管理","slug":"博客管理","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E7%AE%A1%E7%90%86/"},{"name":"git","slug":"git","permalink":"https://silenwang.github.io/tags/git/"},{"name":"githook","slug":"githook","permalink":"https://silenwang.github.io/tags/githook/"},{"name":"post-commit","slug":"post-commit","permalink":"https://silenwang.github.io/tags/post-commit/"}]},{"title":"装饰器入门","slug":"装饰器入门","date":"2019-08-15T22:48:43.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2019/08/15/装饰器入门/","permalink":"https://silenwang.github.io/2019/08/15/%E8%A3%85%E9%A5%B0%E5%99%A8%E5%85%A5%E9%97%A8/","excerpt":"很早之前, 前公司的Python大神就有给我们科普过装饰器的使用, 但是由于个人愚钝, 一直没有很好理解这个东西, 也没有在实际的写代码的时候用过. 因此这里把这种工作总遇到的一个例子记录一下.","text":"很早之前, 前公司的Python大神就有给我们科普过装饰器的使用, 但是由于个人愚钝, 一直没有很好理解这个东西, 也没有在实际的写代码的时候用过. 因此这里把这种工作总遇到的一个例子记录一下. 首先, Python中装饰器本身的作用是在不改动原函数代码的前提下为其附加新的功能, 因为它本身其实也要求你去定义一个函数, 只不过这个函数以函数为接收对象, 也以函数为返回对象. 我本周碰到的一个问题是, 我写了一个函数去计算Bam文件中UMI序列的一些指标, 但是输入的Bam带的UMI有两种情况: 双端各N个bpUMI 单端N个bpUMI这两种情况在从Bam文件中读取UMI的时候处理是不一样的, 单端的话要读取UMI全长, 双端的话只读UMI的半长. 原本单端的代码如下: 1234567891011121314151617181920212223242526def single_count(file, tag, mode): umi_count = &#123; &#x27;R1&#x27;: [], &#125; infos = load_single(file) for info in infos: if info[&#x27;strand&#x27;] == &#x27;R1&#x27;: umi_count[&#x27;R1&#x27;].append(info[&#x27;umi&#x27;]) umi_count[&#x27;R1&#x27;] = Counter(umi_count[&#x27;R1&#x27;]) total_umi = 0 read_with_umi = 0 max_grp_size = 0 max_umi = &#x27;&#x27; size_stat = Counter([1, 5, 10, 100, 1000]) for umi in umi_count[&#x27;R1&#x27;]: if umi_count[&#x27;R1&#x27;][umi] &gt; max_grp_size: max_grp_size = umi_count[&#x27;R1&#x27;][umi] max_umi = umi for size in size_stat: # 注意初始化的时候, 全都是1, 不是0, 所以最后要处理(-1) if umi_count[&#x27;R1&#x27;][umi] &lt;= size: size_stat[size] += 1 total_umi += 1 read_with_umi += umi_count[&#x27;R1&#x27;][umi] size_stat = OrderedDict(list([(&quot;%%Group_Size_below_%s(%s)&quot; % (size, tag), str((size_stat[size] - 1) / total_umi )) \\ for size in size_stat])) # python所以要先list化 return total_umi, read_with_umi, max_grp_size, max_umi, size_stat 而双端读取的代码与单端的区别仅仅是infos = load_single(file)这一句需要替换成infos = load_duplex(file)而已. 为了实现这一目的其实也有很直接简单的方式, 就是更改这个函数, 加上一个参数, 然后在这一句前面加一个判断, 根据传入的参数决定调用load_duplex还是load_single. 但是这样一来会需要改动这个函数的代码, 以及调用这个函数的其他代码. 如果这样的地方一多, 其实难免会产生新的bug. 因此这次我尝试使用装饰器来解决这个问题: 1234567def load_mod(func): load_single = load_duplex return func@load_moddef duplex_count(file, tag, mode): return single_count(file, tag, mode) 这里我新定义了两个函数, duplex_count想达到的效果是重复single_count中除了infos = load_single(file)之外的所有步骤, 然后只把调用的函数改成load_duplex. 因此可以看到这个函数的内容其实就是返回single_count的计算结果. 单这样一来并没有完成两个load函数的替换. 这里就是load_mod发挥作用的地方了: 它用来对局部命名空间内的内容进行替换, 具体是将load_single的内容以load_duplex替换. 以load_mod装饰duplex_count后, 相当于在执行函数前先把load_single的内容以load_duplex替换, 这样一来, 这个函数的执行的东西就改变了. 当然, 我这么用其实更像常见装饰器教程中的’闭包’用法, 而不是’为函数添加新功能’. 其他的应用之后再继续水.","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"装饰器","slug":"装饰器","permalink":"https://silenwang.github.io/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/"},{"name":"函数式编程","slug":"函数式编程","permalink":"https://silenwang.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"name":"闭包","slug":"闭包","permalink":"https://silenwang.github.io/tags/%E9%97%AD%E5%8C%85/"}]},{"title":"黑历史计划,启动!","slug":"黑历史计划-启动","date":"2019-07-27T21:40:03.000Z","updated":"2026-02-10T14:03:13.682Z","comments":true,"path":"2019/07/27/黑历史计划-启动/","permalink":"https://silenwang.github.io/2019/07/27/%E9%BB%91%E5%8E%86%E5%8F%B2%E8%AE%A1%E5%88%92-%E5%90%AF%E5%8A%A8/","excerpt":"作为一个曾经其实现在还是中二过的怪叔叔少年, 怎么能没有黑历史呢!","text":"作为一个曾经其实现在还是中二过的怪叔叔少年, 怎么能没有黑历史呢! 前天Google自己ID的时候, 猛然想起自己曾经是用过网易LOFTER和蚂蚁笔记发过博客的…网易博客上有前女友的恩怨情仇就让它去吧, 简单看了一下, 内容还不少, 原来我曾经也不是这么的自闭的嘛hhhhhhh. 那么正逢我的个人gitpage, 不如就学学卡婊, 把老料翻出来抄个冷饭好了, 也看看过去的自己是…多么的闲…LOFTER加起来几百条, 我的导师对我真是太仁慈了 因为过去的老料基本都是生活向的, 所以就统一丢Daliy好了… 因为是搬运, 所以文的日期会保持当时写的日期, 也就是说这些内容不会在首页前面出现. 然后因为有些短内容没有特别的搬运意义, 就忽略好了… 以上~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Daily","slug":"Daily","permalink":"https://silenwang.github.io/tags/Daily/"},{"name":"博客迁移","slug":"博客迁移","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB/"},{"name":"内容搬运","slug":"内容搬运","permalink":"https://silenwang.github.io/tags/%E5%86%85%E5%AE%B9%E6%90%AC%E8%BF%90/"},{"name":"个人博客","slug":"个人博客","permalink":"https://silenwang.github.io/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"黑历史","slug":"黑历史","permalink":"https://silenwang.github.io/tags/%E9%BB%91%E5%8E%86%E5%8F%B2/"},{"name":"网易LOFTER","slug":"网易LOFTER","permalink":"https://silenwang.github.io/tags/%E7%BD%91%E6%98%93LOFTER/"},{"name":"蚂蚁笔记","slug":"蚂蚁笔记","permalink":"https://silenwang.github.io/tags/%E8%9A%82%E8%9A%81%E7%AC%94%E8%AE%B0/"},{"name":"gitpage","slug":"gitpage","permalink":"https://silenwang.github.io/tags/gitpage/"}]},{"title":"MultiQC简单使用","slug":"MultiQC使用","date":"2019-07-27T21:02:16.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2019/07/27/MultiQC使用/","permalink":"https://silenwang.github.io/2019/07/27/MultiQC%E4%BD%BF%E7%94%A8/","excerpt":"MultiQC是一个NGS数据的质控工具, 不过跟很多其他工具不同的一点是, 它本身并直接进行数据获取和指标计算, 而是读入各种常见质控工具的结果文件然后做综合展示.","text":"MultiQC是一个NGS数据的质控工具, 不过跟很多其他工具不同的一点是, 它本身并直接进行数据获取和指标计算, 而是读入各种常见质控工具的结果文件然后做综合展示. 目前MultiQC支持的工具已经达到了75种, 且支持自行添加更多信息(虽然我还没试过), 支持工具覆盖了碱基读取到变异检测的整个过程, 出具的报告也相当美观, 非常适合用来做最后的数据质量汇总. MultiQC的使用很简单, 首先要将其他工具产生的结果文件放到一个统一的路径下, 然后运行MultiQC /path/to/file, MultiQC就会检索文件夹下的各种质控结果, 然后生成最后的汇总报告了, 比如我这里有一份使用MultiQC读取fastqc结果生成的fastq质控报告: 可以看见整个报告还是很漂亮的, 在报告顶部会有各个指标的汇总表格, 左侧是各个软件下计算指标的导航栏, 根据不同的软件, 具体的内容可能是展示图或者展示表. 在顶部的汇总表格中, 默认只显示部分指标, 如果想更改选择的指标可以点configure columns来对需要显示的指标进行调整. 然后还有一个比较方便的功能是, 可以点击plot按钮自行选择汇总表中的两个指标做散点图, 这个功能在后续查看一些异常的时候可能会特别有用. 简单的介绍就这么多, 更多高级的用法如自定义新的指标和变更样品名称匹配规则以让同一个样品的结果汇聚到一起等等, 之后有了新的成果之后再继续水~","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"NGS","slug":"NGS","permalink":"https://silenwang.github.io/tags/NGS/"},{"name":"质控工具","slug":"质控工具","permalink":"https://silenwang.github.io/tags/%E8%B4%A8%E6%8E%A7%E5%B7%A5%E5%85%B7/"},{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"数据分析","slug":"数据分析","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"MultiQC","slug":"MultiQC","permalink":"https://silenwang.github.io/tags/MultiQC/"},{"name":"fastqc","slug":"fastqc","permalink":"https://silenwang.github.io/tags/fastqc/"}]},{"title":"常见机器学习方法","slug":"常见机器学习方法","date":"2019-07-09T00:33:42.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2019/07/09/常见机器学习方法/","permalink":"https://silenwang.github.io/2019/07/09/%E5%B8%B8%E8%A7%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/","excerpt":"最近工作需要了解了一下常见的机器学习方法, 顺便水一篇好了…","text":"最近工作需要了解了一下常见的机器学习方法, 顺便水一篇好了… 决策树(Decision Trees): 根据属性构建多层递归二分类路径, 最后将输入对象根据这一系列二分类结果安排在合适的位置 优点: 容易理解和解释 缺点: 缺失数据敏感; 容易过拟合; 不考虑属性的相互关联性(当作独立?) 随机森林算法(Random Forest): 在决策树基础上构建. 首先将训练数据分成多个子集, 每个子集生成一个决策树, 然后输入待分类信息给每一个决策树, 最后以少数服从多数的方式决定最后结果 优点: 不容易过拟合, 有很好的抗噪声能力, 对异常点离群点不敏感 缺点: 解释性差, 容易受多分类属性影响 lasso回归(Lasso regression): 是对一般线性回归的改良, 通过对系数进行惩罚来降低模型复杂度 优点: 解释力强, 解决过拟合 缺点: 惩罚会造成欠拟合 逻辑回归(Logistic regression): 使用逻辑回归得到因变量分类结果与输入自变量概率比值的关系 优点: 可解释性强 缺点: 本质是广义线模, 在一些复杂情况下不适用 支持向量机(SVM): 将平面上的点以一条直线分开,两类中离直线最近的点的距离最大. 将这个问题拓展到多维空间, 就成了支持向量机 优点: 适用小样本量, 泛用性好 缺点: 可解释性质差, 对缺失数据敏感 K最近邻算法(KNN): 将新给的数据放在多维空间中, 里面有已知分类的点, 在与其最近的K的点中, 属于某一类的多, 这个点就属于哪一类 优点: KNN理论简单，容易实现 缺点: 计算量大, 每次分类都重新计算, 受分类不平衡影响大 朴素贝叶斯(Naive Bayes): 是用贝叶斯公式计算处于某类内的概率 优点: 实现简单与只需要少量的训练数据, 大量计算时速度快 缺点: 应用朴素贝叶斯分类器时必须满足条件: 所有的属性都是条件独立的 K均值算法(K-Mean): 聚类算法, 无监督学习; 首先在一堆数据中选K个初始点, 计算所有点与这K个点的距离, 然后将点与K个中最近的那一个归成一类. 在第一轮分类完成后, 根据每一类的点计算一个平均的中心点(K个), 然后再将所有点到这K个中心点的距离计算以便, 并将点归到最近的一类. 如此重复下去. 当重复一定次数后, 分组会固定不动, 此时停止. 优点: 异常值不敏感 缺点: 数据量大时计算量大, 数据量少则效果不好; 易受分类不平衡影响 Adaboost算法: 将多个分类器(多种模型)组合起来, 达到更好的分类效果. 优点: 结合多种基本算法, 考虑不同分类器的权重 缺点: 训练耗时 神经网络(NN): 比较复杂的深度学习(DL)方法, 个人理解神经网络中的神经元类似决策树, 会根据输入数据得到一个分类结果, 然后将这个结果交给下游神经元, 下游神经元接受上游信息后得出结果继续传递, 最后将最后一层的结果汇总起来给出分类结果. 优点: 分类准确度高, 鲁棒性和容错性较强 缺点: 深度学习, 计算量大, 解释性差 马尔可夫链(MarCov Model): 没有看懂… 主要内容摘自:轻松看懂机器学习十大常用算法机器学习算法优缺点及其应用领域 当然…我写的解释完全不如这个视频讲的简单清楚明白, 果然现在学习要上B站了么… 视频出处, 喜欢的话一定去关注一下up然后三连一波哟~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"逻辑回归","slug":"逻辑回归","permalink":"https://silenwang.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"机器学习","slug":"机器学习","permalink":"https://silenwang.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"logistic regression","slug":"logistic-regression","permalink":"https://silenwang.github.io/tags/logistic-regression/"},{"name":"machine learning","slug":"machine-learning","permalink":"https://silenwang.github.io/tags/machine-learning/"},{"name":"算法比较","slug":"算法比较","permalink":"https://silenwang.github.io/tags/%E7%AE%97%E6%B3%95%E6%AF%94%E8%BE%83/"},{"name":"决策树","slug":"决策树","permalink":"https://silenwang.github.io/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"name":"随机森林","slug":"随机森林","permalink":"https://silenwang.github.io/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"},{"name":"支持向量机","slug":"支持向量机","permalink":"https://silenwang.github.io/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"},{"name":"KNN","slug":"KNN","permalink":"https://silenwang.github.io/tags/KNN/"},{"name":"朴素贝叶斯","slug":"朴素贝叶斯","permalink":"https://silenwang.github.io/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"},{"name":"K均值","slug":"K均值","permalink":"https://silenwang.github.io/tags/K%E5%9D%87%E5%80%BC/"},{"name":"Adaboost","slug":"Adaboost","permalink":"https://silenwang.github.io/tags/Adaboost/"},{"name":"神经网络","slug":"神经网络","permalink":"https://silenwang.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"algorithm comparison","slug":"algorithm-comparison","permalink":"https://silenwang.github.io/tags/algorithm-comparison/"},{"name":"decision tree","slug":"decision-tree","permalink":"https://silenwang.github.io/tags/decision-tree/"},{"name":"random forest","slug":"random-forest","permalink":"https://silenwang.github.io/tags/random-forest/"},{"name":"SVM","slug":"SVM","permalink":"https://silenwang.github.io/tags/SVM/"},{"name":"naive bayes","slug":"naive-bayes","permalink":"https://silenwang.github.io/tags/naive-bayes/"},{"name":"K-means","slug":"K-means","permalink":"https://silenwang.github.io/tags/K-means/"}]},{"title":"使用gitbook和mkdocs写文档","slug":"使用Gitbook和mkdocs写文档","date":"2019-07-07T22:13:31.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2019/07/07/使用Gitbook和mkdocs写文档/","permalink":"https://silenwang.github.io/2019/07/07/%E4%BD%BF%E7%94%A8Gitbook%E5%92%8Cmkdocs%E5%86%99%E6%96%87%E6%A1%A3/","excerpt":"我的博客是使用hexo生成的, 这是一款基于Node.js的静态博客框架, 他可以帮助像我一样对前端一无所知的人快速搭建一个看上去有模有样的博客, 而我只需要会用markdown写博文就行. 同样, 在开发过程中总会有写技术文档的需要, 因此也就有了gitbook和mkdocs这样的工具.","text":"我的博客是使用hexo生成的, 这是一款基于Node.js的静态博客框架, 他可以帮助像我一样对前端一无所知的人快速搭建一个看上去有模有样的博客, 而我只需要会用markdown写博文就行. 同样, 在开发过程中总会有写技术文档的需要, 因此也就有了gitbook和mkdocs这样的工具. gitbook和mkdocs的定位其实应该不太一样, gitbook的初衷是让人使用markdown快速写书(也就包括文档), 而mkdocs则是帮助技术人员快速撰写及形成一个可修改性好的文档. 不过到了我这种菜鸡手里…基本的够能都比较类似, 也就没有太大的区别了… gitbookgitbook-cli是基于Node.js的工具, 可通过npm安装: npm install gitbook-cli. 需要注意的是, 由于gitbook项目组方向的调整, 这个命令行工具已经不再更新了. 不过基本的功能也差不多了, 继续用似乎也没啥问题… 安装完成之后就可以使用gitbook命令创建和编写文档, 创建命令是gitbook init, 目录下会产生README.md和SUMMARY.md两个文件, 其中SUMMARY.md是整个文档的目录文件兼结构文件, gitbook-cli会根据这个文件的内容生成最后的文档. SUMMARY.md本身也是个markdown文件: 1234567# 第一章* [文档说明](README.md)* [第一部分](Part1/README.md) * [内容1](Part1/content1.md) * [内容小标题](Part1/content1.md)# 第二章* [XXXX](NNNN.md) 首先书的章节由一级标题的语法(#)控制, 不同章节的内容在目录树里会用分隔线分开, 如果开启自动序号的话, 不同章节的小序号也会不一样. 章节里面以无序列表的形式保存目录结构, 每一级列表项目都使用链接的语法([]())链接到具体的markdown文件. 具体的markdown文件内可以以一级标题作为锚点. 目前实测只有一级标题有锚点的作用, 如果想要锚定二级标题或其他内容则要手动添加html tag作为锚点. gitbook支持所有的基本markdown语法, 同时也支持html, 因此如果需要在文档中加入比较复杂的表格, 可以写成html的格式的然后直接贴入. 基本上知道这些就能够写书了. 如果对文档的表现或者使用的插件有要求, 可以自行建立book.json配置文件, 在其中按格式填写配置信息, 即可在生成书籍的时候作调整. 书籍在写作完成后可以使用gitbook serve开启本地的书籍预览, 默认端口8000. 预览服务可以一直保持开启, 对markdown源文件进行的修改会实时反映在预览网页内(可能需要刷新). 当然如果确定写的书没有问题, 可以直接使用gitbook build, 创建好的html书籍会保存在_book/内. mkdocsmkdocs是基于python的工具, 使用pip或者conda都可以方便的安装. 安装完后mkdocs命令即可使用, 创建文档的命令是mkdocs new proj_name, 运行后会在名为proj_name/的文件夹内建立mkdocs.yml文件和docs/文件夹. 其中mkdocs.yml是配置文件兼目录结构文件, 采用yaml格式进行记录. 文件大概是这样: 12345678site_name: &quot;我的文档&quot;pages:- 目录: index.md- 第一章: chapter1.md- 第二章: chapter2.mdtheme: readthedocs mkdocs形成的目录基本等同于常见的markdown TOC, 不需要像gitbook一样去做额外的锚点设置. 然后由于我这次使用mkdocs写的文件比较简单, 对于其更多的功能没有涉及. 编写完成的文档可以通过mkdocs serve预览, 同样会根据markdown源文件实时更新. 也可以通过mkdocs build直接构建, 构建结果会在site/目录中. 两款工具的比较我这次整理离职文档的过程中两个工具都使用过一次, 也有一些对比使用的体会. 首先从基本功能上, 两个工具对我来说几乎没有区别, 都是用markdown写文档, 然后基本命令都很简单易用, 都可以本地浏览. 不过gitbook-cli毕竟是不更新了, 之后会不会出什么问题我也不知道. 然后从扩展性上来说呢…其实两者也差不多, 都有很多作者在给两个工具写插件. 不过有一点值得注意的是, gitbook似乎没什么第三方主题? 我搜了很多次也没有能够拿来直接用的主题, 而mkdocs内置的就有好几个了. 另外由于本次的是工作交接用的文档, 我的同事其实不太习惯看html的, 因此两个工具的第三方pdf导出插件我都用了…怎么说呢…能用…但是确实不是那么好用吧…跟html的效果比起来两个的pdf都显得比较砢碜了…不过硬要说的话mkdocs的稍微好一些.","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"文档工具","slug":"文档工具","permalink":"https://silenwang.github.io/tags/%E6%96%87%E6%A1%A3%E5%B7%A5%E5%85%B7/"},{"name":"技术写作","slug":"技术写作","permalink":"https://silenwang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%86%99%E4%BD%9C/"},{"name":"gitbook","slug":"gitbook","permalink":"https://silenwang.github.io/tags/gitbook/"},{"name":"mkdocs","slug":"mkdocs","permalink":"https://silenwang.github.io/tags/mkdocs/"},{"name":"markdown","slug":"markdown","permalink":"https://silenwang.github.io/tags/markdown/"}]},{"title":"Bash小技巧两则","slug":"Bash小技巧两则","date":"2019-06-05T21:17:03.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2019/06/05/Bash小技巧两则/","permalink":"https://silenwang.github.io/2019/06/05/Bash%E5%B0%8F%E6%8A%80%E5%B7%A7%E4%B8%A4%E5%88%99/","excerpt":"使用Bash串联各个程序的过程中总是能发现一些神奇好用的技巧, 这里记录两个.","text":"使用Bash串联各个程序的过程中总是能发现一些神奇好用的技巧, 这里记录两个. 第一则是我前些时候尝试使用sambamba取代samtools的时候发现的, sambamba是用来取代samtools处理bam文件的一个工具, 其很多命令都跟samtools非常接近, 但是当时有一个子命令却不支持标准输出, 导致要先生成中间文件然后再读取中间文件进行下一步, 非常浪费IO资源, 所以我搜索了一下有没啥好的解决方案. 不搜不知道, 一搜才知道, 原来Linux下面是有三个特殊文件的, 分别是/dev/stdin, /dev/stdout, /dev/null, 分别对应标准输入, 标准输出和丢弃. 对于没有明确说明支持标准输入&#x2F;输出的程序, 可以尝试将输入&#x2F;输出文件替换为上述特殊文件, 这样就能实现从标准输入读取内容或者将接过输出到标准输出了: 1234sambamba merge -t 4 /dev/stdout input1.bam input2.bam \\| sambamba sort -o /dev/stdout /dev/stdin \\| samtools view -Sb -f 30 \\&gt; output.srt.flt.bam /dev/null同样很有用, 比如samblaster, 默认只支持-o, 也就是主接过输出到标准输出, 但是我其实需要-s或者-u的接过, 并且我需要对这些接过做另外的处理, 那么就可以使用/dev/null将主要结果丢弃, 然后将需要的结果输出到/dev/stdout然后继续后续操作即可: 12345678910111213samtools view -h \\| samblaster \\ --ignoreUnmated \\ -o /dev/null \\ -d /dev/null \\ -s /dev/null \\ -u /dev/stdout \\| sed &quot;s/_[0-9]//g&quot; \\| /soft/bwa-0.7.15/bin/bwa mem \\ -t 30 -k 32 -M -R &quot;@RG\\tID:$&#123;sam_id&#125;\\tLB:$&#123;sam_id&#125;\\tSM:$&#123;sam_id&#125;\\tPL:ILLUMINA&quot; \\ /resource/GV/ref_genome/hg38/bwa-0.7.15/hg38.fa /dev/stdin \\| samtools view -Sb -f 256 \\| samtools merge -f output.bam input.bam /dev/stdin 另外一个技巧是将命令结果伪装成文件进行输入. 比如我现在有多个两列的文件, 一列是数据标题, 一列是数据值. 我现在需要把多个文件合并成一个, 同时还想保留第一列的标题, 那么就可以: 12345paste file1 \\ &lt;(cut -f 2 file2) \\ &lt;(cut -f 2 file3) \\ &lt;(cut -f 2 file4) \\ &gt; pasted_file 在上面的操作中, file&#123;2..4&#125;的数据被cut -f 2截取出来, 然后伪装成文件, 输入给了paste命令, 这样避免了使用中间文件, 更加快捷高效.","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"Bash","slug":"Bash","permalink":"https://silenwang.github.io/tags/Bash/"},{"name":"命令行","slug":"命令行","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"name":"输入输出重定向","slug":"输入输出重定向","permalink":"https://silenwang.github.io/tags/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91/"},{"name":"进程替换","slug":"进程替换","permalink":"https://silenwang.github.io/tags/%E8%BF%9B%E7%A8%8B%E6%9B%BF%E6%8D%A2/"}]},{"title":"用Go语言重写我的项目","slug":"用Go语言重写我的项目","date":"2019-06-02T14:46:49.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2019/06/02/用Go语言重写我的项目/","permalink":"https://silenwang.github.io/2019/06/02/%E7%94%A8Go%E8%AF%AD%E8%A8%80%E9%87%8D%E5%86%99%E6%88%91%E7%9A%84%E9%A1%B9%E7%9B%AE/","excerpt":"为了学习Go语言, 我把之前工作中一个用的比较多的脚本用Go重写了. 所谓没有对比就没有伤害, 实际写下来的感受是, Python真的简单快捷易懂…好用的第三方模块多…中英文的学习资料更是非常容易找. 要不是为了性能…我真是不想换…","text":"为了学习Go语言, 我把之前工作中一个用的比较多的脚本用Go重写了. 所谓没有对比就没有伤害, 实际写下来的感受是, Python真的简单快捷易懂…好用的第三方模块多…中英文的学习资料更是非常容易找. 要不是为了性能…我真是不想换… 一只Python菜鸡眼里的Go由于我之前比较大一点的程序都是Python和R写的, 均不属于强类型语言, 对变量的声明和使用的都比较灵活, 所以开发的主要难度集中在第三方模块的使用和处理自己设计中的逻辑bug上. Go就不一样了…它是一种强类型的语言, 变量要先声明再使用, 且一旦声明, 后面不可再更改类型, 这在我前期开始上手的时候着实让我难受了好久… 虽然Go为了一定程度上增加易用性设计了接口这个灵活的类型, 但我毕竟是菜鸡出身, 在Python R Bash内都没有类似概念的情况下…明白这到底是个什么东西着实花了我不少时间. 在解决了基本的变量使用后, 还有错误处理的方式不同, 第三方模块较少以及缺少Magic写法等种种问题要一点一点解决… 最终导致这个改写拖了整整两个星期才初步完成… 虽然困难不少, 但是只要体验过它的速度, 相信很多人会和我一样激动异常(虽然本次我重写的时候顺带着对算法也做了优化, 但是那点优化是绝对不足以带来200倍的差距) 嘛, 世界变化这么快, 多学一样东西总是不会错的~ 附上这个重写项目的地址: FUEX 以Python为参照快速上手Go就像我学英语的时候总是扰不开从中文的角度进行思考, 我写这个练习项目的时候总是不可避免的想要按照Python里面的方式是来进行代码实现. 但是Python和Go毕竟是两种差异很大的语言, 一些Python里用到的东西在Go里只有类似物, 甚至是连类似物都没有, 这里就总结一下本次开发中涉及到的一些替代实现方案. 变量&#x2F;数据类型变量声明及初始化在Python中没有单独的变量声明及初始化的步骤, 想使用的话直接var=value就可以使用, 并且变量的类型可以在后续处理中进行变更. 比如: 123var1 = Truevar2 = 1var1 = var2 if var2 else True 在上面的代码中, var1和var2在赋值的过程中会被自动赋予变量类型(boolean, int), 且两者虽然类型不同, 仍然可以把var2的值传递给var1, 在传递完成后var1会从boolean变成int. 而Go中, 一个变量首先要被声明才能使用, 且一个变量声明后类型固定, 是无法把var2内的数值赋给var1的 1234Var var1 bool // 变量声明Var var2 int // 变量声明var1 = Truevar2 = 1 当然, 所有变量都要这么些的话确实有点麻烦, Go针对这个给出了简单的写法:var1 := 1, 这种写法在创建变量的同时给变量赋值, 同时变量的类型会自动指定. 不过由于是自动指定的, 如果对类型有什么特殊的需求, 可能还是自己声明比较好. Go是强类型的语言所谓强类型, 就是对变量的类型有细致的分类, 并且在程序执行过程中对传递和使用的变量类型作严格的限制(个人理解). 比如在Python中, 变量的类型也就数字, 字符串, 逻辑和空(None), 复杂一点的也就只有数字, 因为下面还分为了浮点数和整数. 甚至, Python中连常量都砍掉了, 只有变量, 只是在语言编写建议中推荐使用全大写字母来提示常量(实际上值是可以被更改的). Go就不同了…首先是分了常量(Const)和变量(Var)的, 而在变量中, 虽然也是有整数, 浮点数, 逻辑这几类, 但是整数和浮点数下面又细分了不同长度, 比如什么int16, int32, int64, 甚至还有我目前不是很明白的uint…这些变量类型在使用过程中如上一点中所说一样, 是不会自动转换的, 也就是如果某个函数给了你int16, 下一个函数要的是int64, 还得自己手动转换一次…这些类型的转换对我一个习惯了Python的人来说真的非常难受. 另外需要注意的一点是, Go的字符(byte)和字符串(string)也是两个不同的类型, 字符固定使用单引号(‘), 字符串则固定使用双引号(“). 复杂数据类型—-数组&#x2F;切片&#x2F;集合&#x2F;结构体就像Python有Tuple, List, Dict, Set等存储多个元素&#x2F;映射的数据类型, Go中也有数据类型满足数据存储和处理需要: 数组(Array): 数组类似于List或Turple, 单又与它们都不同. 首先Go中数组的长度是固定的, 一单声明即不可更改. 同时, 虽然数组内存储内容是可变的, 但存储物的类型必须是固定的. 切片(Slice)基本跟数组差不多, 但是其长度是可变的. 集合(Map)相当于Dict, 同样其Key和Value的类型是固定不可变更的. Map的Key可使用的类型比较丰富, 只要能进行逻辑比较==操作的都可以. 这一点倒是跟Dict的Key只要能Hash化就行非常类似 最后也是我的项目中最需要的就是结构体了. 它比较类似R中的list或者Python中的嵌套Dict, 其中能存储各式各样的信息. 强类型下的灵活处理—-接口(interface)接口是我在接触Go时接触到的一个全新概念, 它与我之前听过的API其实是很不一样的东西, 我查了好半天才对它有了一丢丢的了解…这里也记录一下. 首先根据上一节的内容, 我们知道Go是强类型的. 这个强类型贯穿了整个语言体系, 会在某些时候导致一些不必要的麻烦. 比如我们在写函数的时候, 要定义函数的接收和返回变量, 输入和返回变量是要给定类型的. 而一旦类型确定了, 函数就智能接收&#x2F;这个类型的变量, 不可以更改. 这就很蛋疼了, 我们写程序的时候, 多少都会有一些函数是要接收一些情况不明的对象, 然后根据对象的情况进行判断后做下一步处理的. 但是强类型的规则规定了接收的东西类型要确定, 这就逼着人写两个重复性很高的函数来接收不同类型的对象然后做类似的处理. 举一个实际的例子, vcfgo中的Info().Get()函数. 这个函数的作用是将vcf文件中INFO列的对应信息取出然后返回. 每一个INFO项目下可能会有多个值, 如果只有一个值, 则返回对应的字符串, 如果有多个, 则将他们放入一个以字符串为元素的列表返回. 这个看上去很简单, 但是在强类型的规则下是不能直接实现的. 因为在定义函数时, 就必须定义好返回变量的类型. 一个变量的类型如果定义成了字符串, 那它就不能存储字符串列表, 反之毅然. 那为了实现目标功能, 难道要让函数多一个返回值吗? 这种时候就是interface发挥作用的时候了. interface的定义是, 只要一个对象实现了interface中定义的方法, 那它就实现了这个接口, 可以被以这个类型的接口的方式传递. 回到刚才那个问题, 只要定义一个接口, 然后让要返回的东西都实现这个接口, 就可以将他们以接口的方式返回了. 最后需要注意的是, 由于返回的是接口, 所以他们的类型都是interface, 如果你需要进一步传递他们, 可能还需要用断言的方式将他们从接口中取出成为原来的类型. 比如我的项目里面就有这么一句: 123if annObj, ok := anns.(string); ok &#123; // 单个注释, 直接解析 annTarget = annObj&#125; 这句话中的ann就是Info().Get()函数返回给我的接口, 这个接口里可能是字符串, 也可能是一个字符串列表, 而我就使用anns.(string)尝试断言它里面是字符串, 如果断言正确, 则直接将取出的字符串赋值, 如果错误, 则进行另一种处理 文件操作Python中的文件读写非常简单, 一条语句打开文件, 获得的对象是可迭代的, 直接for循环就可以对文件按行处理了. 写文件同理, 也是几条语句就能搞定. 同时Python还有with语句可以在操作完成后自动关闭文件句柄, 可谓非常方便了. 123with open(&quot;file&quot;, &quot;r&quot;) as f: for line in f: print(line) 相比之下Go在读写就麻烦了很多, 比如我想按行读取文件内容并打印的话: 12345678910111213file, err := os.Open(vcfFile)defer file.Close() // 自动关闭文件文件, 相当于用python里用withif err != nil &#123; panic(err)&#125;reader := bufio.NewReader(file)for &#123; str, err := reader.ReadString(&#x27;\\n&#x27;) if err == io.EOF &#123; break &#125; fmt.Println(str)&#125; 上面步骤主要是先打开一个文件, 然后使用另外一个函数指定以&#39;\\n&#39;作为分隔读取一行的内容, 然后将读到的内容打印到屏幕. 其实说来核心的东西可能跟Python差不多, 但是有些东西变成了自己处理, 代码自然就多了. 比如打开文件后的异常处理, Python如果读不到文件, 会自动抛出异常, 告诉你文件不存在, 所以退出. 而写Go则要自己手动panic, 把err中的错误显示出来进行提示并终止程序. Python中使用for便利打开的文件对象即可按行读取文件, 并且会在达到文件末时自动终止. 而Go中这个过程是自己手动写出来的, 甚至文件按&#39;\\n&#39;分行都是自己指定的. 写文件的情况与读文件类似, 然后Go的写文件比读还要复杂一点, 这里先挖坑, 后面填. 嵌套数据结构Python中常用的数据结构之间可以进行相互嵌套, 形成复杂的数据结构以满足实际的数据处理需要. 这种嵌套的数据结构非常自由, 因为dict&#x2F;list&#x2F;tuple&#x2F;set对其中存放的东西没有特别的限制, 所以我们可以轻松的把一系列不同的东西组成一个整理. 这是我在某些数据处理时喜欢用Python而不是R的原因之一(R的一些数据结构内部存同类的东西). 以我这个项目里存储的refGene文件信息为例. 我的程序需要从数据库文件中读取出一个基因的转录本号码, 外显子起止位点, 转录方向, 基因名称等等一系列信息. 其中转录本号码是一个字符串, 外显子起止点里存储的是一个列表的整数, 转录方向是单个字符, 基因名称则又是字符串. 这一系列信息我都可以以Key: Value的形式存储在一个大字典中, 需要的时候根据Key来获取对应的值就可以了. 这在Go中是不可能的, 因为list对应的数组, dict对应的集合, 在Go中都是只能存储声明好的东西的: 12outStrList := []string&#123;&quot;out1&quot;, &quot;out2&quot;&#125; // 只能存stringgene2tran := make(map[string][]string) // Key和Value都必须是string 因此要做到类似Python里面那种不同类型数据的嵌套, 就智能使用结构体struct了: 1234567891011// 我代码里面定义的存储转录本信息的结构体type geneRecord struct &#123; exon [][]int64 intron [][]int64 transRegion [2]int64 cdsRegion [2]int64 chr string strand string geneSymbol string&#125;tran2info := make(map[string]geneRecord) // map 套结构体 控制结构Go中的控制结构甚至比Python还简单…判断用的if/else, 循环用的for, 多分支结构的switch——就只有这些了. 123456789101112131415161718192021222324252627282930// if else 和 for 举例if cols[3] == &quot;+&quot; &#123; for idx, _ := range exonStarts &#123; exons = append(exons, []int64&#123;exonStarts[idx], exonEnds[idx], exonFrames[idx]&#125;) if idx != len(exonStarts)-1 &#123; introns = append(introns, []int64&#123;exonEnds[idx], exonStarts[idx+1]&#125;) &#125; &#125;&#125; else &#123; for idx, _ := range exonStarts &#123; exons = reverSlice(append(exons, []int64&#123;exonStarts[idx], exonEnds[idx], exonFrames[idx]&#125;)) if idx != len(exonStarts)-1 &#123; introns = reverSlice(append(introns, []int64&#123;exonEnds[idx], exonStarts[idx+1]&#125;)) &#125; &#125;&#125;// switch举例switch &#123;case AinA &amp;&amp; BinB: // 目标fusion, 对应正确 locates[&quot;breakA&quot;] = locAinA locates[&quot;breakB&quot;] = locBinB return locates, &quot;right&quot;, nilcase AinB &amp;&amp; BinA: // 目标fusion, 对应颠倒 locates[&quot;breakA&quot;] = locAinB locates[&quot;breakB&quot;] = locBinA return locates, &quot;wrong&quot;, nildefault: err := errors.New(&quot;Not Fusion&quot;)&#125; 虽然东西是比较少, 但也够用了… 另外Go除了break和continue之外, 还提供了goto这种跳转性的控制语句. 不过我暂时没有使用过… 构建函数Go中创建函数没有啥特别的…就是注意输入参数和返回值的类型要先声明好(下面例子中, reverSlice后面跟的是传入的参数, 括号外面的是返回值的声明), 声明好就不能变了. 如果需要灵活的输入和返回, 需要靠interface了 1234567func reverSlice(a [][]int64) [][]int64 &#123; for i := len(a)/2 - 1; i &gt;= 0; i-- &#123; opp := len(a) - 1 - i a[i], a[opp] = a[opp], a[i] &#125; return a&#125; 错误处理本质上来说, Go里面没有Python中那样专门的错误处理, 或者说, 并没有专门的异常抛出这一操作. 但是在使用Go的时候会发现, 很多函数的返回值会有两个, 比如打开文件的函数: 1file, err := os.Open(yourFile) 上面的文件打开函数除了返回打开的文件对象, 还会返回另外一个变量, 这个变量我个人理解为类似Shell执行命令后状态码一样的东西, 一般情况下, 函数内程序执行正常的话, 这个变量会是nil. 而一旦函数内的部分执行出错, 返回的就会是一个error类的对象, 对象里包含了错误的说明字符. 对这个变量进行处理, 也就等同于在Python里面用Try: Except:了 字符处理Go的字符串处理基本依赖strings包, 包内基本的连接, 拆分, 替换, 前后去空白都有…实际使用感受类似于R中的stringr…就是东西都有…但是总觉得没那么好用. 另外Python中的格式化字符串在Go内暂时没有对等物. 所以无法像Python内弄一个硕大的文本模板然后填充内容. JSON处理Go也有专门的json包来读取json文件内容形成Go的数据结构, 和将Go对象转化为json字串. 不过可能还是类型限制大, 实际用起来比Python还是复杂一点… 12345678tarTranFile := &quot;RXA_gene_trans.json&quot;data, err := ioutil.ReadFile(tarTranFile)if err != nil &#123; return&#125;var targetTransFile interface&#123;&#125;err = json.Unmarshal(data, &amp;targetTransFile)targetTrans := targetTransFile.(map[string]interface&#123;&#125;) 可以看到我为了读取写好的json文件, 执行了打开文件, 载入内容, 将内容用特定函数处理, 然后因为返回的是interface, 所以最后又进行了类型断言. 类似的操作…在python中1~2行就可以完成了… 程序编译与Python这种边翻译边执行的语言不同, Go语言是要先编译后使用的(虽然也有go run), 所以还要研究一下编译可执行文件的问题.(挖坑占位) Python与Go的独有物这一部分记录Python和Go各自独有的一些东西(挖坑占位). Python部分 列表&#x2F;字典生成式: 在Python中生成式是非常方便的可迭代对象生成&#x2F;处理方式, 可以有效的简化代码(效率有没提升我不太清楚), 然而Go里就智能乖乖写循环了. 字符串格式化: Python内的字符串格式化的好处就在于将常常的一段文本挖空后依次填充, 这种写法代码的可读性非常好. 可以一目了然的知道最后出现的字符串是个怎样的框架. 而Go中就只能自己拼接了. Go部分 接口(见上) switch控制结构 方便的并行化: Python虽然多线程, 多进程, 协程都有…但确实是没那么高效或者好用…这也是促使我学Go的一个原因了.","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"性能优化","slug":"性能优化","permalink":"https://silenwang.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"golang","slug":"golang","permalink":"https://silenwang.github.io/tags/golang/"},{"name":"Go语言","slug":"Go语言","permalink":"https://silenwang.github.io/tags/Go%E8%AF%AD%E8%A8%80/"},{"name":"编程语言对比","slug":"编程语言对比","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%AF%B9%E6%AF%94/"},{"name":"项目重构","slug":"项目重构","permalink":"https://silenwang.github.io/tags/%E9%A1%B9%E7%9B%AE%E9%87%8D%E6%9E%84/"},{"name":"programming","slug":"programming","permalink":"https://silenwang.github.io/tags/programming/"}]},{"title":"使用Caddy设置https","slug":"https配置","date":"2019-05-07T21:59:51.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2019/05/07/https配置/","permalink":"https://silenwang.github.io/2019/05/07/https%E9%85%8D%E7%BD%AE/","excerpt":"之前自建了一个gogs, 但是并没有弄https, 直接用的http, 上次自己试了一下发现截密码太容易了…所以思考了一下…还是弄个域名然后上了https…","text":"之前自建了一个gogs, 但是并没有弄https, 直接用的http, 上次自己试了一下发现截密码太容易了…所以思考了一下…还是弄个域名然后上了https… 首先, 使用https需要申请SSL证书, 然后要申请证书的话, 似乎免费的SSL证书是基本都是要有域名的, 所以我找了最便宜的INVALID POST SLUG PROVIDED www.namesilo.com/‎申请了一个. 域名申请和绑定IP见这个博文. 有了域名之后下一步就是设置反代理服务器了, 我选择了简单易用的Caddy, 因为我查到的资料都说Caddy设置简单, 易用性完爆Nginx还能自动申请和更新SSL证书. 也许是我脸比较黑…设置虽然很简单完成了, 但是申请SSL证书怎么也用不了. 无奈只有在github上又找了个专门申请SSL证书的项目acme.sh. 这个脚本使用非常简单, 作者的使用说明也写的详细, 照它说的做就可以. 当然这里也有个更傻瓜化的教程 使用acme.sh会生成四个文件, 其中fullchain.cer, your.domain.key就是证书和密钥. 由于我使用docker部署gogs和caddy, 为了方便把两者都写到一个compose文件里: 123456789101112131415161718192021222324version: &quot;2&quot;services: gogs: image: 08fa8ee955da container_name: gogs restart: always ports: - &quot;3022:22&quot; volumes: - /var/gogs:/data caddy: container_name: caddy image: abiosoft/caddy environment: - ACME_AGREE=true volumes: - &quot;~/gogs/Caddyfile:/etc/Caddyfile&quot; - &quot;/root/.acme.sh/your.domain/fullchain.cer:/root/fullchain.cer&quot; - &quot;/root/.acme.sh/your.domain/your.domain.key:/root/your.domain.key&quot; ports: - &quot;8080:2015&quot; - &quot;80:80&quot; - &quot;443:443&quot; restart: always 上面文件中配置了两个容器, gogs只暴露22端口用于ssh服务, http的端口不暴露, Caddy可以在配置文件里直接设置访问(虽然我不知道怎么做到的).Caddy的容器则注意设置ACME_AGREE=true这个环境变量的设置, 不然acme会提示不能使用… 再就是要指定Caddy的配置文件Caddyfile和上面生成的证书和密钥了. Caddy容器的端口暴露这里设置的有问题…之后再看怎么改. Caddyfile的具体内容如下: 1234567891011your.domain &#123; proxy / gogs:3000 &#123; header_upstream Host &#123;host&#125; header_upstream X-Real-IP &#123;remote&#125; header_upstream X-Forwarded-For &#123;remote&#125; header_upstream X-Forwarded-Proto &#123;scheme&#125; &#125; log /var/log/caddy.log gzip tls /root/fullchain.cer /root/your.domain.key&#125;","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://silenwang.github.io/tags/HTTPS/"},{"name":"SSL证书","slug":"SSL证书","permalink":"https://silenwang.github.io/tags/SSL%E8%AF%81%E4%B9%A6/"},{"name":"Caddy","slug":"Caddy","permalink":"https://silenwang.github.io/tags/Caddy/"},{"name":"反向代理","slug":"反向代理","permalink":"https://silenwang.github.io/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"},{"name":"域名","slug":"域名","permalink":"https://silenwang.github.io/tags/%E5%9F%9F%E5%90%8D/"}]},{"title":"Graphviz的使用","slug":"Graphviz的使用","date":"2019-04-25T21:31:53.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2019/04/25/Graphviz的使用/","permalink":"https://silenwang.github.io/2019/04/25/Graphviz%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"进行软件开发时, 不论是为了展示或者是自己梳理需要都会要用到流程图, 如果自己开个绘图板或者word来画呢也不是不可以, 但是如果图一单复杂了, 或者图是不是会需要更改的话, 就很花时间了, 因此一个类似markdown这样可以让人专注与内容而不是形式的工具就非常重要了.","text":"进行软件开发时, 不论是为了展示或者是自己梳理需要都会要用到流程图, 如果自己开个绘图板或者word来画呢也不是不可以, 但是如果图一单复杂了, 或者图是不是会需要更改的话, 就很花时间了, 因此一个类似markdown这样可以让人专注与内容而不是形式的工具就非常重要了. Graphviz是一个脚本化做图的工具, 其可以制作的图形很多, 我目前只使用了流程图. 作流程图需要编写一个.dot格式的文件, 这个文件的形式如下: 12345678910111213141516digraph workflow&#123; // 图形的总定义部分 label = &quot;Workflow For Mutation Call&quot; node[shape = box] // 流程图元素的定义部分 raw [label=&quot;Raw Bam&quot;]; clean [label=&quot;UMI Dedup Bam&quot;]; align [label=&quot;Split Bam&quot;]; vcf [label=&quot;Disc Bam(Prototype)&quot;]; // 流程图关系部分 raw -&gt; clean [label=&quot;fastp&quot;]; clean -&gt; align [label=&quot;bwa&quot;]; align -&gt; vcf [label=&quot;GATK Mutect2&quot;];&#125; 上面的代码我分成了三个部分: 第一部分是图形中元素的默认设定, 比如label是图形的标题, node是流程图的各个节点, 我把默认的节点图形设定为方框(默认是圆) 第二部分是图形中节点的设定, 即定义有哪些节点, 然后在后面的[]中对节点进行自定义, 比如label就可以指定显示的文字 第三部分是流程图的顺序关系, 比如raw -&gt; clean就从raw到clean画了一个箭头, 同样后面可以用[]自定义 完成上面代码编写后, 就可以调用graphviz的dot命令生成图片了: 1dot -Tpng workflow.dot &gt; workflow.png vscode下有相应的插件, Linux上安装插件后就可以边写边预览流程图, 非常方便.","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"流程图","slug":"流程图","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E7%A8%8B%E5%9B%BE/"},{"name":"Graphviz","slug":"Graphviz","permalink":"https://silenwang.github.io/tags/Graphviz/"},{"name":"可视化工具","slug":"可视化工具","permalink":"https://silenwang.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/"},{"name":"软件开发","slug":"软件开发","permalink":"https://silenwang.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/"}]},{"title":"Linux发行版的易用性越来越高了","slug":"Linux下的软件越来越丰富了","date":"2019-04-06T17:03:42.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2019/04/06/Linux下的软件越来越丰富了/","permalink":"https://silenwang.github.io/2019/04/06/Linux%E4%B8%8B%E7%9A%84%E8%BD%AF%E4%BB%B6%E8%B6%8A%E6%9D%A5%E8%B6%8A%E4%B8%B0%E5%AF%8C%E4%BA%86/","excerpt":"前些天帮师姐弄了一下序列比对, 才发现原来经常用的MEGA出到了X(10), 并且现在有了Linux的GUI版本. 不由得小感叹了一下: 世界真是在慢慢变化的.","text":"前些天帮师姐弄了一下序列比对, 才发现原来经常用的MEGA出到了X(10), 并且现在有了Linux的GUI版本. 不由得小感叹了一下: 世界真是在慢慢变化的. 记得我第一次装Linux发行版玩是在大三, 当时装的是Ubuntu. 界面和特效都很酷炫, 而且在我的老电脑上也比win来得顺畅的多, 然而界面这种东西很快就会看腻歪, 然后各种头疼的问题跟着就来了: 中文支持不行, 常用软件完全没有, 系统更新容易挂(涉及内核或跨大版本), 小白看的懂的资料几乎没有, 然后就是我至今已经记不起来的各种小问题. 当时深度的发行版还是基于Ubuntu的, 着重于在Ubuntu基础上优化中文用户的使用体验. 于是没半个月我就从Ubuntu换到了Deepin. 然而虽然在中文支持和系统更新上较原版Ubuntu好了很多, 但常用软件的缺失(办公&#x2F;通信)让人几乎不可能在一个大家都用Windows的环境下用这个系统. 于是一两个月之后为了作业和打游戏(其实本质上还是打游戏…)我就弃坑了… 之后再装回Linux发行版是研一下学期了, 初衷是想少玩游戏好好学习, 因为当时智能手机已经完全普及了, 基本的通信可以用手机, 不是非要用电脑, 而且当时WPS已经有Linux版本了, 基本的写个文档PPT完全没问题(虽然win下播放还是要调格式). 学业相关的东西上, 统计我可以用R, 序列分析我可以用Ugene, 而写脚本这种东西在Linux下远比在Win下容易(Linux一条命令, Win下得安装配置一堆东西), 所以很顺畅的就且到纯Linux环境了. 之后则是入Arch教的姿势错误入了Manjaro然后再也没出坑, 然后G胖致力推进Linux游戏生态的发展让我第一次体会了被打折支配的恐惧… 至此, 在日常生活中我已经能用Linux发行版作为主役操作系统并且不会出太大问题了. 当然, 这一方面是因为Linux GUI本身的发展, 另一方面则是其他的因素导致过去的问题不再是问题. 比如上面说的通讯软件, 其实至今也没有解决(微信 QQ 阿里旺旺至今没有原生客户端), 但是由于智能手机的崛起, 很多时候不再需要使用电脑来进行即时通讯了. 另一个例子则是Flash和HTML5, 本来Linux下Flash的支持极差, 然而大陆内有许多网站又恰好非要用这个, 导致过去很多必须要用的网站无法正常使用, 必须在系统里装个虚拟机. 然而Flash最终没落了, 开始全面被HTML5替代… 希望在我有生之年的某一天, Windows的市场份额真的会发生动摇, 我们可以不再被局限在单一的系统平台上","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"Steam","slug":"Steam","permalink":"https://silenwang.github.io/tags/Steam/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://silenwang.github.io/tags/Ubuntu/"},{"name":"Deepin","slug":"Deepin","permalink":"https://silenwang.github.io/tags/Deepin/"},{"name":"Manjaro","slug":"Manjaro","permalink":"https://silenwang.github.io/tags/Manjaro/"},{"name":"中文支持","slug":"中文支持","permalink":"https://silenwang.github.io/tags/%E4%B8%AD%E6%96%87%E6%94%AF%E6%8C%81/"},{"name":"软件生态","slug":"软件生态","permalink":"https://silenwang.github.io/tags/%E8%BD%AF%E4%BB%B6%E7%94%9F%E6%80%81/"},{"name":"跨平台","slug":"跨平台","permalink":"https://silenwang.github.io/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/"},{"name":"Windows对比","slug":"Windows对比","permalink":"https://silenwang.github.io/tags/Windows%E5%AF%B9%E6%AF%94/"},{"name":"MEGA","slug":"MEGA","permalink":"https://silenwang.github.io/tags/MEGA/"},{"name":"WPS","slug":"WPS","permalink":"https://silenwang.github.io/tags/WPS/"},{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"Ugene","slug":"Ugene","permalink":"https://silenwang.github.io/tags/Ugene/"}]},{"title":"使用GNU Parallel在Bash中执行并行","slug":"使用GNU-Parallel在Bash中执行并行","date":"2019-03-31T23:07:26.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2019/03/31/使用GNU-Parallel在Bash中执行并行/","permalink":"https://silenwang.github.io/2019/03/31/%E4%BD%BF%E7%94%A8GNU-Parallel%E5%9C%A8Bash%E4%B8%AD%E6%89%A7%E8%A1%8C%E5%B9%B6%E8%A1%8C/","excerpt":"之前已经在R和Python中都使用过并行了, 我是最近才知道原来Bash下面也有简单好用的并行程序: GNU Parallel[^1]. 这是一个Perl实现的程序, 可以方便的将Bash中各种命令并行执行.","text":"之前已经在R和Python中都使用过并行了, 我是最近才知道原来Bash下面也有简单好用的并行程序: GNU Parallel[^1]. 这是一个Perl实现的程序, 可以方便的将Bash中各种命令并行执行. [^1]: GNU Parallel on Zeondo 由于刚刚上手, 现在暂时只知道一种使用方式, 就是替代For循环, 将并行的命令替换成并行执行, 比如下面写了一个分染色体合并vcf的例子: 1234for chr in &#123;&#123;1..22&#125;,X,Y&#125;;do bcftools view -f PASS -r chr$&#123;chr&#125; sample.vcf &gt; sample.chr$&#123;chr&#125;.flt.vcfdonebcftools merge sample.chr&#123;&#123;1..22&#125;,X,Y&#125;.vcf &gt; sample.flt.vcf 使用GNU Parallel替代可以是这样子: 12echo &#123;&#123;1..22&#125;,X,Y&#125; | tr &quot; &quot; &quot;\\n&quot; | parallel &#x27;bcftools view -f PASS -r chr&#123;&#125; sample.vcf &gt; sample.chr&#123;&#125;.flt.vcf&#x27;bcftools merge sample.chr&#123;&#123;1..22&#125;,X,Y&#125;.vcf &gt; sample.flt.vcf 上面的会是循环bcftools view然后合并, 下面则是并行执行后再合并. 当然我这个例子没有意义…因为第一种先循环再合并…和直接过滤没有什么区别… 默认情况下parallel有多少核心就用多少核心, 所以实际使用可能会使用-j指定核心上限或者使用--load 80%指定用80%的核心. 有了这个东西, 只要使用的工具是支持输入参数定位分析区域的, 都可以快速的将其变成并行执行, 加快分析速度. 这么一来, 用Snakemake写流程舒心了很多… 关于这个程序的其他用法之后有缘继续更…","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"并行计算","slug":"并行计算","permalink":"https://silenwang.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"},{"name":"bash","slug":"bash","permalink":"https://silenwang.github.io/tags/bash/"},{"name":"GNU Parallel","slug":"GNU-Parallel","permalink":"https://silenwang.github.io/tags/GNU-Parallel/"},{"name":"命令行工具","slug":"命令行工具","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/"},{"name":"性能优化","slug":"性能优化","permalink":"https://silenwang.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"}]},{"title":"Lumpy的算法解读","slug":"Lumpy的算法解读","date":"2019-03-31T22:10:20.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2019/03/31/Lumpy的算法解读/","permalink":"https://silenwang.github.io/2019/03/31/Lumpy%E7%9A%84%E7%AE%97%E6%B3%95%E8%A7%A3%E8%AF%BB/","excerpt":"Lumpy作者对这个项目的定位与其说是做一个好用的工具, 不如说是构建一个通用的结构变异信号生成方案, 然后顺便对这个方案做了一个基本的实现. 与其他工具相比, lumpy的文章中花了更多的篇幅去阐述这个方案中设定的证据概念, 及获取信息的方案. 解读这个工具让我更加了解如何从NGS测序数据中获取结构变异的信号.","text":"Lumpy作者对这个项目的定位与其说是做一个好用的工具, 不如说是构建一个通用的结构变异信号生成方案, 然后顺便对这个方案做了一个基本的实现. 与其他工具相比, lumpy的文章中花了更多的篇幅去阐述这个方案中设定的证据概念, 及获取信息的方案. 解读这个工具让我更加了解如何从NGS测序数据中获取结构变异的信号. 工具基本情况lumpy使用C++编写, 所有的功能似乎都是自己实现的, 没有引用什么已有的模块. 软件可以从conda上获得, 程序本身近几年似乎没有更新, 所以不需要自己头疼从源码编译的问题. 软件检测结果格式可在VCF及BEDPE中进行选择. 不过需要注意的是, 两种格式包含的接过信息似乎有差异, VCF的会更详细一些. 另外本工具完全依赖BAM文件中对比对情况的记录, 因此如果比对本身的情况不理想, 必然影响下游结果. 然后, 工具本身不含有任何随机化的成分, 输入的文件一样, 检测结果就会是一模一样的. Lumpy中的结构变异模型Lumpy首先创建了一种结构变异断点模型: $b &#x3D; (E,l,r,v)$ 在这个模型中, 断点被定义为在待测基因组相邻但是在参考基因组上不相邻的一对基因坐标. 这一对断点通过四个指标进行描述, 分别是: $E$: 支持断点的一系列证据集合 $l$: 左侧断点区间(interval), 包含区间的起止位点s和e(start&#x2F;end)一个向量p, 这个向量p代表区间内每一个点是这个点是真正断点位置的相对概率(relative probability) $r$: 与$l$一致, 包含右侧断点的所有信息 $v$: 断点复杂性(variety)信息, 主要包含不同证据的方向信息. 这个指标的存在是为了保留更多原始信息, 因为当结果被检出时, 只会标注其为某一类结构变异(如deletion), 但是原始的信号中可能包含支持其它类型的证据. Lumpy对SR和RP信号都有使用, 每一个信号都能解析出一个断点的实例, 那么在读出所有断点实例后, 就需要根据包含的信息推断是否同一断点, 然后进行断点合并, 合并的条件是: 两个断点的两侧断点区间均有重合部分(阈值不详) 两个断点的复杂性一致 在满足上述条件后, 即可将两个断点合并起来, $E$中包含原先的两个信号, $v$不变(本来就一致), $l$和$r$则采取取算术均数(mean)的方式来合并, 即$l$的起点为原来两个起点的算术均数, 终点也是原来两个终点的算术均数, $r$也一样(但是多条时具体如何执行的未知, 两两依次去平均和直接取平均的结果是不一样的): $$merge.start &#x3D; \\frac{l1.start + l2.start}{2}\\ \\ merge.end &#x3D; \\frac{l1.end + l2.end}{2}$$ 根据作者描述, 这么做是为了减少离群证据对断点区间的影响. 证据合并完之后, 证据数目大于预设阈值的断点会被检测为结构变异. 确定检出的结构变异, 需要根据断点实例里包含的信息来确定, 以下是默认的计算方案: 断点的可能区间 区间内每个点是真实断点的可能性 首先, 变异的断点可能区间(interval)取断点实例的左侧断点的最大值, 和右侧断点的最小值(即取最小的可能区间). 而区间内每个点的可能性见下(以左侧断点为例): $$l.p[i] &#x3D; \\prod_{e{\\in}E}e.l.p[i-o]$$ $i$是某一个基因坐标位置 $l.p$是单个点是真断点的可能性向量, 前面的$l.$代表是左侧断点的 $E$是所有证据的集合 $e$是证据集合里面的每一个证据 $e.l.p$单个证据里左侧断点的可性向量 $o$是偏移量(offset value), $o &#x3D; e.l.s - s.l.s$, 即当前证据的左侧断点起点减去预检出的结构变异起点位置. $e.l.p[i-o]$这一个略微有点绕, 其实本质跟变异位点的覆盖类似, 最终区间里每一个位置的p是证据里有这个位置的e的p值的积. 所以, 理论上最终区间中的某个点与越多的原始证据区间重合, 这个点的p值就越小, 对应就越可能是真的断点所在位置. 在进行证据合并的时候, 由于是不断的取算术均数来却确定合并后的起止点的, 因此有可能最后的起点和止点中间是没有区间的(相等或颠倒?没有实例验证过), 在这种情况下, 作者会在所有的起点区间中, 找到坐标最大的那个坐标, 然后把没有经过这个坐标的区间删掉, 用剩下来的区间重新进行证据合并和区间以及概率向量的确定.(这一部分我不能完全确定, 因此原文贴出) In the paper, Layer wrote:Given the liberal merge process, it is possible for b.E to contain nonoverlapping distributions that would result in a zerolength product. In this case, we identify the maximum point among the sum of the distributions in b.E, any distribution not intersecting this point is removed, and the resulting subset processed normally. 如此一来, 就形成了最终的结果条目. 最终的结果条目中的断点区间还可以根据预设的百分比, 来进行缩小, 比如只取前99.9%等. 除了上述的方案, 还有一个Summation方案, 用于低质量数据, 这里暂时不解读. 从上面的方案可以看出, Lumpy本质上就是从bam里面读取含有信息的比对记录, 从记录抽取需要的信息, 然后根据信息解读结构变异. 那么一个关键的点就是从信号中抽取哪些信息. 为了定义需要的信息, Lumpy设计了一个叫做Breakpoint evidence的接口, 或者说通e用证据类: 这个接口要求下面3样信息: is_bp: 是否含有断点位置信息 get_v: 结构变异的类型信息 get_bpi: 断点的可能区间信息 也就是说, 对于每一个信号&#x2F;证据, 都会解读出上述3样信息, 然后将这些信息做为一个单独的证据e, 加入到证据集E中, 进行之前说的解读过程. 那么如和从信号&#x2F;证据中解读上述信息呢, 文章分别从SR, RP以及general breakpoint interface三类证据举例: RP证据的解读在双端测序中, Reads Pair内的插入片段是有一个正常的长度范围的, 且Read1和Read2的比对方向也是应该分别为+&#x2F;-, 任何不正常的比对都提示了断点的存在, 因此解读出的信息如下: is_bp: 是, 可以确定断点存在 get_v: 当两条Read在同一染色体上, 根据Read1和Read2的实际比对方向可推测变异类型(DEL&#x2F;INV&#x2F;DUP), 否则, 将统一为inter-chromosomal get_bpi: 通过两个Read的比对信息获取最终的断点区间以及区间的p, 有点复杂故见下 获得断点区间本质上就是根据比对信息从一条read的信息映射出断点的l(包含区间及区间中点的p值), 另一条read映射出r. 以l为例子: 根据Read的比对方向确定断点是在比对位置的上游还是下游 在进行判定前, 程序会通过从bam中抽取比对没有问题的Reads Pairs来估算插入片段的分布, 获取插入片段的平均长度$l$和标准偏差$s$(注意是标准偏差Standard Deivation, 非标准差), 另外要求一个人为指定的变量$v$, 以$l + vs$作为正常插入片段的预期数值. 由于打断时不太会出现超出预期的片段, 因此可以推测断点应该就在比对位置上游或下游$l + vs$(bp)长度的范围内, 也就有了断点的区间范围 对于上述区间内的每个点$i$, 其为真断点的可能性计算方式为$P(S(y).e-S(x).s &gt; i - R(x).s)$(这里的$S()$原文没有明确解释, 我推断是sample的缩写, 与$R()$相对, 代表实际片段上的情况) $y$代表Read2, $x$对应Read1 $S(y).e$是实际片段上Read2的终止位置, $S(x).s$就是实际片段上Read1的起始位置 $S(y).e-S(x).s$即为实际片段的长度 $i-R(x).s$即点$i$距离Read1比对起点的距离 $P()$应当为从正常比对Reads获得的插入片段长度分布得到出的p值函数, $P(a&gt;b)$的意义类似我们使用正态分布时里面的$P(Z&gt;2.94)$, 使用对应分布的曲线下面积可以获得最后的p值, 从而评估这个位点是真正断点的可能性 SR证据解读SR证据中, 一条read的相邻部分会比对到不相邻的基因组位置, 在lumpy中, 如果一条read存在多于两个小片端的比对, 则将这些小片端拆成两两小片段组分别考虑(比如三个片段就分$x_1,x_2$和$x_2,x_3$两组进行考虑), 从每一对小片段中解析出的信息如下: is_bp: 是, 可以确定断点存在 get_v: 当两个片段的比对方向一致, 结构变异可能是DEL或者DUP中的一种(依据比对方向+&#x2F;-不同), 比对方向不一致但在同一染色体上则为INV, 如果比对到不同的染色体则为inter-chromosomal get_bpi: 断点的区间位置与推测的结构变异类型有关. 考虑到测序中可能存在的错误, SR证据给出的断点位置也是有范围的, 这个范围大小取决于上述提到的输入参数$v$, 样品的质量(?)以及比对是使用的算法(?). 由于文献中对这部分的描述不如RP部分详细, 所以下面这些是个人的推论, 有空的话需要通过实际测试证实: 关于区间的获得: 理想的Split-Read断裂的两部分应该是相互不重叠的, 但是在实际中其实会存在两个部分有重叠的情况. 从lumpy作者自己写的SR Read提取脚本来看, 其确实是允许两个部分有一定长度的重叠的. 所以文中所说的SR证据的断点区间的与样品质量和比对算法有关可能就是指这个. 关于区间内的p值确定: 由于作者只说了这个区间的中点p值最小, 越靠近两边p值越大, 可能是内部分配了一个比例吧…这个可能需要自己造个证据bam一点一点去试了 general breakpoint interface解读这种证据本质上就是记录了确定存在结构变异信息的BEDPE文件, 由于BEDPE文件中原本就会记录双边断点区间和结构变异的类型, 所以将这些信息与get_v, get_bpi对应即可. 关于BEDPE格式因为后面会有专门叙述所以这里略. 该类证据的存在作用我觉得有两个: 第一是在做遗传相关的分析时, 可以让人群中确定存在的变异更容易检出. 另一方面, 在做多工具同时检出时, 可将其他工具检出的比较可靠的变异接过与Lumpy的结果进行合并.","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"结构变异","slug":"结构变异","permalink":"https://silenwang.github.io/tags/%E7%BB%93%E6%9E%84%E5%8F%98%E5%BC%82/"},{"name":"算法解读","slug":"算法解读","permalink":"https://silenwang.github.io/tags/%E7%AE%97%E6%B3%95%E8%A7%A3%E8%AF%BB/"},{"name":"NGS数据分析","slug":"NGS数据分析","permalink":"https://silenwang.github.io/tags/NGS%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"RP证据","slug":"RP证据","permalink":"https://silenwang.github.io/tags/RP%E8%AF%81%E6%8D%AE/"},{"name":"SR证据","slug":"SR证据","permalink":"https://silenwang.github.io/tags/SR%E8%AF%81%E6%8D%AE/"},{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/tags/Bioinformatics/"},{"name":"SV检测","slug":"SV检测","permalink":"https://silenwang.github.io/tags/SV%E6%A3%80%E6%B5%8B/"}]},{"title":"NGS检测结构变异中的基本概念","slug":"结构变异检测基本","date":"2019-03-16T20:04:36.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2019/03/16/结构变异检测基本/","permalink":"https://silenwang.github.io/2019/03/16/%E7%BB%93%E6%9E%84%E5%8F%98%E5%BC%82%E6%A3%80%E6%B5%8B%E5%9F%BA%E6%9C%AC/","excerpt":"“我所知道的结构变异相关信息”这个博客构想的内容有点太多了, 一次写太多我自己回查也不是很方便, 所以还是决定拆成各个小的部分, 之后再用gitbook写个综合的.","text":"“我所知道的结构变异相关信息”这个博客构想的内容有点太多了, 一次写太多我自己回查也不是很方便, 所以还是决定拆成各个小的部分, 之后再用gitbook写个综合的. 结构变异&#x2F;拷贝数变异&#x2F;基因融合结构变异与SNP&#x2F;InDel这两种小范围的基因突变相对, 泛指所有相对大规模的基因变异(具体多少bp以上算, 我暂时也不清楚). 大部分文献中这些变异都称为结构变异( Structural Variation), 这些变异被认为来源于基因组的重组(reorgnization)或称重排(rearrangement)这些变异的大小和样式比较多样了, 有生物课上讲过的整段染色体的交换, 也有单纯的片段缺失, 只是片段相对大而已. 目前对结构变异更多是按下面的类型来分: 插入&#x2F;缺失(Insertion&#x2F;Deletion, INS&#x2F;DEL): 本质上就是InDel, 但是片段大 重复(Duplication, DUP): 代表某个区域连续重复出现, 另外重复下还有一种由’串联重复’(Tandem duplication), 待进一步考证 倒位(Inversion, INV): 即染色体内某区域的5’端和3’端颠倒过来 易位(Translocation, ITX, CTX): 即某个区段的转移, 可能是染色体内的转移, 也可能是染色体间的. 易位本身其实是一种复杂的结构变异. 比如染色体内易位, 某个片段从染色体上的A位置整段移动到了B, 那么A位置就会有这个片段的缺失, 而B位置则会有插入. 而如果片段插入的时候不是按原来方向插入的, 则同时也发生了倒位. 下面这幅图取自Gawroński的博士论文, 形象的展示了上述结构变异的类型. 在结构变异的基础之上, 我们就可以进一步的来了解一下拷贝数变异(Copy Number Variation)以及基因融合(Gene Fusion). 拷贝数变异的关键是拷贝(Copy), 拷贝的概念呢…emmmmmm…这么说吧: 假设ATGCGGTAGCCGTAT是一个基因的完整序列, 我们就把这段序列称作一个拷贝. 然后人是双倍体, 所以正常来说, 一个人应该有两份这个基因, 也就是两个拷贝. 那么当基因检测的时候, 发现一个人的基因组里这个基因的拷贝数不为2, 我们就说检测到了这个基因的拷贝数变异. 由上面的概念可以看出, 拷贝数变异本质就是结构变异, 或者更确切一点, 是结构变异导致的一种结果. 如果基因组发生了缺失, 那么势必会有基因的拷贝数下降. 而重复则很明显会导致拷贝数增加. 那么, 为何拷贝数变异会被单独拿出来呢? 我个人认为, 这可能跟概念的提出时间或者其背后的实际意义有关. 假设每个不同拷贝的基因都具有一样的表达能力, 那么, 基因拷贝数的增加势必会使得基因的表达增加, 而拷贝数减少则会导致基因表达下降甚至相关表达产物消失. 简而言之, 与结构变异侧重于弄清楚基因区段到底发生了怎样的变化, 比如消失的区段从哪到哪开始, 消失的区段有没有去到基因组的某一个位置, 有的话这个位置在哪等具体的信息相比. 拷贝数变异关切的重点在于, 某个基因&#x2F;区段的拷贝数是否变化了. 由于侧重点的不同, 拷贝数变异可以在结构变异检测中一并进行, 也可以单独进行, 当然实际上现在大多数时候是分开用不同策略进行的. 本篇主要还是侧重于结构变异, 所以后面的内容不会专门写拷贝数变异的相关内容. 与拷贝数变异类似, 基因融合(Gene Fusion)也是结构变异的结果. 比如某个基因区段整段缺失了, 那么区段的上下游必然会连接起来. 如果消失区段的前后两个断点刚好都在两个基因的表达区域内, 那么这两个基因就被连接在了一起, 这就是基因融合. 所以我们可以看出, 所有的结构变异都有可能导致基因的融合, 只是最终融合起来的方式不太一样. 基因融合受到关注由一些疾病&#x2F;癌症的病因确认有关. 比如癌症中的EML4-ALK融合, 慢性粒细胞白血病中的BCR-ABL融合. 由于基因融合关注的是最后是否有基因连在了一起, 以及怎么连接的(这关乎基因表达是上升还是下降了), 所以其在检测的时候也有专门的策略与工具, 详细见后. 使用NGS数据检测结构变异&#x2F;基因融合二代基因组重测序的基本原理是把完整的基因序列打碎, 对碎片序列进行测序后将其比对回参考基因组后重组序列的原貌. 在这个比对的过程中会产生一些”不正常”的比对结果, 这些结果中, 有些能提示我们待测基因组相对参考基因组发生了结构变异, 我们的检测也就是基于这些比对结果, 我们将之称为结构变异信号(signal)&#x2F;证据(evidence) 结构变异检测策略结构变异检测的基本策略一般归类为4类, 一类一类来: 1. Split-Reads如果之前有接触过NGS的序列比对文件(SAM&#x2F;BAM), 一定在文件中见过Clip-Reads. 简单来说, 这些序列在比对的时候并不能全长比对到基因组的某个地方, 而是一部分比对到一个地方, 另一部分比对到另外一个地方. 这些序列可能来自于刚好包含了结构变异断点的序列, 因此才会出现这种异常的”嵌合比对(Chimeric alignment)“. 通过将这些序列抽取出来, 并对两处Clip序列的比对情况进行回溯, 可以一定程度长推测发生的结构变异类型. 而基于这种信息进行结构变异检测的策略就是SR策略. 2. Discordant Read Pairs如果采用了双端测序(Pair-End Sequencing), 那么测序结果将是成对出现的. 根据测序原理可知, 双端测序得到的是一个DNA单链5’端和3’端的序列. 由于测序文库制备时, 会将DNA打断到一个固定的范围内, 因此, 正常情况下一对序列的Read1和Read2在基因组上的距离应该是出于一个固定范围内, 并且应该是一条正向比对上参考基因组, 另一条则是反向互补比对. 但是在实际的比对结果中, 总会有一些序列对不符合上述情况, 比如比对距离相去甚远甚至不在同个染色体上, 或者Read1 Read2都正向比对到基因组上等等. 在这种情况下, 这一对序列就称作”Discordant Read Pairs”, 可能由于这种信号来自一对序列, 所以Lumpy中直接称其为”Pair-End Evidence, PE”, 但基于这种信号的检测策略好像更经常被RP(Read Pair)策略(这个需要之后多看一点评测文章确认). 这样的Reads对同样可能来自包含了结构变异断点的序列, 区别则在于断点的位置. 对于Split-Read, 断点位于序列一端, 所以刚好被测出来了. 而对于Discordant Read Pairs, 断点应该在插入片段范围内, 也就是并没有直接体现在测得的序列上. 3. Read Count或者叫Read Depth这种策略就如其名字, 是基于特定片段的测序深度的检测方案. 很明显, 这是用来检测拷贝数变异的. 不论发生了何种结构变异, 如果最终导致了某基因的拷贝数减少, 那应该会直观反应到该基因的比对结果上—-该基因区域的测序深度明显下降. 反之, 如果发生了拷贝数增加, 测序深度就应该相应增加才是. 这个策略从原理上说来相当简单, 但是在实际应用的时候并不会必前面的两个策略简单多少. 因为其面临一个说来简单但非常麻烦的问题: 深度高多少算明显高, 低多少算明显少? 这个问题使用外显子或目标区域测序进行拷贝数变异检测时会变得更为复杂. 4. de novo Assembly这里的de novo Assembly和二代测序中的不依赖参考序列, 从头组装基因组其实是一个意思. 应用在结构变异检测上, 则是在查看SR或者PE信号之前, 先对获取下来的序列进行组装. 因为序列组装后获得更长的片段, 这些使用这些片段再次进行比对会获得比短序列更好的结果. 可以看出这种简称AS的策略不会单独使用, 因为其目的在于获取更长的片段, 重新比对后再按照SR的思路来进行检测. 关于检测策略的个人思考1. 测序方案的理论和现实就象黄树嘉老师博文中写的那样, 想获得更可靠的结构变异检测结果, 提高片段长度, 进行全基因组测序是最简单直接的方式. 然而这两种方案都意味着单次检测成本的增加, 在测序的成本真正白菜价以前, 使用尽可能少的数据来获取更可靠的结果必然是结构变异检测应用在临检领域所必须面临的问题. 2. PE和SR信号的获取难度的差异假设一个结构变异断点周围的序列被测出来的可能性是相等的, 那么出现PE信号的可能应该是大于SR信号的, 因为测序时插入片段的长度往往是比Read本身要长, 自然断点位于插入片段区域的时候会更多一些. 另外, 由于大多数检测手段还是要基于比对, 那么一些SR信号还可能会因为断点位置不好(太靠近Read两端), 难以正确比对而导致信号丢失. 所以, 在同样的测序深度下, 尽量去应用PE信号理论上是能提高检测的灵敏度的. 3. 基于比对带来的检测瓶颈由于大部分工具都还是要基于序列的比对情况的, 因此如果真实的变异信号存在比对困难(序列太短无法比对), 必然会导致一些信号的丢失而影响检出. 这也催生了一些不基于比对的检测方案的尝试. 基因融合专属检测策略在前面我们已经说过, 基因融合是结构变异的一种结果. 某种基因融合受关注, 多半是因为这种融合会导致基因表达的异常, 进而产生疾病. 因此在基因融合的检测中, 侧重点在于检测是否有基因融合在一起了, 以及它是怎么融合的. 由于这个侧重点的不同, 除了使用结构变异的检测策略从基因组上检出结构变异然后再进行融合可能的解读外, 也衍生出了专门进行融合检测的方案: RNA-Seq融合检测. 这种方案直接在转录组中进行融合检测, 如果检测到了来自与不同基因转录本的序列, 即可以说明存在基因的融合事件. 同时, 由于检测的是RNA, 也不用费力去推测融合会不会发生, 因为检测到即证明了融合的有效性. 当然, 个人认为这种方式也不是十全十美的, 能想到的缺点有如下: 检测难度较DNA高, 毕竟RNA易降解… 作为应用于临床检测的方案, 使用RNA检测应该会有样品的限制和成本上的限制 由于我暂时没有在实际工作中使用过这类工具, 也暂时没有使用的计划, 所以这个部分等下文的坑填完了再回来挖坑. 另外, 目前大多数结构变异&#x2F;融合的检出方案中, 向参考基因组比对都是必不可少的, 然而这个过程目前来说比较耗时的(使用了FGPA芯片做专门优化除外). 而基因融合本质上只需要了解是否有序列显示两个基因融合在一起了, 因此, 目前也见到有商业公司开发了基于非比对数据(fastq)的检测方案(INVALID POST SLUG PROVIDED ), 该方案但从检测速度来说确实快了非常多. 最后还有一点要注意, 由于侧重点的不同, 一些专门的基因融合检测软件在汇报融合结果的时候只汇报融合的基因及具体的外显子, 其形式多种多样, 无法直接与结构变异的检测工具进行比较. 工具早期的结构变异软件会使用前述的一到两个检测策略, 而比较新的检测软件基本都是多策略的了…物尽其用嘛. 我之后解读的几个工具都是相对较新的, 他们在策略上都是多策略并用的. 其中Creast是我第一个使用较多的结构变异检测工具, 对结构变异的初步了解也是来自它, 不过它的年份也是相对久远了… Lumpy是我第二份工作中首要接触的工具. SvABA和SViCT是两个我在Github上找到的工具, 都比较新, 前者是2018年发布的, 是一个与Broad Insititute合作的项目, 后者2019年发布, 号称是第一个针对cfDNA设计的结构变异检测工具. 这里目前挖坑的都是我有实际用过的工具. 对于我在工作中见人提起的比较多的Manta, Delly以及后续新看到的工具, 如果有必要的话我再慢慢补充.","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"结构变异","slug":"结构变异","permalink":"https://silenwang.github.io/tags/%E7%BB%93%E6%9E%84%E5%8F%98%E5%BC%82/"},{"name":"拷贝数变异","slug":"拷贝数变异","permalink":"https://silenwang.github.io/tags/%E6%8B%B7%E8%B4%9D%E6%95%B0%E5%8F%98%E5%BC%82/"},{"name":"基因融合","slug":"基因融合","permalink":"https://silenwang.github.io/tags/%E5%9F%BA%E5%9B%A0%E8%9E%8D%E5%90%88/"},{"name":"NGS检测","slug":"NGS检测","permalink":"https://silenwang.github.io/tags/NGS%E6%A3%80%E6%B5%8B/"},{"name":"Split-Reads","slug":"Split-Reads","permalink":"https://silenwang.github.io/tags/Split-Reads/"},{"name":"Discordant Read Pairs","slug":"Discordant-Read-Pairs","permalink":"https://silenwang.github.io/tags/Discordant-Read-Pairs/"},{"name":"Read Depth","slug":"Read-Depth","permalink":"https://silenwang.github.io/tags/Read-Depth/"},{"name":"de novo Assembly","slug":"de-novo-Assembly","permalink":"https://silenwang.github.io/tags/de-novo-Assembly/"}]},{"title":"R中的逻辑回归","slug":"R中的逻辑回归","date":"2019-03-16T14:07:19.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2019/03/16/R中的逻辑回归/","permalink":"https://silenwang.github.io/2019/03/16/R%E4%B8%AD%E7%9A%84%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/","excerpt":"想不到4年之后, 又要弄回归了…这一次用的R而不是SPSS, 之前作的是统计分析, 这次…居然变成机器学习了…","text":"想不到4年之后, 又要弄回归了…这一次用的R而不是SPSS, 之前作的是统计分析, 这次…居然变成机器学习了… 简介逻辑(logistic)回归是广义线性模型的一种, 其特点在于因变量是分类变量, 通过将所有分类中的一个设为对照, 将其他的分类选项发生的的可能都与对照做比较的方式, 将分类变量转变成连续变量, 然后进行模型构建. 在逻辑回归中, 变量的系数取exp(x)后即为这个变量对应的OR值, 实际意义为, 该变量每增加一个单位, 接过被分类为1的可能性将提高exp(x). 模型构建本次我使用的逻辑回归因变量是二分类的, 所以使用基本包的glm()函数就够了, 具体模型构建使用: family=binomial(link=&#39;logit&#39;)指定调用二分类逻辑回归模型 12model &lt;- glm(y ~ x1 + x2, family=binomial(link=&#x27;logit&#x27;), data=fit_data)summary(model) # 显示模型信息 在回归的时候, 很难保证第一次回归就能得到最好的结果. 在纳入的协变量中, 总会有系数过小的(也就是实际没太大作用), 或者统计检验不显著的(再抽样一次可能就没作用的), 因此我们需要变更变量多次进行回归. 在R中step()可以帮助我们自动进行回归, 并将对模型贡献小和不显著的变量自动去除: 12model.step &lt;- step(model)summary(model.step) 当然, 这仅仅是个自动化的参考, 最后模型怎么确定好还是要根据实际情况由人来进行具体判断. 模型预测情况估计模型构建好后, 即可以用predict()对测试数据集做预测, 以对模型进行评价, 然后使用一些第三方包通过ROC曲线确定拟合情况, 并对最终的分类阈值做选择 12345678910test_data$prob &lt;- predict(model.step, test_data, type = &quot;response&quot;) # response的话接过是0~1的概率, 不指定默认是个常数# 使用第三方的pROClibrary(pROC)obj_roc &lt;- roc(test_data$Real, test_data$prob) # Real是分类的正确答案, prob是给的预测概率plot(obj_roc, print.auc=TRUE, auc.polygon=TRUE, grid=c(0.1, 0.2), # 做图 grid.col=c(&quot;green&quot;, &quot;red&quot;), max.auc.polygon=TRUE, auc.polygon.col=&quot;skyblue&quot;, print.thres=TRUE)# pROC给的ROC曲线图y轴是灵敏度(真阳性), x轴则是特异度(真阴性), 而非更常见的假阳性率, 所以x轴是1-&gt;0而非0-1 小Tips生成的模型对象本身也会包含详细的模型信息, 但是直接从模型上取信息与summary()看到的并不一致, 如系数的统计表, summary()给出的表格包含了系数数值, 系数表准误, 统计检验P值等详细信息, 但是直接从model取的话就只有系数数值. 想要取summary()信息的话, 要在其生成的对象上取, 或者先将其赋值后再取: 12345# 先赋值model_info &lt;- summary(model)model_info$coefficients# 直接取summary(model)$coefficients 博客文章学习找了及篇使用R进行逻辑回归的博文, 主要是补充模型的评价方法 Logistic Regression 二分类变量的均一性: 逻辑回归中因变量的两个分类均衡的话, 分类结果会比较理想. 因此进行回归前应先查勘一下两个分类的情况: table(your_data$val). 如果不均衡的话, 理论上应该对例数更大的一个分类进行抽样, 样本量以另一个分类的例数作参考. 多重共线性检测: 逻辑回归和线性回归一样需要例行检测一下共线性的问题, 博客中似乎推荐VIF&lt;4 How to perform a Logistic Regression in R $R^2$获取: 逻辑回归不能计算$R^2$, 文章说可以计算McFadden $R^2$ index替代. 关于这个指标的更多信息: R squared in logistic regression Logistic regression on biased data 不均衡分类中评价指标的选择: 在分类不均衡时, accuracy并不是一个好的评价指标, 推荐使用F1-score 解决分类不均衡的方案有两类: oversampling the minority class以及fixing the model by altering the INVALID POST SLUG PROVIDED or INVALID POST SLUG PROVIDED 根据文章的描述, 对少数项目的oversampling和多数项的undersampling可以一定程度上提高检测结果准确性, 但是在测试用的数据中没有好到可以使用. 12library(pscl)pR2(model) 其它材料 逻辑回归算法 机器学习中的交叉验证思想 Dealing with unbalanced data in machine learning","categories":[{"name":"Statistic","slug":"Statistic","permalink":"https://silenwang.github.io/categories/Statistic/"}],"tags":[{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"https://silenwang.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"机器学习","slug":"机器学习","permalink":"https://silenwang.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"统计分析","slug":"统计分析","permalink":"https://silenwang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/"},{"name":"logistic regression","slug":"logistic-regression","permalink":"https://silenwang.github.io/tags/logistic-regression/"},{"name":"machine learning","slug":"machine-learning","permalink":"https://silenwang.github.io/tags/machine-learning/"}]},{"title":"换新主题&Hexo框架搭建博客记录","slug":"换新主题-Hexo框架搭建博客记录","date":"2019-03-12T00:20:02.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2019/03/12/换新主题-Hexo框架搭建博客记录/","permalink":"https://silenwang.github.io/2019/03/12/%E6%8D%A2%E6%96%B0%E4%B8%BB%E9%A2%98-Hexo%E6%A1%86%E6%9E%B6%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/","excerpt":"昨天因为markdown文章里面用了无法解析的符号, 导致我以为hexo挂了, 遂折腾换了新的主题…顺便又回顾了一下搭建过程","text":"昨天因为markdown文章里面用了无法解析的符号, 导致我以为hexo挂了, 遂折腾换了新的主题…顺便又回顾了一下搭建过程 一般搭建过程hexo基于Node.js, 在arch系系统下sudo pacman -S nodejs npm即可 安装后使用npm在全局环境中安装hexo和hexo-cli(hexo-cli必要, hexo是否必要线下次再测) 123# -g代表全局模块, 安装后可使用hexo命令行工具sudo npm install -g hexosudo npm install -g hexo-cli 接下来使用hexo创建新的博客项目, 一句hexo init就好, 不过要注意, 这一步需要在空目录进行, 否则会提示目录非空, 无法运行. hexo创建的博客有个默认的主题, 不过一般我们不会去用它就是了…在网上搜索一个你喜欢的主题, 然后使用git克隆到项目的theme目录下即可 之后对项目下的_config.yml进行修改就可以修改博客设置了. 修改完毕后hexo g &amp; hexo s可生成并本地预览博客. hexo d则可以发布&#x2F;跟新博客网站, 不过这需要在配置文件内指定好使用的方式(我是git), 并按照提示使用npm装好相应的发布用模块(直接npm install, 这个不需要装到全局) 博客项目备份在很多情况下, 都可能会涉及到在多个地方编辑博客内容的问题. 这个就很简单了….直接git整个项目就可以了, 唯一需要注意的是, 如果使用git安装主题, theme下每个文件夹本来就是一个git项目, 我个人觉得在建立整个项目的git时在.gitignore中设置主题文件夹内所有文件被忽略, 然后主题的_config.yml另外备份一下比价好","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://silenwang.github.io/tags/hexo/"},{"name":"博客搭建","slug":"博客搭建","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"主题更换","slug":"主题更换","permalink":"https://silenwang.github.io/tags/%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%8D%A2/"},{"name":"Node.js","slug":"Node-js","permalink":"https://silenwang.github.io/tags/Node-js/"},{"name":"git备份","slug":"git备份","permalink":"https://silenwang.github.io/tags/git%E5%A4%87%E4%BB%BD/"}]},{"title":"Snakemake的一些有用特性","slug":"Snakemake的一些有用特性","date":"2019-03-06T23:41:40.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2019/03/06/Snakemake的一些有用特性/","permalink":"https://silenwang.github.io/2019/03/06/Snakemake%E7%9A%84%E4%B8%80%E4%BA%9B%E6%9C%89%E7%94%A8%E7%89%B9%E6%80%A7/","excerpt":"在使用snakemake一段时间后, 发现其中确实有很多实用的特性来方便平常的分析, 做个记录整理","text":"在使用snakemake一段时间后, 发现其中确实有很多实用的特性来方便平常的分析, 做个记录整理 资源限制在rule内可使用resources关键字来限定资源, 这在需要用到GPU(只有一个GPU)或者磁盘性能有限(不能同时进行太多高IO操作)的时候非常有用. 如下面的设定 12345678910111213141516171819202122232425rule all: expand(&quot;&#123;sam&#125;.vcf&quot;, sam=[&quot;sam1&quot;, &quot;sam2&quot;, &quot;sam3&quot;, &quot;sam4&quot;])rule samtools_sort: input: rules.samtools_flt.output output: &quot;&#123;sam&#125;.flt.srt.bam&quot; resources: IO=8 shell: &quot;samtools sort -@ 8 &#123;input&#125; &gt; &#123;output&#125;&quot;rule samtools_call: input: &quot;&#123;sam&#125;.bam&quot; output: &quot;&#123;sam&#125;.vcf&quot; resources: IO=1 shell: &#x27;&#x27;&#x27; bcftools mpileup -Ou -f reference.fa &#123;input&#125; \\\\ | bcftools call -mv -O -o &#123;output&#125; &#x27;&#x27;&#x27; 上面的流程中, sort过程8线程同时进行, 相当消耗IO, 因此设定其使用的IO为8, 而call操作设IO=1, 之后在运行的时候设定最大IO数值就可以达到控制高IO任务数目的目的: snakemake --resources IO=16 任务组需要使用集群时, 在特定的情况下, 将相互关联的任务投递到同一个节点会更节省IO(防止节点间来回传输中间文件, 大概吧…), 使用关键字是group, 同一个组内的任务会被一次性的投递到同一个节点中去执行(节点上会再启动一个snakemake用于控制). 实际使用很简单所以就不写例子. 但是需要注意一个问题, 同组同任务投递上节点后, 虽然有snakemake进行控制, 但是在投递任务结束后, 本地的snakemake进程是会再一次检查input和output是否满足的, 这一点要注意. 比如我使用这个功能是为了利用节点的本地磁盘, 但是这些磁盘是计算节点限定的, 登录节点并不能访问. 这就会导致登录节点的进程检查任务是否完成时, 部分中间结果找不到而导致任务执行失败.","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"snakemake","slug":"snakemake","permalink":"https://silenwang.github.io/tags/snakemake/"},{"name":"工作流管理","slug":"工作流管理","permalink":"https://silenwang.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%AE%A1%E7%90%86/"},{"name":"资源控制","slug":"资源控制","permalink":"https://silenwang.github.io/tags/%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6/"},{"name":"任务分组","slug":"任务分组","permalink":"https://silenwang.github.io/tags/%E4%BB%BB%E5%8A%A1%E5%88%86%E7%BB%84/"},{"name":"workflow","slug":"workflow","permalink":"https://silenwang.github.io/tags/workflow/"},{"name":"resource management","slug":"resource-management","permalink":"https://silenwang.github.io/tags/resource-management/"},{"name":"task grouping","slug":"task-grouping","permalink":"https://silenwang.github.io/tags/task-grouping/"}]},{"title":"python中的itertools","slug":"python中的itertools","date":"2019-02-13T00:37:27.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2019/02/13/python中的itertools/","permalink":"https://silenwang.github.io/2019/02/13/python%E4%B8%AD%E7%9A%84itertools/","excerpt":"原来写脚本的时候很多实用的功能都没有用过, 这次学习了一点点, 做个记录","text":"原来写脚本的时候很多实用的功能都没有用过, 这次学习了一点点, 做个记录 本次涉及到对大文件进行处理, 但是大部分时候是单行处理的, 所以想到用itertools以生成生成器. 这样之后也许可以将生成器分割成小部分, 应用到并行运算中. 本次用到的itertools中的三个函数: groupby tee chain groupby用于对迭代对象进行聚类, 对应实例是UMI分组时, 需要对比对位置接近的reads进行判断, 将比对情况认为一致的reads放一起进一步判断UMI情况 123# 后面是一个以iter_obj的单个对象作为输入的函数, 以函数的返回值作为判断依据grp_generator = groupby(iter_obj, lambda x: x[0])# 需要注意的是, groupby只将临近的对象聚在一起, 所以有必要的话自行排序 tee则很简单, 如果迭代对象是生成器的话, 由于生成器只能用一次的, 对于要用到两次及以上的生成器就需要用tee函数做个副本出来 1iterable_fork_1, iterable_fork_2 = tee(iterable, 2) # 2可以不写, 默认就是2 chain则是酱多个迭代对象的接过连起来, 我本次具体是用来展平嵌套结果: 12flat_iter = chain.from_iterable(ori_iter)# [[1,2],3] -&gt; [1,2,3] 当然实际生成的是生成器, 要自己list(flat_iter)获取完整结果","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"迭代器","slug":"迭代器","permalink":"https://silenwang.github.io/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8/"},{"name":"生成器","slug":"生成器","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E6%88%90%E5%99%A8/"},{"name":"itertools","slug":"itertools","permalink":"https://silenwang.github.io/tags/itertools/"},{"name":"groupby","slug":"groupby","permalink":"https://silenwang.github.io/tags/groupby/"},{"name":"tee","slug":"tee","permalink":"https://silenwang.github.io/tags/tee/"},{"name":"chain","slug":"chain","permalink":"https://silenwang.github.io/tags/chain/"}]},{"title":"python中的多进程","slug":"python中的多进程","date":"2019-02-12T23:45:59.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2019/02/12/python中的多进程/","permalink":"https://silenwang.github.io/2019/02/12/python%E4%B8%AD%E7%9A%84%E5%A4%9A%E8%BF%9B%E7%A8%8B/","excerpt":"R中可以方便的使用多进程, Python中也有类似的东西.","text":"R中可以方便的使用多进程, Python中也有类似的东西. 首先引用廖雪峰的Python教程解释一下进程和线程: 对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个Word就启动了一个Word进程。 有些进程还不止同时干一件事，比如Word，它可以同时进行打字、拼写检查、打印等事情。在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。 由于每个进程至少要干一件事，所以，一个进程至少有一个线程。当然，像Word这种复杂的进程可以有多个线程，多个线程可以同时执行，多线程的执行方式和多进程是一样的，也是由操作系统在多个线程之间快速切换，让每个线程都短暂地交替运行，看起来就像同时执行一样。当然，真正地同时执行多线程需要多核CPU才可能实现。 我们前面编写的所有的Python程序，都是执行单任务的进程，也就是只有一个线程。如果我们要同时执行多个任务怎么办？有两种解决方案：一种是启动多个进程，每个进程虽然只有一个线程，但多个进程可以一块执行多个任务。 还有一种方法是启动一个进程，在一个进程内启动多个线程，这样，多个线程也可以一块执行多个任务。 当然还有第三种方法，就是启动多个进程，每个进程再启动多个线程，这样同时执行的任务就更多了，当然这种模型更复杂，实际很少采用。 我需要执行的任务并不是IO等待很久的, 所以没有选择Python的多线程或者协程, 而是用多进程进行尝试 主要的代码如下: 12345678910111213141516171819202122from multiprocessing import Pooldef func_to_process(args): do someting return resultdef main(): sub_procs = Pool(10) # 10是使用的子进程数 results = [] # 用来存结果 for obj in iterable: result = sub_procs.apply_async(func_to_process, (args)) # 提交任务到进程池, apply_async代表等待提交任务完成, 直接继续提交 # 直到进程池填满后阻塞 results.append(result) sub_procs.close() # 关闭进程池, 不再能提交新任务 sub_procs.join() # 等待所有进程完毕, 这是为了下面正确的取回结果 results = [result.get() for result in results] # 使用get()取出所有结果if __name__ == &quot;__main__&quot;: main() 这段代码存在两个问题: 这种写法等于把我要处理的文件按照行数拆分并执行, 每一行就进程, 拆得太碎了. 尤其是在执行的任务中如果有比较长时间的准备步骤时, 这么做其实会大大降低效率(单进程只准备一次, 而多进程准备无数次) 这样执行后, 结果顺序是有可能打乱的, 如果任务要求结果保持一定顺序, 则需要对接过再次排序 对于问题1, 经过今天学习, 可能是可以通过itertools中的部分功能实现对原文件的定量拆分的, 预计明天更新 对于问题2, 可以使用对应的map方法代替apply, 这个需要再进行尝试","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"并行计算","slug":"并行计算","permalink":"https://silenwang.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"},{"name":"多进程","slug":"多进程","permalink":"https://silenwang.github.io/tags/%E5%A4%9A%E8%BF%9B%E7%A8%8B/"},{"name":"multiprocessing","slug":"multiprocessing","permalink":"https://silenwang.github.io/tags/multiprocessing/"},{"name":"Pool","slug":"Pool","permalink":"https://silenwang.github.io/tags/Pool/"}]},{"title":"R中parellel包的使用","slug":"R中parellel包的使","date":"2019-01-01T02:04:56.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2019/01/01/R中parellel包的使/","permalink":"https://silenwang.github.io/2019/01/01/R%E4%B8%ADparellel%E5%8C%85%E7%9A%84%E4%BD%BF/","excerpt":"最近用写了个画图的脚本, 需要一次性用ggplot绘制大量的图片. 虽然在脚本内所有需要使用循环的地方都已经使用上apply了, 但依然架不住一次画几百图, 所以捣鼓了一下parellel, 将画图的部分并行执行已加快速度.","text":"最近用写了个画图的脚本, 需要一次性用ggplot绘制大量的图片. 虽然在脚本内所有需要使用循环的地方都已经使用上apply了, 但依然架不住一次画几百图, 所以捣鼓了一下parellel, 将画图的部分并行执行已加快速度. 之前在用python的时候就有了解到多线程和多进程, 但是到了R这…好像没有太强调线程和进程的问题, 都是说并行计算…中文资料中能找得到的与并行计算相关的基本就是parellel以及foreach了, 当然我这里用的是parellel, 然后两种方案的异同…没研究过… 使用方法其实比较简单, 就是先注册集群, 然后把任务丢到集群上跑(以函数的形式), 然后合并结果(我这里不需要), 注销集群就行. 当然, 这里的集群并不是指集群服务器, 而是英文中就写的是’cluster’, 我也不知道怎么翻译好…随便叫一下算了. 具体的实现代码如下: 1234567891011# 准备绘图函数plot_process &lt;- function (data_list, args) &#123; library(ggplot2) plot &lt;- ggplot() + geom_line() ggsave(&quot;plot.png&quot;, plot)&#125;cl &lt;- makeCluster(core_num) # 注册parLapply(cl, data_list, plot_process, args) # 除了第一个参数指定集群, 其他参数同lapplystopCluster(cl) # 注销# 由于我只是分别处理数据并绘图, 所以没有很多教程里的合并结果数据的那一步 所以其实超简单的…唯一有点麻烦的问题是, 对于每一个集群节点, 计算需要的变量, 包, 函数都得单独加载一次. 对于变量和包都好说, 变量有专门的函数进行传递, 包的话可以把载入包的语句写到plot_process里面, 但是自己编写的函数就没有直接可用的方式了…在查了很久都没有解决方案后, 我突发奇想的把函数作为参数写到了plot_process上, 居然有用… 在写完这个脚本后, 我还看到了另外一种解决方案, 就是把这些自定义函数单独写在另一个文件里, 然后在plot_process使用source()导入, 这个应该是个更好的方案, 回头我准备试试看….","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"数据可视化","slug":"数据可视化","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"并行计算","slug":"并行计算","permalink":"https://silenwang.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"},{"name":"ggplot","slug":"ggplot","permalink":"https://silenwang.github.io/tags/ggplot/"},{"name":"parallel","slug":"parallel","permalink":"https://silenwang.github.io/tags/parallel/"},{"name":"performance","slug":"performance","permalink":"https://silenwang.github.io/tags/performance/"}]},{"title":"teamviewer+ssh跳转=vpn","slug":"teamviewer-ssh跳转-vpn","date":"2018-12-23T23:00:13.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2018/12/23/teamviewer-ssh跳转-vpn/","permalink":"https://silenwang.github.io/2018/12/23/teamviewer-ssh%E8%B7%B3%E8%BD%AC-vpn/","excerpt":"好久不更了, 今天来记录一下自制vpn的升级版~","text":"好久不更了, 今天来记录一下自制vpn的升级版~ 之前因为一些原因笔记本装了win10, 然后又装回了manjaro. 于是又要重新开始配置一些东西, 其中一项就是回家加班要用的vpn. 由于现在的公司是没有搭vpn的, 所以之前一直用的teamviewer. 但是实际使用下来相当的不方便. 因为我在公司电脑上用的时虚拟机, 经常会出现一些莫名其妙的问题, 再就是网络繁忙的时候会出现明显的卡顿. 之前装win10的那段时间偶然发现teamviewer最新的14版本有一个vpn模式, 试用了一下, 是真的有用的…于是就效仿在上一间公司的自制vpn又如法炮制了一遍: 材料准备 virtualbox with micro xp teamviewer 14 cygwin with openssh tip: 本次试了tiny xp的镜像…发现cygwin在里面没法正常用…没办法还是回百度云下回了原来的备份镜像… SSH设置: 配置~/.ssh/config, 在面设置好跳板就行了, 其中跳到公司工作电脑的那一级借助teamviewer14的vpn, 地址在连接后可从teamviewer中获取. 地址好像是固定的, 因此直接写在配置文件里面就好了. 12345678910111213141516171819Host vpn_vm User Administrator HostName 127.0.0.1 Port 8022 IdentityFile ~/.ssh/vpn_vm_keyHost Jump HostName 123.456.789.0 Port 8022 User silen IdentityFile ~/.ssh/jump_key ProxyCommand ssh Administrator@vpn_vm -W %h:%pHost Target HostName 123.456.789.1 Port 22 User silen IdentityFile ~/.ssh/target_key ProxyCommand ssh silen@Jump -W %h:%p 这里做了一个2级的跳转, vpn_vm是本地的虚拟机, 里面装好了teamviewer进行vpn连接, openssh则负责使本机能通过该虚拟机进行跳转 Jump是公司的机器, 上面用vobx装了manjaro并启动了sshd服务 Target时最终的服务器 上面ProxyCommand设置了每1级的跳转命令, 同时设置了密钥以实现无密直接登录 登陆时本机直接ssh Target就可以了, 相当方便, scp, sftp也直接用就好","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"VPN","slug":"VPN","permalink":"https://silenwang.github.io/tags/VPN/"},{"name":"SSH跳转","slug":"SSH跳转","permalink":"https://silenwang.github.io/tags/SSH%E8%B7%B3%E8%BD%AC/"},{"name":"TeamViewer","slug":"TeamViewer","permalink":"https://silenwang.github.io/tags/TeamViewer/"},{"name":"VirtualBox","slug":"VirtualBox","permalink":"https://silenwang.github.io/tags/VirtualBox/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://silenwang.github.io/tags/Cygwin/"},{"name":"Windows","slug":"Windows","permalink":"https://silenwang.github.io/tags/Windows/"}]},{"title":"用外门邪道的方式使用snakemake实现流程控制","slug":"用外门邪道的方式使用snakemake实现流程控制","date":"2018-11-17T12:47:57.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2018/11/17/用外门邪道的方式使用snakemake实现流程控制/","permalink":"https://silenwang.github.io/2018/11/17/%E7%94%A8%E5%A4%96%E9%97%A8%E9%82%AA%E9%81%93%E7%9A%84%E6%96%B9%E5%BC%8F%E4%BD%BF%E7%94%A8snakemake%E5%AE%9E%E7%8E%B0%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","excerpt":"Snakemake 确实是非常好用的流程开发及管理工具. 但是在特定的场景下…它也会带来一些问题, 然后在机缘巧合下, 我发现了一种非常蛋疼的使用方式: 只使用snakemake的依赖处理和人物管理, 执行脚本另外生成.","text":"Snakemake 确实是非常好用的流程开发及管理工具. 但是在特定的场景下…它也会带来一些问题, 然后在机缘巧合下, 我发现了一种非常蛋疼的使用方式: 只使用snakemake的依赖处理和人物管理, 执行脚本另外生成. 其实起因是因为让我写流程的时候要在特定位置放一份实际的执行脚本, 这样使用流程的人可以读这些脚本之后可以对特定的步骤进行修改后再次投递执行. 初衷是非常好的: 让使用流程, 但不了解snakemake的人也能轻松的对特定样本的分析参数作修改. 可是问题是…snakemake并不支持将实际执行的脚本单独导出形成文件, 只能使用-p参数将执行的内容直接输出在日志里, 并且之前在找解决方案的时候我还不知道可以在cluster模式的投递命令中使用wildcard…所以几经周折, 我找到了如下这个非常歪门邪道的解决方案. 将整个流程划分为若干部分, 然后自写程序生成所有需要执行的脚本 在投递到SGE时, 使用qsub的-sync y参数, 使qsub投递后并不直接结束程序, 而是的等待到投递的完成&#x2F;失败, 如果人物失败, 会返回非0数值 使用snakemake构建流程依赖, input &#x2F; output照常指定, 在input中加上执行脚本, 然后shell:后只写qsub的投递命令 这样一来, 可以曲线解决不能直接生成脚本的问题 –&gt; 我自己生成, 给你投递就好同时也可以利用snakemake的依赖解决和任务管理特性 –&gt; 可以进度监测, 可以断点继续但同时也挖了一个巨坑: 脚本执行内容和各文件名未在snakemake内指定, 如果不一致流程会出错, 且这种问题不会有什么比较好的方法能定位, 全靠写的人自己小心… 比如: 你写了这样一个脚本test.sh: 12#$ -sync ycat test.txt | cut -f 2 &gt; tset.col2.txt 然后写的snakemakefile是这样的: 12345678910111213rule all: input: test.col2.txtrule test: input: &#123;sample&#125;.txt output: &#123;sample&#125;.col2.txt shell: &#x27;&#x27;&#x27; qsub test.sh &#x27;&#x27;&#x27; 那么在使用snakemake运行的时候, 是永远不会运行成功的…因为脚本生成的结果名字和snakemake的目的文件名不一致…然后在默认情况下, 因为判定rule test执行失败, 其他被用于判定的结果文件(如果存在的话)会被删除… 也就是说, 用这种方式的话, 得自己保证目标文件的一致性. 排除这个缺点之外, 这种方式能充分利用snakemake在任务管理上的优势, 又可以避免初期上手snakemake时在理解wildcard机制时所必须要花的时间.","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"snakemake","slug":"snakemake","permalink":"https://silenwang.github.io/tags/snakemake/"},{"name":"workflow","slug":"workflow","permalink":"https://silenwang.github.io/tags/workflow/"},{"name":"流程控制","slug":"流程控制","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/"},{"name":"任务管理","slug":"任务管理","permalink":"https://silenwang.github.io/tags/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/"},{"name":"脚本生成","slug":"脚本生成","permalink":"https://silenwang.github.io/tags/%E8%84%9A%E6%9C%AC%E7%94%9F%E6%88%90/"}]},{"title":"snakemake的使用","slug":"snakemake的使用","date":"2018-10-30T12:40:03.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2018/10/30/snakemake的使用/","permalink":"https://silenwang.github.io/2018/10/30/snakemake%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"写流程是生物信息分析中经常需要涉及的工作, 一个成熟完善的好工具可以使工作的效率大大提高.","text":"写流程是生物信息分析中经常需要涉及的工作, 一个成熟完善的好工具可以使工作的效率大大提高. 最简单的流程编写方式可以是将所有需要运行的命令都写成一个shell脚本, 并使用&amp;&amp;或其他方式指定任务的先后顺序, 然后挂到后台就好. 这么做虽然容易, 但是其重复性和抗错误性实在堪忧. 因此也就有了各种各样的流程管理工具: 我过去单位用的sjm, 10x Genomics自己开发的Martian, Broad Institute的WDL, 我最近在用的snakemake等等. snakemake简介snakemake是德国杜伊斯堡-埃森大学的Köster lab开发的生物信息分析流程管理工具, 其全部代码完全由python实现, 因此可以很好的和python程序整合在一起(当然其也有一套完整的命令行程序). snakemake的特点包括但不限于: 简单易用 可直接使用python代码 内置分布式运算集群支持(SGE, LSF, etc.) 内置Conda环境部署支持 内置容器支持(注意这个容器不是docker) 自动处理依赖并进行断点重启 内置测试功能(benchmark) 与make完全一样的执行逻辑, 有相关基础的人可快速上手 snakemake简单示例snakemake文件中以rule为最基本单位, 一个rule就算是流程中的一个步骤. 在rule下可定义输入文件, 输出文件以及要执行的命令. 由于snakemake基于python, 所以其在语法格式上也与python一致, 也是以缩进来定义控制范围, 比如写一个简单的rule: 1234567rule samtools_sort: input: &quot;test.bam&quot; output: &quot;test.srt.bam&quot; shell: &quot;samtools sort &#123;input&#125; &gt; &#123;output&#125;&quot; 这个名称为”samtools_sort”的rule执行的步骤是将输入的test.bam通过samtools的sort命令进行排序, 然后将输出结果指定为”test.srt.bam”. 最后的shell:代表这里执行的是shell命令, 命令以字符串的形式给出, snakemake还支持直接执行python代码, 此时的关键词需要更改为run:. 此外也支持调用R代码以及其他外部脚本, 详情参考snakemake的INVALID POST SLUG PROVIDED . 使用snakemake进行样品批量处理了解了最基本的rule写法之后就可以写出一串rule, 然后把他们串成流程了, 不过虽然snakemake简单易学, 要写出一个能处理一堆样品的完整流程还是需要了解些东西的. snakemake中的特殊字符串格式化方式从之前的简例中可以看出, snakefile中执行的命令, 输入及输出的文件都以字符串的形式给出. 而在这些字符串中可以使用类似str.format()的格式化字符串方式减少硬编码, 增加应用性. 比如前面的&quot;samtools sort &#123;input&#125; &gt; &#123;output&#125;&quot;中, &#123;input&#125;会被替换成该rule内定义的input后面字符串(如果input不只一个, 则会以空格分隔全部列出). 类似的, 我们可以调用任意rule内定义过的内容来填充文本模板, 以生成最终需要运行的命令或者字符串. 但是有一点需要注意, 对于习惯了用format()的人来说可能会写类似下面的表达: 123456789path=&quot;path/to/input&quot;rule samtools_flt: input: &quot;test.bam&quot; output: &quot;test.flt.bam&quot; shell: &quot;samtools sort &#123;path&#125;/&#123;input&#125; &gt; &#123;output&#125;&quot;.format(path=path) 即将python中的字符串格式化和snakamake的字符串格式化混用. 这种写法snakemake是没法正确处理的, 一个字符串要么只能使用内置的格式化方式, 要么只能用python原有的格式化方式, 上面那种写法, 会按照python原有的方式去处理, 即根据format()内给的信息去填充字符串, 没有指定的input和output会作留空处理. snakemake是可以处理这种情况的, 但是写法上要进行变更: 123456789path=&quot;path/to/input&quot;rule samtools_flt: input: &quot;test.bam&quot; output: &quot;test.flt.bam&quot; shell: &quot;samtools sort &#123;path&#125;/&#123;&#123;input&#125;&#125; &gt; &#123;&#123;output&#125;&#125;&quot;.format(path=path) 用python比较多的话, 一定了解&quot;\\&#123;\\&#123;\\&#125;\\&#125;&quot;代表不对字符串内的&#123;&#125;进行转义, 而当作一般符号. 结合snakemake的执行逻辑, 可知snakemake会自行处理一次纯字符串的输入, 而这一切发生在python部分执行完之后. snakemake的流程执行逻辑snakemake并没有准备专门的顺序或依赖的语法关键词, 流程的串联完全依靠输入和输出文件的依赖关系自动完成. 由于snakemake默认会去解析并完成第一个rule, 因此官方文档推荐的使用方式是创建一个名称为”all”的rule, 然后在这个rule的input中(注意不是output)指定所有的最终文件. 然后程序会发现结果文件不存在, 便在文件中寻找到某条rule的output符合文件模式, 然后继续解析这个rule需要要什么作为input, 如果input(即执行依赖)已满足, 则会开始运行该规则下的命令&#x2F;脚本, 如果不满足, 则会继续向前查找, 直到找到源头或者找不到源头而报错为止, 例如: 123456789101112131415161718rule all: &quot;test.flt.srt.bam&quot;rule samtools_flt: input: &quot;test.bam&quot; output: &quot;test.flt.bam&quot; shell: &quot;samtools sort &#123;input&#125; &gt; &#123;output&#125;&quot;rule samtools_sort: input: rules.samtools_flt.output output: &quot;test.flt.srt.bam&quot; shell: &quot;samtools sort &#123;input&#125; &gt; &#123;output&#125;&quot; 在上面的snakefile中, 流程运行的逻辑是: 最终目标是test.flt.srt.bam, 搜寻可以产生这个文件的rule 发现samtools_sort可产生需要的文件, 而这个规则需要输入samtools_flt规则的结果, 因此samtools_flt先执行 samtools_flt需要输入test.bam, 查询该文件是否存在, 如果存在则按照samtools_flt &gt; samtools_sort &gt; all的顺序执行流程, 如果找不到该文件, 则会提示依赖不满足, 流程无法运行. 由于这种回溯式的流程执行逻辑, 在流程中某一个rule失败后, 非常容易实现流程断点重启: 即回溯式的检查每个步骤的依赖是否已满足, 如果满足, 则从当前步骤执行, 如果不满足, 则继续向上回溯. 另外, snakemake在和执行流程的过程中, 本身会检查输出文件的更新情况以及文件完整性以确定规则是否顺利运行. 如果某个规则出错, 改规则下的结果文件默认会被删除, 所以除非snakemake本身的进程被异常终止, 否则不太会出现某个步骤未完成但是流程继续向后跑的情况. snakemake内建的实用函数由于snakefile内是可以直接写python代码的, 所以对于用惯了python的人, 可以比较轻松的使用生成式之类的东西快速生成批量处理时需要的信息. 而对于没有太多python基础的人, snakemake也准备了一些内建的函数来快速实现类似的功能. 比如: expand: 用来生成字符串列表的函数, 相当于组合了列表生成试和格式化字符串, 默认情况下会将多个替换变量两两组合, 但也可以设置为类似zip()的模式, 即依次组对, 可以满足不同情况下的需要 samples = expand(&quot;&#123;sample_id&#125;.&#123;fq&#125;.fasta&quot;, sample_id=[&#39;sam1&#39;, &#39;sam2&#39;], fq=[&#39;fq1&#39;, &#39;fq2&#39;]) 多样品&#x2F;多文件的批量处理批量处理涉及到snakemake中的一个比较重要的内置对象—-wildcards. 我虽不是太清楚这个东西应该怎么翻译…大致上来说, 这个对象用来进行种带捕获效果的模式匹配(正则). 比如官方文档中给出的例子: 1234567rule complex_conversion: input: &quot;&#123;dataset&#125;/inputfile&quot; output: &quot;&#123;dataset&#125;/file.&#123;group&#125;.txt&quot; shell: &quot;somecommand --group &#123;wildcards.group&#125; &lt; &#123;input&#125; &gt; &#123;output&#125;&quot; 这里规则的输入输出中的&#123;dataset&#125;以及&#123;group&#125;就是两个wildcard, 而每一个wildcard都可以匹配近乎任意字符(对应正则表达式为.+)如果某个规则需要一个file_path/file.001.txt的文件. snakemake在进行查找的时候就会发现这个文件的命名符合complex_conversion下的output规定的模式, 因此snakemake认为file_path/file.001.txt由该规则产生, 并将dataset设定为”file_path”, group设定为”001”, 然后把这两个变量向上传递到input, 继续进行依赖解析. 如此依赖, 当请求的结果文件是按照一定规则去命名的(通常来说会有样品&#x2F;项目ID之类的信息), 就可以通过wildcard来匹配每个样品&#x2F;项目需要进行哪些步骤, 然后自动生成完整的流程路线并开始执行. snakemake &amp; conda为了保证已完成流程的可重复性, snakemake内置了使用conda来进行流程依赖部署的功能.不过这个功能和我最开始理解的不太一样. snakemake &amp; 容器除了conda, snakamake还支持使用容器来进行依赖部署. 只不过这个容器并非最火热的docker, 而是singularity. 我也是用了snakemake才知道原来docker只是容器计数中的一种实现, 只是它特别的广为人知. snakemake支持的singularity与docker相比的特点是: 不需要root权限 更低的资源占用 该项目从3.0版本开始从c++迁移到了go, 我虽然克服了网络压力装上了, 但应该是由于发行版的问题不能正常使用, 所以暂时没有实际的使用经验. 问题解决方案收集本人在使用snakemake过程中时不时会碰到一些大小问题, 由于这个软件的中文使用者似乎并不多, 英文材料虽然完善但是由于我相关的储备不足, 并不能很快从中找到解决方案, 因此将我碰到的问题&amp;解决方案收集在此, 部分问题的描述可能并不专业, 以后有机会慢慢更正","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"snakemake","slug":"snakemake","permalink":"https://silenwang.github.io/tags/snakemake/"},{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"生物信息","slug":"生物信息","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF/"},{"name":"流程管理","slug":"流程管理","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"singularity","slug":"singularity","permalink":"https://silenwang.github.io/tags/singularity/"}]},{"title":"bash-it","slug":"bash-it","date":"2018-10-29T21:17:23.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2018/10/29/bash-it/","permalink":"https://silenwang.github.io/2018/10/29/bash-it/","excerpt":"bash-it是受oh-my-zsh启发而创建的bash插件集合项目. 安装上bash-it不仅可以让bash界面变得更炫酷, 也可以让命令行变得更为好用","text":"bash-it是受oh-my-zsh启发而创建的bash插件集合项目. 安装上bash-it不仅可以让bash界面变得更炫酷, 也可以让命令行变得更为好用 安装根据bash-it首页的安装教程, 很快就能够安装好 12git clone --depth=1 https://github.com/Bash-it/bash-it.git ~/.bash_it~/.bash_it/install.sh 不过选择的时候要注意, 会让你选择是否保留原来的.bashrc以及.bash_profile, 当然如果不保留这俩文件也不会被删除, 只是会被备份一下, 如果安装后出了什么问题手动换回来就好了. 使用bash-it -h可查看所有可使用的命令, bash-it show plugins可以查看所有可用的插件, 目前我只用了base和git, 其他的日后再慢慢了解好了","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"命令行","slug":"命令行","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"name":"bash","slug":"bash","permalink":"https://silenwang.github.io/tags/bash/"},{"name":"plugin","slug":"plugin","permalink":"https://silenwang.github.io/tags/plugin/"}]},{"title":"Python命令行解析","slug":"Python命令行解析","date":"2018-10-22T12:12:50.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2018/10/22/Python命令行解析/","permalink":"https://silenwang.github.io/2018/10/22/Python%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%A7%A3%E6%9E%90/","excerpt":"一直都在用argparse写命令行解析, 但是直到前段时间才发现原来它可以用来写子命令","text":"一直都在用argparse写命令行解析, 但是直到前段时间才发现原来它可以用来写子命令 一般参数解析一般的参数解析很简单了, 示例化一个argparse, 然后调用对象的添加参数方法就可以 1234567891011import argparsefrom argparse import RawTextHelpFormatterparser = argparse.ArgumentParser( prog=&#x27;program&#x27;, description=&#x27;Some description&#x27;, formatter_class=RawTextHelpFormatter )parser.add_argument(&#x27;-s&#x27;, help=&quot;description for args&quot;, required=False, type=str) 子命令创建子命令需要在主参数解析对象(上面是parser)的基础上首先创建子解析对象,然后调用这个对象的方法添加子命令 1234567sub_parser = parser.add_subparsers(title=&#x27;sub-commands&#x27;, description=&#x27;Some description&#x27;, help=&#x27;Some help description&#x27;)sub_parser_a = sub_parser.add_parser(&#x27;a&#x27;, help=&#x27;Some help description&#x27;)sub_parser_a.add_argument(&#x27;-s&#x27;, help=&quot;description for args&quot;, type=str) 这样就可以实现在主程序下定义子程序了, argparse还提供了一个方法, 在特定子命令被调用时, 指定运行某函数, 这个函数会接收到所有子命令下参数值组成的一个命名空间, 可以进行参数解析后开始执行子程序 12345sub_parser_a.set_defaults(func=subFun)def countFun(args): args = vars(args) print(args) 其他argparse还可以实现多重子程序以及子程序参数继承主程序参数, 这个还未实际使用过, 后面再更新~","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"命令行解析","slug":"命令行解析","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%A7%A3%E6%9E%90/"},{"name":"argparse","slug":"argparse","permalink":"https://silenwang.github.io/tags/argparse/"},{"name":"子命令","slug":"子命令","permalink":"https://silenwang.github.io/tags/%E5%AD%90%E5%91%BD%E4%BB%A4/"}]},{"title":"写一个程序真不容易","slug":"写一个程序真不容易","date":"2018-10-18T22:19:45.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2018/10/18/写一个程序真不容易/","permalink":"https://silenwang.github.io/2018/10/18/%E5%86%99%E4%B8%80%E4%B8%AA%E7%A8%8B%E5%BA%8F%E7%9C%9F%E4%B8%8D%E5%AE%B9%E6%98%93/","excerpt":"","text":"也没太多想说的, 就纪念一下自己第一个独立写完的命令行程序~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"编程","slug":"编程","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E7%A8%8B/"},{"name":"命令行程序","slug":"命令行程序","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%A8%8B%E5%BA%8F/"},{"name":"scSeq","slug":"scSeq","permalink":"https://silenwang.github.io/tags/scSeq/"}]},{"title":"conda安装sscClust","slug":"conda安装sscClust","date":"2018-10-09T08:19:01.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2018/10/09/conda安装sscClust/","permalink":"https://silenwang.github.io/2018/10/09/conda%E5%AE%89%E8%A3%85sscClust/","excerpt":"原来又撞到了bug….","text":"原来又撞到了bug…. 之前尝试conda安装sscClust失败, 原来是撞到了bug, 在特殊情况下conda安装的R可能会找不到conda安装的bioconductor包, 导致在R里运行时R会重新安装相关依赖.记录完整安装方法如下(假设conda已安装完毕) 123456789101112conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/mro/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config --set show_channel_urls yes# 之后进入~/.condarc把里面的&#x27;- defualt&#x27;删除, 这步非常关键!conda install -y bioconductor-SingleCellExperiment bioconductor-scran bioconductor-SC3 bioconductor-zinbwave bioconductor-BiocParallel r-base r-devtools r-rcolorbrewer r-rtsne r-class r-factoextra r-cowplot r-data.table r-ggplot2 r-mass r-rjson r-cluster r-ks r-fields r-doparallel r-plyr r-igraph r-densityclust r-e1071 之后进入R补充未收录的包 123456options(repos=&quot;https://mirrors.shu.edu.cn/CRAN/&quot;)options(BioC_mirror=&quot;http://mirrors.ustc.edu.cn/bioc/&quot;)source(&quot;http://bioconductor.org/biocLite.R&quot;)install.packages(c(&#x27;RhpcBLASctl&#x27;, &#x27;ADPclust&#x27;, &#x27;varSelRF&#x27;))options(unzip = &quot;internal&quot;)devtools::install_github(&quot;SilenWang/sscClust&quot;, dependencies=F, ref=&quot;dev&quot;) 最后devtools::install_github时参数一定要保证不安装依赖, 可能是构建文件有问题, 不管依赖在不在都会强制重新安装依赖?或者是有包的版本不满足?","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"sscClust","slug":"sscClust","permalink":"https://silenwang.github.io/tags/sscClust/"},{"name":"Bioconductor","slug":"Bioconductor","permalink":"https://silenwang.github.io/tags/Bioconductor/"},{"name":"安装问题","slug":"安装问题","permalink":"https://silenwang.github.io/tags/%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/"}]},{"title":"docker内进行conda测试","slug":"docker内进行conda测试","date":"2018-10-06T19:01:12.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2018/10/06/docker内进行conda测试/","permalink":"https://silenwang.github.io/2018/10/06/docker%E5%86%85%E8%BF%9B%E8%A1%8Cconda%E6%B5%8B%E8%AF%95/","excerpt":"装软件的时候想了想, 用conda的移植性和可行性还是更好一些, 所以想用conda再尝试一下, 顺便可以看看snakemake怎么样…","text":"装软件的时候想了想, 用conda的移植性和可行性还是更好一些, 所以想用conda再尝试一下, 顺便可以看看snakemake怎么样… 新建docker并安装miniconda 初始化一个centos 7的容器, 然后安装minicoda, 因为容器是新初始化的所以啥都没…要安装一下必要的东西 123456docker run --name &quot;conda_test&quot; -dti IMAGE_ID /bin/bashdocker exec -it DOCKER_ID /bin/bashyum -y install wget bzip2.x86_64 vimwget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.shsh Miniconda3-latest-Linux-x86_64.shsource ~/.bashrc # conda修改了环境变量, 手动让其生效 安装R和sscClust 本次要模拟的是普通用户使用conda安装sscClust(root获取不可), 因此所有需要的包均不使用yum安装, R包则进入R后进行安装, 不是用conda提供的二进制版本(防止有包conda未收录, 依赖出问题). 设置conda的镜像, 然后安装R 1234567conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/conda config --set show_channel_urls yesconda install r 必要包安装, 由于conda提供的包不包含用于编译的组件, 所以还是要自己编译一部分东西 12345wget ftp://xmlsoft.org/libxml2/libxml2-2.7.2.tar.gz ftp://ftp.gnu.org/gnu/gsl/gsl-2.5.tar.gz https://www.openssl.org/source/openssl-1.1.1.tar.gz https://curl.haxx.se/download/curl-7.61.1.tar.gztar xvf openssl-1.1.1.tar.gztar xvf gsl-2.5.tar.gztar xvf libxml2-2.7.2.tar.gz 解压后进入相应目录编译安装, 注意编译前加prefix=/path/to/install, 然后进行PATH配置, 将上述软件安装到的路径加到PATH最前面, 这样会优先读取 curl需要在libgit2之前 R内安装sscClust 1234options(repos=&quot;https://mirrors.shu.edu.cn/CRAN/&quot;)options(BioC_mirror=&quot;http://mirrors.ustc.edu.cn/bioc/&quot;)install.packages(&quot;BiocInstaller&quot;,repos=&quot;https://bioconductor.org/packages/3.7/bioc&quot;)install.packages(&quot;devtools&quot;) 测试暂停 在测试过程遇到了各种依赖问题, 由于conda提供的包不包含编译需要用的*-devel系列包, 如果构建需要的所有包都要从头编译相当花费时间. 思路变更 对于比较新, 在R源或者bioconductor获取不了的包, 查看其构建的依赖情况, 使用conda安装其依赖项后R内安装该包 12345678910111213yum install -y unzip wget curl make gcc gcc-gfortran gcc-c++ bzip2.x86_64 vimconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/conda config --set show_channel_urls yesconda install -y -c https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ bioconductor-SingleCellExperiment bioconductor-scran bioconductor-SC3 bioconductor-zinbwave bioconductor-BiocParallelconda install -y r-RColorBrewer r-Rtsne r-class r-factoextra r-cowplot r-data.table r-ggplot2 r-MASS r-rjson r-cluster r-ks r-fields r-doParallel r-plyr r-igraph r-densityClust r-e1071 r-devtools R内安装的部分 123456options(repos=&quot;https://mirrors.shu.edu.cn/CRAN/&quot;)options(BioC_mirror=&quot;http://mirrors.ustc.edu.cn/bioc/&quot;)install.packages(c(&#x27;varSelRF&#x27;, &#x27;RhpcBLASctl&#x27;, &#x27;ADPclust&#x27;))options(unzip = &quot;internal&quot;)source(&quot;http://bioconductor.org/biocLite.R&quot;)devtools::install_github(&#x27;SilenWang/sscClust&#x27;, dependencies=FALSE, ref=&quot;dev&quot;) 使用conda安装的r依然会有依赖问题, 包虽然安装成功, 但是会无法载入(有依赖安装不完全) 小结在无法取得root权限的情况下安装R包会特别麻烦, 还是获取权限装好必要组件后在R内编译安装比较简单, 或者让管理员装了docker之后给docker的使用权限然后自行在docker内操作比较方便.","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"依赖管理","slug":"依赖管理","permalink":"https://silenwang.github.io/tags/%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"},{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"sscClust","slug":"sscClust","permalink":"https://silenwang.github.io/tags/sscClust/"},{"name":"docker","slug":"docker","permalink":"https://silenwang.github.io/tags/docker/"},{"name":"容器","slug":"容器","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"软件安装","slug":"软件安装","permalink":"https://silenwang.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"}]},{"title":"单细胞相关记录","slug":"单细胞相关记录","date":"2018-09-28T21:35:18.000Z","updated":"2026-02-10T14:03:13.678Z","comments":true,"path":"2018/09/28/单细胞相关记录/","permalink":"https://silenwang.github.io/2018/09/28/%E5%8D%95%E7%BB%86%E8%83%9E%E7%9B%B8%E5%85%B3%E8%AE%B0%E5%BD%95/","excerpt":"因为工作需要了解了一些单细胞研究的基本思路及方案, 写个记录, 当作整理一下","text":"因为工作需要了解了一些单细胞研究的基本思路及方案, 写个记录, 当作整理一下 总体思路总的来说, 单细胞测序是为了考虑细胞间的差异, 将细胞作为测序单位进行测序的一种研究方式, 目前我看的都是单细胞转录组测序, 尚不涉及基因组测序. 实现单细胞测序的实验手段我目前看到了两种: 流式细胞仪分选细胞, 然后但个细胞在版孔内进行后续反应 10X Genomics提供的单细胞测序方案, 其实看原理图也有点流式的影子, 但是并不是把单个版孔中, 而是把细胞送到GEM液滴中, 在液滴内加上条码后上illumina的机器测序 从原理上可以看出两种思路在建库和拆分的时候不太一样. 前者本质上是通过流式筛选后, 但个细胞在版孔中单独反应并建库. 因此本质上是将单个细胞当作单个样品, 然后混样测序. 而后者则采用了特殊的建库方式, 即使用基于GEM的实验系统, 在建库前先给每个细胞的核酸加上标签(16nt的10X Barcode以及10nt的UMI), 然后把所有核酸混在一起建库. 这样一个illumina sample index下的核酸其实来自不同细胞, 依靠核酸上的10X Barcode进行细胞数据拆分, 然后由于UMI存在, 可以依据它来进行后续的duplicate处理 技术路线基于流式的方案 由于本质上是按照经典的方式进行转录组建库, 只是通过流式的方法将样品个体缩小到了细胞, 所以这种方案下的软件&#x2F;技术路线原则上和原来单样本的并无太大差异, 但可能会需要注意duplicate和运行效率的问题. 基于10X GEM的方案 由于使用了特殊的建库方式, 最方便的方式是使用10X Genomics提供的cellranger软件套件, 改软件涵盖了数据从下机到出矩阵, 以及一些下游分析(降维展示, 细胞聚类, 差异表达, marker选取)的完整分析流程, 使用还是很方便的. 下游分析思路细胞分类&#x2F;聚类 -&gt; 差异表达 -&gt; marker选取 -&gt; 关联?","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"单细胞测序","slug":"单细胞测序","permalink":"https://silenwang.github.io/tags/%E5%8D%95%E7%BB%86%E8%83%9E%E6%B5%8B%E5%BA%8F/"},{"name":"转录组","slug":"转录组","permalink":"https://silenwang.github.io/tags/%E8%BD%AC%E5%BD%95%E7%BB%84/"},{"name":"10X Genomics","slug":"10X-Genomics","permalink":"https://silenwang.github.io/tags/10X-Genomics/"},{"name":"cellranger","slug":"cellranger","permalink":"https://silenwang.github.io/tags/cellranger/"},{"name":"single cell","slug":"single-cell","permalink":"https://silenwang.github.io/tags/single-cell/"},{"name":"RNA-seq","slug":"RNA-seq","permalink":"https://silenwang.github.io/tags/RNA-seq/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://silenwang.github.io/tags/scRNA-seq/"}]},{"title":"Git使用笔记","slug":"Git使用笔记","date":"2018-09-28T12:34:12.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2018/09/28/Git使用笔记/","permalink":"https://silenwang.github.io/2018/09/28/Git%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","excerpt":"很早之前就看过Git的教程, 一直没实际使用过, 现在用起来, 感觉自己有那么点像程序员了呢~","text":"很早之前就看过Git的教程, 一直没实际使用过, 现在用起来, 感觉自己有那么点像程序员了呢~ Git 是一种分布式的版本管理程序, 方便多人协作&#x2F;管理一个项目的代码. 不过对我来说, 因为绝大多数时候是单人使用, 所以对我来说更多的是在不同设备上同步我的代码了. 操作方法记录 用户初始化, 新设备上第一次使用时需要 123git config --global user.name &quot;Silen Wang&quot; # 设置用户名称git config --global user.email &quot;mymail@gmail.com&quot; # 设置用户邮箱git config --global core.editor &#x27;vim&#x27; # 设置提价commit时使用的 克隆一个项目的所有代码: 1git clone PROJ_URL 拉取更新 12git pull # 适用项目来自克隆的情况, 如果有多个来源好像要指定从哪个来源拉git pull origin master # 指定拉取origin远程库的master分支上的修改 推送更新 12git pushgit push origin master # 指定推送到origin的master分支, 如果不指定好像会调用某种默认情况? 具体不是很清楚 远程管理 12git remote # 查看远程信息git remote add REMOTE_URL # 添加信息的远程库 修改提交, Git在对本地文件作出修改后, 修改是存在暂存区域的, 要提交这些更改, 首先得确认提交修改 123git add FILE # 新增跟踪的文件/或将对文件的修改变成准备提交的状态git commit # 提交所有未提交的修改, 这里会要求给一个简单的描述, 说明修改了什么东西, 通过这个描述可以回溯自己之前做了什么git commit -a # 直接提交所有未提交修改, 并加上相同的描述 分支操作, 分支的概念允许创造当前项目的一个分支(就是一个备份), 然后在这个分支进行修改, 原分支(比如master)不受影响, 等修改的分支测试无问题后再将修改合并到需要修改的分支即可 123git chcekout -b dev # 创建并切换到dev分支git chcekout dev # 切换到dev分支git merge dev # 将dev分支的改动合并到当前分支","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"命令行","slug":"命令行","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"name":"Git","slug":"Git","permalink":"https://silenwang.github.io/tags/Git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://silenwang.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"分支管理","slug":"分支管理","permalink":"https://silenwang.github.io/tags/%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86/"},{"name":"远程仓库","slug":"远程仓库","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93/"},{"name":"代码同步","slug":"代码同步","permalink":"https://silenwang.github.io/tags/%E4%BB%A3%E7%A0%81%E5%90%8C%E6%AD%A5/"}]},{"title":"Gogs部署","slug":"Gogs部署-md","date":"2018-09-21T18:32:00.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2018/09/21/Gogs部署-md/","permalink":"https://silenwang.github.io/2018/09/21/Gogs%E9%83%A8%E7%BD%B2-md/","excerpt":"买个VPS, 一个月百分之一的流量都用不到, 确实挺浪费的…所以还是多搭点东西利用起来吧, 毕竟一个月$5呢….","text":"买个VPS, 一个月百分之一的流量都用不到, 确实挺浪费的…所以还是多搭点东西利用起来吧, 毕竟一个月$5呢…. 部署步骤Gogs是一个Go语言实现的轻量级的git托管服务. 其资源占用之小, 甚至可以直接放在树莓派上. 之前虽然搭建了一次了…但是没有做记录, 这次搭的时候又查了半天…. 总的来说, 使用docker部署(简单), 所以实际上配置个文件执行几个就好了, docker的安装不另外说明, archwiki中有了. 主要的安装命令: 1docker pull docker.io/gogs/gogs 然后准备一个含有下面内容的文件(docker-compose.yml), 执行在有这个文件下的目录执行docker-compose start, 就可以开始用了, gogs的访问端口是10080 12345678910111213version: &quot;2&quot;services: gogs: image: docker.io/gogs/gogs restart: always ports: - &quot;10022:22&quot; - &quot;10080:3000&quot; volumes: - /var/gogs:/data 然后为了免密码推送, 还需要设置一下ssh, 默认开启gogs之后, 内置的ssh是没有开启的, 需要编辑/var/gogs/gogs/conf/app.ini修改到如下样子(这是我的配置文件目录, 根据volumes后面实际挂载的位置修改) 12345678[server]DOMAIN = http://XXX.XXX.XXX.XXXHTTP_PORT = 3000ROOT_URL = http://localhost:10080/DISABLE_SSH = falseSSH_PORT = 10022START_SSH_SERVER = trueOFFLINE_MODE = false 剩下的跟github一样设置就好了~ 无法添加多个密钥问题解决(update@20180921)gogs 虽然自带有图形化的密钥设置界面, 但是可能时我当时拉取的版本有bug, 添加第一个密钥时是没问题的, 但是当有多台机器, 需要添加一个以上的密钥时, 在图形化界面虽然显示为添加成功, 但并不能正常的通过ssh进行免密登陆, 还需要进一步设置: 因为我的docker容器是把/data挂载到容器外目录的, 所以不需要登陆docker内系统直接进行修改. 对应的文件是:挂载目录/gogs/git/.ssh/authorized_keys. 自行对照格式添加公钥内容进去就可以, 比如: 1command=&quot;/app/gogs/gogs serv key-1 --config=&#x27;/data/gogs/conf/app.ini&#x27;&quot;,no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty ssh-rsa AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA test 保存后即可登陆, 不需要重启容器","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Gogs部署","slug":"Gogs部署","permalink":"https://silenwang.github.io/tags/Gogs%E9%83%A8%E7%BD%B2/"},{"name":"Docker","slug":"Docker","permalink":"https://silenwang.github.io/tags/Docker/"},{"name":"Git托管","slug":"Git托管","permalink":"https://silenwang.github.io/tags/Git%E6%89%98%E7%AE%A1/"},{"name":"SSH配置","slug":"SSH配置","permalink":"https://silenwang.github.io/tags/SSH%E9%85%8D%E7%BD%AE/"},{"name":"VPS","slug":"VPS","permalink":"https://silenwang.github.io/tags/VPS/"},{"name":"gogs","slug":"gogs","permalink":"https://silenwang.github.io/tags/gogs/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://silenwang.github.io/tags/docker-compose/"},{"name":"ssh","slug":"ssh","permalink":"https://silenwang.github.io/tags/ssh/"}]},{"title":"G胖牛逼!!!!!!!!!!!!!!!","slug":"G胖牛逼","date":"2018-09-07T20:12:02.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2018/09/07/G胖牛逼/","permalink":"https://silenwang.github.io/2018/09/07/G%E8%83%96%E7%89%9B%E9%80%BC/","excerpt":"这TM一定是历史性的一刻!","text":"这TM一定是历史性的一刻! 一周前看新闻说steam最新的linux版内置了一项叫steam play功能, 整合了wine及Proton, 让用户在linux上可以直接运行windows游戏, 并给出了第一批适配完成的游戏名单(27个)的时候, 我是无感的, 觉得这种技术估计还是开发阶段, 要等真的成熟又要等号长时间. 但是昨晚睡前, 觉得无聊, 就下了steam试试……………………………………… ……………………………………………………………………. 哎呀真香, 真特么超级香!!!!!!!!!!!!!!!!!!! 我运行的是之前补票的仙剑4, 我特么点点鼠标, 就真的能玩了! 在一台只是core M5的破笔记本上!!!!!!!!!!!! woc…….心情久久不能平复. 多少一般用户, 就因为没有足够的游戏玩所以离不开windows, 或者双系统尝鲜一下之后又把linux删了, 这一切在未来的一年半内有望出现翻天覆地的变化! GTMD windows!","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"游戏","slug":"游戏","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"Steam","slug":"Steam","permalink":"https://silenwang.github.io/tags/Steam/"},{"name":"Wine","slug":"Wine","permalink":"https://silenwang.github.io/tags/Wine/"},{"name":"Proton","slug":"Proton","permalink":"https://silenwang.github.io/tags/Proton/"},{"name":"仙剑4","slug":"仙剑4","permalink":"https://silenwang.github.io/tags/%E4%BB%99%E5%89%914/"}]},{"title":"R小技巧收集","slug":"R小问题收集","date":"2018-09-07T12:01:44.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2018/09/07/R小问题收集/","permalink":"https://silenwang.github.io/2018/09/07/R%E5%B0%8F%E9%97%AE%E9%A2%98%E6%94%B6%E9%9B%86/","excerpt":"用R总是会碰到各种问题, 收集一下","text":"用R总是会碰到各种问题, 收集一下 数据框操作取单列&#x2F;行不返回向量 使用df[]的方式对数据框取子集时, 若取出的是单列&#x2F;行, 或者删除后只剩下但列&#x2F;行的话返回的对象会是向量而不再是数据框, 需要的时候要加参数指定以返回数据框 本方法对matrix一样有效 1df[c(1, 2, 3), -2, drop = F] 合并数据时以row.names为key 大多中文材料对合并时的描述都是采用某一列数据作为key进行列合并, 其实也可以以row.names作为key, 但是合并后row.name就变成一列数据了, 需要再次指定row.names 12345# 分两步进行merge_data &lt;- merge(x, y, all.x = T, by = 0)merge_data &lt;- data.frame(merge_data), row.names = 1)# 合并成一步merge_data &lt;- data.frame(merge(x, y, all.x = T, by = 0), row.names = 1) 其他R中的Python Dict替代 许多网上的资料会使用list配合match函数实现类dict功能, 但其实R中的向量是可以被命名的, 通过命名向量即可实现key-value的映射, 十分方便. 不过这么做的效率是否好就不得而知了.. 1234a &lt;- c(1, 2, 3)names(a) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)tmp &lt;- a[&quot;a&quot;]print(tmp)","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"数据操作","slug":"数据操作","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"},{"name":"数据框","slug":"数据框","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E6%A1%86/"},{"name":"数据结构","slug":"数据结构","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"dataframe","slug":"dataframe","permalink":"https://silenwang.github.io/tags/dataframe/"},{"name":"data structure","slug":"data-structure","permalink":"https://silenwang.github.io/tags/data-structure/"},{"name":"data manipulation","slug":"data-manipulation","permalink":"https://silenwang.github.io/tags/data-manipulation/"}]},{"title":"hexo代码高亮插件","slug":"hexo高亮主题插件","date":"2018-09-05T21:53:50.000Z","updated":"2026-02-10T14:03:13.676Z","comments":true,"path":"2018/09/05/hexo高亮主题插件/","permalink":"https://silenwang.github.io/2018/09/05/hexo%E9%AB%98%E4%BA%AE%E4%B8%BB%E9%A2%98%E6%8F%92%E4%BB%B6/","excerpt":"感觉hexo默认的主题不是太好看, 想找个亮色的, 所以找了个插件来试用.","text":"感觉hexo默认的主题不是太好看, 想找个亮色的, 所以找了个插件来试用. 插件的地址在这里, 安装相当简单, 直接npm i -S hexo-prism-plugin, 就行. 然后打开博客的配置文件_config.yml, 关闭自带的高亮, 在下面添加这个插件的设置字段就ok了. 1234567highlight: enable: falseprism_plugin: mode: &#x27;preprocess&#x27; # realtime/preprocess theme: &#x27;default&#x27; line_number: false # default false custom_css: &#x27;path/to/your/custom.css&#x27; # optional 之后像往常一样更新就行, 该插件支持多种高亮方式及自定义css, 支持的语言在上面的地址中也有.","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://silenwang.github.io/tags/hexo/"},{"name":"代码高亮","slug":"代码高亮","permalink":"https://silenwang.github.io/tags/%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE/"}]},{"title":"R安装github上的包出现timeout问题解决","slug":"R安装git包出现timeout问题","date":"2018-09-05T08:57:17.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2018/09/05/R安装git包出现timeout问题/","permalink":"https://silenwang.github.io/2018/09/05/R%E5%AE%89%E8%A3%85git%E5%8C%85%E5%87%BA%E7%8E%B0timeout%E9%97%AE%E9%A2%98/","excerpt":"R安装github上面的包有时会出现连接不到github的问题, 记录一下解决方案","text":"R安装github上面的包有时会出现连接不到github的问题, 记录一下解决方案 本质上是加载curl包, 通过curl来下载的样子, 这个可能只使用于linux了. 123options(download.file.method = &quot;libcurl&quot;)library(&#x27;curl&#x27;)install_github(PACKAGENAME) 重新安装的包依然不能返回对象, 尝试手动下载包然后更改源代码, 直接从源代码安装 1install.packages(path_to_file, repos = NULL, type=&quot;source&quot;)","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"github","slug":"github","permalink":"https://silenwang.github.io/tags/github/"},{"name":"包安装","slug":"包安装","permalink":"https://silenwang.github.io/tags/%E5%8C%85%E5%AE%89%E8%A3%85/"},{"name":"timeout","slug":"timeout","permalink":"https://silenwang.github.io/tags/timeout/"},{"name":"curl","slug":"curl","permalink":"https://silenwang.github.io/tags/curl/"},{"name":"手动安装","slug":"手动安装","permalink":"https://silenwang.github.io/tags/%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85/"}]},{"title":"docker使用记录","slug":"docker使用记录","date":"2018-09-02T20:15:02.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2018/09/02/docker使用记录/","permalink":"https://silenwang.github.io/2018/09/02/docker%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/","excerpt":"为了充分利用二手不出去的烂设备…我决定自己搭服务器积累经验…考虑到搭建的东西的移植性, 使用docker放在容器内执行, 这样以后方面迁移与使用.","text":"为了充分利用二手不出去的烂设备…我决定自己搭服务器积累经验…考虑到搭建的东西的移植性, 使用docker放在容器内执行, 这样以后方面迁移与使用. 安装环境系统使用manjaro, 毕竟这个我最熟悉. 并且archwiki能为许多奇怪的问题提供帮助, 安装docker的话很简单: 123456789sudo pacman -S docker# 为了让普通用户使用docker, 需要添加相应用户组并把要使用的用户加入组中sudo groupadd dockersudo gpasswd -a $&#123;USER&#125; docker# 上面用usermod命令也可以:sudo usermod -Ga docker $&#123;USER&#125;# 如果已经启用过则`restart`, 不需要`enable`systemctl start dockersystemctl enable docker 为加快镜像(images)拉取速度, 设施dockerhub的国内镜像源(registry mirror), 配置文件是/etc/docker/daemon.json, 配置完成后执行sudo systemctl restart docker: 123&#123; &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn/&quot;]&#125; 镜像创建及镜像内部操作准备在镜像内安装R并安装sscClust包, 公司的服务器是CentOS6, 所以使用拉取相应镜像: 1docker pull centos:6 但是在进行了上述拉取之后, 一直不能正常的运行镜像, 根据这里的描述, 似乎这是官方镜像有问题, 所以改为拉取了centos:7, 确实在更换版本后正常启动. 123docker run -dti IMAGE_ID /bin/bash# 登陆入dcoker进行操作, 注意, 登陆后是root, 操作小心...docker exec -it CONTAINER_ID /bin/bash 登陆后安装vim, 对环境变量作基本设置, 然后开始安装R 1234567891011yum -y install epel-release# 更改镜像源yum install wgetmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bakmv /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel.repo.bakwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repowget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo# 不同的镜像源包版本会不一样, 删除已有缓存防止报错yum clean allyum -y makecacheyum -y install R 补充R包安装需要的一些系统软件包 1yum install -y openssl-devel libcurl-devel libxml2-devel gsl-devel 之后进入R开始安装sscClust(安装R本来就会自动安装一大堆依赖, 安装这个包的时候会有更多依赖…) 123456options(&quot;repos&quot; = c(CRAN=&quot;https://mirrors.ustc.edu.cn/CRAN/&quot;))options(BioC_mirror=&quot;http://mirrors.ustc.edu.cn/bioc/&quot;)source(&quot;http://bioconductor.org/biocLite.R&quot;)install.packages(&quot;devtools&quot;)biocLite(c(&#x27;SingleCellExperiment&#x27;, &#x27;scran&#x27;, &#x27;SC3&#x27;, &#x27;zinbwave&#x27;, &#x27;BiocParallel&#x27;))devtools::install_github(&quot;Japrin/sscClust&quot;) 如果网络没有特别问题, sscClust应该是能够顺利安装的, 最后将docker容器的更改保存为一个镜像(image), 保存完成后会显示一串sha256值, 使用docker images可看到已经保存下来的镜像 1docker commit CONTAINER_ID r/sscclust","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"sscClust","slug":"sscClust","permalink":"https://silenwang.github.io/tags/sscClust/"},{"name":"docker","slug":"docker","permalink":"https://silenwang.github.io/tags/docker/"},{"name":"容器技术","slug":"容器技术","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"镜像配置","slug":"镜像配置","permalink":"https://silenwang.github.io/tags/%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE/"},{"name":"CentOS","slug":"CentOS","permalink":"https://silenwang.github.io/tags/CentOS/"}]},{"title":"SGE系统使用笔记","slug":"SGE系统使用笔记","date":"2018-08-30T09:36:38.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2018/08/30/SGE系统使用笔记/","permalink":"https://silenwang.github.io/2018/08/30/SGE%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","excerpt":"在新公司使用SGE的方式有点不太一样, 做个笔记","text":"在新公司使用SGE的方式有点不太一样, 做个笔记 脚本编写脚本写完后, 并不在投递时进行参数指定, 而是写到被投递的脚本中, 然后直接qsub shell.sh 123456789#！/bin/bash#$ -S /bin/bash //表明此脚本为bash#$ -V //传递当前命令的所有环境变量#$ -cwd //将当前路径设置为工作路径#$ -N WorkName //任务名#$ -o WorkName.log //任务输出日志文件名#$ -j y //指定任务的标准错误流是否合并到标准输出流y[es] n[o]shell script 投递含有上述内容本质上等价于: 12345qsub -S -V -cwd \\ -N WorkName \\ -o WorkName.log \\ -j y \\ shell script qlogin的使用在进行测试时, 可使用qlogin登陆到计算节点, 然后在计算节点环境下进行的操作与写好脚本qsub投递到集群上效果一致","categories":[{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"}],"tags":[{"name":"SGE","slug":"SGE","permalink":"https://silenwang.github.io/tags/SGE/"},{"name":"网格引擎","slug":"网格引擎","permalink":"https://silenwang.github.io/tags/%E7%BD%91%E6%A0%BC%E5%BC%95%E6%93%8E/"},{"name":"qsub","slug":"qsub","permalink":"https://silenwang.github.io/tags/qsub/"},{"name":"qlogin","slug":"qlogin","permalink":"https://silenwang.github.io/tags/qlogin/"},{"name":"集群计算","slug":"集群计算","permalink":"https://silenwang.github.io/tags/%E9%9B%86%E7%BE%A4%E8%AE%A1%E7%AE%97/"},{"name":"sge","slug":"sge","permalink":"https://silenwang.github.io/tags/sge/"}]},{"title":"Pandas操作笔记","slug":"Pandas操作笔记","date":"2018-08-29T12:16:24.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2018/08/29/Pandas操作笔记/","permalink":"https://silenwang.github.io/2018/08/29/Pandas%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/","excerpt":"最近用Pandas比较多, 把常用的东西摘抄一下备查","text":"最近用Pandas比较多, 把常用的东西摘抄一下备查 数据读取 基本读取直接read_csv就可以了, 主要是涉及到一些参数 1234import pandas as pddf = pd.read_csv(file_path, sep=&quot;\\t&quot;, index_col=0, header=0)# index_col等同R里面的row.names, 都是把特定列作为行标签使用, 并且将该列从数据中去除, 如果不指定则会生成0-length的数字作为标签# header函数与R里的逻辑不太一样, 默认是header=0, 即将读取的第一行作为表头, 如果不要表头的话用header=None, 如果制定别的行为表头, 则表头行以上的数据会被丢弃 在处理很大的数据时, 为防止爆内存, 需要生成迭代器分块读取文件 1234567891011import pandas as pd# reader是以一个生成器reader = pd.read_csv(file_path, sep=&quot;\\t&quot;, iterator=True, chunksize=1000))# iterator / chunksize这两个参数指定一个就会生成迭代器, 其实如果指定了chunksize可以不写iterator了# 如果生成reader时指定过chunksize, 那可可以直接调用get_chunk()# 获得特定数量的行, 否则就要写get_chunk(num), 这个我还没详尽测试过# 注意, 这里的行数是数据的行数, 不包括表头, 因为生成reader的时候# 默认以第一行作为表头了, 所以后面生成的df都是带表头的chunk = reader.get_chunk()df = pd.DataFrame(chunk) 另外, pandas可以智能识别读入文件是否是压缩文件(通过扩展名识别), 所以经过压缩的文本文件只要分隔符指定无问题就可以读取, 写入时也是 已淘汰的`read_table` 不记得从哪个版本开始, read_table就被放弃了, 只保留read_csv, 说是csv文件的读写效率更高处理更快但是比较蛋疼的是生信领域其实是有大量内容都是用tsv文件, 或者类tsv文件的… 数据写入 我最常用的主要是tsv格式和xlsx格式 普通文本文件1 写入Excel 写法很简单: 1data.to_excel(FILE, sheet_name=&#x27;SHEET&#x27;) 需要注意的是如果想一次性将多个数据表写入多个sheet可以这样操作: 1data.to_excel(FILE, sheet_name=&#x27;SHEET&#x27;) 子集选取 与R类似, pandas也支持多种子集选取方式, 部分选取逻辑也跟R非常类似, 但是有些东西与R并不一样, 一般来说在pandas里能实现的方式R都可以, 但是反过来则不然, 这里只记录与R中选取逻辑类似的方法 123456789import pandas as pddf = pd.read_table(file_path, sep=&quot;\\t&quot;)# 依据标签选取行列使用.loc[row, col]df = df.loc[[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;]]# 注意与R不一样的是, 单取列时, 前面不可以留空, 单取行则可以后面留空df = df.loc[:, [&#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;]]df = df.loc[[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;], ]# 与.loc对应有一个.iloc, 这里使用的行/列序号, 而不是标签, 注意需要从0起算 行列删减遍历处理","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"数据分析","slug":"数据分析","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"数据处理","slug":"数据处理","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"},{"name":"Pandas","slug":"Pandas","permalink":"https://silenwang.github.io/tags/Pandas/"}]},{"title":"使用conda安装R包及jupyter","slug":"使用conda安装R包","date":"2018-08-28T22:37:57.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2018/08/28/使用conda安装R包/","permalink":"https://silenwang.github.io/2018/08/28/%E4%BD%BF%E7%94%A8conda%E5%AE%89%E8%A3%85R%E5%8C%85/","excerpt":"由于工作需要, 得安装一篇文献中提及的一个包, 本两想着两条命令完事, 谁知道一大堆依赖要解决…然后linux下的R包都是要编译的, 这可是要了老命了…还好有conda这个东西…","text":"由于工作需要, 得安装一篇文献中提及的一个包, 本两想着两条命令完事, 谁知道一大堆依赖要解决…然后linux下的R包都是要编译的, 这可是要了老命了…还好有conda这个东西… 说起来原来看公众号的时候还不知道为啥里面推荐的用conda来装需要的工具…这次算是体会了linux的依赖有多烦人…而且作为普通用户又没有完全权限…路被赌死了不少…像conda这种直接在自己山头自立为王的方式…虽然浪费空间, 可是非常又用啊! conda安装 conda有两个…emmm我也不知道能不能说是发行版? 一个是ancoda, 另一个是minicoda, 可以理解是完整安装和最小安装的区别, ancoda自带一套异常完整的python环境, 连jupyter都打包好了, 而miniconda除了最基本的pyton, 好像没太多别的东西了, 因为我主要是用来装r的, 所以选择了miniconda 下载到的linux安装文件是一个异常大的shell脚本, 直接运行即可开始安装 安装完之后即可调用conda命令安装想要的东西, 比如我就可以开始安装r了 1conda install r 调用conda安装的东西全部都由conda统一放置在conda的安装目录下, 里面的文件夹分布好像跟根目录的不是特别一样 在最初完成conda安装时, 如果不作特别制定, conda会改写原本的~/.bash文件, 在里面把conda的bin目录添加到PATH变量中, 但是优先级在系统默认的目录(/bin)之后, 因为我是要用conda的覆盖系统默认配置, 所以手动把这一行加到了~/.bash_profile中并把conda的bin目录调到了系统默认的前面 conda在国内也是有镜像源的, 编辑~/.condarc(没有可以直接创建), 加入下列内容即可使用中科大的镜像(清华的看人说有问题, 就没用了). 当然这只是个示例, pkg下还有其他的源, 需要的可以都添加上 1234channels: - https://mirrors.ustc.edu.cn/anaconda/pkgs/free/ - defaultsshow_channel_urls: true 之后进入R, 在里面再安装相关包就好. 这时安装的R包不会放在~/R下, 也是全部在conda的目录下面, 具体可参考安装时的输出. 由于R包都是要编译的, 我又是用的minicoda, 所以难免会有依赖不满足. 不满足的包可以使用conda install安装, 另外也可以上anconda的网站先所有有哪些版本, 再对应执行命令安装即可 本次安装在conda的助力下解决了绝大多数的依赖问题, 唯一不能解决的我在本地编译后上传了…花了两天总算是把包装好了…但愿用不要出什么问题 jupyter安装与配置R放在集群上, 调试起来多少有些不便, 毕竟我习惯了Rstudio或者jupyter notebook的那种编写边测试的方式. 正好conda也能装jupyter, 就搜索了一下远程访问的配置方式. 首先肯定使用conda安装jupyter了 1conda install jupyter 完成后对jupyter进行配置 1234# 生成配置文件jupyter notebook --generate-config# 设定密码, 根据提示输入两次即可jupyter notebook password 使用编辑器打开生成的配置文件(普通用户的话是, 具体看生成文件后的提示~/.jupyter/jupyter_notebook_config.py) 找到下面几项, 取消注释后更改相应数值, 其中密码见生成时提示的那个json文件, 里面会有一段长长的字符串, 全部复制贴过来就好 1234c.NotebookApp.ip=&#x27;*&#x27;c.NotebookApp.password = u&#x27;your_key_str&#x27;c.NotebookApp.open_browser = False # 代表启动notebook服务时不打开浏览器并访问c.NotebookApp.port = 8888 # 这个可以不指定, 会自动分配一个端口 然后就可以在能连接到集群ip的电脑上打开浏览器以0.0.0.0:8888的方式访问了, 输入密码即可使用","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"jupyter","slug":"jupyter","permalink":"https://silenwang.github.io/tags/jupyter/"},{"name":"包管理","slug":"包管理","permalink":"https://silenwang.github.io/tags/%E5%8C%85%E7%AE%A1%E7%90%86/"},{"name":"环境配置","slug":"环境配置","permalink":"https://silenwang.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"远程访问","slug":"远程访问","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/"},{"name":"jupyter notebook","slug":"jupyter-notebook","permalink":"https://silenwang.github.io/tags/jupyter-notebook/"}]},{"title":"使用minicap从手机中截图","slug":"使用minicap从手机中截图","date":"2018-08-28T12:05:17.000Z","updated":"2026-02-10T14:03:13.677Z","comments":true,"path":"2018/08/28/使用minicap从手机中截图/","permalink":"https://silenwang.github.io/2018/08/28/%E4%BD%BF%E7%94%A8minicap%E4%BB%8E%E6%89%8B%E6%9C%BA%E4%B8%AD%E6%88%AA%E5%9B%BE/","excerpt":"练习手机自动操作不可避免要涉及到截取手机当前的图像, 手机adb自带的截图实在太慢, 所以安装minicap取代之.","text":"练习手机自动操作不可避免要涉及到截取手机当前的图像, 手机adb自带的截图实在太慢, 所以安装minicap取代之. 软件编译123456789# 克隆项目代码并进行初始化git clone https://github.com/openstf/minicapcd minicap/git submodule initgit submodule update# 编译需要ndk(archlinuxcn源内有, 直接安装即可)sudo pacman -S android-ndk# 进行编译, 书面包安装之后不会自行添加到bin, 需要给绝对路径运行/opt/android-ndk/ndk-build 软件部署到手机12345678910111213141516# 要使用adb连接到设备, 如果没有安装adb首先安装# manjaro community里面有, 我记得官方版本是自带的, 现在用的社区发行版可能处于精简考虑没有默认安装sudo pacman -S android-tools# 手机打开usb调试然后连接到电脑, device现实未注册的话在手机上选择允许当前设备的调试adb devices# 获取手机基本信息以推送对应版本的minicap到手机ABI=$(adb shell getprop ro.product.cpu.abi | tr -d &#x27;\\r&#x27;)SDK=$(adb shell getprop ro.build.version.sdk | tr -d &#x27;\\r&#x27;)adb push libs/$ABI/minicap /data/local/tmp/adb push jni/minicap-shared/aosp/libs/android-$SDK/$ABI/minicap.so /data/local/tmp/adb shell chmod 777 /data/local/tmp/minicap# 测试是否可运行adb shell LD_LIBRARY_PATH=/data/local/tmp /data/local/tmp/minicap -P 1080x1920@1080x1920/0 –t# 如果运行成功最后会显示&#x27;OK&#x27; 截图123# 前面的环境变量设定是必须的, 因为要指定运行库位置, -P后面是截图参数, 详情可参见minicap的项目网页, -s但表截图并输出到# 标准输出, 所以重定向就好adb shell LD_LIBRARY_PATH=/data/local/tmp /data/local/tmp/minicap -P 1080x1920@1080x1920/0 –s &gt; /sdcard/minicap/test.jpg 待完成 把上述命令封装成脚本, 然后顺便设定wifi连接的信息, 这样可以实现同时控制多个设备","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"安卓","slug":"安卓","permalink":"https://silenwang.github.io/tags/%E5%AE%89%E5%8D%93/"},{"name":"截图","slug":"截图","permalink":"https://silenwang.github.io/tags/%E6%88%AA%E5%9B%BE/"},{"name":"minicap","slug":"minicap","permalink":"https://silenwang.github.io/tags/minicap/"},{"name":"adb","slug":"adb","permalink":"https://silenwang.github.io/tags/adb/"},{"name":"android","slug":"android","permalink":"https://silenwang.github.io/tags/android/"}]},{"title":"Python使用Sqlite3","slug":"Python使用Sqlite3","date":"2018-08-26T23:54:24.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2018/08/26/Python使用Sqlite3/","permalink":"https://silenwang.github.io/2018/08/26/Python%E4%BD%BF%E7%94%A8Sqlite3/","excerpt":"为了以后操作使用Sqlite3做准备, 上周上班的时候特意试了一下用操作数据库的数据, 为了方便直接用了sqlite3, 没想到sqlite3并不是所有语句都支持, 并且sqlite自由的点命令是无法被python的sqlite模块调用的….","text":"为了以后操作使用Sqlite3做准备, 上周上班的时候特意试了一下用操作数据库的数据, 为了方便直接用了sqlite3, 没想到sqlite3并不是所有语句都支持, 并且sqlite自由的点命令是无法被python的sqlite模块调用的…. 简单的使用方式:1234567import sqlite3 # 导入模块conn = sqlite3.connect(&#x27;test.db&#x27;) # 连接数据库(如果不存在的话会被创建)cursor = conn.cursor() # 从数据库对象创建指针cursor.execute(&#x27;sql cmd&#x27;) # 向数据库传入sql语句, 注意这里的操作不是立刻保存/同步到数据库中cursor.close() # 关闭指针conn.commit() # 确认更改conn.close() # 关闭连接 使用中的注意事项 只支持标准的SQL语句, 由于使用的是sqlite, 其不支持的SQL语法一概无法使用, 也不支持使用sqlite特有的点命令, 因为这些命令本质上是在shell内执行的, 不是SQL语句 如果一定要使用点命令, 则需要使用os模块或其他可以调用shell的模块, 本质上是在执行shell命令 不是所有的操作都一定要指针对象完成, 有部分可以使用数据库对象, 这样可以少写两句, 具体见菜鸟教程网站的介绍 注意一定要确认更改(obj.commit() ), 否则数据库内的内容是不会变化的 尝试使用了with的方式进行连接, 但是在with语句的范围外是不会自动断开连接的(obj.close()), 所以还是得老实写 调用点命令的方式1234567891011121314151617181920import os, textwrap# 这里是使用textwrap进行了shell命令的缩进调整, 并不必要, 只是输出的时候方便看def cmd_gen(cmd_str): cmd_str = textwrap.dedent(cmd_str) cmd_str = cmd_str.strip() return cmd_strdb_file = &#x27;test.db&#x27;index_file = &#x27;index.txt&#x27;# 生成命令, 这个写法是我从网上搜回来的, 是找到的唯一有效的写法, 具体意义日后再看...cmd = cmd_gen(&#x27;&#x27;&#x27; sqlite3 &#123;db_file&#125; &lt;&lt; EOF .separator &quot;\\\\t&quot; .import &#123;index_file&#125; idx_tab EOF &#x27;&#x27;&#x27;.format(db_file=db_file, index_file=index_file))os.system(cmd)","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"数据库","slug":"数据库","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQLite3","slug":"SQLite3","permalink":"https://silenwang.github.io/tags/SQLite3/"},{"name":"sqlite","slug":"sqlite","permalink":"https://silenwang.github.io/tags/sqlite/"}]},{"title":"桌面叒迁移","slug":"桌面叒迁移","date":"2018-08-26T21:26:54.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2018/08/26/桌面叒迁移/","permalink":"https://silenwang.github.io/2018/08/26/%E6%A1%8C%E9%9D%A2%E5%8F%92%E8%BF%81%E7%A7%BB/","excerpt":"用linux后时不时就会看见一句名言: 生命不息, 折腾不止. 不过说真的, 去年工作之后, 由于公司抠门不配电脑, 需要用自己的电脑进行工作…真的是不敢乱折腾(犹记当年删了自己的论文找不回来的绝望…). 但是在换了工作, 所有东西丢上百度云盘之后…我就又蠢蠢欲动了.","text":"用linux后时不时就会看见一句名言: 生命不息, 折腾不止. 不过说真的, 去年工作之后, 由于公司抠门不配电脑, 需要用自己的电脑进行工作…真的是不敢乱折腾(犹记当年删了自己的论文找不回来的绝望…). 但是在换了工作, 所有东西丢上百度云盘之后…我就又蠢蠢欲动了. 说起来本质上这次的折腾并不是由于蛋疼, 而是由于现在的系统确实叒出问题了——莫名其妙的屏幕闪烁.我已经不记得这是从什么时候开始的了, 笔记本的屏幕会随机不规律的黑屏闪烁, 有时候会出现横条的雪花闪烁. 最开始我觉得可能是比本大限将之了…毕竟在淘宝工厂店买的(真的便宜…), 电脑到手的时候感觉是被翻新过的(盒子有点破, 笔记本背部的螺有磨损), 然后用了3个月键盘背光失效了. 不过在观察一段时间后发现…这个闪屏挺蹊跷的, 因为明显在外接屏幕的时候和使用浏览器的时候闪烁严重, 如果不用浏览器不外接的话, 几乎不会出事. 并且闪烁之出现在普通用户上, 如果使用root登陆…怎么玩都不会闪…综上, 我判定是我又不小心动了什么配置文件导致软件有问题了, 就琢磨着重装试试(绝对不是因为联系商家要求保修被无视了~). 既然要重装, 且本子现在又不用于工作了, 那不如这次再尝试点新的~ 其实本人观望deepin的dde很久了…怎么说呢…要不怎么说还是自己人了解自己人…感觉dde的团队真的很会抓主国内用户的需求点, 从最开始的虚有其表(一开始真的是漂亮归漂亮, 但用起来bug一大堆还不让自定义的那种), 到现在的颜值依旧, 并且功能 &amp; 易用性 &amp; 性能都有提升…真的是进步神速. 以至于dde在国际上也有了不少用户(deepin的国际区还是有挺多人发帖的, manjaro的社区维护发行版板块也经常有人讨论deepin). 虽然我之前每次dde有最新的社区发行版, 都会下一个live cd来试试, 不过奈何一是有些xfce的快捷键和功能deepin里面没有, 而是本次版本之前, deepin的资源消耗和&#x2F;流畅性&#x2F;稳定性还是远不如xfce, 所以都是试了一晚上最终没有安装到实机上. 这次就不一样了, 一来我不需要用个人笔记本工作了, 二来现在相对比较闲, 也不差那点时间去适应新的操作模式了, 加上deepin前两天更新了15.7, manjaro的deepin源也得到更新了. 所以果断格了电脑开始使用. 不得不说…头几个小时的感受根之前的差异还是不大, 不过过了两天之后其实也在逐渐适应了…所以人哪…一旦接受了设定… 另外我还发现了一个hin牛逼的事情: deepin去年就已经内置了触控板手势操作了. 支持三指最大化及还原窗口, 以及快速将窗口左右分割. 有了这个手势能很大程度上缓解不能super+鼠标拖动窗口带来的不习惯. 注意这个手势目前是dde内置的, 并且与libinput-gesture并不互斥, 所以如果再安装一份libinput-gesture, 是会俩手势同时打架的…dde内置的手势在控制面板里每见到开关, 默认为开, 可以通过dconf软件内搜索’gesture’找到对应选项并关闭. 目前的dde手势配置文件是: /usr/share/dde-daemon/gesture.json, 是json格式, 感觉比libinput-gesture更容易看懂. 还是附上我历代的桌面截图: Mint(Cinnamon) Manjaro(Cinnamon) Manjaro(Xfce) Manjaro(deepin)","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"Deepin","slug":"Deepin","permalink":"https://silenwang.github.io/tags/Deepin/"},{"name":"Manjaro","slug":"Manjaro","permalink":"https://silenwang.github.io/tags/Manjaro/"},{"name":"桌面环境","slug":"桌面环境","permalink":"https://silenwang.github.io/tags/%E6%A1%8C%E9%9D%A2%E7%8E%AF%E5%A2%83/"},{"name":"DDE","slug":"DDE","permalink":"https://silenwang.github.io/tags/DDE/"},{"name":"触控板手势","slug":"触控板手势","permalink":"https://silenwang.github.io/tags/%E8%A7%A6%E6%8E%A7%E6%9D%BF%E6%89%8B%E5%8A%BF/"}]},{"title":"换工作小记","slug":"换工作小记","date":"2018-08-14T22:41:00.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2018/08/14/换工作小记/","permalink":"https://silenwang.github.io/2018/08/14/%E6%8D%A2%E5%B7%A5%E4%BD%9C%E5%B0%8F%E8%AE%B0/","excerpt":"旧坑跳新坑, 也不知道是不是越来越坑…","text":"旧坑跳新坑, 也不知道是不是越来越坑… 2017年7月, 我终于告别学生身份正式参加工作. 岗位是生物信息工程师, 就职单位天津诺禾致源. 2018年8月, 氪着命勉强完成了工作交接, 总算是在一年零一个月后顺利离开了诺禾. 新公司为杭州瑞普基因, 仍然是生物信息工程师. 对于前东家本来没太多感想, 虽然真的从提前转正开始就疯狂氪命了, 但总算是学到了东西, 付出也算有了回报. 但是偶然了解了公司IT组的状况之后…请容我把心里的MMP大声喊出来, 然后祝还在坑的小伙伴早日找到好的下家, 脱离这个天坑…","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"工作变动","slug":"工作变动","permalink":"https://silenwang.github.io/tags/%E5%B7%A5%E4%BD%9C%E5%8F%98%E5%8A%A8/"},{"name":"生物信息工程师","slug":"生物信息工程师","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%B8%88/"},{"name":"诺禾致源","slug":"诺禾致源","permalink":"https://silenwang.github.io/tags/%E8%AF%BA%E7%A6%BE%E8%87%B4%E6%BA%90/"},{"name":"瑞普基因","slug":"瑞普基因","permalink":"https://silenwang.github.io/tags/%E7%91%9E%E6%99%AE%E5%9F%BA%E5%9B%A0/"},{"name":"职业发展","slug":"职业发展","permalink":"https://silenwang.github.io/tags/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/"},{"name":"job-change","slug":"job-change","permalink":"https://silenwang.github.io/tags/job-change/"},{"name":"bioinformatics-engineer","slug":"bioinformatics-engineer","permalink":"https://silenwang.github.io/tags/bioinformatics-engineer/"},{"name":"career-development","slug":"career-development","permalink":"https://silenwang.github.io/tags/career-development/"}]},{"title":"正则匹配符号收录","slug":"正则匹配符号收录","date":"2018-07-29T02:04:01.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2018/07/29/正则匹配符号收录/","permalink":"https://silenwang.github.io/2018/07/29/%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%E7%AC%A6%E5%8F%B7%E6%94%B6%E5%BD%95/","excerpt":"正则在很多时候时候都还是相当实用的的, 然而不同程序中正则的写法总用些差异, 所以做个cheatsheet备查不亏~","text":"正则在很多时候时候都还是相当实用的的, 然而不同程序中正则的写法总用些差异, 所以做个cheatsheet备查不亏~ 基本通用部分表格来源:yirlin的博客 \\: 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，n 匹配字符 n。\\n 匹配一个换行符。序列 \\\\ 匹配 \\ 而 \\( 则匹配 (。 ^: 匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 \\n 或 \\r 之后的位置。 \\$: 匹配输入字符串的结束位置。如果设置了RegExp 对象的 Multiline 属性，\\$ 也匹配 \\n 或 \\r 之前的位置。 *: 匹配前面的子表达式零次或多次。例如，zo* 能匹配 z 以及 zoo。* 等价于&#123;0,&#125;。 +: 匹配前面的子表达式一次或多次。例如，zo+ 能匹配 zo 以及 zoo，但不能匹配 z。+ 等价于 &#123;1,&#125;。 ?: 匹配前面的子表达式零次或一次。例如，do(es)? 可以匹配 do 或 does 中的do 。? 等价于 &#123;0,1&#125;。 &#123;n&#125;: n 是一个非负整数。匹配确定的 n 次。例如，o&#123;2&#125; 不能匹配 Bob 中的 o，但是能匹配 food 中的两个 o。 &#123;n,&#125;: n 是一个非负整数。至少匹配n 次。例如，o&#123;2,&#125; 不能匹配 Bob 中的 o，但能匹配 foooood 中的所有 o。o&#123;1,&#125; 等价于 o+。o&#123;0,&#125; 则等价于 o*。 &#123;n,m&#125;: m 和 n 均为非负整数，其中n &lt;&#x3D; m。最少匹配 n 次且最多匹配 m 次。例如，o&#123;1,3&#125; 将匹配 fooooood 中的前三个 o。o&#123;0,1&#125; 等价于 o?。请注意在逗号和两个数之间不能有空格。 ?: 当该字符紧跟在任何一个其他限制符 (*, +, ?, &#123;n&#125;, &#123;n,&#125;, &#123;n,m&#125;) 后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串 oooo，o+? 将匹配单个 o，而 o+ 将匹配所有 o。 .: 匹配除 \\n 之外的任何单个字符。要匹配包括 \\n 在内的任何字符，请使用象 [.\\n] 的模式。 (pattern): 匹配 pattern 并获取这一匹配。所获取的匹配可以从产生的 Matches 集合得到，在VBScript 中使用 SubMatches 集合，在JScript 中则使用 $0…$9 属性。要匹配圆括号字符，请使用 \\( 或 \\)。 (?:pattern): 匹配 pattern 但不获取匹配结果，也就是说这是一个非获取匹配，不进行存储供以后使用。这在使用”或”字符来组合一个模式的各个部分是很有用。例如， industr(?:y|ies) 就是一个比 industry|industries 更简略的表达式。 (?=pattern): 正向预查，在任何匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如，Windows (?=95|98|NT|2000) 能匹配 Windows 2000 中的 Windows ，但不能匹配 Windows 3.1 中的 Windows。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?!pattern)负向预查，在任何不匹配 pattern 的字符串开始处匹配查找字符串。这是一个非获取匹配，也就是说，该匹配不需要获取供以后使用。例如Windows (?!95|98|NT|2000) 能匹配 Windows 3.1 中的 Windows，但不能匹配 Windows 2000 中的 Windows。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始 x|y: 匹配 x 或 y。例如，z|food 能匹配 z 或 food。(z|f)ood 则匹配 zood 或 food。 [xyz]: 字符集合。匹配所包含的任意一个字符。例如， [abc] 可以匹配 plain 中的 a。 [^xyz]: 负值字符集合。匹配未包含的任意字符。例如， [^abc] 可以匹配 plain 中的p。 [a-z]: 字符范围。匹配指定范围内的任意字符。例如，[a-z] 可以匹配 a 到 z 范围内的任意小写字母字符。 [^a-z]: 负值字符范围。匹配任何不在指定范围内的任意字符。例如，[^a-z] 可以匹配任何不在 a 到 z 范围内的任意字符。 \\b: 匹配一个单词边界，也就是指单词和空格间的位置。例如， er\\b可以匹配never 中的 er，但不能匹配 verb 中的 er。 \\B: 匹配非单词边界。er\\B 能匹配 verb 中的 er，但不能匹配 never 中的 er。 \\cx: 匹配由 x 指明的控制字符。例如， \\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 c 字符。 \\d: 匹配一个数字字符。等价于 [0-9]。 \\D: 匹配一个非数字字符。等价于 [^0-9]。 \\f: 匹配一个换页符。等价于 \\x0c 和 \\cL。 \\n: 匹配一个换行符。等价于 \\x0a 和 \\cJ。 \\r: 匹配一个回车符。等价于 \\x0d 和 \\cM。 \\s: 匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [\\f\\n\\r\\t\\v]。 \\S: 匹配任何非空白字符。等价于[^\\f\\n\\r\\t\\v]。 \\t: 匹配一个制表符。等价于 \\x09 和 \\cI。 \\v: 匹配一个垂直制表符。等价于 \\x0b 和 \\cK。 \\w: 匹配包括下划线的任何单词字符。等价于[A-Za-z0-9_]。 \\W: 匹配任何非单词字符。等价于 [^A-Za-z0-9_]。 \\xn: 匹配 n，其中 n 为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，\\x41 匹配 A。\\x041 则等价于 \\x04 &amp;1。正则表达式中可以使用 ASCII 编码。. \\num: 匹配 num，其中 num 是一个正整数。对所获取的匹配的引用。例如，(.)&#39;\\1 匹配两个连续的相同字符。 \\n: 标识一个八进制转义值或一个向后引用。如果 \\n 之前至少 n 个获取的子表达式，则 n 为向后引用。否则，如果 n 为八进制数字 (0-7)，则 n 为一个八进制转义值。 \\nm: 标识一个八进制转义值或一个向后引用。如果 \\nm 之前至少有 nm 个获得子表达式，则 nm 为向后引用。如果 \\nm 之前至少有 n 个获取，则 n 为一个后跟文字 m 的向后引用。如果前面的条件都不满足，若 n 和 m 均为八进制数字 (0-7)，则 \\nm 将匹配八进制转义值 nm。 \\nml: 如果 n 为八进制数字 (0-3)，且 m 和 l 均为八进制数字 (0-7)，则匹配八进制转义值 nml。 \\un: 匹配 n，其中 n 是一个用四个十六进制数字表示的 Unicode 字符。例如， \\u00A9 匹配版权符号 (?)。","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"https://silenwang.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"正则语法","slug":"正则语法","permalink":"https://silenwang.github.io/tags/%E6%AD%A3%E5%88%99%E8%AF%AD%E6%B3%95/"},{"name":"正则符号","slug":"正则符号","permalink":"https://silenwang.github.io/tags/%E6%AD%A3%E5%88%99%E7%AC%A6%E5%8F%B7/"},{"name":"正则匹配","slug":"正则匹配","permalink":"https://silenwang.github.io/tags/%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D/"},{"name":"regex","slug":"regex","permalink":"https://silenwang.github.io/tags/regex/"}]},{"title":"系统迁移记录","slug":"系统迁移记录","date":"2018-07-29T00:58:36.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2018/07/29/系统迁移记录/","permalink":"https://silenwang.github.io/2018/07/29/%E7%B3%BB%E7%BB%9F%E8%BF%81%E7%A7%BB%E8%AE%B0%E5%BD%95/","excerpt":"自我大二开始接触linux桌面发行版起, 我就不断的在更换不同的发行版本, 折腾了几年才最后稳定使用manjaro.","text":"自我大二开始接触linux桌面发行版起, 我就不断的在更换不同的发行版本, 折腾了几年才最后稳定使用manjaro. Mint 迁移记录由于ubuntu挂掉, 重装ubuntu过程中出现一些问题, 索性就换成了世界人气第一的mint, 据说比ubuntu更加对新手友好, 开箱可用. 不过实践出真知…对于稍微习惯了unity的我来说并不是那么简单… 安装上倒是还好, 几乎和ubuntu的liveCD一模一样, 本来想连home都不要格式化了, 后来想想昨天重装的ubuntu依然有问题, 所以还是咬咬牙格掉了, 于是复制一些东西回来又花了时间. 安装好之后进入mint界面, 登陆的窗口真的是比ubuntu漂亮多了, 超高清晰度的美景(并不是美女&#x3D; &#x3D;|||)照片, 比ubuntu暗色调的设计感觉清爽多了. 登陆之后的界面就….花了半年去习惯的unity布局, 换回Gnome&#x2F;win样的界面, 实在是有点蛋疼.除了布局不一样, mint的显示效果对我来说感觉没有ubuntu好, 中文字体感觉发虚明显, 可能随时是Noto sans的问题? 在换了文泉驿微米黑之后大部分地方都好多了, 不过惨淡依旧不太性, 百度说温泉以在字体小的时候本来就发虚…于是鄙人直接把所有字体都调大了. 输入法设置mint本身不预置任何输入法, 虽然firefox有了, 但是没有输入法总不能完全英文百度…mint的输入发在语言设置下, 虽然里面又显示支持的输入法, 但是软件源里并没有, 无法直接从软件中心安装. PPA安装代码: 123sudo add-apt-repository ppa:fcitx-team/nightlysudo apt-get updatesudo apt-get install fcitx 安装后还需要一些依赖包, 我没有使用PPA安装, 直接进入语言-&gt;输入法, 选择fcitx可以直接安装需要依赖. 安装完成后上搜狗网站下载搜狗linux版本, 安装完毕后重启(注销是否可未尝试), 输入法即可使用. 重装的时候有把之前ubuntu的&#x2F;home复制过来, 但是搜狗输入法的词库好像没有保留. 软件安装 PPA安装: VirtualBox GoldenDict Shadowsocks-Qt5 PlayOnLinux Okular WizNote R-base Numix-circle PPA添加代码 1sudo add-apt-repository ppa:hzwhuang/ss-qt5 ppa:wiznote-team ppa:numix/ppa R-base直接将源信息deb http://mirror.bjtu.edu.cn/cran/bin/linux/ubuntu trusty/添加至软件源 1sudo gedit /etc/apt/sources.list PPA安装 1sudo apt-get install VirtualBox GoldenDict Shadowsocks-Qt5 PlayOnLinux Okular WizNote R-base numix-icon-theme-circle kolourpaint Deb安装 mendeley haroopad\u0001 Rstudio bcloud wps 配置迁移将原来的&#x2F;home进行备份, 重装完成后复制即可, 大部分软件配置会保留(firefox插件、配置丢失, 原因不明) 程序设置由于已习惯使用unity, 对mint界面做了些许调整, 降低重适应难度. 面板上移 用户小程序置于最左侧 Firefox设置与插件由于firefox配置丢失, 所以特别记录一下相关设定以防下次再丢失 使用插件 Adblock Plus FxoyProxy Hide Cpation Titlebar Plus Stylish Stylish设置(另一贴有,重复记录下) 1234567891011@-moz-document regexp(&quot;https?://(?!.+\\\\.coursera\\\\.org).*&quot;)&#123;*:not([class*=&quot;icon&quot;]):not(i)&#123;font-family: &quot;WenQuanYi Microhei&quot; !important;&#125; span.fui-logo-text&#123;font-family: &quot;IterCast-Icon&quot; !important;&#125; span.diffstat-bar&#123;font-family: &quot;octicons&quot; !important;&#125; span.diff-added&#123;font-family: &quot;octicons&quot; !important;&#125; #indexbutton&#123;font-family: &quot;html5test&quot; !important;&#125; .toolbox ins a&#123;font-family: &quot;2345&quot; !important;&#125; .tool_ul li a ins&#123;font-family: &quot;2345&quot; !important;&#125; .panel ins a&#123;font-family: &quot;2345&quot; !important;&#125; span.nba_matchnav_score&#123;font-family: &quot;Sans-Serif&quot; !important;&#125;&#125; Ubuntu unity 与 Mint cinnamon使用对比 显示效果&#x2F;界面布置 个人是更习惯于unity的, 毕竟也用了半年, 虽然ubuntu本身的配色确实不太好看, 但是安装了numix主题, 换个壁纸之后还是挺不错的. unity的程序面板放在了左侧, 上面板用于整合标题栏, 这种设计在现在16:9的屏幕上确实是节省了很多空间, 能让更多内容显示出来. 并且ubuntu本身字体、图标都挺大的, 看习惯了换回win下以及现在的mint下一下真是有点难以适应, 即使笔记本是15.6都觉得整个世界都小了….只好强制调大字体了. ubuntu的默认字体效果感觉也比mint好, 可能也是因为字体比较大, 使用微米黑不会发虚… 易用性 这方面mint确实是比ubuntu好, 不愧是常年点击量第一. mint对操作的图形化程度确实更高. 设置中心相比ubuntu集成了更多的选项, 甚至登陆窗口软件源都可以通过Gui进行非常方便的管理. 文件操作上右键菜单里就可以选择以root打开, 不需要命令行操作. 当然…其实知道路径可拖拽之后命令行其实也很快就是. 细节方面也很贴心, 比如root权限打开的管理器会有特别提示, 不会出现ubuntu下傻傻分不清楚的状况. mint面板的扩展性以及主题切换也十分方便, 有可以直接下载的资源, 不用自己另外找. 当然因为我是从unity又迁移回来的, 所以有些习惯对易用性有不小影响, 如果是对于直接从win迁移的人来说mint易用性肯定爆表. 然后我觉得在软件更新方面mint真的做的很好…它设置了对核心部分更新的特殊保护, 不会让用户轻易更新内核什么的, 这对我这种半新手又强迫症的人来说非常友好(上一个ubuntu是否因为更新挂掉至今未知). 小问题从3年前第一次用ubuntu系的各种发行版起, 小问题就没有断过. 像字体乱码这种由于win的用户基数问题完全不可避免. 另外一些零碎的不一定影响使用的问题….就只能期待后续修复了. ubuntu下遇见的小问题 双显卡,独立显卡驱动(无法解决) 触控板(开机默认打开) 屏幕亮度(无法记忆上一次亮度) 错误报告(不知道哪里冒出来的错误提示, 没有任何实际影响) 偶尔长时间看视频时死机 偶尔卡, 不知道为何卡(程序运行不多) mint下小问题 双显卡,独立显卡驱动 屏幕亮度 偶尔小卡 睡眠&#x2F;挂起无法唤醒 字体总觉得有点虚 某有线鼠标自动休眠 firefox下载菜单中点击打开文件位置firefox卡死 okular修复安装mint后直接使用sudo apt-get install okular安装okular无法使用, 需要补充安装其他软件包. 1sudo apt-get install kdelibs5-plugins kdelibs5-data oxygen-icon-theme 安装后可正常使用. 界面重布人无聊的时候就会干无聊事, 前段时间不知道为什么又觉得看自己桌面不顺眼了所以就开启折腾模式.其实归根结底还是更喜欢unity的布局方式, 虽然很多人觉得很奇怪, 但是我接受了这个设定之后….还真是觉得挺带感的….奈何显卡驱动我折腾不来. 最开始我的mint布局是这样: 基本上就是win(而且是xp)下的样子, 菜单-&gt;快捷启动-&gt;已开窗口, 通知栏. 本来刚从ubuntu转win的时候还保留了窗口栏按钮左置, 在误触菜单无数次之后还是换回了右边…. 但是用着用着就觉得中间放已开窗口的位置实在太小, 同时开四个以上窗口标签就要被部分遮盖了, 然后因为看不见标签切换起来略蛋疼…. 于是我就尝试使用dock工具尝试替代工具栏上的快捷启动, 有了下面这个布局:啊, 有那么一点unity的感觉呢! 不过并没unity好用就是…..有尝试过使用工具栏模式, 无奈docky在工具栏模式下会被系统自带工具栏遮挡….这个布局使用了几天之后又发现问题, 毕竟相当多的软件在左侧都会有些按钮啊菜单什么的….习惯直接一鼠标飞过去的我经常会误触然后打开别的程序… 于是, 我还是把docky放到了底部…&#x3D; &#x3D;|||啊….于是我的桌面布局变得跟大部分gnome2时代的用户一毛一样了…….该说这个布局是经过实践检验的么……所以我的挣扎都是无意义的么…上帝… mint2manjaro从Ubuntu系到Arch系鄙人从大三开始尝试使用Linux系统, 一直以来都是用的Ubuntu以及基于Ubuntu的发行版, 所以这次的系统更换为基于Arch的Manjaro算是一次比较大的改变. 其实换之前也是很忐忑, 毕竟咱出了名的脸黑….而且虽然用了挺久的linux但是其实在linux依旧是小白状态, 总怕过程中粗大事导致电脑挂掉…..不过从好在这次结果是好的, 到目前为止更换系统刚好满一周了, 个人需要用的常用软件都顺利安装了(包括游戏), 没有严重妨碍使用的问题(虽然小bug遍地…), 目前计划继续这么跑两个月. 如果两个月后系统不出太大的问题的话就可以考虑卸掉mint了. 为什么选Manjaro因为简单! 虽然我受人安利转入Arch系, 但我毕竟对linux不是那么熟悉, 所以我并没有考虑直接装原版的Arch, 而是从DistrioWatch上搜索了人气比较高的Arch衍生版, 也就是现在在用的Manjaro了.虽然真正的原生Arch粉可能觉得这属于歪门邪道….毕竟Manjaro不符合Arch最精简, 把一切交给用户的理念, 但是对于我这种又想体验Pacman又不想花太多时间去细读Arch Wiki的人来说Manjaro真是非常好的解决方案… 安装方案由于第一次使用Ubuntu系之外的Linux, 为了给自己留条后路当然是要选择双系统的安装方案了.我的笔记本硬盘使用了GPT分区, 只安装了一个Linux Mint, 没有安装过任何Windows, 引导的问题解决起来还是挺方便的, 安装的时候设置让Manjaro把它的Grub2装到已经存在的EFI分区中, 然后直接手动把Linux Mint放在EFI分区中的efi文件删除就可以了.之所以直接删除有两个原因: 从Mint的Grub2中无法正确引导Manjaro, 但是Manjaro的Grub2可以正确引导Mint, 问题原因不明, 可能是Mint的版本太低? 不知道如何让系统自动选择用Manjaro安装的Grub2, 干脆就删掉Mint的只留Manjaro的.总的来说安装挺顺利的, 跟安装Ubuntu或者Mint一样点几下鼠标就好了. 不过第一次安装完成后我尝试折腾了一下显卡的驱动, 然后桌面的分辨率变得不正常且无法复原了, 于是重新安装过一遍…. Manjaro(Cinnamon Edition)与Linux Mint的比较桌面环境Manjaro支持多种桌面环境, 为了减小我的迁移阻力, 我选择了搭载Cinnamon的版本.所以虽然是不同的系统了, 但是外观看上去其实没有什么不同, 在默认搭载软件上两者比较一致, 发现的不一样之处有: 一些系统选项驱动程序管理需要使用”Manjaro Setting Manager”进行, 而Mint下是全部整合在设置面板中的 Mint语言与输入法位于同一设置项中, 可同时管理语言与输入法, Manjaro下仅有位于”Manjaro Setting Manager”中的独立语言设置项, 未见输入法管理 对于双显卡的电脑Manjaro默认会安装bumblebee, 并且于软件库内并未找到Nvidia Prime的相关软件包, 推测Arch系的系统里都是使用bumblebee来进行双显卡切换的 软件包管理软件于源更新软件不同 Manjaro没有默认安装字体管理程序 计算器程序不一样 中文化情况这一项Manjaro比Mint好很多, 选择中文进行安装后基本上该中文化的都中文化了(包括Gimp &#x2F; Firefox &#x2F; Libre Office). 并且后续安装的软件有中文语言包的话也会一并被安装, 如Okular &#x2F; Kolour Paint 这些KDE下的软件.而Mint 17经常出现中文化不全, 系统安装完毕后仅有部分常用菜单项是中文, Gimp &#x2F; Firefox &#x2F; Libre Office这些全部都是英文, 需要自己重新安装语言包. 并且后续安装的软件也都会一直是默认为英文. 字体效果 在没有进行任何配置的情况下, 个人感觉Manjaro的效果比Mint差一些, 这个比较出乎我的意料, 因为我之前有用Live CD体验过Manjaro的KDE版本, 字体看上去挺舒服的. 使用系统设置中的字体项进行简单设置后显示效果感觉依然不如Mint, 总感觉中文字的边缘特别虚…..不过这一些可以通过安装fontconfig-ubuntu和freetype2-ubuntu这两个包解决, 安装过后可以获得和Mint一致的显示效果. 常用软件获取一个基于Ubuntu, 一个基于Arch, 软件包管理自然大不同. Arch受到许多用户喜爱的原因之一就是其几乎什么都有并且随时保持最新的软件库.官方库与AUR中确实是什么软件都有, 所有我在U系系统中用到的软件都能在官方库与AUR中获得. 并且像Rstudio &#x2F; sogou-pinyin &#x2F; WPS &#x2F; Steam等等一些软件以前是要自己去下载deb包或者添加PPA源进行安装的, 但是换了Manjaro后一条命令或者在Pamac中点几下鼠标就能解决了.但是, 上述方便是建立在网络环境良好的情况下的.像我学校的校园网, 长期不定时抽风, 本来理论下行速度就只有512kb&#x2F;s, 平常实际使用的时候一般就只有100-200kb&#x2F;s, 万一是从国外网站获取软件包, 速度能有50kb&#x2F;s我就要偷笑了…..因此实际的软件安装体验相当之糟……特别是从AUR安装, 即使勾选不需要确认, 大部分包都是要输入密码获取权限的, 因为下载太慢时间长, 装软件时无法实现自动安装, 得守在旁边一遍遍输入密码……然后还不一定能安装成功……好在国内的Arch爱好者开了一个叫做”archliunxcn”的软件源造福国内用户, 源中有许多AUR中才能获取的软件, 其下载速度飞快并且安装不会出什么错误. 依据ArchWiki的指导添加”archlinuxcn”源后我顺利完成了绝大部分常用软件的安装.值得一提的是, 在安装软件的过程中我发现Arch库中并不是所有软件都保持最新, 比如R.Arch官方库中提供的R为3.2.4版本, 而最新版本为3.3.0. 虽然AUR中的r-kml是最新的3.3.0版本, 但是我怕安装出问题所以没有考虑使用.如果是使用Mint, 我可以通过添加第三方PPA方便的获取最新的R, 但Arch系的系统下并不能这么干, 于是我最后选择了编译安装, 具体安装过程参看之前的另一篇记录. 显卡驱动Linux下的双显卡驱动一直是个我折腾不来的问题, 这也是我最早从原生Ubuntu迁移到Mint的最重要原因: 能一键安装显卡驱动.可能是Manjaro在设计理念上与Mint颇有相似之处, 因此在显卡驱动这方面做得也挺好的, 系统安装之初所有驱动就默认安装好了, 并且使用时没有什么大问题, 不过我在Mint下进行显卡切换时用的是Nvidia-prime, Manjaro下似乎只能用Bumblebee. 而最近这段时间我可能只打个炉石和火炬之光2就可以了, 也并不需要用到独显, 所以暂时也不折腾了… 输入法Manjaro下并没有专门的输入法管理项, 直接从库安装输入法使用就成. 不得不说有搜狗拼音的感觉真好! 虽然之前在Mint下也适应了Rime, 但是总的来说还是不如搜狗顺手啊!求老天不要再让fcitx挂掉了! 我都换系统了就放过我吧!!!!!! 小问题与小Bug不知道是不是我真的脸黑得没治了, 从我开始用Linux起, 各种小Bug就没有断过, 这次从Mint转到Manjaro有一部分也是因为Firefox的Flash说挂就挂了, 而且我还找不到解决办法……..然而我转到了Manjaro下…..依然是各种小Bug不断…..整理了一下, 转Manjaro至今遇到的小问题与小Bug有: leanote默认编辑器下字体不正常(升级内核后解决) vivaldi安装flash后闪烁(放弃使用) 启动时提示: [failed]failed to start setup virtual console(已解决) 启动时无鼠标指针, 重新登陆后指针出现(已解决) 使用截图程序的区域截图功能时程序不响应(未解决) unzip解决乱码无效(已解决) 字体模糊(已解决) steam 无法直接启动(已解决) neemo 无法锁定到docky后启动, 因为docky将其辨认为root manager(未解决) Rstudio无法输入中文(未解决) telegram无法输入中文(已解决) pdf不显示中文(已解决) 桌面显示不正常, 仅能使用低分辨率(原因未知, 重装解决) 文本拖动复制时, 拖动无法通过面板跨窗口(未解决) rename不支持正则表达式(已解决) 全局快捷键小概率失灵(未解决) …问题如此之多, 以至于小伙伴说, 你用的不是Arch, 是充满Bug的Arch…不过好在上述问题中并没有严重影响使用的, 并且在Manjaro下我的电脑可以正常的休眠于挂起, 全局快捷键的失灵也没有Mint下那么严重. 所以总的来说, 顺利完成了Mint到Manjaro的迁移. 学习资料Arch Wiki的详尽细致一直为所有Arch用户及一些非Arch用户所称道, 在使用一周Arch衍生版之后我也对这一点有了一点体会. 但是对我来说, 对比Ubuntu及其衍生版, 搜索一个Arch下问题的解决办法要难得多.举Vivaldi安装Flash出现闪烁这个问题为例, 我直接中文百度&#x2F;Bing&#x2F;Google”Arch Vivaldi Flash 闪烁”出不了任何有用的结果……考虑到Vivaldi毕竟是小众中的小众, 所以把”Vivaldi”换成 “Chrome” &#x2F; “Chromium”, 依然找不到任何有用的结果……这个就相当尴尬了…原来我在Mint下都是先搜索中文, 实在找不到才搜索英文的. 毕竟Mint基于Ubuntu, 而Ubuntu在国内的用户还是相当多的, 大部分时候都能找到有效的解决方案. 即使找不到有效解决方案, 我也能通过中文的搜索结果对问题进行初步了解, 在了解基础上尝试进行英文结果的搜索, 从而找到解决方法.换了Manjaro就不行了, 且不谈国内Manjaro的用户极少(论坛贴吧等连灌水的都没有), 就连Archlinux中文论坛以及贴吧的用户活跃程度也远远不及Ubuntu, 于是中文搜索的难度实在是高了不只一点.虽然Linux下非常多问题都是相通的, 以”Linux”作为关键词可以得到一部分问题的解决方案, 但是总不如直接用”Ubuntu”做关键词就能解决来得快捷舒心. 迁移后感历时一周, 目前我已经能在Manjaro下完成所有我之前完成的事情了, 虽然依然有小Bug缠身(说得像之前就没有一样…), 但是也有非常多的惊喜(搜狗能用了, 休眠&#x2F;挂起正常了)支持我继续用下去. 期待接下来两个月Manjaro能保持稳定了…….至于内核……到底是更新还是不更新好呢……. 致谢在此郑重感谢安利我入坑的晨星姐! 有个用过的人能问总是比较安心的~ 桌面截图留念其实吧…前后两张图还真看不出有多大区别, 毕竟都是Cinnamon, 毕竟都用了风格类似的主题… Mint截图 Manjaro截图 备忘录(额外安装软件与包一览)官方库 docky virtualbox steam fcitx fcitx-sogoupinyin steam-manjaro steam-native kdegraphics-okular kdegraphics-kolourpaint texmaker uget qbittorrent flashplugin perl-rename gnome-font-viewer goldendict Archlinuxcn telegram-desktop mendeleydesktop rstudio-desktop-bin shadowsocks-qt5 atom-editor AUR crossover 下载即用 Leanote Unipro Ugene VirtualBox Extention Pack 编译安装 R-3.3.0 界面设置(manjaro)今天在油管上看到了一个manjaro deepin 16.08的体验视频, 于是手痒痒下了dde下来尝试. 不得不说deepin团队还是有用心做软件的, 最新的deepin15.3已经比较流畅了, 而且整个界面的设计简洁美观(在我心目中未配置状态下仅次于kde了…), 感觉很有前景呀~可是毕竟现在的布局用了快半年了, 一下切去dde总觉得好空虚…另外毕竟是发展中的桌面环境, 插件和可配置(嗯…对我来说是通过GUI来配置)的地方还比较少, 所以虽然看上去很美…15分钟之后我还是卸掉了继续xfce… …不过…在看了年轻漂亮的之后, 再回到原来的环境…咳…总觉得有点难受…(果然我也是喜新厌旧的渣…)于是又开始各种换主题…在浏览pamac里的软件时偶然发现了个插件:xfce4-windowck-plugin, 这个插件可以把标题栏和标题按钮放到面板上, 这一下让我想起了unity… 就想我之前说的, 我还是挺喜欢unity的布局的, 可惜之前配置的时候没有找到比较好的解决方案. 有了这个插件, 虽然不能达到unity的效果(unity同时整合标题栏和菜单到面板), 但总算也能节省一点空间了~具体方案如下: 安装xfce4-windowck-plugin 将插件放到上面板 在窗口管理器里设置窗口最大化时隐藏标题栏 将所有按钮左置 将菜单按钮移到左面板, 工作区指示器移到下面板 铛铛铛铛~ manjaro挂掉之后挂的这么突然, 还要作大死当初迁移的时候就有想过…以自己的人品估计半年内怎么也得挂一次, 没想到真的就挂了…本周2的时候因为不明原因GUI就进不去了, 卡在了Manjaro Logo载入的地方, 切换到控制台什么也不显示…根本不知道什么问题, 然后又急着用电脑, 想着之前重装Mint的时候保留home, 重装完成后直接挂上home软件设置和个人文件都不会丢, 就想着不如重装吧!然后就作!大!!死!!!了!!!!重装进入GUI的时候瞬间懵逼…我的home怎么被格式化了!!!推想是重装的时候手抖勾了格式化了…啊…真特么是晴天霹雳…我的实验数据全放在home没有备份啊…在忧伤了半个小时之后开始寻找恢复的办法, 淘宝问了好几个店发现数据恢复服务全都是win的…真是欲哭无泪…尝试使用photorec以及testdisk进行了一下修复, 并没有卵用…于是在周二晚…终于认清现实, 重头来过…(你妹啊…) 桌面环境变更(不知道第几次了…)反正整个系统要重装加重新配置, 所以就想要不要这次连桌面环境一起也换了, 毕竟上次迁移时为了最快上手保留了Cinnamon, 这次不如再学习点新东西, 反正自己一直以来都想试一试传说中的Xfce…恰好Xfce是Manjaro官方支持的桌面环境, 就直接下了Manjaro Xfce准备再次重装. 安装过程Manjaro各个版本安装起来都是相当简单…点点点就好了…只要记得不要像我一样手抖去勾格式化就好… Xfce与CinnamonXfce与之前从Unity或者Cinnamon不太相同. Unity与Cinnamon都是旨在提供漂亮易用并且功能完善的操作界面, 而Xfce是把轻量列为重要考虑因素的桌面, 所以使用起来跟前两者的感受还是很不一样的.简单来说, Xfce给人的感受真的是非常非常快!不论是启动电脑还是加载程序, 速度差异真的是肉眼可见的…这个真是只有用了才有感受. 当初从Mint转到Manjaro Cinnamon就觉得速度有了明显的提升, 现在从Cinnamon换到Xfce速度又有了明显的提升…现在倒回去打开Mint真的会觉得慢的有点不能忍…轻量 &amp; 简洁, Xfce非常符合这两点, 不过对于我一个从Cinnamon转过来的人来说…有些小地方太简洁了我有点难受: 面板的音量插件非常之简洁…简洁到很多时候我不知道这个插件要怎么用…经常莫名其妙的调不了声音… unzip不支持-O这个参数…导致zip文件乱码成了问题… 键盘快捷键设置的地方没有太多预设方案…需要自己先找要实现的功能的命令怎么写(我的笔记本没有专门开关触控板的功能键, 必须自己另外设置快捷键)… 自带文件管理器不支持前进后退键, 并且在设置里耶找不到相应选项…另外…这货长得真是没nemo好看… 没有disk(管理磁盘分区挂载的程序)…于是在自动挂载设置方面瞬间懵逼… 找不到自带的mousepad(文本编辑器)的设置在哪…对着白底和小得我快受不了黑字好难受… 自带音乐播放器看上去功能很多可是完全不知道怎么用…也不支持拖拽打开文件… 网络设置页面没有系统代理的设置项, 只有VPN 这些问题都不是很大, 更多的属于突然转换桌面环境后的不适应. 作为用户来说, 我可以选择慢慢的改变习惯来适应, 另一方面其实也可以根据习惯去对环境作相应修改…毕竟这是linux, 只要想折腾…大部分还是可以实现的.对于我个人来说, Xfce这飞一般的速度给了我足够的动力继续使用下去, 毕竟特效再炫, 也没有炫的对象, 还是自己用的流畅舒适比较重要… 再看Arch Wiki当时脱U系入A系的时候感觉A系系统的资料还没U系丰富, 现在Manjaro用了一个半月之后对这一点有了改观, 讲道理…丰富还是Arch Wiki丰富…一个半月以来8成以上问题都是能在里面找到答案的, Arch Wiki里没有的, 基本也很难找到答案了…其实, A系的资料并不是难找, 而是没有U系的那么傻瓜式.原来用U系系统时, 在网上找到的材料里一般都会附有可以直接运行的问题解决命令或代码, 只要能确定描述问题一致, 把那几行代码复制下来终端直接跑就可以了. Arch Wiki则不同, 其在编写时候大概是默认读者有一定Linux基础了, 里面会写到问题的原因与解决方案, 但很少会直接写一步到位的代码出来给大家直接用.从这个角度上, Arch确实是不适合新手, 但非常适合用来学Linux. 对系统进行配置我的配置原则是尽量符合原来在Cinnamon下的工作习惯, 因此主要对面板进行了重拍(最后其实回到了Gnome2的布局…), 删除了部分自带软件并以原来在Cinnamon下使用的进行替换. 另外Xfce下Steam的运行库再次除了问题…之前Cinnamon下使用本地运行库后所有游戏就能正常运行, 现在Xfce下这招不好使了, 于是从Arch Wiki翻到了另外的解决方案.具体如下: 替换音量控制插件 卸载自带的音量控制插件pa-applet, 安装xfce4-pulseaudio-plugin, 手动将后者添加到面板(不支持在通知栏出现) 安装上述插件后调整音量时会有两个音量改变通知, 在插件上右键属性可关掉一个(另一个大概是系统自带的…不知道怎么关). 替换unzip包 安装unzip-iconv(archlinuxcn repo)取代unzip 设置开关触控板的快捷键 解决方案来自Arch Wiki: Touchpad_Synaptics#Software_toggle 进入页面后将脚本代码复制后保存到制定位置, 然后进入Xfce的键盘快捷键设置页面进行按键绑定即可. 替换文件管理器 自行安装nemo(软件源里有) 一并nemo-fileroller, nemo-previewer以及nemo-share已保证功能完整 增加磁盘管理程序 安装gnome-disk-utility 替换文本编辑器 卸载mousepad, 安装gedit 替换音乐播放器 卸载guayadeque, 安装pragha, netease-cloud-music 配置中文输入法 按照Arch Wiki指引为输入法声明环境变量, 使绝大部分程序可以正常输入中文 Steam无法启动 解决方案来自:Arch Wiki:Steam_runtime_issues 按照说明添加环境变量即可 ##未解决的Bug Pamac内无法更新Archlinuxcn源软件, 可在命令行下使用pacman正常更新 使用无线网卡时, 挂起唤醒后无线网卡无法接受信号, 必须注销重登陆 leanote普通编辑器内字体显示不太正常 浪漫雅圆字体安装后无法正常显示 蓝牙耳机暂停键无用 软件清单 安装软件(库):dockyvirtualboxsteamfcitxfcitx-sogoupinyinsteam-manjarosteam-nativekdegraphics-kolourpainttexmakerugetqbittorrentflashpluginperl-renamegnome-font-viewergoldendicttelegram-desktopmendeleydesktoprstudio-desktop-binrshadowsocks-qt5atom-editorinkscape AUR:crossover 下载即用:ugeneleanote 新桌面纪念 照例来一发新桌面的截图 顺带秀一下自带的下拉控制台, 实际使用起来还挺带感的~","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://silenwang.github.io/tags/Ubuntu/"},{"name":"Manjaro","slug":"Manjaro","permalink":"https://silenwang.github.io/tags/Manjaro/"},{"name":"manjaro","slug":"manjaro","permalink":"https://silenwang.github.io/tags/manjaro/"},{"name":"Linux系统","slug":"Linux系统","permalink":"https://silenwang.github.io/tags/Linux%E7%B3%BB%E7%BB%9F/"},{"name":"桌面环境","slug":"桌面环境","permalink":"https://silenwang.github.io/tags/%E6%A1%8C%E9%9D%A2%E7%8E%AF%E5%A2%83/"},{"name":"linux","slug":"linux","permalink":"https://silenwang.github.io/tags/linux/"},{"name":"系统迁移","slug":"系统迁移","permalink":"https://silenwang.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%BF%81%E7%A7%BB/"},{"name":"Mint","slug":"Mint","permalink":"https://silenwang.github.io/tags/Mint/"},{"name":"双系统","slug":"双系统","permalink":"https://silenwang.github.io/tags/%E5%8F%8C%E7%B3%BB%E7%BB%9F/"},{"name":"显卡驱动","slug":"显卡驱动","permalink":"https://silenwang.github.io/tags/%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8/"},{"name":"输入法","slug":"输入法","permalink":"https://silenwang.github.io/tags/%E8%BE%93%E5%85%A5%E6%B3%95/"},{"name":"linuxmint","slug":"linuxmint","permalink":"https://silenwang.github.io/tags/linuxmint/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://silenwang.github.io/tags/ubuntu/"},{"name":"desktop-environment","slug":"desktop-environment","permalink":"https://silenwang.github.io/tags/desktop-environment/"},{"name":"dual-boot","slug":"dual-boot","permalink":"https://silenwang.github.io/tags/dual-boot/"},{"name":"graphics-driver","slug":"graphics-driver","permalink":"https://silenwang.github.io/tags/graphics-driver/"},{"name":"input-method","slug":"input-method","permalink":"https://silenwang.github.io/tags/input-method/"}]},{"title":"用R绘制地图的笔记","slug":"用R绘制地图的笔记","date":"2018-07-29T00:38:09.000Z","updated":"2026-02-10T14:03:13.681Z","comments":true,"path":"2018/07/29/用R绘制地图的笔记/","permalink":"https://silenwang.github.io/2018/07/29/%E7%94%A8R%E7%BB%98%E5%88%B6%E5%9C%B0%E5%9B%BE%E7%9A%84%E7%AC%94%E8%AE%B0/","excerpt":"研究生期间曾有作地图展示结果的需要, 使用R绘制过地图, 将当时的代码记录如下","text":"研究生期间曾有作地图展示结果的需要, 使用R绘制过地图, 将当时的代码记录如下 #流行病学数据地图展示 代码来源脚本代码主要改写自统计之都文章:R绘制中国地图，并展示流行病学数据 代码本体(已包含备注)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475####loading packages 载入需要的程序包####library(maptools) #用于读取并操作地图数据library(ggplot2) #用于绘制地图####set working directory####getwd()setwd(&quot;/home/silen/R _Data/Map&quot;) #设定当前工作目录,将目录设置为地图数据所在位置即可####loading map data(shape data)####map &lt;- readShapePoly(&quot;countries_shp/countries.shp&quot;) #读取*.shp格式的地图数据,注意*.shp数据须和其他文件放置在一起如*.shx才可读取,否则会出现错误####check loaded data 调试部分,用于查看已读取地图数据情况####names(map)str(map$NAME)table(map$EU)####Normal method, using geom_polygon / geom_path 使用基本的polygon方法与path方法进行地图绘制(暂不清楚如何展示流行病数据)####DB &lt;- fortify(map) #重要语句,通过此步骤将读入地图数据转化为ggplot可以识别的格式p &lt;- ggplot(DB, aes(x=long,y=lat, group = group)) #creat a plot 图形初始化,确定使用数据库并将经纬度映射到x,y轴;group=group保证绘制图形无错乱# World map, using geom_path instead of geom_polygon(来自ggplot帮助文档,暂不明为何)World &lt;- p + geom_polygon(color=&quot;white&quot;, fill = &quot;grey&quot;) + #使用polygon(多边形)绘制地图,并设置填充色为灰,线条色为白 theme(panel.grid.major=element_blank(),#theme()内都为样式效果设定,主要为隐藏x.y轴以及相应文字,背景去除,网格去除, panel.background=element_blank(), axis.title.x=element_blank(), axis.title.y=element_blank(), axis.text.x=element_blank(), axis.text.y=element_blank(), axis.line=element_blank(), axis.ticks=element_blank())+ ggtitle(&quot;World&quot;)+ scale_y_continuous(breaks = (-2:2) * 30) +#忘了干嘛的 scale_x_continuous(breaks = (-4:4) * 45) + #coord_map(&quot;orthographic&quot;) #极视图 #coord_map(&quot;gilbert&quot;) #ball 球形视图 coord_map(&quot;lagrange&quot;) #flat#coord_map()内为特殊坐标轴映射,具体见ggplot包说明####Epi method using geom_map 使用专有的geom_map方法绘制地图,可展示流行病学数据(热图)#####load data and get prepared for plotting 生成需要的地图数据,载入部分在开头DB &lt;- fortify(map, region = &quot;NAME&quot;)#transform map shape data to object can be read by ggplot#DB &lt;- transform(DB, id = iconv(id, from = &#x27;GBK&#x27;), code = iconv(code, from = &#x27;GBK&#x27;))#transform coding from GBKhead(DB) #查看数据情况names(DB)[c(1, 2)] = c(&quot;x&quot;, &quot;y&quot;)#change head of data, for purpose of using expand_limits() 改变数据表中变量的名称,此处为geom_map方法所需#prepare Epidemiology data -&gt; crude death rate 准备好流行病学数据,注意对应问题mor &lt;- read.csv(&quot;mapRate.csv&quot;,head =T, sep =&quot;,&quot;) #从*.csv文件中读入流行病学数据epi &lt;- data.frame(id = unique(sort(DB$id)))# 使用名为epi的数据框保存流行病学数据,从DB(地图数据)中获得所有区域(或地点)的名称(对应用)epi &lt;- merge(epi, mor, by.x= &quot;id&quot;, all.x = T)# 以id变量为对应标准,合并区域名称及相应流行病数据#write.csv(epi, &quot;1234.csv&quot;) #调试用#epip1 &lt;- ggplot(epi, fill = &quot;#595959&quot;) + geom_map(aes(map_id = id, fill = rate ),#使用geom_map绘制地图并展示数据 colour = &quot;white&quot;, map = DB) + expand_limits(DB) +#重要语句,无此语句无法绘制出地图,语句意义待查 #changing theme, make backgroud blank/transparent theme(panel.grid.major = element_blank(),#主题设置,大致为隐藏x.y轴并去掉背景、网格,使背景透明 panel.background = element_blank(), plot.background = element_rect(fill = &quot;transparent&quot;,colour = NA), legend.background = element_rect(fill = &quot;transparent&quot;,colour = NA), legend.title = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank(), axis.line = element_blank(), axis.ticks = element_blank())+ #ggtitle(&quot;World&quot;) + #title of plot scale_fill_gradient(high = &quot;#F70909&quot;, low = &quot;#E99799&quot;) + #设定热图颜色 scale_y_continuous(breaks = (-2:2) * 30) +#意义不明 scale_x_continuous(breaks = (-4:4) * 45) + #coord_map(&quot;orthographic&quot;) #coord_map(&quot;gilbert&quot;) #ball coord_map(&quot;lagrange&quot;) #flat#坐标设定####print plot 输出图像,只有在需要输出透明背景图像时使用####png(&#x27;world.png&#x27;,width=600,height=600,units=&quot;px&quot;,bg = &quot;transparent&quot;)#设定名称、大小、大小单位以及设背景为透明print (p1)#输出p1dev.off()#表示完成输出","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"ggplot2","slug":"ggplot2","permalink":"https://silenwang.github.io/tags/ggplot2/"},{"name":"地图绘制","slug":"地图绘制","permalink":"https://silenwang.github.io/tags/%E5%9C%B0%E5%9B%BE%E7%BB%98%E5%88%B6/"},{"name":"流行病学数据","slug":"流行病学数据","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E8%A1%8C%E7%97%85%E5%AD%A6%E6%95%B0%E6%8D%AE/"},{"name":"热图","slug":"热图","permalink":"https://silenwang.github.io/tags/%E7%83%AD%E5%9B%BE/"},{"name":"shapefile","slug":"shapefile","permalink":"https://silenwang.github.io/tags/shapefile/"}]},{"title":"R培训笔记","slug":"R培训笔记","date":"2018-07-29T00:35:55.000Z","updated":"2026-02-10T14:03:13.675Z","comments":true,"path":"2018/07/29/R培训笔记/","permalink":"https://silenwang.github.io/2018/07/29/R%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/","excerpt":"研究生期间参加广东省疾控R培训的笔记, 这算是我真正意义上的编程入门课了","text":"研究生期间参加广东省疾控R培训的笔记, 这算是我真正意义上的编程入门课了 R培训笔记整理总览 本次培训共计3天,包含5部分内容,分别为: R语言简介及基本概念、操作 使用R绘制统计图(graph &amp; ggplot2) 时间序列分析简介以及广义线性模型(GLM)及广义相加模型(GAM)的使用 分布滞后非线性模型的使用 R中的meta分析 R语言简介及基本概念、操作 R特点 优:免费、功能多、更新快、过程可视化、作图美观 劣:难精、不统一、学习须时间、运行慢(可通过特定包优化) 软件安装 R以及Rstudio可从官网获取安装包 package&#x2F;包 可从官网自行获取后安装,亦可软件内安装 R内函数需要先加载相应软件包后才可使用, 也仅有加载后才可在帮助中查看对应帮助. 软件界面简介(略)R常用语法 大小写区分 语句由函数与赋值构成 所有符号须使用半角英文 #用于注释,#文本####可索引(script模式下) 每行句末不需要特殊符号,语句未完成时程序向下行继续执行直到完成 &lt;-为赋值符号, 如x&lt;-3, =可替换之 ==为逻辑运算符等于, &amp;为和, |为或, &gt;=大于等于, &lt;=小于等于 单双引号大多数情况无差别 路径有两种等价的表达方式, C:\\\\R\\\\Data等同 C:/R/Data; R对中文支持不佳, 尽量使用全英文路径 $可用于提取对象内变量, 提取后可进行赋值或改写等操作. []可用于提取数据框的子集 !为反义符号 工作目录设置 &amp; 数据读写 目录:getwd(&quot;路径&quot;)/setwd(&quot;路径&quot;) 数据导入: Excel(仅支持.csv): read.csv(&quot;路径+文件名, header= , sep=&quot;,&quot;) txt: read.table(&quot;路径+文件名&quot;, header= , ) Spss(.sav): read.spss(&quot;路径+文件名&quot;, use.value.labels= ) SAS(.sav): read.sas7bdat(&quot;路径+文件名&quot;) R(.rda): load(&quot;路径+文件名&quot;) 直接读取: read.table(textConnection(&quot;内容&quot;), header=, sep=) 数据导出 R: save(对象, file=&quot;路径+文件名&quot;) Excel(.csv): write.csv(对象, file=&quot;路径+文件名&quot;) txt: write.table(对象, file=&quot;test.txt&quot;,sep = &quot;分隔符&quot;) 对象(数据)查看 可使用多种函数对已经加载(创建)的对象进行查看, 每种函数的功能各有侧重. View(对象)可在左上调出窗口显示对象&#x2F;数据情况; head(对象, 条目数)可在控制台内显示前n条数据情况, 不设置数目时默认6条; tail(对象, 条目数)可在控制台内显示后n条数据情况, 不设置数目时默认6条; names(对象) 可在控制台内显示对象内所有变量的名称(即header). str(对象) 可在控制台显示对象的条目数及变量数, 并显示每个变量的名称、类型以及前10条目的值. dim(对象) 可在控制台显示对象的条目数及变量数 对象(数据)的统计描述 函数最基本形式 函数用途 备注 summary(对象) 数值变量显示最大,最小,算数均,中位,四分位距;分类变量显示各值对应计数; 若存在缺失值显示缺失值数目. mean(对象) 计算算数平均数 对象须为数值型变量 sd(对象) 计算标准差 对象须为数值型变量 max(对象) 计算最大值 对象须为数值型变量 min(对象) 计算最小值 对象须为数值型变量 tips: 使用rm.na=参数可在计算相应统计量时自动移除缺失值 对象(数据)简单操作 函数表达式 操作效果 备注 names(data)&lt;-c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;) 将data数据框前三个变量的变量名更改为1. 2. 3 数据框内变量超出3个时, 3个之后的变量名将丢失,如果赋予名称过多则无法执行 data=rename(data,c(&quot;old1&quot;=&quot;new1&quot;, &quot;old2&quot;=&quot;new2&quot;)) 将data数据框内变量名指定替换 rename()为plyr包函数 as.date(data)as.numeric(data)as.charactor(data)as.factor(data)等等 将制定变量转换类型, 转换后可赋值给对象 subset(data, select=c(v1,v2))subset(data, v1==n)data[row,colum] 提取指定数据框的行&#x2F;列 两种方式是否完全等价未知; t[]默认取行 data$v=data$v1+test$v2 对数据框内已有数据进行计算并写入到数据框中成为新变量 substr(strData,1,3) 从字符串变量中提取特定位数的字符串 mutate(data,) 对data数据框同时进行多种操作, mutate()的主要作用是简化代码 join(data1, data2, by= ,type=) 将不同数据框按照一定标准合并 join()函数不需要对表格进行排序 str_count(data, v) 对data数据框内的v变量的每一种值进行计数 stringr包函数 order(x) 对数据框按照特定变量进行排序 使用-可调节为降序 使用R绘制统计图 R中常用的统计图绘制包有两种: graph(自带): 基本作图 ggplot2(需要安装):高级作图, 作图自定义程度高, 成品漂亮","categories":[{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"}],"tags":[{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"数据分析","slug":"数据分析","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"统计绘图","slug":"统计绘图","permalink":"https://silenwang.github.io/tags/%E7%BB%9F%E8%AE%A1%E7%BB%98%E5%9B%BE/"},{"name":"数据操作","slug":"数据操作","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"},{"name":"培训笔记","slug":"培训笔记","permalink":"https://silenwang.github.io/tags/%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/"},{"name":"data analysis","slug":"data-analysis","permalink":"https://silenwang.github.io/tags/data-analysis/"},{"name":"statistics","slug":"statistics","permalink":"https://silenwang.github.io/tags/statistics/"}]},{"title":"宿命传说2","slug":"宿命传说2","date":"2016-07-22T18:50:07.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2016/07/22/宿命传说2/","permalink":"https://silenwang.github.io/2016/07/22/%E5%AE%BF%E5%91%BD%E4%BC%A0%E8%AF%B42/","excerpt":"","text":"感冒伴发过敏…在家里躺了两天半, 一件正事没干, 通了宿命传说2(PSP版本)…果然打游戏对我来说比什么动力都大… 我还在上小学的时候就知道这个游戏了…那时电视上还有挺多电玩介绍节目, 报刊亭也还买得到各种游戏攻略杂志, 我至少在两个节目里、以及三本中看过宿命传说2, 印象中他们对这个游戏的评价都非常好… 然而我毕竟不是主机玩家(那时也没有可能成为, 太贵…), 对于这等大作也只能看着手痒了…不过感谢科技的进步, 十四年之后我终于有机会玩到这个游戏了~ 不过不知道是不是期望越高失望越高…这个游戏很多地方真的是特别的糟心… 首先是画风…该说人变得太快么…我记得小学的时候我看片头动画觉得还是挺好的…然而现在再来看…总觉得这些个人物肖像看着好难受…奇大的眼睛…奇瘦的躯干和四肢…然后特别是主角的这个衣服…实在是有点过于…咳咳… 然后是性格设定…主要是针对主角…就好像大多数人的感觉一样…真的是典型的中二小屁孩…啊…我这果然是长大了然后无法直面过去的自己么&#x3D; &#x3D;||| 接着是地图和部分解谜…尤其是世界地图. 说实话刚开始我还觉得游戏的引导做的还挺好的, 会在小地图上标志目标地点, 然而我发现除了刚开始的兰格那遗迹可以直线走过去之外, 几乎所有的地点都是必!须!绕!路!才能到达的! 并且从小地图上根本看!!不!!出!!怎么走!!! 导致每去一个新地点几乎都要把能走的地方跑遍才能到达, 然后绕路过程中要杀无数的怪…解谜方面…有些触发点实在是做的太tm不明显了…也是导致跑来跑去杀了无数怪才明白要怎么搞… 最后是战斗…刚开始玩的时候感觉这个战斗系统还挺有意思的…可是后面敌人越来越恶心…前排的敌人难以击飞, 后排的晶术咏唱快得离谱, 万一甩一个上级晶术出来至少要跪一两个…尝试用控制的人物直接绕到后排打断, 那这个人多半跳进去就回不来了…到最后只好碰到恶心的组合就直接不打了… 总的来说…从游戏系统上…个人感觉这是一个玩着特别累的游戏…剧情方面由于主角实在太中二, 反复穿越时间的各种不合理, 反派的智商硬伤, 最后没道理的强行团圆等等, 也不能给这个游戏带来什么加分…所以对我来说, 打通这个游戏只能算是消除心中的残念, 至于再打一次或者向别人推荐…免了吧…","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"游戏评测","slug":"游戏评测","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E8%AF%84%E6%B5%8B/"},{"name":"宿命传说2","slug":"宿命传说2","permalink":"https://silenwang.github.io/tags/%E5%AE%BF%E5%91%BD%E4%BC%A0%E8%AF%B42/"},{"name":"童年回忆","slug":"童年回忆","permalink":"https://silenwang.github.io/tags/%E7%AB%A5%E5%B9%B4%E5%9B%9E%E5%BF%86/"},{"name":"游戏系统","slug":"游戏系统","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E7%B3%BB%E7%BB%9F/"},{"name":"Tales of Destiny 2","slug":"Tales-of-Destiny-2","permalink":"https://silenwang.github.io/tags/Tales-of-Destiny-2/"}]},{"title":"Melody's Escape","slug":"Melody-s-Escape","date":"2016-06-05T17:06:41.000Z","updated":"2026-02-10T14:03:13.674Z","comments":true,"path":"2016/06/05/Melody-s-Escape/","permalink":"https://silenwang.github.io/2016/06/05/Melody-s-Escape/","excerpt":"","text":"不知这首歌的原出处是哪, 反正我是玩Melody’s Escape听到的… 这游戏的一大特点是音乐自选, 官方只自带的5首歌(就包括这首Regain Control), 但是你可以选择任何自己有的音乐进行游戏(支持MP3s, WMAs, iTunes, FLAC等格式), 把原来喜欢听的ACG歌曲翻出来一首首跑一遍还是挺带感的~ 对于音游粉丝来说旋律逃脱应该还挺简单的, 一共就八个按键…..如果是和我一样第一次玩音游的手残来, 从Medium(四个按键)开始会比较容易上手, 两个手都有点手感了再尝试八个按键. 另外感觉初玩最好还是选节奏感强的乐曲跑, 因为这种乐曲大部分按键都在节奏点上, 比较容易按. 个人玩了一个星期左右发现比较带感且相对简单的乐曲有: AlieZ, βios, X.U, Hero’s Come Back, only my railgun, hollow World 唯一的遗憾是这个游戏目前是完全的单人游戏, 不知道作者之后会不会加入本地对抗的模式呢…… steam链接","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"音游","slug":"音游","permalink":"https://silenwang.github.io/tags/%E9%9F%B3%E6%B8%B8/"},{"name":"音乐游戏","slug":"音乐游戏","permalink":"https://silenwang.github.io/tags/%E9%9F%B3%E4%B9%90%E6%B8%B8%E6%88%8F/"},{"name":"节奏游戏","slug":"节奏游戏","permalink":"https://silenwang.github.io/tags/%E8%8A%82%E5%A5%8F%E6%B8%B8%E6%88%8F/"},{"name":"游戏体验","slug":"游戏体验","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/"},{"name":"游戏推荐","slug":"游戏推荐","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E6%8E%A8%E8%8D%90/"},{"name":"独立游戏","slug":"独立游戏","permalink":"https://silenwang.github.io/tags/%E7%8B%AC%E7%AB%8B%E6%B8%B8%E6%88%8F/"}]},{"title":"哔哩哔哩 - ( ゜- ゜)つロ 乾杯~","slug":"小电视鼠标垫","date":"2016-02-21T16:28:08.000Z","updated":"2026-02-10T14:03:13.679Z","comments":true,"path":"2016/02/21/小电视鼠标垫/","permalink":"https://silenwang.github.io/2016/02/21/%E5%B0%8F%E7%94%B5%E8%A7%86%E9%BC%A0%E6%A0%87%E5%9E%AB/","excerpt":"","text":"啊, 昨天鼠标垫到了耶…..这是本人第一次买周边….. 弄了好大一个箱子过来, 我还幻想发错货多给了个小电视什么的……. 当然现实总是残酷的…….毕竟我也就买了一个鼠标垫嘛&#x3D; &#x3D;|||| 不过见到实物后还是不由得感叹, 果然很大大大大大大~~~~ 摆在桌上的效果还是不错的~可以看着2233还有小电视卖一年的萌了2333333 我很开心的把照片分享给了基友, 然而他的回答&#x3D; &#x3D;||||……… 好吧….我祝你和你女神元宵节愉快&#x3D; &#x3D;|||||","categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"}],"tags":[{"name":"哔哩哔哩","slug":"哔哩哔哩","permalink":"https://silenwang.github.io/tags/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9/"},{"name":"小电视","slug":"小电视","permalink":"https://silenwang.github.io/tags/%E5%B0%8F%E7%94%B5%E8%A7%86/"},{"name":"鼠标垫","slug":"鼠标垫","permalink":"https://silenwang.github.io/tags/%E9%BC%A0%E6%A0%87%E5%9E%AB/"},{"name":"周边","slug":"周边","permalink":"https://silenwang.github.io/tags/%E5%91%A8%E8%BE%B9/"},{"name":"开箱","slug":"开箱","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E7%AE%B1/"},{"name":"Daily","slug":"Daily","permalink":"https://silenwang.github.io/tags/Daily/"},{"name":"Bilibili","slug":"Bilibili","permalink":"https://silenwang.github.io/tags/Bilibili/"},{"name":"Mousepad","slug":"Mousepad","permalink":"https://silenwang.github.io/tags/Mousepad/"}]},{"title":"晶体管","slug":"晶体管","date":"2016-01-01T19:44:34.000Z","updated":"2026-02-10T14:03:13.680Z","comments":true,"path":"2016/01/01/晶体管/","permalink":"https://silenwang.github.io/2016/01/01/%E6%99%B6%E4%BD%93%E7%AE%A1/","excerpt":"这是一个非常有特色的游戏, 画面非常出彩, 披着ARPG的皮的策略游戏. 故事叙事上有点魂的意思(如果不自己探寻隐藏信息的话完全不知道讲了个XX). 印象中这是我在Steam上购买的第一个游戏(当时刚开放国区, 到库还花了小几天), 也是因为这个游戏我开始关注游戏的制作组, 后来还补了堡垒和后来的柴堆(柴堆至今没打开过…)","text":"这是一个非常有特色的游戏, 画面非常出彩, 披着ARPG的皮的策略游戏. 故事叙事上有点魂的意思(如果不自己探寻隐藏信息的话完全不知道讲了个XX). 印象中这是我在Steam上购买的第一个游戏(当时刚开放国区, 到库还花了小几天), 也是因为这个游戏我开始关注游戏的制作组, 后来还补了堡垒和后来的柴堆(柴堆至今没打开过…)","categories":[{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"}],"tags":[{"name":"独立游戏","slug":"独立游戏","permalink":"https://silenwang.github.io/tags/%E7%8B%AC%E7%AB%8B%E6%B8%B8%E6%88%8F/"},{"name":"策略游戏","slug":"策略游戏","permalink":"https://silenwang.github.io/tags/%E7%AD%96%E7%95%A5%E6%B8%B8%E6%88%8F/"},{"name":"晶体管","slug":"晶体管","permalink":"https://silenwang.github.io/tags/%E6%99%B6%E4%BD%93%E7%AE%A1/"},{"name":"ARPG","slug":"ARPG","permalink":"https://silenwang.github.io/tags/ARPG/"},{"name":"Transistor","slug":"Transistor","permalink":"https://silenwang.github.io/tags/Transistor/"},{"name":"Supergiant-Games","slug":"Supergiant-Games","permalink":"https://silenwang.github.io/tags/Supergiant-Games/"}]}],"categories":[{"name":"Others","slug":"Others","permalink":"https://silenwang.github.io/categories/Others/"},{"name":"Coding","slug":"Coding","permalink":"https://silenwang.github.io/categories/Coding/"},{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/categories/Bioinformatics/"},{"name":"Other","slug":"Other","permalink":"https://silenwang.github.io/categories/Other/"},{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/categories/Gaming/"},{"name":"Script","slug":"Script","permalink":"https://silenwang.github.io/categories/Script/"},{"name":"Statistic","slug":"Statistic","permalink":"https://silenwang.github.io/categories/Statistic/"}],"tags":[{"name":"conda","slug":"conda","permalink":"https://silenwang.github.io/tags/conda/"},{"name":"pixi","slug":"pixi","permalink":"https://silenwang.github.io/tags/pixi/"},{"name":"github action","slug":"github-action","permalink":"https://silenwang.github.io/tags/github-action/"},{"name":"recipe","slug":"recipe","permalink":"https://silenwang.github.io/tags/recipe/"},{"name":"rattler","slug":"rattler","permalink":"https://silenwang.github.io/tags/rattler/"},{"name":"rattler-build","slug":"rattler-build","permalink":"https://silenwang.github.io/tags/rattler-build/"},{"name":"conda-build","slug":"conda-build","permalink":"https://silenwang.github.io/tags/conda-build/"},{"name":"Go","slug":"Go","permalink":"https://silenwang.github.io/tags/Go/"},{"name":"devssh","slug":"devssh","permalink":"https://silenwang.github.io/tags/devssh/"},{"name":"Git","slug":"Git","permalink":"https://silenwang.github.io/tags/Git/"},{"name":"版本控制","slug":"版本控制","permalink":"https://silenwang.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"cherry-pick","slug":"cherry-pick","permalink":"https://silenwang.github.io/tags/cherry-pick/"},{"name":"开源软件","slug":"开源软件","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6/"},{"name":"Devpod","slug":"Devpod","permalink":"https://silenwang.github.io/tags/Devpod/"},{"name":"开源项目维护","slug":"开源项目维护","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E7%BB%B4%E6%8A%A4/"},{"name":"社区分支","slug":"社区分支","permalink":"https://silenwang.github.io/tags/%E7%A4%BE%E5%8C%BA%E5%88%86%E6%94%AF/"},{"name":"项目可持续性","slug":"项目可持续性","permalink":"https://silenwang.github.io/tags/%E9%A1%B9%E7%9B%AE%E5%8F%AF%E6%8C%81%E7%BB%AD%E6%80%A7/"},{"name":"Docker Compose","slug":"Docker-Compose","permalink":"https://silenwang.github.io/tags/Docker-Compose/"},{"name":"aider","slug":"aider","permalink":"https://silenwang.github.io/tags/aider/"},{"name":"远程开发","slug":"远程开发","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91/"},{"name":"opencode","slug":"opencode","permalink":"https://silenwang.github.io/tags/opencode/"},{"name":"AI编程","slug":"AI编程","permalink":"https://silenwang.github.io/tags/AI%E7%BC%96%E7%A8%8B/"},{"name":"代码生成","slug":"代码生成","permalink":"https://silenwang.github.io/tags/%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/"},{"name":"devpod","slug":"devpod","permalink":"https://silenwang.github.io/tags/devpod/"},{"name":"openhands","slug":"openhands","permalink":"https://silenwang.github.io/tags/openhands/"},{"name":"DeepSeek","slug":"DeepSeek","permalink":"https://silenwang.github.io/tags/DeepSeek/"},{"name":"自动化工具","slug":"自动化工具","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E5%B7%A5%E5%85%B7/"},{"name":"conda-forge","slug":"conda-forge","permalink":"https://silenwang.github.io/tags/conda-forge/"},{"name":"包管理","slug":"包管理","permalink":"https://silenwang.github.io/tags/%E5%8C%85%E7%AE%A1%E7%90%86/"},{"name":"Bioconda","slug":"Bioconda","permalink":"https://silenwang.github.io/tags/Bioconda/"},{"name":"singler-py","slug":"singler-py","permalink":"https://silenwang.github.io/tags/singler-py/"},{"name":"biocutils","slug":"biocutils","permalink":"https://silenwang.github.io/tags/biocutils/"},{"name":"biocframe","slug":"biocframe","permalink":"https://silenwang.github.io/tags/biocframe/"},{"name":"summarizedexperiment","slug":"summarizedexperiment","permalink":"https://silenwang.github.io/tags/summarizedexperiment/"},{"name":"singlecellexperiment","slug":"singlecellexperiment","permalink":"https://silenwang.github.io/tags/singlecellexperiment/"},{"name":"依赖解析","slug":"依赖解析","permalink":"https://silenwang.github.io/tags/%E4%BE%9D%E8%B5%96%E8%A7%A3%E6%9E%90/"},{"name":"grayskull","slug":"grayskull","permalink":"https://silenwang.github.io/tags/grayskull/"},{"name":"tree_sitter_languages","slug":"tree-sitter-languages","permalink":"https://silenwang.github.io/tags/tree-sitter-languages/"},{"name":"PR","slug":"PR","permalink":"https://silenwang.github.io/tags/PR/"},{"name":"feedstock","slug":"feedstock","permalink":"https://silenwang.github.io/tags/feedstock/"},{"name":"数据可视化","slug":"数据可视化","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"Python","slug":"Python","permalink":"https://silenwang.github.io/tags/Python/"},{"name":"文献管理","slug":"文献管理","permalink":"https://silenwang.github.io/tags/%E6%96%87%E7%8C%AE%E7%AE%A1%E7%90%86/"},{"name":"词云","slug":"词云","permalink":"https://silenwang.github.io/tags/%E8%AF%8D%E4%BA%91/"},{"name":"自动化","slug":"自动化","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"AI","slug":"AI","permalink":"https://silenwang.github.io/tags/AI/"},{"name":"Pixi","slug":"Pixi","permalink":"https://silenwang.github.io/tags/Pixi/"},{"name":"容器","slug":"容器","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"开发环境","slug":"开发环境","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"name":"RenderCV","slug":"RenderCV","permalink":"https://silenwang.github.io/tags/RenderCV/"},{"name":"Aider","slug":"Aider","permalink":"https://silenwang.github.io/tags/Aider/"},{"name":"qwen-image-edit","slug":"qwen-image-edit","permalink":"https://silenwang.github.io/tags/qwen-image-edit/"},{"name":"wan2.5-i2i-preview","slug":"wan2-5-i2i-preview","permalink":"https://silenwang.github.io/tags/wan2-5-i2i-preview/"},{"name":"图像编辑","slug":"图像编辑","permalink":"https://silenwang.github.io/tags/%E5%9B%BE%E5%83%8F%E7%BC%96%E8%BE%91/"},{"name":"git","slug":"git","permalink":"https://silenwang.github.io/tags/git/"},{"name":"docker","slug":"docker","permalink":"https://silenwang.github.io/tags/docker/"},{"name":"devcontainer","slug":"devcontainer","permalink":"https://silenwang.github.io/tags/devcontainer/"},{"name":"跨平台","slug":"跨平台","permalink":"https://silenwang.github.io/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/"},{"name":"生物信息学","slug":"生物信息学","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6/"},{"name":"依赖管理","slug":"依赖管理","permalink":"https://silenwang.github.io/tags/%E4%BE%9D%E8%B5%96%E7%AE%A1%E7%90%86/"},{"name":"数据科学","slug":"数据科学","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"},{"name":"taipy","slug":"taipy","permalink":"https://silenwang.github.io/tags/taipy/"},{"name":"callback","slug":"callback","permalink":"https://silenwang.github.io/tags/callback/"},{"name":"html","slug":"html","permalink":"https://silenwang.github.io/tags/html/"},{"name":"CD","slug":"CD","permalink":"https://silenwang.github.io/tags/CD/"},{"name":"自动部署","slug":"自动部署","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2/"},{"name":"R","slug":"R","permalink":"https://silenwang.github.io/tags/R/"},{"name":"ggplot2","slug":"ggplot2","permalink":"https://silenwang.github.io/tags/ggplot2/"},{"name":"格栅化","slug":"格栅化","permalink":"https://silenwang.github.io/tags/%E6%A0%BC%E6%A0%85%E5%8C%96/"},{"name":"rasterization","slug":"rasterization","permalink":"https://silenwang.github.io/tags/rasterization/"},{"name":"subtree","slug":"subtree","permalink":"https://silenwang.github.io/tags/subtree/"},{"name":"submodule","slug":"submodule","permalink":"https://silenwang.github.io/tags/submodule/"},{"name":"scattermap","slug":"scattermap","permalink":"https://silenwang.github.io/tags/scattermap/"},{"name":"golang","slug":"golang","permalink":"https://silenwang.github.io/tags/golang/"},{"name":"Debug","slug":"Debug","permalink":"https://silenwang.github.io/tags/Debug/"},{"name":"maftools","slug":"maftools","permalink":"https://silenwang.github.io/tags/maftools/"},{"name":"生物信息","slug":"生物信息","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF/"},{"name":"单细胞","slug":"单细胞","permalink":"https://silenwang.github.io/tags/%E5%8D%95%E7%BB%86%E8%83%9E/"},{"name":"软件维护","slug":"软件维护","permalink":"https://silenwang.github.io/tags/%E8%BD%AF%E4%BB%B6%E7%BB%B4%E6%8A%A4/"},{"name":"Linux","slug":"Linux","permalink":"https://silenwang.github.io/tags/Linux/"},{"name":"RISC-V","slug":"RISC-V","permalink":"https://silenwang.github.io/tags/RISC-V/"},{"name":"SAS","slug":"SAS","permalink":"https://silenwang.github.io/tags/SAS/"},{"name":"hexo","slug":"hexo","permalink":"https://silenwang.github.io/tags/hexo/"},{"name":"Volantis","slug":"Volantis","permalink":"https://silenwang.github.io/tags/Volantis/"},{"name":"博客","slug":"博客","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"国际化","slug":"国际化","permalink":"https://silenwang.github.io/tags/%E5%9B%BD%E9%99%85%E5%8C%96/"},{"name":"FydeOS","slug":"FydeOS","permalink":"https://silenwang.github.io/tags/FydeOS/"},{"name":"podman","slug":"podman","permalink":"https://silenwang.github.io/tags/podman/"},{"name":"Bioconductor","slug":"Bioconductor","permalink":"https://silenwang.github.io/tags/Bioconductor/"},{"name":"scanpy","slug":"scanpy","permalink":"https://silenwang.github.io/tags/scanpy/"},{"name":"loom","slug":"loom","permalink":"https://silenwang.github.io/tags/loom/"},{"name":"adata","slug":"adata","permalink":"https://silenwang.github.io/tags/adata/"},{"name":"单细胞分析","slug":"单细胞分析","permalink":"https://silenwang.github.io/tags/%E5%8D%95%E7%BB%86%E8%83%9E%E5%88%86%E6%9E%90/"},{"name":"差异丰度分析","slug":"差异丰度分析","permalink":"https://silenwang.github.io/tags/%E5%B7%AE%E5%BC%82%E4%B8%B0%E5%BA%A6%E5%88%86%E6%9E%90/"},{"name":"Milo","slug":"Milo","permalink":"https://silenwang.github.io/tags/Milo/"},{"name":"Docker","slug":"Docker","permalink":"https://silenwang.github.io/tags/Docker/"},{"name":"DevPod","slug":"DevPod","permalink":"https://silenwang.github.io/tags/DevPod/"},{"name":"DevOps","slug":"DevOps","permalink":"https://silenwang.github.io/tags/DevOps/"},{"name":"Podman","slug":"Podman","permalink":"https://silenwang.github.io/tags/Podman/"},{"name":"调试","slug":"调试","permalink":"https://silenwang.github.io/tags/%E8%B0%83%E8%AF%95/"},{"name":"Typescript","slug":"Typescript","permalink":"https://silenwang.github.io/tags/Typescript/"},{"name":"Javascript","slug":"Javascript","permalink":"https://silenwang.github.io/tags/Javascript/"},{"name":"前端开发","slug":"前端开发","permalink":"https://silenwang.github.io/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"监控","slug":"监控","permalink":"https://silenwang.github.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"Uptime-Kuma","slug":"Uptime-Kuma","permalink":"https://silenwang.github.io/tags/Uptime-Kuma/"},{"name":"网站维护","slug":"网站维护","permalink":"https://silenwang.github.io/tags/%E7%BD%91%E7%AB%99%E7%BB%B4%E6%8A%A4/"},{"name":"服务监控","slug":"服务监控","permalink":"https://silenwang.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%9B%91%E6%8E%A7/"},{"name":"circlize","slug":"circlize","permalink":"https://silenwang.github.io/tags/circlize/"},{"name":"基因组","slug":"基因组","permalink":"https://silenwang.github.io/tags/%E5%9F%BA%E5%9B%A0%E7%BB%84/"},{"name":"突变","slug":"突变","permalink":"https://silenwang.github.io/tags/%E7%AA%81%E5%8F%98/"},{"name":"CNV","slug":"CNV","permalink":"https://silenwang.github.io/tags/CNV/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://silenwang.github.io/tags/ffmpeg/"},{"name":"Taipy","slug":"Taipy","permalink":"https://silenwang.github.io/tags/Taipy/"},{"name":"chromeos","slug":"chromeos","permalink":"https://silenwang.github.io/tags/chromeos/"},{"name":"terminal","slug":"terminal","permalink":"https://silenwang.github.io/tags/terminal/"},{"name":"libapp","slug":"libapp","permalink":"https://silenwang.github.io/tags/libapp/"},{"name":"终端","slug":"终端","permalink":"https://silenwang.github.io/tags/%E7%BB%88%E7%AB%AF/"},{"name":"Steam","slug":"Steam","permalink":"https://silenwang.github.io/tags/Steam/"},{"name":"SteamOS","slug":"SteamOS","permalink":"https://silenwang.github.io/tags/SteamOS/"},{"name":"Bazzite","slug":"Bazzite","permalink":"https://silenwang.github.io/tags/Bazzite/"},{"name":"Gaming","slug":"Gaming","permalink":"https://silenwang.github.io/tags/Gaming/"},{"name":"职场","slug":"职场","permalink":"https://silenwang.github.io/tags/%E8%81%8C%E5%9C%BA/"},{"name":"离职","slug":"离职","permalink":"https://silenwang.github.io/tags/%E7%A6%BB%E8%81%8C/"},{"name":"职业生涯","slug":"职业生涯","permalink":"https://silenwang.github.io/tags/%E8%81%8C%E4%B8%9A%E7%94%9F%E6%B6%AF/"},{"name":"杭州","slug":"杭州","permalink":"https://silenwang.github.io/tags/%E6%9D%AD%E5%B7%9E/"},{"name":"career","slug":"career","permalink":"https://silenwang.github.io/tags/career/"},{"name":"job-hopping","slug":"job-hopping","permalink":"https://silenwang.github.io/tags/job-hopping/"},{"name":"bioinformatics","slug":"bioinformatics","permalink":"https://silenwang.github.io/tags/bioinformatics/"},{"name":"AI辅助开发","slug":"AI辅助开发","permalink":"https://silenwang.github.io/tags/AI%E8%BE%85%E5%8A%A9%E5%BC%80%E5%8F%91/"},{"name":"技术尝试","slug":"技术尝试","permalink":"https://silenwang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%B0%9D%E8%AF%95/"},{"name":"Theia","slug":"Theia","permalink":"https://silenwang.github.io/tags/Theia/"},{"name":"内核","slug":"内核","permalink":"https://silenwang.github.io/tags/%E5%86%85%E6%A0%B8/"},{"name":"openfyde","slug":"openfyde","permalink":"https://silenwang.github.io/tags/openfyde/"},{"name":"fydeos","slug":"fydeos","permalink":"https://silenwang.github.io/tags/fydeos/"},{"name":"硬件兼容","slug":"硬件兼容","permalink":"https://silenwang.github.io/tags/%E7%A1%AC%E4%BB%B6%E5%85%BC%E5%AE%B9/"},{"name":"编译","slug":"编译","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E8%AF%91/"},{"name":"镜像生成","slug":"镜像生成","permalink":"https://silenwang.github.io/tags/%E9%95%9C%E5%83%8F%E7%94%9F%E6%88%90/"},{"name":"Rockchip","slug":"Rockchip","permalink":"https://silenwang.github.io/tags/Rockchip/"},{"name":"ChromeOS","slug":"ChromeOS","permalink":"https://silenwang.github.io/tags/ChromeOS/"},{"name":"ARM","slug":"ARM","permalink":"https://silenwang.github.io/tags/ARM/"},{"name":"GitHub Actions","slug":"GitHub-Actions","permalink":"https://silenwang.github.io/tags/GitHub-Actions/"},{"name":"Codespaces","slug":"Codespaces","permalink":"https://silenwang.github.io/tags/Codespaces/"},{"name":"theia-ide","slug":"theia-ide","permalink":"https://silenwang.github.io/tags/theia-ide/"},{"name":"系统编译","slug":"系统编译","permalink":"https://silenwang.github.io/tags/%E7%B3%BB%E7%BB%9F%E7%BC%96%E8%AF%91/"},{"name":"Linux系统","slug":"Linux系统","permalink":"https://silenwang.github.io/tags/Linux%E7%B3%BB%E7%BB%9F/"},{"name":"补丁修复","slug":"补丁修复","permalink":"https://silenwang.github.io/tags/%E8%A1%A5%E4%B8%81%E4%BF%AE%E5%A4%8D/"},{"name":"chroot环境","slug":"chroot环境","permalink":"https://silenwang.github.io/tags/chroot%E7%8E%AF%E5%A2%83/"},{"name":"自动化测试","slug":"自动化测试","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/"},{"name":"浏览器测试","slug":"浏览器测试","permalink":"https://silenwang.github.io/tags/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%B5%8B%E8%AF%95/"},{"name":"playwright","slug":"playwright","permalink":"https://silenwang.github.io/tags/playwright/"},{"name":"pytest","slug":"pytest","permalink":"https://silenwang.github.io/tags/pytest/"},{"name":"python","slug":"python","permalink":"https://silenwang.github.io/tags/python/"},{"name":"测试","slug":"测试","permalink":"https://silenwang.github.io/tags/%E6%B5%8B%E8%AF%95/"},{"name":"API测试","slug":"API测试","permalink":"https://silenwang.github.io/tags/API%E6%B5%8B%E8%AF%95/"},{"name":"Linux安全","slug":"Linux安全","permalink":"https://silenwang.github.io/tags/Linux%E5%AE%89%E5%85%A8/"},{"name":"服务器安全","slug":"服务器安全","permalink":"https://silenwang.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%89%E5%85%A8/"},{"name":"恶意程序","slug":"恶意程序","permalink":"https://silenwang.github.io/tags/%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F/"},{"name":"挖矿病毒","slug":"挖矿病毒","permalink":"https://silenwang.github.io/tags/%E6%8C%96%E7%9F%BF%E7%97%85%E6%AF%92/"},{"name":"系统工具","slug":"系统工具","permalink":"https://silenwang.github.io/tags/%E7%B3%BB%E7%BB%9F%E5%B7%A5%E5%85%B7/"},{"name":"linux","slug":"linux","permalink":"https://silenwang.github.io/tags/linux/"},{"name":"security","slug":"security","permalink":"https://silenwang.github.io/tags/security/"},{"name":"malware","slug":"malware","permalink":"https://silenwang.github.io/tags/malware/"},{"name":"mining-virus","slug":"mining-virus","permalink":"https://silenwang.github.io/tags/mining-virus/"},{"name":"system-tools","slug":"system-tools","permalink":"https://silenwang.github.io/tags/system-tools/"},{"name":"automation","slug":"automation","permalink":"https://silenwang.github.io/tags/automation/"},{"name":"命令行工具","slug":"命令行工具","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/"},{"name":"批量处理","slug":"批量处理","permalink":"https://silenwang.github.io/tags/%E6%89%B9%E9%87%8F%E5%A4%84%E7%90%86/"},{"name":"AI-assisted programming","slug":"AI-assisted-programming","permalink":"https://silenwang.github.io/tags/AI-assisted-programming/"},{"name":"command-line tool","slug":"command-line-tool","permalink":"https://silenwang.github.io/tags/command-line-tool/"},{"name":"workflow","slug":"workflow","permalink":"https://silenwang.github.io/tags/workflow/"},{"name":"持续集成","slug":"持续集成","permalink":"https://silenwang.github.io/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/"},{"name":"工作流","slug":"工作流","permalink":"https://silenwang.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81/"},{"name":"github actions","slug":"github-actions","permalink":"https://silenwang.github.io/tags/github-actions/"},{"name":"ci","slug":"ci","permalink":"https://silenwang.github.io/tags/ci/"},{"name":"cd","slug":"cd","permalink":"https://silenwang.github.io/tags/cd/"},{"name":"R语言","slug":"R语言","permalink":"https://silenwang.github.io/tags/R%E8%AF%AD%E8%A8%80/"},{"name":"面向对象","slug":"面向对象","permalink":"https://silenwang.github.io/tags/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/"},{"name":"rlang","slug":"rlang","permalink":"https://silenwang.github.io/tags/rlang/"},{"name":"R6","slug":"R6","permalink":"https://silenwang.github.io/tags/R6/"},{"name":"S3","slug":"S3","permalink":"https://silenwang.github.io/tags/S3/"},{"name":"S4","slug":"S4","permalink":"https://silenwang.github.io/tags/S4/"},{"name":"object-oriented","slug":"object-oriented","permalink":"https://silenwang.github.io/tags/object-oriented/"},{"name":"模块化开发","slug":"模块化开发","permalink":"https://silenwang.github.io/tags/%E6%A8%A1%E5%9D%97%E5%8C%96%E5%BC%80%E5%8F%91/"},{"name":"box包","slug":"box包","permalink":"https://silenwang.github.io/tags/box%E5%8C%85/"},{"name":"代码管理","slug":"代码管理","permalink":"https://silenwang.github.io/tags/%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86/"},{"name":"box","slug":"box","permalink":"https://silenwang.github.io/tags/box/"},{"name":"Fydetab duo","slug":"Fydetab-duo","permalink":"https://silenwang.github.io/tags/Fydetab-duo/"},{"name":"Chromium OS","slug":"Chromium-OS","permalink":"https://silenwang.github.io/tags/Chromium-OS/"},{"name":"FydeTab Duo","slug":"FydeTab-Duo","permalink":"https://silenwang.github.io/tags/FydeTab-Duo/"},{"name":"Linux子系统","slug":"Linux子系统","permalink":"https://silenwang.github.io/tags/Linux%E5%AD%90%E7%B3%BB%E7%BB%9F/"},{"name":"Chromebook","slug":"Chromebook","permalink":"https://silenwang.github.io/tags/Chromebook/"},{"name":"arm","slug":"arm","permalink":"https://silenwang.github.io/tags/arm/"},{"name":"Fydetab Duo","slug":"Fydetab-Duo","permalink":"https://silenwang.github.io/tags/Fydetab-Duo/"},{"name":"Linux环境配置","slug":"Linux环境配置","permalink":"https://silenwang.github.io/tags/Linux%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"jupyter","slug":"jupyter","permalink":"https://silenwang.github.io/tags/jupyter/"},{"name":"拟时间分析","slug":"拟时间分析","permalink":"https://silenwang.github.io/tags/%E6%8B%9F%E6%97%B6%E9%97%B4%E5%88%86%E6%9E%90/"},{"name":"monocle3","slug":"monocle3","permalink":"https://silenwang.github.io/tags/monocle3/"},{"name":"xeus-r","slug":"xeus-r","permalink":"https://silenwang.github.io/tags/xeus-r/"},{"name":"环境配置","slug":"环境配置","permalink":"https://silenwang.github.io/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"},{"name":"mamba","slug":"mamba","permalink":"https://silenwang.github.io/tags/mamba/"},{"name":"技术博客","slug":"技术博客","permalink":"https://silenwang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/"},{"name":"写作困境","slug":"写作困境","permalink":"https://silenwang.github.io/tags/%E5%86%99%E4%BD%9C%E5%9B%B0%E5%A2%83/"},{"name":"时间管理","slug":"时间管理","permalink":"https://silenwang.github.io/tags/%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/"},{"name":"焦虑","slug":"焦虑","permalink":"https://silenwang.github.io/tags/%E7%84%A6%E8%99%91/"},{"name":"持续记录","slug":"持续记录","permalink":"https://silenwang.github.io/tags/%E6%8C%81%E7%BB%AD%E8%AE%B0%E5%BD%95/"},{"name":"tech-blog","slug":"tech-blog","permalink":"https://silenwang.github.io/tags/tech-blog/"},{"name":"writing","slug":"writing","permalink":"https://silenwang.github.io/tags/writing/"},{"name":"time-management","slug":"time-management","permalink":"https://silenwang.github.io/tags/time-management/"},{"name":"chromebook","slug":"chromebook","permalink":"https://silenwang.github.io/tags/chromebook/"},{"name":"二合一设备","slug":"二合一设备","permalink":"https://silenwang.github.io/tags/%E4%BA%8C%E5%90%88%E4%B8%80%E8%AE%BE%E5%A4%87/"},{"name":"安卓应用兼容性","slug":"安卓应用兼容性","permalink":"https://silenwang.github.io/tags/%E5%AE%89%E5%8D%93%E5%BA%94%E7%94%A8%E5%85%BC%E5%AE%B9%E6%80%A7/"},{"name":"容器技术","slug":"容器技术","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"},{"name":"singularity","slug":"singularity","permalink":"https://silenwang.github.io/tags/singularity/"},{"name":"ChatGLM2","slug":"ChatGLM2","permalink":"https://silenwang.github.io/tags/ChatGLM2/"},{"name":"chatglm.cpp","slug":"chatglm-cpp","permalink":"https://silenwang.github.io/tags/chatglm-cpp/"},{"name":"容器构建","slug":"容器构建","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8%E6%9E%84%E5%BB%BA/"},{"name":"HPC","slug":"HPC","permalink":"https://silenwang.github.io/tags/HPC/"},{"name":"Rstudio部署","slug":"Rstudio部署","permalink":"https://silenwang.github.io/tags/Rstudio%E9%83%A8%E7%BD%B2/"},{"name":"conda环境","slug":"conda环境","permalink":"https://silenwang.github.io/tags/conda%E7%8E%AF%E5%A2%83/"},{"name":"rstudio-server","slug":"rstudio-server","permalink":"https://silenwang.github.io/tags/rstudio-server/"},{"name":"Hexo","slug":"Hexo","permalink":"https://silenwang.github.io/tags/Hexo/"},{"name":"云端开发","slug":"云端开发","permalink":"https://silenwang.github.io/tags/%E4%BA%91%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"博客写作","slug":"博客写作","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E5%86%99%E4%BD%9C/"},{"name":"Github","slug":"Github","permalink":"https://silenwang.github.io/tags/Github/"},{"name":"Codespace","slug":"Codespace","permalink":"https://silenwang.github.io/tags/Codespace/"},{"name":"ChatGPT","slug":"ChatGPT","permalink":"https://silenwang.github.io/tags/ChatGPT/"},{"name":"API开发","slug":"API开发","permalink":"https://silenwang.github.io/tags/API%E5%BC%80%E5%8F%91/"},{"name":"文献解析","slug":"文献解析","permalink":"https://silenwang.github.io/tags/%E6%96%87%E7%8C%AE%E8%A7%A3%E6%9E%90/"},{"name":"独立开发","slug":"独立开发","permalink":"https://silenwang.github.io/tags/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91/"},{"name":"Gradio","slug":"Gradio","permalink":"https://silenwang.github.io/tags/Gradio/"},{"name":"HuggingFace","slug":"HuggingFace","permalink":"https://silenwang.github.io/tags/HuggingFace/"},{"name":"Flask","slug":"Flask","permalink":"https://silenwang.github.io/tags/Flask/"},{"name":"chatGPT","slug":"chatGPT","permalink":"https://silenwang.github.io/tags/chatGPT/"},{"name":"编程辅助","slug":"编程辅助","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E7%A8%8B%E8%BE%85%E5%8A%A9/"},{"name":"静态网站","slug":"静态网站","permalink":"https://silenwang.github.io/tags/%E9%9D%99%E6%80%81%E7%BD%91%E7%AB%99/"},{"name":"钉钉","slug":"钉钉","permalink":"https://silenwang.github.io/tags/%E9%92%89%E9%92%89/"},{"name":"中文输入","slug":"中文输入","permalink":"https://silenwang.github.io/tags/%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5/"},{"name":"界面缩放","slug":"界面缩放","permalink":"https://silenwang.github.io/tags/%E7%95%8C%E9%9D%A2%E7%BC%A9%E6%94%BE/"},{"name":"会议功能","slug":"会议功能","permalink":"https://silenwang.github.io/tags/%E4%BC%9A%E8%AE%AE%E5%8A%9F%E8%83%BD/"},{"name":"Daily","slug":"Daily","permalink":"https://silenwang.github.io/tags/Daily/"},{"name":"生活","slug":"生活","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"新年","slug":"新年","permalink":"https://silenwang.github.io/tags/%E6%96%B0%E5%B9%B4/"},{"name":"期望","slug":"期望","permalink":"https://silenwang.github.io/tags/%E6%9C%9F%E6%9C%9B/"},{"name":"沮丧","slug":"沮丧","permalink":"https://silenwang.github.io/tags/%E6%B2%AE%E4%B8%A7/"},{"name":"New Year","slug":"New-Year","permalink":"https://silenwang.github.io/tags/New-Year/"},{"name":"Expectation","slug":"Expectation","permalink":"https://silenwang.github.io/tags/Expectation/"},{"name":"Frustration","slug":"Frustration","permalink":"https://silenwang.github.io/tags/Frustration/"},{"name":"个人主页","slug":"个人主页","permalink":"https://silenwang.github.io/tags/%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/"},{"name":"美化","slug":"美化","permalink":"https://silenwang.github.io/tags/%E7%BE%8E%E5%8C%96/"},{"name":"Github Stats","slug":"Github-Stats","permalink":"https://silenwang.github.io/tags/Github-Stats/"},{"name":"Shields.io","slug":"Shields-io","permalink":"https://silenwang.github.io/tags/Shields-io/"},{"name":"README","slug":"README","permalink":"https://silenwang.github.io/tags/README/"},{"name":"博客升级","slug":"博客升级","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E5%8D%87%E7%BA%A7/"},{"name":"Volantis主题","slug":"Volantis主题","permalink":"https://silenwang.github.io/tags/Volantis%E4%B8%BB%E9%A2%98/"},{"name":"插件配置","slug":"插件配置","permalink":"https://silenwang.github.io/tags/%E6%8F%92%E4%BB%B6%E9%85%8D%E7%BD%AE/"},{"name":"utterances","slug":"utterances","permalink":"https://silenwang.github.io/tags/utterances/"},{"name":"B站卡片","slug":"B站卡片","permalink":"https://silenwang.github.io/tags/B%E7%AB%99%E5%8D%A1%E7%89%87/"},{"name":"Github卡片","slug":"Github卡片","permalink":"https://silenwang.github.io/tags/Github%E5%8D%A1%E7%89%87/"},{"name":"游戏","slug":"游戏","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"3DS","slug":"3DS","permalink":"https://silenwang.github.io/tags/3DS/"},{"name":"主机游戏","slug":"主机游戏","permalink":"https://silenwang.github.io/tags/%E4%B8%BB%E6%9C%BA%E6%B8%B8%E6%88%8F/"},{"name":"游戏回顾","slug":"游戏回顾","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E5%9B%9E%E9%A1%BE/"},{"name":"游戏平台","slug":"游戏平台","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E5%B9%B3%E5%8F%B0/"},{"name":"PSV","slug":"PSV","permalink":"https://silenwang.github.io/tags/PSV/"},{"name":"NS","slug":"NS","permalink":"https://silenwang.github.io/tags/NS/"},{"name":"PC","slug":"PC","permalink":"https://silenwang.github.io/tags/PC/"},{"name":"Quest2","slug":"Quest2","permalink":"https://silenwang.github.io/tags/Quest2/"},{"name":"游戏评测","slug":"游戏评测","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E8%AF%84%E6%B5%8B/"},{"name":"女神异闻录","slug":"女神异闻录","permalink":"https://silenwang.github.io/tags/%E5%A5%B3%E7%A5%9E%E5%BC%82%E9%97%BB%E5%BD%95/"},{"name":"P4G","slug":"P4G","permalink":"https://silenwang.github.io/tags/P4G/"},{"name":"P5R","slug":"P5R","permalink":"https://silenwang.github.io/tags/P5R/"},{"name":"JRPG","slug":"JRPG","permalink":"https://silenwang.github.io/tags/JRPG/"},{"name":"Persona","slug":"Persona","permalink":"https://silenwang.github.io/tags/Persona/"},{"name":"Jupyter","slug":"Jupyter","permalink":"https://silenwang.github.io/tags/Jupyter/"},{"name":"内核注册","slug":"内核注册","permalink":"https://silenwang.github.io/tags/%E5%86%85%E6%A0%B8%E6%B3%A8%E5%86%8C/"},{"name":"技术教程","slug":"技术教程","permalink":"https://silenwang.github.io/tags/%E6%8A%80%E6%9C%AF%E6%95%99%E7%A8%8B/"},{"name":"腾讯","slug":"腾讯","permalink":"https://silenwang.github.io/tags/%E8%85%BE%E8%AE%AF/"},{"name":"QQ","slug":"QQ","permalink":"https://silenwang.github.io/tags/QQ/"},{"name":"Electron","slug":"Electron","permalink":"https://silenwang.github.io/tags/Electron/"},{"name":"Tencent","slug":"Tencent","permalink":"https://silenwang.github.io/tags/Tencent/"},{"name":"数据处理","slug":"数据处理","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"},{"name":"数据清洗","slug":"数据清洗","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"},{"name":"Pandas","slug":"Pandas","permalink":"https://silenwang.github.io/tags/Pandas/"},{"name":"内网穿透","slug":"内网穿透","permalink":"https://silenwang.github.io/tags/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/"},{"name":"VPN","slug":"VPN","permalink":"https://silenwang.github.io/tags/VPN/"},{"name":"socks5代理","slug":"socks5代理","permalink":"https://silenwang.github.io/tags/socks5%E4%BB%A3%E7%90%86/"},{"name":"远程办公","slug":"远程办公","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E5%8A%9E%E5%85%AC/"},{"name":"流量代理","slug":"流量代理","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E9%87%8F%E4%BB%A3%E7%90%86/"},{"name":"nps","slug":"nps","permalink":"https://silenwang.github.io/tags/nps/"},{"name":"clash","slug":"clash","permalink":"https://silenwang.github.io/tags/clash/"},{"name":"socks5","slug":"socks5","permalink":"https://silenwang.github.io/tags/socks5/"},{"name":"生活感悟","slug":"生活感悟","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"},{"name":"年度总结","slug":"年度总结","permalink":"https://silenwang.github.io/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"},{"name":"负面情绪","slug":"负面情绪","permalink":"https://silenwang.github.io/tags/%E8%B4%9F%E9%9D%A2%E6%83%85%E7%BB%AA/"},{"name":"2023","slug":"2023","permalink":"https://silenwang.github.io/tags/2023/"},{"name":"life-reflection","slug":"life-reflection","permalink":"https://silenwang.github.io/tags/life-reflection/"},{"name":"year-summary","slug":"year-summary","permalink":"https://silenwang.github.io/tags/year-summary/"},{"name":"云办公","slug":"云办公","permalink":"https://silenwang.github.io/tags/%E4%BA%91%E5%8A%9E%E5%85%AC/"},{"name":"远程工作","slug":"远程工作","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E5%B7%A5%E4%BD%9C/"},{"name":"自部署服务","slug":"自部署服务","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1/"},{"name":"code-server","slug":"code-server","permalink":"https://silenwang.github.io/tags/code-server/"},{"name":"https","slug":"https","permalink":"https://silenwang.github.io/tags/https/"},{"name":"iptables","slug":"iptables","permalink":"https://silenwang.github.io/tags/iptables/"},{"name":"图数据库","slug":"图数据库","permalink":"https://silenwang.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"数据库设计","slug":"数据库设计","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/"},{"name":"关系型数据库","slug":"关系型数据库","permalink":"https://silenwang.github.io/tags/%E5%85%B3%E7%B3%BB%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Neo4j","slug":"Neo4j","permalink":"https://silenwang.github.io/tags/Neo4j/"},{"name":"Graph Database","slug":"Graph-Database","permalink":"https://silenwang.github.io/tags/Graph-Database/"},{"name":"Marp","slug":"Marp","permalink":"https://silenwang.github.io/tags/Marp/"},{"name":"VSCode","slug":"VSCode","permalink":"https://silenwang.github.io/tags/VSCode/"},{"name":"Markdown","slug":"Markdown","permalink":"https://silenwang.github.io/tags/Markdown/"},{"name":"演示文档","slug":"演示文档","permalink":"https://silenwang.github.io/tags/%E6%BC%94%E7%A4%BA%E6%96%87%E6%A1%A3/"},{"name":"论文","slug":"论文","permalink":"https://silenwang.github.io/tags/%E8%AE%BA%E6%96%87/"},{"name":"免疫学","slug":"免疫学","permalink":"https://silenwang.github.io/tags/%E5%85%8D%E7%96%AB%E5%AD%A6/"},{"name":"肿瘤研究","slug":"肿瘤研究","permalink":"https://silenwang.github.io/tags/%E8%82%BF%E7%98%A4%E7%A0%94%E7%A9%B6/"},{"name":"zotero","slug":"zotero","permalink":"https://silenwang.github.io/tags/zotero/"},{"name":"rispy","slug":"rispy","permalink":"https://silenwang.github.io/tags/rispy/"},{"name":"wordcloud","slug":"wordcloud","permalink":"https://silenwang.github.io/tags/wordcloud/"},{"name":"ggpubr","slug":"ggpubr","permalink":"https://silenwang.github.io/tags/ggpubr/"},{"name":"survminer","slug":"survminer","permalink":"https://silenwang.github.io/tags/survminer/"},{"name":"显著性检验","slug":"显著性检验","permalink":"https://silenwang.github.io/tags/%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E9%AA%8C/"},{"name":"生存分析","slug":"生存分析","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90/"},{"name":"交互式分析","slug":"交互式分析","permalink":"https://silenwang.github.io/tags/%E4%BA%A4%E4%BA%92%E5%BC%8F%E5%88%86%E6%9E%90/"},{"name":"Dash","slug":"Dash","permalink":"https://silenwang.github.io/tags/Dash/"},{"name":"Plotly","slug":"Plotly","permalink":"https://silenwang.github.io/tags/Plotly/"},{"name":"爬虫","slug":"爬虫","permalink":"https://silenwang.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"框架","slug":"框架","permalink":"https://silenwang.github.io/tags/%E6%A1%86%E6%9E%B6/"},{"name":"数据采集","slug":"数据采集","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"},{"name":"Scrapy","slug":"Scrapy","permalink":"https://silenwang.github.io/tags/Scrapy/"},{"name":"AUR","slug":"AUR","permalink":"https://silenwang.github.io/tags/AUR/"},{"name":"Arch Linux","slug":"Arch-Linux","permalink":"https://silenwang.github.io/tags/Arch-Linux/"},{"name":"办公软件","slug":"办公软件","permalink":"https://silenwang.github.io/tags/%E5%8A%9E%E5%85%AC%E8%BD%AF%E4%BB%B6/"},{"name":"流程图","slug":"流程图","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E7%A8%8B%E5%9B%BE/"},{"name":"图表工具","slug":"图表工具","permalink":"https://silenwang.github.io/tags/%E5%9B%BE%E8%A1%A8%E5%B7%A5%E5%85%B7/"},{"name":"graphviz","slug":"graphviz","permalink":"https://silenwang.github.io/tags/graphviz/"},{"name":"drawio","slug":"drawio","permalink":"https://silenwang.github.io/tags/drawio/"},{"name":"密特罗德","slug":"密特罗德","permalink":"https://silenwang.github.io/tags/%E5%AF%86%E7%89%B9%E7%BD%97%E5%BE%B7/"},{"name":"银河城","slug":"银河城","permalink":"https://silenwang.github.io/tags/%E9%93%B6%E6%B2%B3%E5%9F%8E/"},{"name":"恶魔城","slug":"恶魔城","permalink":"https://silenwang.github.io/tags/%E6%81%B6%E9%AD%94%E5%9F%8E/"},{"name":"Metroid","slug":"Metroid","permalink":"https://silenwang.github.io/tags/Metroid/"},{"name":"Samus","slug":"Samus","permalink":"https://silenwang.github.io/tags/Samus/"},{"name":"大逆转裁判","slug":"大逆转裁判","permalink":"https://silenwang.github.io/tags/%E5%A4%A7%E9%80%86%E8%BD%AC%E8%A3%81%E5%88%A4/"},{"name":"成步堂三部曲","slug":"成步堂三部曲","permalink":"https://silenwang.github.io/tags/%E6%88%90%E6%AD%A5%E5%A0%82%E4%B8%89%E9%83%A8%E6%9B%B2/"},{"name":"游戏评论","slug":"游戏评论","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E8%AF%84%E8%AE%BA/"},{"name":"医学伦理","slug":"医学伦理","permalink":"https://silenwang.github.io/tags/%E5%8C%BB%E5%AD%A6%E4%BC%A6%E7%90%86/"},{"name":"科研困境","slug":"科研困境","permalink":"https://silenwang.github.io/tags/%E7%A7%91%E7%A0%94%E5%9B%B0%E5%A2%83/"},{"name":"ssh","slug":"ssh","permalink":"https://silenwang.github.io/tags/ssh/"},{"name":"openssh","slug":"openssh","permalink":"https://silenwang.github.io/tags/openssh/"},{"name":"manjaro","slug":"manjaro","permalink":"https://silenwang.github.io/tags/manjaro/"},{"name":"rsa加密","slug":"rsa加密","permalink":"https://silenwang.github.io/tags/rsa%E5%8A%A0%E5%AF%86/"},{"name":"ssh配置","slug":"ssh配置","permalink":"https://silenwang.github.io/tags/ssh%E9%85%8D%E7%BD%AE/"},{"name":"密钥认证","slug":"密钥认证","permalink":"https://silenwang.github.io/tags/%E5%AF%86%E9%92%A5%E8%AE%A4%E8%AF%81/"},{"name":"snakemake","slug":"snakemake","permalink":"https://silenwang.github.io/tags/snakemake/"},{"name":"任务监控","slug":"任务监控","permalink":"https://silenwang.github.io/tags/%E4%BB%BB%E5%8A%A1%E7%9B%91%E6%8E%A7/"},{"name":"Web应用","slug":"Web应用","permalink":"https://silenwang.github.io/tags/Web%E5%BA%94%E7%94%A8/"},{"name":"flask","slug":"flask","permalink":"https://silenwang.github.io/tags/flask/"},{"name":"dash","slug":"dash","permalink":"https://silenwang.github.io/tags/dash/"},{"name":"mongoDB","slug":"mongoDB","permalink":"https://silenwang.github.io/tags/mongoDB/"},{"name":"flasgger","slug":"flasgger","permalink":"https://silenwang.github.io/tags/flasgger/"},{"name":"安卓","slug":"安卓","permalink":"https://silenwang.github.io/tags/%E5%AE%89%E5%8D%93/"},{"name":"android","slug":"android","permalink":"https://silenwang.github.io/tags/android/"},{"name":"手机","slug":"手机","permalink":"https://silenwang.github.io/tags/%E6%89%8B%E6%9C%BA/"},{"name":"刷机","slug":"刷机","permalink":"https://silenwang.github.io/tags/%E5%88%B7%E6%9C%BA/"},{"name":"魔趣","slug":"魔趣","permalink":"https://silenwang.github.io/tags/%E9%AD%94%E8%B6%A3/"},{"name":"坚果Pro","slug":"坚果Pro","permalink":"https://silenwang.github.io/tags/%E5%9D%9A%E6%9E%9CPro/"},{"name":"Mokee","slug":"Mokee","permalink":"https://silenwang.github.io/tags/Mokee/"},{"name":"custom ROM","slug":"custom-ROM","permalink":"https://silenwang.github.io/tags/custom-ROM/"},{"name":"主题升级","slug":"主题升级","permalink":"https://silenwang.github.io/tags/%E4%B8%BB%E9%A2%98%E5%8D%87%E7%BA%A7/"},{"name":"volantis","slug":"volantis","permalink":"https://silenwang.github.io/tags/volantis/"},{"name":"npm","slug":"npm","permalink":"https://silenwang.github.io/tags/npm/"},{"name":"配置文件","slug":"配置文件","permalink":"https://silenwang.github.io/tags/%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"},{"name":"微卫星不稳定性","slug":"微卫星不稳定性","permalink":"https://silenwang.github.io/tags/%E5%BE%AE%E5%8D%AB%E6%98%9F%E4%B8%8D%E7%A8%B3%E5%AE%9A%E6%80%A7/"},{"name":"MSI","slug":"MSI","permalink":"https://silenwang.github.io/tags/MSI/"},{"name":"mSINGS","slug":"mSINGS","permalink":"https://silenwang.github.io/tags/mSINGS/"},{"name":"samtools","slug":"samtools","permalink":"https://silenwang.github.io/tags/samtools/"},{"name":"Web开发","slug":"Web开发","permalink":"https://silenwang.github.io/tags/Web%E5%BC%80%E5%8F%91/"},{"name":"后端","slug":"后端","permalink":"https://silenwang.github.io/tags/%E5%90%8E%E7%AB%AF/"},{"name":"API","slug":"API","permalink":"https://silenwang.github.io/tags/API/"},{"name":"github","slug":"github","permalink":"https://silenwang.github.io/tags/github/"},{"name":"博客部署","slug":"博客部署","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E9%83%A8%E7%BD%B2/"},{"name":"gitee","slug":"gitee","permalink":"https://silenwang.github.io/tags/gitee/"},{"name":"git代理","slug":"git代理","permalink":"https://silenwang.github.io/tags/git%E4%BB%A3%E7%90%86/"},{"name":"缺失值处理","slug":"缺失值处理","permalink":"https://silenwang.github.io/tags/%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86/"},{"name":"怪物猎人","slug":"怪物猎人","permalink":"https://silenwang.github.io/tags/%E6%80%AA%E7%89%A9%E7%8C%8E%E4%BA%BA/"},{"name":"冰原DLC","slug":"冰原DLC","permalink":"https://silenwang.github.io/tags/%E5%86%B0%E5%8E%9FDLC/"},{"name":"Monster Hunter World","slug":"Monster-Hunter-World","permalink":"https://silenwang.github.io/tags/Monster-Hunter-World/"},{"name":"Iceborne","slug":"Iceborne","permalink":"https://silenwang.github.io/tags/Iceborne/"},{"name":"adb","slug":"adb","permalink":"https://silenwang.github.io/tags/adb/"},{"name":"APK破解","slug":"APK破解","permalink":"https://silenwang.github.io/tags/APK%E7%A0%B4%E8%A7%A3/"},{"name":"反编译","slug":"反编译","permalink":"https://silenwang.github.io/tags/%E5%8F%8D%E7%BC%96%E8%AF%91/"},{"name":"Android逆向","slug":"Android逆向","permalink":"https://silenwang.github.io/tags/Android%E9%80%86%E5%90%91/"},{"name":"Apktools","slug":"Apktools","permalink":"https://silenwang.github.io/tags/Apktools/"},{"name":"enjarify","slug":"enjarify","permalink":"https://silenwang.github.io/tags/enjarify/"},{"name":"jd-gui","slug":"jd-gui","permalink":"https://silenwang.github.io/tags/jd-gui/"},{"name":"uber-apk-signer","slug":"uber-apk-signer","permalink":"https://silenwang.github.io/tags/uber-apk-signer/"},{"name":"ggplot","slug":"ggplot","permalink":"https://silenwang.github.io/tags/ggplot/"},{"name":"箱线图","slug":"箱线图","permalink":"https://silenwang.github.io/tags/%E7%AE%B1%E7%BA%BF%E5%9B%BE/"},{"name":"离群值处理","slug":"离群值处理","permalink":"https://silenwang.github.io/tags/%E7%A6%BB%E7%BE%A4%E5%80%BC%E5%A4%84%E7%90%86/"},{"name":"requests","slug":"requests","permalink":"https://silenwang.github.io/tags/requests/"},{"name":"selenium","slug":"selenium","permalink":"https://silenwang.github.io/tags/selenium/"},{"name":"网页抓取","slug":"网页抓取","permalink":"https://silenwang.github.io/tags/%E7%BD%91%E9%A1%B5%E6%8A%93%E5%8F%96/"},{"name":"Web自动化","slug":"Web自动化","permalink":"https://silenwang.github.io/tags/Web%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"魔术方法","slug":"魔术方法","permalink":"https://silenwang.github.io/tags/%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/"},{"name":"特殊方法","slug":"特殊方法","permalink":"https://silenwang.github.io/tags/%E7%89%B9%E6%AE%8A%E6%96%B9%E6%B3%95/"},{"name":"并行计算","slug":"并行计算","permalink":"https://silenwang.github.io/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"},{"name":"工作流管理","slug":"工作流管理","permalink":"https://silenwang.github.io/tags/%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%AE%A1%E7%90%86/"},{"name":"checkpoint","slug":"checkpoint","permalink":"https://silenwang.github.io/tags/checkpoint/"},{"name":"DAG","slug":"DAG","permalink":"https://silenwang.github.io/tags/DAG/"},{"name":"上下文管理器","slug":"上下文管理器","permalink":"https://silenwang.github.io/tags/%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8/"},{"name":"with语句","slug":"with语句","permalink":"https://silenwang.github.io/tags/with%E8%AF%AD%E5%8F%A5/"},{"name":"__enter__","slug":"enter","permalink":"https://silenwang.github.io/tags/enter/"},{"name":"__exit__","slug":"exit","permalink":"https://silenwang.github.io/tags/exit/"},{"name":"怪物猎人世界","slug":"怪物猎人世界","permalink":"https://silenwang.github.io/tags/%E6%80%AA%E7%89%A9%E7%8C%8E%E4%BA%BA%E4%B8%96%E7%95%8C/"},{"name":"历战爆鳞龙","slug":"历战爆鳞龙","permalink":"https://silenwang.github.io/tags/%E5%8E%86%E6%88%98%E7%88%86%E9%B3%9E%E9%BE%99/"},{"name":"狩猎","slug":"狩猎","permalink":"https://silenwang.github.io/tags/%E7%8B%A9%E7%8C%8E/"},{"name":"Bazelgeuse","slug":"Bazelgeuse","permalink":"https://silenwang.github.io/tags/Bazelgeuse/"},{"name":"樱火龙","slug":"樱火龙","permalink":"https://silenwang.github.io/tags/%E6%A8%B1%E7%81%AB%E9%BE%99/"},{"name":"视频录制","slug":"视频录制","permalink":"https://silenwang.github.io/tags/%E8%A7%86%E9%A2%91%E5%BD%95%E5%88%B6/"},{"name":"looking-glass","slug":"looking-glass","permalink":"https://silenwang.github.io/tags/looking-glass/"},{"name":"scream","slug":"scream","permalink":"https://silenwang.github.io/tags/scream/"},{"name":"OBS","slug":"OBS","permalink":"https://silenwang.github.io/tags/OBS/"},{"name":"推理游戏","slug":"推理游戏","permalink":"https://silenwang.github.io/tags/%E6%8E%A8%E7%90%86%E6%B8%B8%E6%88%8F/"},{"name":"game-review","slug":"game-review","permalink":"https://silenwang.github.io/tags/game-review/"},{"name":"ace-attorney","slug":"ace-attorney","permalink":"https://silenwang.github.io/tags/ace-attorney/"},{"name":"the-great-ace-attorney","slug":"the-great-ace-attorney","permalink":"https://silenwang.github.io/tags/the-great-ace-attorney/"},{"name":"Dockerfile","slug":"Dockerfile","permalink":"https://silenwang.github.io/tags/Dockerfile/"},{"name":"容器化","slug":"容器化","permalink":"https://silenwang.github.io/tags/%E5%AE%B9%E5%99%A8%E5%8C%96/"},{"name":"镜像构建","slug":"镜像构建","permalink":"https://silenwang.github.io/tags/%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA/"},{"name":"systemd","slug":"systemd","permalink":"https://silenwang.github.io/tags/systemd/"},{"name":"服务管理","slug":"服务管理","permalink":"https://silenwang.github.io/tags/%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86/"},{"name":"自定义服务","slug":"自定义服务","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1/"},{"name":"service","slug":"service","permalink":"https://silenwang.github.io/tags/service/"},{"name":"Manjaro","slug":"Manjaro","permalink":"https://silenwang.github.io/tags/Manjaro/"},{"name":"显卡直通","slug":"显卡直通","permalink":"https://silenwang.github.io/tags/%E6%98%BE%E5%8D%A1%E7%9B%B4%E9%80%9A/"},{"name":"KVM","slug":"KVM","permalink":"https://silenwang.github.io/tags/KVM/"},{"name":"QEMU","slug":"QEMU","permalink":"https://silenwang.github.io/tags/QEMU/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://silenwang.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"AMD显卡","slug":"AMD显卡","permalink":"https://silenwang.github.io/tags/AMD%E6%98%BE%E5%8D%A1/"},{"name":"Windows虚拟机","slug":"Windows虚拟机","permalink":"https://silenwang.github.io/tags/Windows%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"音频设备","slug":"音频设备","permalink":"https://silenwang.github.io/tags/%E9%9F%B3%E9%A2%91%E8%AE%BE%E5%A4%87/"},{"name":"台式机","slug":"台式机","permalink":"https://silenwang.github.io/tags/%E5%8F%B0%E5%BC%8F%E6%9C%BA/"},{"name":"硬件配置","slug":"硬件配置","permalink":"https://silenwang.github.io/tags/%E7%A1%AC%E4%BB%B6%E9%85%8D%E7%BD%AE/"},{"name":"装机经验","slug":"装机经验","permalink":"https://silenwang.github.io/tags/%E8%A3%85%E6%9C%BA%E7%BB%8F%E9%AA%8C/"},{"name":"AMD处理器","slug":"AMD处理器","permalink":"https://silenwang.github.io/tags/AMD%E5%A4%84%E7%90%86%E5%99%A8/"},{"name":"二手配件","slug":"二手配件","permalink":"https://silenwang.github.io/tags/%E4%BA%8C%E6%89%8B%E9%85%8D%E4%BB%B6/"},{"name":"PC-building","slug":"PC-building","permalink":"https://silenwang.github.io/tags/PC-building/"},{"name":"hardware-configuration","slug":"hardware-configuration","permalink":"https://silenwang.github.io/tags/hardware-configuration/"},{"name":"AMD-Ryzen","slug":"AMD-Ryzen","permalink":"https://silenwang.github.io/tags/AMD-Ryzen/"},{"name":"used-parts","slug":"used-parts","permalink":"https://silenwang.github.io/tags/used-parts/"},{"name":"文件同步","slug":"文件同步","permalink":"https://silenwang.github.io/tags/%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5/"},{"name":"跨设备同步","slug":"跨设备同步","permalink":"https://silenwang.github.io/tags/%E8%B7%A8%E8%AE%BE%E5%A4%87%E5%90%8C%E6%AD%A5/"},{"name":"Syncthing","slug":"Syncthing","permalink":"https://silenwang.github.io/tags/Syncthing/"},{"name":"开源工具","slug":"开源工具","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E6%BA%90%E5%B7%A5%E5%85%B7/"},{"name":"Git钩子","slug":"Git钩子","permalink":"https://silenwang.github.io/tags/Git%E9%92%A9%E5%AD%90/"},{"name":"自动化部署","slug":"自动化部署","permalink":"https://silenwang.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2/"},{"name":"博客管理","slug":"博客管理","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E7%AE%A1%E7%90%86/"},{"name":"githook","slug":"githook","permalink":"https://silenwang.github.io/tags/githook/"},{"name":"post-commit","slug":"post-commit","permalink":"https://silenwang.github.io/tags/post-commit/"},{"name":"装饰器","slug":"装饰器","permalink":"https://silenwang.github.io/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/"},{"name":"函数式编程","slug":"函数式编程","permalink":"https://silenwang.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"name":"闭包","slug":"闭包","permalink":"https://silenwang.github.io/tags/%E9%97%AD%E5%8C%85/"},{"name":"博客迁移","slug":"博客迁移","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB/"},{"name":"内容搬运","slug":"内容搬运","permalink":"https://silenwang.github.io/tags/%E5%86%85%E5%AE%B9%E6%90%AC%E8%BF%90/"},{"name":"个人博客","slug":"个人博客","permalink":"https://silenwang.github.io/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"黑历史","slug":"黑历史","permalink":"https://silenwang.github.io/tags/%E9%BB%91%E5%8E%86%E5%8F%B2/"},{"name":"网易LOFTER","slug":"网易LOFTER","permalink":"https://silenwang.github.io/tags/%E7%BD%91%E6%98%93LOFTER/"},{"name":"蚂蚁笔记","slug":"蚂蚁笔记","permalink":"https://silenwang.github.io/tags/%E8%9A%82%E8%9A%81%E7%AC%94%E8%AE%B0/"},{"name":"gitpage","slug":"gitpage","permalink":"https://silenwang.github.io/tags/gitpage/"},{"name":"NGS","slug":"NGS","permalink":"https://silenwang.github.io/tags/NGS/"},{"name":"质控工具","slug":"质控工具","permalink":"https://silenwang.github.io/tags/%E8%B4%A8%E6%8E%A7%E5%B7%A5%E5%85%B7/"},{"name":"数据分析","slug":"数据分析","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"MultiQC","slug":"MultiQC","permalink":"https://silenwang.github.io/tags/MultiQC/"},{"name":"fastqc","slug":"fastqc","permalink":"https://silenwang.github.io/tags/fastqc/"},{"name":"逻辑回归","slug":"逻辑回归","permalink":"https://silenwang.github.io/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"},{"name":"机器学习","slug":"机器学习","permalink":"https://silenwang.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"logistic regression","slug":"logistic-regression","permalink":"https://silenwang.github.io/tags/logistic-regression/"},{"name":"machine learning","slug":"machine-learning","permalink":"https://silenwang.github.io/tags/machine-learning/"},{"name":"算法比较","slug":"算法比较","permalink":"https://silenwang.github.io/tags/%E7%AE%97%E6%B3%95%E6%AF%94%E8%BE%83/"},{"name":"决策树","slug":"决策树","permalink":"https://silenwang.github.io/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"name":"随机森林","slug":"随机森林","permalink":"https://silenwang.github.io/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"},{"name":"支持向量机","slug":"支持向量机","permalink":"https://silenwang.github.io/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"},{"name":"KNN","slug":"KNN","permalink":"https://silenwang.github.io/tags/KNN/"},{"name":"朴素贝叶斯","slug":"朴素贝叶斯","permalink":"https://silenwang.github.io/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"},{"name":"K均值","slug":"K均值","permalink":"https://silenwang.github.io/tags/K%E5%9D%87%E5%80%BC/"},{"name":"Adaboost","slug":"Adaboost","permalink":"https://silenwang.github.io/tags/Adaboost/"},{"name":"神经网络","slug":"神经网络","permalink":"https://silenwang.github.io/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"algorithm comparison","slug":"algorithm-comparison","permalink":"https://silenwang.github.io/tags/algorithm-comparison/"},{"name":"decision tree","slug":"decision-tree","permalink":"https://silenwang.github.io/tags/decision-tree/"},{"name":"random forest","slug":"random-forest","permalink":"https://silenwang.github.io/tags/random-forest/"},{"name":"SVM","slug":"SVM","permalink":"https://silenwang.github.io/tags/SVM/"},{"name":"naive bayes","slug":"naive-bayes","permalink":"https://silenwang.github.io/tags/naive-bayes/"},{"name":"K-means","slug":"K-means","permalink":"https://silenwang.github.io/tags/K-means/"},{"name":"文档工具","slug":"文档工具","permalink":"https://silenwang.github.io/tags/%E6%96%87%E6%A1%A3%E5%B7%A5%E5%85%B7/"},{"name":"技术写作","slug":"技术写作","permalink":"https://silenwang.github.io/tags/%E6%8A%80%E6%9C%AF%E5%86%99%E4%BD%9C/"},{"name":"gitbook","slug":"gitbook","permalink":"https://silenwang.github.io/tags/gitbook/"},{"name":"mkdocs","slug":"mkdocs","permalink":"https://silenwang.github.io/tags/mkdocs/"},{"name":"markdown","slug":"markdown","permalink":"https://silenwang.github.io/tags/markdown/"},{"name":"Bash","slug":"Bash","permalink":"https://silenwang.github.io/tags/Bash/"},{"name":"命令行","slug":"命令行","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"name":"输入输出重定向","slug":"输入输出重定向","permalink":"https://silenwang.github.io/tags/%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91/"},{"name":"进程替换","slug":"进程替换","permalink":"https://silenwang.github.io/tags/%E8%BF%9B%E7%A8%8B%E6%9B%BF%E6%8D%A2/"},{"name":"性能优化","slug":"性能优化","permalink":"https://silenwang.github.io/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"Go语言","slug":"Go语言","permalink":"https://silenwang.github.io/tags/Go%E8%AF%AD%E8%A8%80/"},{"name":"编程语言对比","slug":"编程语言对比","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%AF%B9%E6%AF%94/"},{"name":"项目重构","slug":"项目重构","permalink":"https://silenwang.github.io/tags/%E9%A1%B9%E7%9B%AE%E9%87%8D%E6%9E%84/"},{"name":"programming","slug":"programming","permalink":"https://silenwang.github.io/tags/programming/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://silenwang.github.io/tags/HTTPS/"},{"name":"SSL证书","slug":"SSL证书","permalink":"https://silenwang.github.io/tags/SSL%E8%AF%81%E4%B9%A6/"},{"name":"Caddy","slug":"Caddy","permalink":"https://silenwang.github.io/tags/Caddy/"},{"name":"反向代理","slug":"反向代理","permalink":"https://silenwang.github.io/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"},{"name":"域名","slug":"域名","permalink":"https://silenwang.github.io/tags/%E5%9F%9F%E5%90%8D/"},{"name":"Graphviz","slug":"Graphviz","permalink":"https://silenwang.github.io/tags/Graphviz/"},{"name":"可视化工具","slug":"可视化工具","permalink":"https://silenwang.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%B7%A5%E5%85%B7/"},{"name":"软件开发","slug":"软件开发","permalink":"https://silenwang.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://silenwang.github.io/tags/Ubuntu/"},{"name":"Deepin","slug":"Deepin","permalink":"https://silenwang.github.io/tags/Deepin/"},{"name":"中文支持","slug":"中文支持","permalink":"https://silenwang.github.io/tags/%E4%B8%AD%E6%96%87%E6%94%AF%E6%8C%81/"},{"name":"软件生态","slug":"软件生态","permalink":"https://silenwang.github.io/tags/%E8%BD%AF%E4%BB%B6%E7%94%9F%E6%80%81/"},{"name":"Windows对比","slug":"Windows对比","permalink":"https://silenwang.github.io/tags/Windows%E5%AF%B9%E6%AF%94/"},{"name":"MEGA","slug":"MEGA","permalink":"https://silenwang.github.io/tags/MEGA/"},{"name":"WPS","slug":"WPS","permalink":"https://silenwang.github.io/tags/WPS/"},{"name":"Ugene","slug":"Ugene","permalink":"https://silenwang.github.io/tags/Ugene/"},{"name":"bash","slug":"bash","permalink":"https://silenwang.github.io/tags/bash/"},{"name":"GNU Parallel","slug":"GNU-Parallel","permalink":"https://silenwang.github.io/tags/GNU-Parallel/"},{"name":"结构变异","slug":"结构变异","permalink":"https://silenwang.github.io/tags/%E7%BB%93%E6%9E%84%E5%8F%98%E5%BC%82/"},{"name":"算法解读","slug":"算法解读","permalink":"https://silenwang.github.io/tags/%E7%AE%97%E6%B3%95%E8%A7%A3%E8%AF%BB/"},{"name":"NGS数据分析","slug":"NGS数据分析","permalink":"https://silenwang.github.io/tags/NGS%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"},{"name":"RP证据","slug":"RP证据","permalink":"https://silenwang.github.io/tags/RP%E8%AF%81%E6%8D%AE/"},{"name":"SR证据","slug":"SR证据","permalink":"https://silenwang.github.io/tags/SR%E8%AF%81%E6%8D%AE/"},{"name":"Bioinformatics","slug":"Bioinformatics","permalink":"https://silenwang.github.io/tags/Bioinformatics/"},{"name":"SV检测","slug":"SV检测","permalink":"https://silenwang.github.io/tags/SV%E6%A3%80%E6%B5%8B/"},{"name":"拷贝数变异","slug":"拷贝数变异","permalink":"https://silenwang.github.io/tags/%E6%8B%B7%E8%B4%9D%E6%95%B0%E5%8F%98%E5%BC%82/"},{"name":"基因融合","slug":"基因融合","permalink":"https://silenwang.github.io/tags/%E5%9F%BA%E5%9B%A0%E8%9E%8D%E5%90%88/"},{"name":"NGS检测","slug":"NGS检测","permalink":"https://silenwang.github.io/tags/NGS%E6%A3%80%E6%B5%8B/"},{"name":"Split-Reads","slug":"Split-Reads","permalink":"https://silenwang.github.io/tags/Split-Reads/"},{"name":"Discordant Read Pairs","slug":"Discordant-Read-Pairs","permalink":"https://silenwang.github.io/tags/Discordant-Read-Pairs/"},{"name":"Read Depth","slug":"Read-Depth","permalink":"https://silenwang.github.io/tags/Read-Depth/"},{"name":"de novo Assembly","slug":"de-novo-Assembly","permalink":"https://silenwang.github.io/tags/de-novo-Assembly/"},{"name":"统计分析","slug":"统计分析","permalink":"https://silenwang.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90/"},{"name":"博客搭建","slug":"博客搭建","permalink":"https://silenwang.github.io/tags/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"},{"name":"主题更换","slug":"主题更换","permalink":"https://silenwang.github.io/tags/%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%8D%A2/"},{"name":"Node.js","slug":"Node-js","permalink":"https://silenwang.github.io/tags/Node-js/"},{"name":"git备份","slug":"git备份","permalink":"https://silenwang.github.io/tags/git%E5%A4%87%E4%BB%BD/"},{"name":"资源控制","slug":"资源控制","permalink":"https://silenwang.github.io/tags/%E8%B5%84%E6%BA%90%E6%8E%A7%E5%88%B6/"},{"name":"任务分组","slug":"任务分组","permalink":"https://silenwang.github.io/tags/%E4%BB%BB%E5%8A%A1%E5%88%86%E7%BB%84/"},{"name":"resource management","slug":"resource-management","permalink":"https://silenwang.github.io/tags/resource-management/"},{"name":"task grouping","slug":"task-grouping","permalink":"https://silenwang.github.io/tags/task-grouping/"},{"name":"迭代器","slug":"迭代器","permalink":"https://silenwang.github.io/tags/%E8%BF%AD%E4%BB%A3%E5%99%A8/"},{"name":"生成器","slug":"生成器","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E6%88%90%E5%99%A8/"},{"name":"itertools","slug":"itertools","permalink":"https://silenwang.github.io/tags/itertools/"},{"name":"groupby","slug":"groupby","permalink":"https://silenwang.github.io/tags/groupby/"},{"name":"tee","slug":"tee","permalink":"https://silenwang.github.io/tags/tee/"},{"name":"chain","slug":"chain","permalink":"https://silenwang.github.io/tags/chain/"},{"name":"多进程","slug":"多进程","permalink":"https://silenwang.github.io/tags/%E5%A4%9A%E8%BF%9B%E7%A8%8B/"},{"name":"multiprocessing","slug":"multiprocessing","permalink":"https://silenwang.github.io/tags/multiprocessing/"},{"name":"Pool","slug":"Pool","permalink":"https://silenwang.github.io/tags/Pool/"},{"name":"parallel","slug":"parallel","permalink":"https://silenwang.github.io/tags/parallel/"},{"name":"performance","slug":"performance","permalink":"https://silenwang.github.io/tags/performance/"},{"name":"SSH跳转","slug":"SSH跳转","permalink":"https://silenwang.github.io/tags/SSH%E8%B7%B3%E8%BD%AC/"},{"name":"TeamViewer","slug":"TeamViewer","permalink":"https://silenwang.github.io/tags/TeamViewer/"},{"name":"VirtualBox","slug":"VirtualBox","permalink":"https://silenwang.github.io/tags/VirtualBox/"},{"name":"Cygwin","slug":"Cygwin","permalink":"https://silenwang.github.io/tags/Cygwin/"},{"name":"Windows","slug":"Windows","permalink":"https://silenwang.github.io/tags/Windows/"},{"name":"流程控制","slug":"流程控制","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/"},{"name":"任务管理","slug":"任务管理","permalink":"https://silenwang.github.io/tags/%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86/"},{"name":"脚本生成","slug":"脚本生成","permalink":"https://silenwang.github.io/tags/%E8%84%9A%E6%9C%AC%E7%94%9F%E6%88%90/"},{"name":"流程管理","slug":"流程管理","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E7%A8%8B%E7%AE%A1%E7%90%86/"},{"name":"plugin","slug":"plugin","permalink":"https://silenwang.github.io/tags/plugin/"},{"name":"命令行解析","slug":"命令行解析","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%A7%A3%E6%9E%90/"},{"name":"argparse","slug":"argparse","permalink":"https://silenwang.github.io/tags/argparse/"},{"name":"子命令","slug":"子命令","permalink":"https://silenwang.github.io/tags/%E5%AD%90%E5%91%BD%E4%BB%A4/"},{"name":"编程","slug":"编程","permalink":"https://silenwang.github.io/tags/%E7%BC%96%E7%A8%8B/"},{"name":"命令行程序","slug":"命令行程序","permalink":"https://silenwang.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%A8%8B%E5%BA%8F/"},{"name":"scSeq","slug":"scSeq","permalink":"https://silenwang.github.io/tags/scSeq/"},{"name":"sscClust","slug":"sscClust","permalink":"https://silenwang.github.io/tags/sscClust/"},{"name":"安装问题","slug":"安装问题","permalink":"https://silenwang.github.io/tags/%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/"},{"name":"软件安装","slug":"软件安装","permalink":"https://silenwang.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"},{"name":"单细胞测序","slug":"单细胞测序","permalink":"https://silenwang.github.io/tags/%E5%8D%95%E7%BB%86%E8%83%9E%E6%B5%8B%E5%BA%8F/"},{"name":"转录组","slug":"转录组","permalink":"https://silenwang.github.io/tags/%E8%BD%AC%E5%BD%95%E7%BB%84/"},{"name":"10X Genomics","slug":"10X-Genomics","permalink":"https://silenwang.github.io/tags/10X-Genomics/"},{"name":"cellranger","slug":"cellranger","permalink":"https://silenwang.github.io/tags/cellranger/"},{"name":"single cell","slug":"single-cell","permalink":"https://silenwang.github.io/tags/single-cell/"},{"name":"RNA-seq","slug":"RNA-seq","permalink":"https://silenwang.github.io/tags/RNA-seq/"},{"name":"scRNA-seq","slug":"scRNA-seq","permalink":"https://silenwang.github.io/tags/scRNA-seq/"},{"name":"分支管理","slug":"分支管理","permalink":"https://silenwang.github.io/tags/%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86/"},{"name":"远程仓库","slug":"远程仓库","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E4%BB%93%E5%BA%93/"},{"name":"代码同步","slug":"代码同步","permalink":"https://silenwang.github.io/tags/%E4%BB%A3%E7%A0%81%E5%90%8C%E6%AD%A5/"},{"name":"Gogs部署","slug":"Gogs部署","permalink":"https://silenwang.github.io/tags/Gogs%E9%83%A8%E7%BD%B2/"},{"name":"Git托管","slug":"Git托管","permalink":"https://silenwang.github.io/tags/Git%E6%89%98%E7%AE%A1/"},{"name":"SSH配置","slug":"SSH配置","permalink":"https://silenwang.github.io/tags/SSH%E9%85%8D%E7%BD%AE/"},{"name":"VPS","slug":"VPS","permalink":"https://silenwang.github.io/tags/VPS/"},{"name":"gogs","slug":"gogs","permalink":"https://silenwang.github.io/tags/gogs/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://silenwang.github.io/tags/docker-compose/"},{"name":"Wine","slug":"Wine","permalink":"https://silenwang.github.io/tags/Wine/"},{"name":"Proton","slug":"Proton","permalink":"https://silenwang.github.io/tags/Proton/"},{"name":"仙剑4","slug":"仙剑4","permalink":"https://silenwang.github.io/tags/%E4%BB%99%E5%89%914/"},{"name":"数据操作","slug":"数据操作","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"},{"name":"数据框","slug":"数据框","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E6%A1%86/"},{"name":"数据结构","slug":"数据结构","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"dataframe","slug":"dataframe","permalink":"https://silenwang.github.io/tags/dataframe/"},{"name":"data structure","slug":"data-structure","permalink":"https://silenwang.github.io/tags/data-structure/"},{"name":"data manipulation","slug":"data-manipulation","permalink":"https://silenwang.github.io/tags/data-manipulation/"},{"name":"代码高亮","slug":"代码高亮","permalink":"https://silenwang.github.io/tags/%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE/"},{"name":"包安装","slug":"包安装","permalink":"https://silenwang.github.io/tags/%E5%8C%85%E5%AE%89%E8%A3%85/"},{"name":"timeout","slug":"timeout","permalink":"https://silenwang.github.io/tags/timeout/"},{"name":"curl","slug":"curl","permalink":"https://silenwang.github.io/tags/curl/"},{"name":"手动安装","slug":"手动安装","permalink":"https://silenwang.github.io/tags/%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85/"},{"name":"镜像配置","slug":"镜像配置","permalink":"https://silenwang.github.io/tags/%E9%95%9C%E5%83%8F%E9%85%8D%E7%BD%AE/"},{"name":"CentOS","slug":"CentOS","permalink":"https://silenwang.github.io/tags/CentOS/"},{"name":"SGE","slug":"SGE","permalink":"https://silenwang.github.io/tags/SGE/"},{"name":"网格引擎","slug":"网格引擎","permalink":"https://silenwang.github.io/tags/%E7%BD%91%E6%A0%BC%E5%BC%95%E6%93%8E/"},{"name":"qsub","slug":"qsub","permalink":"https://silenwang.github.io/tags/qsub/"},{"name":"qlogin","slug":"qlogin","permalink":"https://silenwang.github.io/tags/qlogin/"},{"name":"集群计算","slug":"集群计算","permalink":"https://silenwang.github.io/tags/%E9%9B%86%E7%BE%A4%E8%AE%A1%E7%AE%97/"},{"name":"sge","slug":"sge","permalink":"https://silenwang.github.io/tags/sge/"},{"name":"远程访问","slug":"远程访问","permalink":"https://silenwang.github.io/tags/%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/"},{"name":"jupyter notebook","slug":"jupyter-notebook","permalink":"https://silenwang.github.io/tags/jupyter-notebook/"},{"name":"截图","slug":"截图","permalink":"https://silenwang.github.io/tags/%E6%88%AA%E5%9B%BE/"},{"name":"minicap","slug":"minicap","permalink":"https://silenwang.github.io/tags/minicap/"},{"name":"数据库","slug":"数据库","permalink":"https://silenwang.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQLite3","slug":"SQLite3","permalink":"https://silenwang.github.io/tags/SQLite3/"},{"name":"sqlite","slug":"sqlite","permalink":"https://silenwang.github.io/tags/sqlite/"},{"name":"桌面环境","slug":"桌面环境","permalink":"https://silenwang.github.io/tags/%E6%A1%8C%E9%9D%A2%E7%8E%AF%E5%A2%83/"},{"name":"DDE","slug":"DDE","permalink":"https://silenwang.github.io/tags/DDE/"},{"name":"触控板手势","slug":"触控板手势","permalink":"https://silenwang.github.io/tags/%E8%A7%A6%E6%8E%A7%E6%9D%BF%E6%89%8B%E5%8A%BF/"},{"name":"工作变动","slug":"工作变动","permalink":"https://silenwang.github.io/tags/%E5%B7%A5%E4%BD%9C%E5%8F%98%E5%8A%A8/"},{"name":"生物信息工程师","slug":"生物信息工程师","permalink":"https://silenwang.github.io/tags/%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%B7%A5%E7%A8%8B%E5%B8%88/"},{"name":"诺禾致源","slug":"诺禾致源","permalink":"https://silenwang.github.io/tags/%E8%AF%BA%E7%A6%BE%E8%87%B4%E6%BA%90/"},{"name":"瑞普基因","slug":"瑞普基因","permalink":"https://silenwang.github.io/tags/%E7%91%9E%E6%99%AE%E5%9F%BA%E5%9B%A0/"},{"name":"职业发展","slug":"职业发展","permalink":"https://silenwang.github.io/tags/%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95/"},{"name":"job-change","slug":"job-change","permalink":"https://silenwang.github.io/tags/job-change/"},{"name":"bioinformatics-engineer","slug":"bioinformatics-engineer","permalink":"https://silenwang.github.io/tags/bioinformatics-engineer/"},{"name":"career-development","slug":"career-development","permalink":"https://silenwang.github.io/tags/career-development/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://silenwang.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"正则语法","slug":"正则语法","permalink":"https://silenwang.github.io/tags/%E6%AD%A3%E5%88%99%E8%AF%AD%E6%B3%95/"},{"name":"正则符号","slug":"正则符号","permalink":"https://silenwang.github.io/tags/%E6%AD%A3%E5%88%99%E7%AC%A6%E5%8F%B7/"},{"name":"正则匹配","slug":"正则匹配","permalink":"https://silenwang.github.io/tags/%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D/"},{"name":"regex","slug":"regex","permalink":"https://silenwang.github.io/tags/regex/"},{"name":"系统迁移","slug":"系统迁移","permalink":"https://silenwang.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%BF%81%E7%A7%BB/"},{"name":"Mint","slug":"Mint","permalink":"https://silenwang.github.io/tags/Mint/"},{"name":"双系统","slug":"双系统","permalink":"https://silenwang.github.io/tags/%E5%8F%8C%E7%B3%BB%E7%BB%9F/"},{"name":"显卡驱动","slug":"显卡驱动","permalink":"https://silenwang.github.io/tags/%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8/"},{"name":"输入法","slug":"输入法","permalink":"https://silenwang.github.io/tags/%E8%BE%93%E5%85%A5%E6%B3%95/"},{"name":"linuxmint","slug":"linuxmint","permalink":"https://silenwang.github.io/tags/linuxmint/"},{"name":"ubuntu","slug":"ubuntu","permalink":"https://silenwang.github.io/tags/ubuntu/"},{"name":"desktop-environment","slug":"desktop-environment","permalink":"https://silenwang.github.io/tags/desktop-environment/"},{"name":"dual-boot","slug":"dual-boot","permalink":"https://silenwang.github.io/tags/dual-boot/"},{"name":"graphics-driver","slug":"graphics-driver","permalink":"https://silenwang.github.io/tags/graphics-driver/"},{"name":"input-method","slug":"input-method","permalink":"https://silenwang.github.io/tags/input-method/"},{"name":"地图绘制","slug":"地图绘制","permalink":"https://silenwang.github.io/tags/%E5%9C%B0%E5%9B%BE%E7%BB%98%E5%88%B6/"},{"name":"流行病学数据","slug":"流行病学数据","permalink":"https://silenwang.github.io/tags/%E6%B5%81%E8%A1%8C%E7%97%85%E5%AD%A6%E6%95%B0%E6%8D%AE/"},{"name":"热图","slug":"热图","permalink":"https://silenwang.github.io/tags/%E7%83%AD%E5%9B%BE/"},{"name":"shapefile","slug":"shapefile","permalink":"https://silenwang.github.io/tags/shapefile/"},{"name":"统计绘图","slug":"统计绘图","permalink":"https://silenwang.github.io/tags/%E7%BB%9F%E8%AE%A1%E7%BB%98%E5%9B%BE/"},{"name":"培训笔记","slug":"培训笔记","permalink":"https://silenwang.github.io/tags/%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/"},{"name":"data analysis","slug":"data-analysis","permalink":"https://silenwang.github.io/tags/data-analysis/"},{"name":"statistics","slug":"statistics","permalink":"https://silenwang.github.io/tags/statistics/"},{"name":"宿命传说2","slug":"宿命传说2","permalink":"https://silenwang.github.io/tags/%E5%AE%BF%E5%91%BD%E4%BC%A0%E8%AF%B42/"},{"name":"童年回忆","slug":"童年回忆","permalink":"https://silenwang.github.io/tags/%E7%AB%A5%E5%B9%B4%E5%9B%9E%E5%BF%86/"},{"name":"游戏系统","slug":"游戏系统","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E7%B3%BB%E7%BB%9F/"},{"name":"Tales of Destiny 2","slug":"Tales-of-Destiny-2","permalink":"https://silenwang.github.io/tags/Tales-of-Destiny-2/"},{"name":"音游","slug":"音游","permalink":"https://silenwang.github.io/tags/%E9%9F%B3%E6%B8%B8/"},{"name":"音乐游戏","slug":"音乐游戏","permalink":"https://silenwang.github.io/tags/%E9%9F%B3%E4%B9%90%E6%B8%B8%E6%88%8F/"},{"name":"节奏游戏","slug":"节奏游戏","permalink":"https://silenwang.github.io/tags/%E8%8A%82%E5%A5%8F%E6%B8%B8%E6%88%8F/"},{"name":"游戏体验","slug":"游戏体验","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E4%BD%93%E9%AA%8C/"},{"name":"游戏推荐","slug":"游戏推荐","permalink":"https://silenwang.github.io/tags/%E6%B8%B8%E6%88%8F%E6%8E%A8%E8%8D%90/"},{"name":"独立游戏","slug":"独立游戏","permalink":"https://silenwang.github.io/tags/%E7%8B%AC%E7%AB%8B%E6%B8%B8%E6%88%8F/"},{"name":"哔哩哔哩","slug":"哔哩哔哩","permalink":"https://silenwang.github.io/tags/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9/"},{"name":"小电视","slug":"小电视","permalink":"https://silenwang.github.io/tags/%E5%B0%8F%E7%94%B5%E8%A7%86/"},{"name":"鼠标垫","slug":"鼠标垫","permalink":"https://silenwang.github.io/tags/%E9%BC%A0%E6%A0%87%E5%9E%AB/"},{"name":"周边","slug":"周边","permalink":"https://silenwang.github.io/tags/%E5%91%A8%E8%BE%B9/"},{"name":"开箱","slug":"开箱","permalink":"https://silenwang.github.io/tags/%E5%BC%80%E7%AE%B1/"},{"name":"Bilibili","slug":"Bilibili","permalink":"https://silenwang.github.io/tags/Bilibili/"},{"name":"Mousepad","slug":"Mousepad","permalink":"https://silenwang.github.io/tags/Mousepad/"},{"name":"策略游戏","slug":"策略游戏","permalink":"https://silenwang.github.io/tags/%E7%AD%96%E7%95%A5%E6%B8%B8%E6%88%8F/"},{"name":"晶体管","slug":"晶体管","permalink":"https://silenwang.github.io/tags/%E6%99%B6%E4%BD%93%E7%AE%A1/"},{"name":"ARPG","slug":"ARPG","permalink":"https://silenwang.github.io/tags/ARPG/"},{"name":"Transistor","slug":"Transistor","permalink":"https://silenwang.github.io/tags/Transistor/"},{"name":"Supergiant-Games","slug":"Supergiant-Games","permalink":"https://silenwang.github.io/tags/Supergiant-Games/"}]}